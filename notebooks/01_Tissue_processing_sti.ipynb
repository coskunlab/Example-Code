{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c99c1b3d-0f5e-47ce-b458-20513c01ac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.io\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import trange, tqdm, tqdm_notebook\n",
    "from joblib import Parallel, delayed\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef58cb63-e03a-4012-af0b-a986bc715ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d884fb1-2834-4d35-829f-78326a0f924a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = (Path().cwd().parents[0] / 'data').absolute()\n",
    "data_processed = data_dir / 'processed'\n",
    "data_raw = r'Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\PLA\\HCC827-derived OCT mouse'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9160ae1-466b-48f6-89ea-c1879563be21",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Get info\n",
    "\n",
    "Here we look at stitched images in all z stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df037664-aec1-47b9-a4e2-6396f0bdcda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "markers_map = {\n",
    "    'cycle1': {\n",
    "        1: 'Hoeschst', \n",
    "        4: 'TEAD1 & YAP1'\n",
    "    },\n",
    "    'cycle2': {\n",
    "        1: 'Hoeschst', \n",
    "        4: 'CylinE & CDK2'\n",
    "    },\n",
    "    'cycle3': {\n",
    "        1: 'Hoeschst', \n",
    "        4: 'P-ERK & c-MYC'\n",
    "    },\n",
    "    'cycle4': {\n",
    "        1: 'Hoeschst', \n",
    "        4: 'p-AKT & mTOR'\n",
    "    },\n",
    "    'cycle5': {\n",
    "        1: 'Hoeschst', \n",
    "        4: 'Mcl-1 & BAK'\n",
    "    },\n",
    "    'cycle6': {\n",
    "        1: 'Hoeschst',\n",
    "        2: 'p-EGFR',\n",
    "        3: 'Tom20',\n",
    "        4: 'Ki67'\n",
    "    },\n",
    "    'cycle7': {\n",
    "        1: 'Hoeschst',\n",
    "        2: 'Pan-cytokeratin',\n",
    "        3: 'Golph4',\n",
    "        4: 'Bim'\n",
    "    },\n",
    "    'cycle8': {\n",
    "        1: 'Hoeschst',\n",
    "        2: 'Concanavalin A',\n",
    "        3: 'Phalloidin',\n",
    "        4: 'WGA'\n",
    "    },\n",
    "    'cycle9': {\n",
    "        1: 'Hoeschst',\n",
    "        2: 'NBD-C6'\n",
    "    },\n",
    "}\n",
    "\n",
    "def get_info(data_raw, marker_dict = markers_map):\n",
    "    timepoints = []\n",
    "    resolutions = []\n",
    "    fovs = []\n",
    "    cycles = []\n",
    "    afs = []\n",
    "    channels = []\n",
    "    markers = []\n",
    "    paths = [] \n",
    "    \n",
    "    # Loop through image folder\n",
    "    for (dirpath, dirnames, filenames) in os.walk(data_raw):\n",
    "        for name in sorted(filenames):\n",
    "            if \"tif\" in name and \"stitched\" in name and 'defocused' not in dirpath:\n",
    "                # Get information from image name\n",
    "                d_split = dirpath.split('\\\\')\n",
    "                n_split = name.split('_')\n",
    "                                \n",
    "                time = d_split[-1].split('_')[0]\n",
    "                fov = d_split[-1].split('_')[-1]\n",
    "                if 'FW' not in fov:\n",
    "                    res = '20X'\n",
    "                    fov = ''\n",
    "                else:\n",
    "                    res = '40X'\n",
    "                    \n",
    "                cycle = d_split[-1].split('_')[1]\n",
    "                if 'Af' in cycle:\n",
    "                    after_bleach = True\n",
    "                    cycle = cycle[2:]\n",
    "                else:\n",
    "                    after_bleach = False\n",
    "                \n",
    "                ch = int(n_split[1][0])\n",
    "                try:\n",
    "                    marker = marker_dict[cycle][ch]\n",
    "                except:\n",
    "                    continue \n",
    "                    \n",
    "                timepoints.append(time)\n",
    "                resolutions.append(res)\n",
    "                fovs.append(fov)\n",
    "                cycles.append(cycle)\n",
    "                afs.append(after_bleach)\n",
    "                channels.append(ch)\n",
    "                markers.append(marker)\n",
    "                paths.append(os.path.join(dirpath, name))\n",
    "                \n",
    "    info = {\n",
    "            \"Timepoint\": timepoints,\n",
    "            \"Resolution\": resolutions,\n",
    "            \"FOV\": fovs,\n",
    "            \"Cycle\": cycles,\n",
    "            \"AfBleach\": afs,\n",
    "            \"Channels\": channels,\n",
    "            \"Markers\": markers,\n",
    "            \"Path\": paths\n",
    "        }\n",
    "\n",
    "    df = pd.DataFrame(info)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d4961d8-06ba-4a99-bfc3-1d3d298f6f74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder is already there\n",
      "Loaded df\n"
     ]
    }
   ],
   "source": [
    "df_meta_path = data_dir / 'OCT mouse' / 'Whole' / 'metadata' / 'info.csv'\n",
    "\n",
    "try:\n",
    "    df_meta_path.parent.mkdir(parents=True, exist_ok=False)\n",
    "except FileExistsError:\n",
    "    print(\"Folder is already there\")\n",
    "\n",
    "df_exist = df_meta_path.is_file()\n",
    "\n",
    "if not df_exist:\n",
    "    print('Created df')\n",
    "    df = get_info(data_raw)\n",
    "    df.to_csv(df_meta_path, index=False)\n",
    "else:\n",
    "    print('Loaded df')\n",
    "    df = pd.read_csv(df_meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2edb940-322f-4e80-9be2-80f1581fb805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timepoint</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>FOV</th>\n",
       "      <th>Cycle</th>\n",
       "      <th>AfBleach</th>\n",
       "      <th>Channels</th>\n",
       "      <th>Markers</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1M</td>\n",
       "      <td>20X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cycle1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>Hoeschst</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1M</td>\n",
       "      <td>20X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cycle1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>TEAD1 &amp; YAP1</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1M</td>\n",
       "      <td>40X</td>\n",
       "      <td>FW1</td>\n",
       "      <td>cycle1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>Hoeschst</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1M</td>\n",
       "      <td>40X</td>\n",
       "      <td>FW1</td>\n",
       "      <td>cycle1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>TEAD1 &amp; YAP1</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1M</td>\n",
       "      <td>40X</td>\n",
       "      <td>FW2</td>\n",
       "      <td>cycle1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>Hoeschst</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>1W</td>\n",
       "      <td>40X</td>\n",
       "      <td>FW1</td>\n",
       "      <td>cycle9</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>NBD-C6</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>1W</td>\n",
       "      <td>40X</td>\n",
       "      <td>FW2</td>\n",
       "      <td>cycle9</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Hoeschst</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>1W</td>\n",
       "      <td>40X</td>\n",
       "      <td>FW2</td>\n",
       "      <td>cycle9</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>NBD-C6</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>1W</td>\n",
       "      <td>40X</td>\n",
       "      <td>FW3</td>\n",
       "      <td>cycle9</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Hoeschst</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>1W</td>\n",
       "      <td>40X</td>\n",
       "      <td>FW3</td>\n",
       "      <td>cycle9</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>NBD-C6</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>335 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Timepoint Resolution  FOV   Cycle  AfBleach  Channels       Markers  \\\n",
       "0          1M        20X  NaN  cycle1      True         1      Hoeschst   \n",
       "1          1M        20X  NaN  cycle1      True         4  TEAD1 & YAP1   \n",
       "2          1M        40X  FW1  cycle1      True         1      Hoeschst   \n",
       "3          1M        40X  FW1  cycle1      True         4  TEAD1 & YAP1   \n",
       "4          1M        40X  FW2  cycle1      True         1      Hoeschst   \n",
       "..        ...        ...  ...     ...       ...       ...           ...   \n",
       "330        1W        40X  FW1  cycle9     False         2        NBD-C6   \n",
       "331        1W        40X  FW2  cycle9     False         1      Hoeschst   \n",
       "332        1W        40X  FW2  cycle9     False         2        NBD-C6   \n",
       "333        1W        40X  FW3  cycle9     False         1      Hoeschst   \n",
       "334        1W        40X  FW3  cycle9     False         2        NBD-C6   \n",
       "\n",
       "                                                  Path  \n",
       "0    Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  \n",
       "1    Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  \n",
       "2    Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  \n",
       "3    Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  \n",
       "4    Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  \n",
       "..                                                 ...  \n",
       "330  Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  \n",
       "331  Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  \n",
       "332  Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  \n",
       "333  Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  \n",
       "334  Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  \n",
       "\n",
       "[335 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905b8f46-a73a-4361-a2cc-c82a67e8fc49",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Convert data to hdf5 \n",
    "\n",
    "Convert stitch data to hdf5 format.\n",
    "\n",
    "For each file we are organized into the format of: File -> Cycle \n",
    "\n",
    "Attributes are Channels and Markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98432863-1927-4f8a-a5e3-e7cd7157c838",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "def save_hdf5(\n",
    "    path: str, name: str, data: np.ndarray, attr_dict=None, mode: str = \"a\"\n",
    ") -> None:\n",
    "    # Read h5 file\n",
    "    hf = h5py.File(path, mode)\n",
    "    # Create z_stack_dataset\n",
    "    if hf.get(name) is None:\n",
    "        data_shape = data.shape\n",
    "        data_type = data.dtype\n",
    "        chunk_shape = (1,) + data_shape[1:]\n",
    "        max_shape = (data_shape[0],) + data_shape[1:]\n",
    "        dset = hf.create_dataset(\n",
    "            name,\n",
    "            shape=data_shape,\n",
    "            maxshape=max_shape,\n",
    "            chunks=True,\n",
    "            dtype=data_type,\n",
    "            compression=\"gzip\",\n",
    "        )\n",
    "        dset[:] = data\n",
    "        if attr_dict is not None:\n",
    "            for attr_key, attr_val in attr_dict.items():\n",
    "                dset.attrs[attr_key] = attr_val\n",
    "    else:\n",
    "        print(f\"Dataset {name} exists\")\n",
    "\n",
    "    hf.close()\n",
    "\n",
    "def read_img(path):\n",
    "    return skimage.io.imread(path, as_gray=True)\n",
    "\n",
    "def joblib_loop(task, pics):\n",
    "    return Parallel(n_jobs=20)(delayed(task)(i) for i in pics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f9174b8-c053-4bbe-9388-051cbdaff27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder is already there\n",
      "Folder is already there\n",
      "Loaded df\n"
     ]
    }
   ],
   "source": [
    "df_imgs_path = data_dir / 'OCT mouse' / 'Whole' / 'metadata' / 'imgs.csv'\n",
    "\n",
    "try:\n",
    "    df_imgs_path.parent.mkdir(parents=True, exist_ok=False)\n",
    "except FileExistsError:\n",
    "    print(\"Folder is already there\")\n",
    "    \n",
    "temp_path = data_dir / 'OCT mouse' / 'Whole' / 'hdf5' / 'raw'\n",
    "temp_path.mkdir(parents=True, exist_ok=False)\n",
    "\n",
    "df_exist = df_imgs_path.is_file()\n",
    "\n",
    "if not df_exist:\n",
    "    print('Created df')\n",
    "    df_z = df[df.Resolution == '40X']\n",
    "    group = df_z.groupby(['Timepoint', 'Resolution', 'FOV', 'AfBleach'])\n",
    "    rows = []\n",
    "\n",
    "    for name, df_group in tqdm(group, total=len(group)):\n",
    "        file_name = '_'.join(np.array(name).astype(str)) + '.hdf5'\n",
    "        file_path = temp_path / file_name\n",
    "        rows.append(list(name)+[file_path])\n",
    "        \n",
    "        group_cycle = df_group.groupby('Cycle')\n",
    "        for cycle, df_cycle in group_cycle:\n",
    "            channels = df_cycle.Channels.to_list()\n",
    "            markers = df_cycle.Markers.to_list()\n",
    "            paths = df_cycle.Path.to_numpy()\n",
    "    \n",
    "            imgs = joblib_loop(read_img, paths)\n",
    "            imgs = np.array(imgs)\n",
    "            info = {\"Channels\": channels, \"Markers\": markers}\n",
    "            \n",
    "            # hdf5 as Channel -> Z mapping\n",
    "            save_hdf5(file_path, cycle, imgs, info)\n",
    "    df_imgs = pd.DataFrame(rows, columns=['Timepoint', 'Resolution', 'FOV', 'AfBleach', 'Path'])        \n",
    "    df_imgs.to_csv(df_imgs_path, index=False)\n",
    "else:\n",
    "    print('Loaded df')\n",
    "    df_imgs = pd.read_csv(df_imgs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b6a094f-597d-404e-a548-311247bfc2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imgs = df_imgs[df_imgs.AfBleach == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feda2db-f51f-4a8e-8c1a-35c42177a6e0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Save tifffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ed949a4-05f7-413d-84d5-bdc38f6055b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile as tiff\n",
    "save_path = data_dir / 'OCT mouse' / 'Whole' / 'imgs' / 'raw'\n",
    "\n",
    "def make_imgs_same_dim(imgs):\n",
    "    # Get max dimensions\n",
    "    shapes = np.array([img.shape[1:] for img in imgs])\n",
    "    min_x, min_y = shapes.min(axis=0)\n",
    "        \n",
    "    return [img[:, :min_x, :min_y] for img in imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea9374f4-297e-4a29-a1c1-42c50e586f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "group = df_imgs.groupby(['Timepoint', 'FOV'])\n",
    "for name, df_group in group:\n",
    "    path = df_group.iloc[0].Path\n",
    "             \n",
    "    # Read images\n",
    "    cycles = []\n",
    "    imgs_all = []\n",
    "    channels = []\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        for k in tqdm(f.keys(), total=len(f.keys()), leave=False):\n",
    "            cycle = k.split('_')[0]\n",
    "            channel = f[k].attrs['Channels']\n",
    "\n",
    "            imgs = f[k][:]\n",
    "            cycles.append(cycle)\n",
    "            channels.append(channel)\n",
    "            imgs_all.append(imgs)\n",
    "    \n",
    "    imgs_same_shape = make_imgs_same_dim(imgs_all)\n",
    "    \n",
    "    for i, imgs in enumerate(imgs_same_shape):\n",
    "        temp_path = save_path / '_'.join(np.array(name).astype(str))\n",
    "        temp_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        file_name = f'001_{cycles[i]}.tif'\n",
    "        file_path = temp_path / file_name\n",
    "\n",
    "        # Write image\n",
    "        tiff.imwrite(file_path, imgs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b22be07-69be-40f2-93c6-b53ee73beacd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95f93366-8459-417f-be10-30d8f627e7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ashlar import fileseries, thumbnail,reg\n",
    "import matplotlib.pyplot as plt\n",
    "from ashlar.scripts.ashlar import process_axis_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e07370b9-b4e0-4682-bfe6-3c51d006850b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: 'Y:\\\\coskun-lab\\\\Thomas\\\\15_PLA\\\\data\\\\OCT mouse\\\\Whole\\\\imgs\\\\registered'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m imgs_dir \u001b[38;5;241m=\u001b[39m data_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOCT mouse\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhole\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimgs\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m save_dir \u001b[38;5;241m=\u001b[39m data_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOCT mouse\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhole\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimgs\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregistered\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m imgs_dir_list \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(imgs_dir)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dir_path \u001b[38;5;129;01min\u001b[39;00m tqdm(imgs_dir_list):\n\u001b[0;32m     10\u001b[0m     \n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# Create reader for each cycle\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\PLA\\lib\\pathlib.py:1323\u001b[0m, in \u001b[0;36mPath.mkdir\u001b[1;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;124;03mCreate a new directory at this given path.\u001b[39;00m\n\u001b[0;32m   1321\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1323\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[0;32m   1325\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parents \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m:\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: 'Y:\\\\coskun-lab\\\\Thomas\\\\15_PLA\\\\data\\\\OCT mouse\\\\Whole\\\\imgs\\\\registered'"
     ]
    }
   ],
   "source": [
    "# Loop all images\n",
    "imgs_dir = data_dir / 'OCT mouse' / 'Whole' / 'imgs' / 'raw'\n",
    "save_dir = data_dir / 'OCT mouse' / 'Whole' / 'imgs' / 'registered'\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "imgs_dir_list = os.listdir(imgs_dir)\n",
    "\n",
    "for dir_path in tqdm(imgs_dir_list):\n",
    "    \n",
    "    # Create reader for each cycle\n",
    "    readers = []\n",
    "    for i in range(1, 10):\n",
    "        reader = fileseries.FileSeriesReader(\n",
    "            str(imgs_dir / dir_path),\n",
    "            pattern='{series}_cycle'+f'{i}.tif',\n",
    "            overlap=0.29,\n",
    "            width=1,\n",
    "            height=1,\n",
    "            layout='snake',\n",
    "            direction='horizontal',\n",
    "            pixel_size=0.18872, \n",
    "        )\n",
    "        readers.append(reader)\n",
    "    reader_1 = readers[0]\n",
    "    \n",
    "    # Run stitching\n",
    "    aligner0 = reg.EdgeAligner(reader_1, channel=0, filter_sigma=2, verbose=False,)\n",
    "    aligner0.run()\n",
    "    \n",
    "    # Generate merge image for 1 cycle\n",
    "    # Parramter\n",
    "    mosaic_args = {}\n",
    "    mosaic_args['verbose'] = False\n",
    "\n",
    "    mosaic = reg.Mosaic(\n",
    "            aligner0,aligner0.mosaic_shape,**mosaic_args\n",
    "        )\n",
    "    writer_class = reg.TiffListWriter\n",
    "    writer = writer_class(\n",
    "            [mosaic], str(save_dir / (dir_path + '_cycle1_ch{channel}.ome.tif'))\n",
    "    )\n",
    "    writer.run()\n",
    "    \n",
    "    # Loop through rest of cycles\n",
    "    aligners = list()\n",
    "    aligners.append(aligner0)\n",
    "\n",
    "    for j in range(1, 9):\n",
    "        aligners.append(\n",
    "            reg.LayerAligner(readers[j], aligners[0], channel=0, filter_sigma=2, verbose=False)\n",
    "        )\n",
    "        aligners[j].run()\n",
    "        mosaic = reg.Mosaic(\n",
    "            aligners[j], aligners[0].mosaic_shape,**mosaic_args\n",
    "        )\n",
    "        writer = writer_class(\n",
    "                [mosaic], str(save_dir / (dir_path +'_cycle'+str(j+1)+'_ch{channel}.ome.tif'))\n",
    "        )\n",
    "        writer.run()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e202d0-6eca-46c2-be79-c100d76104bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4cb2a5a-72af-4c7f-aafa-a9c187491b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "markers_map = {\n",
    "    'cycle1': {\n",
    "        'ch0': 'Hoeschst', \n",
    "        'ch1': 'TEAD1 & YAP1'\n",
    "    },\n",
    "    'cycle2': {\n",
    "        'ch0': 'Hoeschst', \n",
    "        'ch1': 'CylinE & CDK2'\n",
    "    },\n",
    "    'cycle3': {\n",
    "        'ch0': 'Hoeschst', \n",
    "        'ch1': 'P-ERK & c-MYC'\n",
    "    },\n",
    "    'cycle4': {\n",
    "        'ch0': 'Hoeschst', \n",
    "        'ch1': 'p-AKT & mTOR'\n",
    "    },\n",
    "    'cycle5': {\n",
    "        'ch0': 'Hoeschst', \n",
    "        'ch1': 'Mcl-1 & BAK'\n",
    "    },\n",
    "    'cycle6': {\n",
    "        'ch0': 'Hoeschst',\n",
    "        'ch1': 'p-EGFR',\n",
    "        'ch2': 'Tom20',\n",
    "        'ch3': 'Ki67'\n",
    "    },\n",
    "    'cycle7': {\n",
    "        'ch0': 'Hoeschst',\n",
    "        'ch1': 'Pan-cytokeratin',\n",
    "        'ch2': 'Golph4',\n",
    "        'ch3': 'Bim'\n",
    "    },\n",
    "    'cycle8': {\n",
    "        'ch0': 'Hoeschst',\n",
    "        'ch1': 'Concanavalin A',\n",
    "        'ch2': 'Phalloidin',\n",
    "        'ch3': 'WGA'\n",
    "    },\n",
    "    'cycle9': {\n",
    "        'ch0': 'Hoeschst',\n",
    "        'ch1': 'NBD-C6'\n",
    "    },\n",
    "}\n",
    "\n",
    "def get_info(data_raw, marker_dict = markers_map):\n",
    "    timepoints = []\n",
    "    fovs = []\n",
    "    cycles = []\n",
    "    channels = []\n",
    "    markers = []\n",
    "    paths = [] \n",
    "\n",
    "    # Loop through image folder\n",
    "    for (dirpath, dirnames, filenames) in os.walk(data_raw):\n",
    "        for name in sorted(filenames):\n",
    "            if \"tif\" in name:\n",
    "                # Get information from image name\n",
    "                n_split = name.split('_')\n",
    "                                \n",
    "                time=n_split[0]\n",
    "                fov=n_split[1]\n",
    "                cycle=n_split[2]\n",
    "                ch = n_split[3][:3]\n",
    "                try:\n",
    "                    marker = marker_dict[cycle][ch]\n",
    "                except:\n",
    "                    continue \n",
    "                    \n",
    "                timepoints.append(time)\n",
    "                fovs.append(fov)\n",
    "                cycles.append(cycle)\n",
    "                channels.append(ch)\n",
    "                markers.append(marker)\n",
    "                paths.append(os.path.join(dirpath, name))\n",
    "                \n",
    "    info = {\n",
    "            \"Timepoint\": timepoints,\n",
    "            \"FOV\": fovs,\n",
    "            \"Cycle\": cycles,\n",
    "            \"Channels\": channels,\n",
    "            \"Markers\": markers,\n",
    "            \"Path\": paths\n",
    "        }\n",
    "\n",
    "    df = pd.DataFrame(info)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_min(imgs):\n",
    "    shapes = np.array([np.array(img.shape) for img in imgs])\n",
    "    return np.min(shapes, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9d9cdb3-c7d8-4ddf-859c-011aa68a8d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder is already there\n",
      "Loaded df\n"
     ]
    }
   ],
   "source": [
    "data_raw = data_dir / 'OCT mouse' / 'Whole' / 'imgs' / 'registered'\n",
    "df_meta_path = data_dir / 'OCT mouse' / 'Whole' / 'metadata' / 'info_sti.csv'\n",
    "\n",
    "try:\n",
    "    df_meta_path.parent.mkdir(parents=True, exist_ok=False)\n",
    "except FileExistsError:\n",
    "    print(\"Folder is already there\")\n",
    "\n",
    "df_exist = df_meta_path.is_file()\n",
    "\n",
    "if not df_exist:\n",
    "    print('Created df')\n",
    "    df = get_info(data_raw)\n",
    "    df.to_csv(df_meta_path, index=False)\n",
    "else:\n",
    "    print('Loaded df')\n",
    "    df = pd.read_csv(df_meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1b384c26-c1ca-4975-bc09-2d1ae9486e8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder is already there\n",
      "Created df\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "788742b7df1a4ae7b997a4c9e1762a23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_imgs_path = data_dir / 'OCT mouse' / 'Whole' / 'metadata' / 'imgs_reg.csv'\n",
    "\n",
    "temp_path =data_dir /'OCT mouse' / 'Whole' / 'hdf5' / 'registered'\n",
    "try:\n",
    "    temp_path.mkdir(parents=True, exist_ok=False)\n",
    "except FileExistsError:\n",
    "    print(\"Folder is already there\")\n",
    "\n",
    "df_exist = df_imgs_path.is_file()\n",
    "\n",
    "if not df_exist:\n",
    "    print('Created df')\n",
    "    group = df.groupby(['Timepoint','FOV'])\n",
    "    rows = []\n",
    "\n",
    "    for name, df_group in tqdm(group, total=len(group)):\n",
    "        file_name = '_'.join(np.array(name).astype(str)) + '.hdf5'\n",
    "        file_path = temp_path / file_name\n",
    "        rows.append(list(name)+[file_path])\n",
    "        \n",
    "        if file_path.exists():\n",
    "            continue\n",
    "        \n",
    "        channels = df_group.Channels.to_list()\n",
    "        cycles = df_group.Cycle.to_list()\n",
    "        markers = df_group.Markers.to_list()\n",
    "        paths = df_group.Path.to_numpy()\n",
    "            \n",
    "        imgs = joblib_loop(read_img, paths)\n",
    "        min_shape = get_min(imgs)\n",
    "        imgs_cropped = np.array([img[:min_shape[0], :min_shape[1]] for img in imgs])\n",
    "        info = {\"Cycle\": cycles, \"Channel\": channels, \"Marker\": markers}\n",
    "            \n",
    "            # hdf5 as Channel -> Z mapping\n",
    "        save_hdf5(file_path, 'imgs', imgs_cropped, info)\n",
    "    df_imgs = pd.DataFrame(rows, columns=['Timepoint', 'FOV', 'Path'])        \n",
    "    df_imgs.to_csv(df_imgs_path, index=False)\n",
    "else:\n",
    "    print('Loaded df')\n",
    "    df_imgs = pd.read_csv(df_imgs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f37419-ea2a-4181-adf6-d87b11356632",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create segmentation training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cfffa72a-5cb4-48f7-9781-c97ebf1d57c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from skimage import exposure, util\n",
    "\n",
    "def random_crop(image, NEW_IMG_HEIGHT, NEW_IMG_WIDTH):\n",
    "    cropped_image = tf.image.random_crop(\n",
    "      image, size=[3, NEW_IMG_HEIGHT, NEW_IMG_WIDTH])\n",
    "\n",
    "    return cropped_image\n",
    "\n",
    "def contrast_str(img, n_min=0.01, n_max=99.95):\n",
    "    p2, p98 = np.percentile(img, (n_min, n_max))\n",
    "    img_rescale = exposure.rescale_intensity(img, in_range=(p2, p98))\n",
    "    img_rescale = util.img_as_ubyte(img_rescale)\n",
    "    return img_rescale\n",
    "\n",
    "def joblib_loop(task, pics):\n",
    "    return Parallel(n_jobs=20)(delayed(task)(i) for i in pics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8ee2533c-3ba4-43e1-ac2f-1d6b7d045363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cyto_markers = ['p-EGFR', 'Pan-cytokeratin']\n",
    "cyto_markers = ['Pan-cytokeratin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cb42ff34-6ef9-47b2-b459-9a17d2b26712",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder is already there\n",
      "Folder is already there\n"
     ]
    }
   ],
   "source": [
    "whole_seg_path = data_dir / 'OCT mouse' / 'Whole' / 'imgs' / 'segmentation'\n",
    "crop_seg_path =  data_dir / 'OCT mouse' / 'Whole' / 'imgs' / 'training_seg'\n",
    "\n",
    "try:\n",
    "    whole_seg_path .mkdir(parents=True, exist_ok=False)\n",
    "except FileExistsError:\n",
    "    print(\"Folder is already there\")\n",
    "\n",
    "try:\n",
    "    crop_seg_path .mkdir(parents=True, exist_ok=False)\n",
    "except FileExistsError:\n",
    "    print(\"Folder is already there\")\n",
    "\n",
    "N_crop = 10\n",
    "\n",
    "for row in df_imgs.itertuples():\n",
    "    # Read image\n",
    "    path = row.Path\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        imgs = f['imgs'][:]\n",
    "        markers = f['imgs'].attrs['Marker']\n",
    "    \n",
    "    # Get dapi and cyto imgaes\n",
    "    indices = np.isin(markers, cyto_markers)\n",
    "    img_dapi = imgs[0]\n",
    "    imgs_cyto = imgs[indices,:]\n",
    "    \n",
    "    # Contrast streching and combine to rgb image\n",
    "    img_dapi = contrast_str(img_dapi)\n",
    "    # img_cyto = contrast_str(imgs_cyto[0], n_max=99)\n",
    "    # imgs_cyto_scaled = [contrast_str(imgs_cyto[0],n_max=99.5), contrast_str(imgs_cyto[1])]\n",
    "    # img_cyto = np.max(np.array(imgs_cyto_scaled), axis=0)\n",
    "    img_cyto = contrast_str(imgs_cyto[0],n_max=99.)\n",
    "    img_rgb = np.stack([np.zeros(img_dapi.shape),img_cyto, img_dapi], axis=0).astype(np.uint8)\n",
    "    \n",
    "    # Crop and save\n",
    "    file_name = f'{\"_\".join(row[1:3])}.tif'\n",
    "    file_path = whole_seg_path / file_name\n",
    "    tiff.imwrite(file_path, img_rgb)\n",
    "    \n",
    "    for i in range(N_crop):\n",
    "        img_cropped = random_crop(img_rgb, 1000, 1000).numpy().astype(np.uint8)\n",
    "        \n",
    "        file_name = f'{\"_\".join(row[1:3])}_{i}.tif'\n",
    "        file_path = crop_seg_path / file_name\n",
    "        tiff.imwrite(file_path, img_cropped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550c7401-2fdd-4c8f-a6a0-154f9c61549f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PLA]",
   "language": "python",
   "name": "conda-env-PLA-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
