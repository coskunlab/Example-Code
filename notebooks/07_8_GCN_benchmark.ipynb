{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.io\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import re\n",
    "import h5py\n",
    "import napari\n",
    "import tifffile as tiff\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.utils\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_dir = (Path().cwd().parents[0]).absolute()\n",
    "\n",
    "module_path = str(p_dir / \"src\")\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = (Path().cwd().parents[0] / 'data').absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import lightning.pytorch as pl\n",
    "import PPIGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Define condition mapping\n",
    "condition_mapping = {'control': 0, '100nM': 1}\n",
    "\n",
    "# Load graph dataset and process if neede\n",
    "graph_path = data_dir / '13cyc' / 'graphs' \n",
    "\n",
    "dataset = PPIGraph.GraphDataset(graph_path, 'raw', 'pt', condition_mapping=condition_mapping, n_c=2)\n",
    "train_set, val_set, test_set = PPIGraph.train_test_val_split(dataset)\n",
    "\n",
    "# Create Dataloader\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: GraphDataset(2230):\n",
      "======================\n",
      "Number of graphs: 2230\n",
      "Number of features: 13\n",
      "Number of classes: 2\n",
      "Train set: 1071, test set: 892, val set: 267\n",
      "Step 1:\n",
      "=======\n",
      "Number of graphs in the current batch: 32\n",
      "DataBatch(edge_index=[2, 18674], pos=[3257, 2], labels=[3257, 13], nuclei=[3257], weight=[18674], condition=[32], fov=[32], id=[32], train_mask=[3257], test_mask=[3257], edge_attr=[18674, 2], x=[3257, 13], y=[32], edge_weight=[18674], name=[32], batch=[3257], ptr=[33])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print some information on the dataset\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('======================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "print(f'Train set: {len(train_set)}, test set: {len(test_set)}, val set: {len(val_set)}')\n",
    "for step, data in enumerate(train_loader):\n",
    "\n",
    "    print(f'Step {step + 1}:')\n",
    "    print('=======')\n",
    "    print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "    print(data)\n",
    "    print()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-fold on filter dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from lightning.pytorch.accelerators import find_usable_cuda_devices\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from torch.utils.data import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out by maximum number of counts per cell\n",
    "min_count = 20\n",
    "max_count = 70\n",
    "\n",
    "graph_path = data_dir / '13cyc' / 'graphs' \n",
    "dataset = PPIGraph.GraphDataset(graph_path, 'raw', 'pt', condition_mapping=condition_mapping, n_c=2)\n",
    "\n",
    "# Create Dataloader\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Get Indices\n",
    "indices = []\n",
    "for step, data in enumerate(loader):\n",
    "    if len(data.x) <= min_count:\n",
    "        continue \n",
    "    \n",
    "    if (data.x.sum(axis=0) >= max_count).any():\n",
    "        continue\n",
    "    indices.append(step)\n",
    "    \n",
    "# Get subset dataset\n",
    "dataset_filtered = dataset.index_select(indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2117"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = '13PPI'\n",
    "condition = 'Kfold'\n",
    "checkpoint_folder = (Path().cwd().parents[0]).absolute() / 'data' / '9PPI' /\"saved_models\" / dataset_name / f\"Graph_GNNs_{condition}\" \n",
    "project_name = f'PLA_10152023_{dataset_name}_{condition}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "AVAIL_GPUS = [0]\n",
    "\n",
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "NUM_LAYERS = 2\n",
    "HIDDEN_CHANNELS = 16\n",
    "pools = ['mean', 'max', 'sum', 'attention', 'attention2']\n",
    "num_layers = [2,3,4]\n",
    "hiddens = [16, 32, 64]\n",
    "\n",
    "\n",
    "epochs = 80\n",
    "models = ['GCN', 'GraphConv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_0\\mean\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_0\\mean\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_0\\max\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_0\\max\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_0\\sum\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_0\\sum\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_0\\attention\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_0\\attention\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_0\\attention2\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_0\\attention2\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_0\\mean\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_0\\mean\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_0\\max\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_0\\max\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_0\\sum\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_0\\sum\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_0\\attention\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_0\\attention\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_0\\attention2\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_0\\attention2\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_0\\mean\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_0\\mean\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_0\\max\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_0\\max\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_0\\sum\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_0\\sum\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_0\\attention\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_0\\attention\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_0\\attention2\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_0\\attention2\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_0\\mean\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_0\\mean\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_0\\max\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_0\\max\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_0\\sum\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_0\\sum\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_0\\attention\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_0\\attention\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_0\\attention2\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_0\\attention2\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_0\\mean\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_0\\mean\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_0\\max\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_0\\max\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_0\\sum\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_0\\sum\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_0\\attention\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_0\\attention\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_0\\attention2\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_0\\attention2\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_0\\mean\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_0\\mean\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_0\\max\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_0\\max\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_0\\sum\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_0\\sum\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_0\\attention\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_0\\attention\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_0\\attention2\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_0\\attention2\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_0\\mean\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_0\\mean\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_0\\max\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_0\\max\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_0\\sum\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_0\\sum\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_0\\attention\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_0\\attention\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_0\\attention2\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_0\\attention2\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_0\\mean\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_0\\mean\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_0\\max\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_0\\max\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_0\\sum\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_0\\sum\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_0\\attention\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_0\\attention\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_0\\attention2\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_0\\attention2\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_0\\mean\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_0\\mean\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_0\\max\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_0\\max\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_0\\sum\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_0\\sum\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_0\\attention\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_0\\attention\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_0\\attention2\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_0\\attention2\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_1\\mean\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_1\\mean\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_1\\max\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_1\\max\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_1\\sum\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_1\\sum\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_1\\attention\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_1\\attention\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_1\\attention2\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_1\\attention2\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_1\\mean\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_1\\mean\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_1\\max\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_1\\max\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_1\\sum\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_1\\sum\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_1\\attention\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_1\\attention\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_1\\attention2\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_1\\attention2\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_1\\mean\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_1\\mean\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_1\\max\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_1\\max\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_1\\sum\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_1\\sum\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_1\\attention\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_1\\attention\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_1\\attention2\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_1\\attention2\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_1\\mean\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_1\\mean\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_1\\max\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_1\\max\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_1\\sum\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_1\\sum\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_1\\attention\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_1\\attention\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_1\\attention2\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_1\\attention2\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_1\\mean\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_1\\mean\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_1\\max\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_1\\max\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_1\\sum\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_1\\sum\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_1\\attention\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_1\\attention\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_1\\attention2\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_1\\attention2\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_1\\mean\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_1\\mean\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_1\\max\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_1\\max\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_1\\sum\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_1\\sum\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_1\\attention\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_1\\attention\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_1\\attention2\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_1\\attention2\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_1\\mean\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_1\\mean\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_1\\max\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_1\\max\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_1\\sum\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_1\\sum\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_1\\attention\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_1\\attention\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_1\\attention2\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_1\\attention2\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_1\\mean\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_1\\mean\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_1\\max\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_1\\max\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_1\\sum\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_1\\sum\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_1\\attention\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_1\\attention\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_1\\attention2\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_1\\attention2\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_1\\mean\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_1\\mean\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_1\\max\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_1\\max\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_1\\sum\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_1\\sum\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_1\\attention\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_1\\attention\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_1\\attention2\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_1\\attention2\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_2\\mean\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_2\\mean\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_2\\max\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_2\\max\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_2\\sum\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_2\\sum\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_2\\attention\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_2\\attention\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_2\\attention2\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_2\\attention2\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_2\\mean\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_2\\mean\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_2\\max\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_2\\max\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_2\\sum\\GraphLevelGCN\\GraphLevelGCN.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_2\\sum\\GraphLevelGraphConv\\GraphLevelGraphConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_2\\attention\\GraphLevelGCN\\GraphLevelGCN.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mthoomas\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231226_220753-l9s1boou</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/l9s1boou' target=\"_blank\">GraphConv_2_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/l9s1boou' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/l9s1boou</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py:397: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\torch_geometric\\deprecation.py:22: UserWarning: 'nn.glob.GlobalAttention' is deprecated, use 'nn.aggr.AttentionalAggregation' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA RTX A2000 12GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_2\\attention\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 3.0 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "3.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 K     Total params\n",
      "0.014     Total estimated model params size (MB)\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:486: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:438: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\utilities\\data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:438: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dae5f86a4b44261bb8ecb448a65feb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇█▇██▇████▇███▇██▇██</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇▇██▇█▇███▇█████████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇█▇██▇████▇███▇██▇██</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▂▁▁▁▁▁▁▁▂▂▁▁▁▁▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>██▅▇▄▃▆▅▄▄▃▃▂▂▄▂▅▄▃▅▄▆▁▅▄▃▂▃▂▄▂▄▃▃▂▂▃▃▄▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▆▅▆▇▆▇▆▆██▅▇▆▆▆▇▆▆▇▆▇▆█▇▇▆▇▇▆▇▇▆▇▆▇▆█▇</td></tr><tr><td>val_auc</td><td>▁▅▆▆▆▆▇▇▇▇▇█▇▇▇▇▇█▇▇▇▇▇▇█▇▇▇▇▇▇▇████████</td></tr><tr><td>val_f1</td><td>▂▆▅▄▅▅▇▅▄▅▇█▁▆▅▄▅▆▃▄▇▄▅▅█▅▆▅▅▅▆▇▆▄▅▅▆▄▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▃▃▂▂▂▂▂▂▁▃▂▂▂▁▂▂▂▃▂▂▃▂▂▂▂▂▃▂▂▂▃▂▂▁▂▂▂</td></tr><tr><td>val_loss_step</td><td>█▅▄▅▅▂▄▃▃▂▄▃▃▆▄▄▂▄▂▆▇▃▃▇▄▃▆▃▃▅▄▃▂▇▂▂▁▃▆▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87544</td></tr><tr><td>train_auc</td><td>0.93528</td></tr><tr><td>train_f1</td><td>0.87754</td></tr><tr><td>train_loss_epoch</td><td>0.32513</td></tr><tr><td>train_loss_step</td><td>0.22799</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82506</td></tr><tr><td>val_auc</td><td>0.91464</td></tr><tr><td>val_f1</td><td>0.81407</td></tr><tr><td>val_loss_epoch</td><td>0.36187</td></tr><tr><td>val_loss_step</td><td>0.2636</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_2_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/l9s1boou' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/l9s1boou</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231226_220753-l9s1boou\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ef71f6c194a4c24bb125a068c3acc88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666883975, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231226_223233-pjwya3ge</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/pjwya3ge' target=\"_blank\">GCN_2_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/pjwya3ge' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/pjwya3ge</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_2\\attention2\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 1.6 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "3.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.2 K     Total params\n",
      "0.013     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f699e2415654c8b89a8cfd12fa04cbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇███▇▇▇▇▇▇▇██▇█████▇</td></tr><tr><td>train_auc</td><td>▁▆▇▆▇▇▇▇▇▇▇██▇▇▇▇█▇▇█████▇███████▇██████</td></tr><tr><td>train_f1</td><td>▁▅▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇██▇▇▇▇▇▇▇▇██▇██████</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▁▂▂▁▂▁▂▁▂▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>▆▅▅▄▄▄▄▅▃▆▅▅█▄▅▄▄▂▅▅▄▃▆▄▃▄▅▁▄▄▆▄▄▄▄▄▅▃▄▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▅▃▆▇▇▅▆▅▆▁▆▇▆▆▅▄▆▇▄▇▇▆█▅▆▅█▆▆▆▆█▅▅▇▇▆▆</td></tr><tr><td>val_auc</td><td>▁▅▅▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇███▇▇███▇█▇██▇</td></tr><tr><td>val_f1</td><td>▄▄▆▃▇▇▆▆▆▆▆▁▆█▆▆▆▄▆█▇▇▇▇▇▆▇▆█▆▇▆██▅▆▇▇▆▆</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▃▃▂▂▂▂▂▁▂▃▃▂▂▂▂▂▂▄▂▁▂▁▁▁▁▂▁▂▁▂▁▂▂▂▁▂▂</td></tr><tr><td>val_loss_step</td><td>█▅▇▅▄▄▄▂▄▄▁▂█▅▂▃▄▃▂▃▅▄▂▄▂▂▁▃▃▂▃▂▃▃▄▅▃▁▇▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84829</td></tr><tr><td>train_auc</td><td>0.9224</td></tr><tr><td>train_f1</td><td>0.85153</td></tr><tr><td>train_loss_epoch</td><td>0.35649</td></tr><tr><td>train_loss_step</td><td>0.2607</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82742</td></tr><tr><td>val_auc</td><td>0.92336</td></tr><tr><td>val_f1</td><td>0.80217</td></tr><tr><td>val_loss_epoch</td><td>0.34301</td></tr><tr><td>val_loss_step</td><td>0.36091</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/pjwya3ge' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/pjwya3ge</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231226_223233-pjwya3ge\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231226_225710-08m2bepz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/08m2bepz' target=\"_blank\">GraphConv_2_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/08m2bepz' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/08m2bepz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_2\\attention2\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 3.0 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "4.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.6 K     Total params\n",
      "0.019     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "486d9346d7e54c71a8fbb087664b5cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇████▇▇████</td></tr><tr><td>train_auc</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇▇█████▇█████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▇▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇█████▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▃▃▃▃▃▃▃▂▂▃▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▁▂▂▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>██▆▆▅▄▅▄▆▅▆▅▅▆▅▆▅▂▂▄▄▄▃▅▃▃▄▁▄▄▃▃▃▅▄▃▄▃▄▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▇▇█▇▇▇▇▇▇▇▇▆▆▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇████▇█▇</td></tr><tr><td>val_auc</td><td>▁▄▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▆█▇</td></tr><tr><td>val_f1</td><td>▁▅▅▇▅▆▆▇▇▇▇▆▁▅█▇██▇█▆▇▇▆▆▇▆█▇▇▇▇▇▇█▇▇▇█▆</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▂▁▃▂▁▂▂▂▂▃▂▂▂▃▃▁▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▁▄▁▃</td></tr><tr><td>val_loss_step</td><td>█▄▆▃▂▇▄▁▃▃▅▅▅▆▄▅█▆▁▃▄▅▃▄▄▅▃▅▃▄▁▃▃▅▂▇▃▇▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.88253</td></tr><tr><td>train_auc</td><td>0.94344</td></tr><tr><td>train_f1</td><td>0.88583</td></tr><tr><td>train_loss_epoch</td><td>0.30162</td></tr><tr><td>train_loss_step</td><td>0.20502</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83215</td></tr><tr><td>val_auc</td><td>0.91342</td></tr><tr><td>val_f1</td><td>0.80965</td></tr><tr><td>val_loss_epoch</td><td>0.40015</td></tr><tr><td>val_loss_step</td><td>0.40491</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_2_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/08m2bepz' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/08m2bepz</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231226_225710-08m2bepz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a370253615c43a2a2863d1ed7efb699",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231226_232010-zo4ond8k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zo4ond8k' target=\"_blank\">GCN_2_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zo4ond8k' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zo4ond8k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_2\\mean\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 5.2 K \n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "7.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.3 K     Total params\n",
      "0.029     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e9c4d2cf62543268751d16d42b9a7a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇█▇▇█▇█▇█▇███▇███▇█▇█▇██</td></tr><tr><td>train_auc</td><td>▁▇▇▇▇▇▇▇▇█▇▇▇▇▇▇██▇█▇▇█▇█▇███▇▇██▇█▇████</td></tr><tr><td>train_f1</td><td>▁▇▇▇▇▇██▇▇▇███▇▇▇█▇██████▇███▇█████▇████</td></tr><tr><td>train_loss_epoch</td><td>█▃▃▂▂▂▂▂▂▁▂▂▂▂▁▂▂▂▂▂▂▁▂▂▁▂▁▁▁▂▂▁▁▂▁▂▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>▅▄▂▅▅▅▅▁▆▃▃▁▆▂▃▄▁▃▅▅▆▃▄▅▂▃▃▂▂▃▂▃▃▃▂▃▃▃█▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▇▆▅▆▇▇▅▅██▄▅▃▆▇▆▆▆▅▇▇▅▇▆▇█▆▆▅█▆▆▆▆▅▅▄▆▅</td></tr><tr><td>val_auc</td><td>▁▆▇▇▇█▇▇▇▇▇▇▇▇▇█▇▇▆▇██▇▇▇██▇▇▇█▇▇█▇▆▆█▇▆</td></tr><tr><td>val_f1</td><td>▅▅▆▄▆██▆▆▇█▃▇▁▇█▇▅▇▅▇█▇█▇█▇▇▇▆█▇▇▅▇▆▆▃▇▆</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▃▂▂▁▁▁▁▂▂▂▃▁▂▁▂▃▁▁▂▃▂▁▂▂▁▂▂▁▂▁▂▂▃▂▂▂▂</td></tr><tr><td>val_loss_step</td><td>█▄▆▆▆▄▂▁▁▂▄▄▃▄▁▃▂▃▂▃▃▅▆▄▂▄▅▃▄▄▄▅▁▄▄▄▄▄▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85301</td></tr><tr><td>train_auc</td><td>0.92286</td></tr><tr><td>train_f1</td><td>0.85045</td></tr><tr><td>train_loss_epoch</td><td>0.36143</td></tr><tr><td>train_loss_step</td><td>0.42049</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80851</td></tr><tr><td>val_auc</td><td>0.91338</td></tr><tr><td>val_f1</td><td>0.7907</td></tr><tr><td>val_loss_epoch</td><td>0.36223</td></tr><tr><td>val_loss_step</td><td>0.34046</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zo4ond8k' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zo4ond8k</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231226_232010-zo4ond8k\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231226_234325-ltcdq0d2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ltcdq0d2' target=\"_blank\">GraphConv_2_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ltcdq0d2' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ltcdq0d2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_2\\mean\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 10.1 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "12.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "12.3 K    Total params\n",
      "0.049     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▆▆▇▆▆▇▆▆▇▇▇▆▇▆▇▇▇▇▇▇█▇▇█▇▇▇▇█▇█▇██▇▇</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇██▇█▇▇████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▇▆▆▇▆▆▇▇▇▆▇▇▇▇▇▇▇▇█▇▇█▇▇▇▇█▇█▇██▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▃▃▃▃▂▃▃▂▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▁▁▂▂</td></tr><tr><td>train_loss_step</td><td>██▆▇▇▆▇▆█▇▇▅▅▅▆▇▄▅▄▅▆▅▁▅▄█▆▄▆▅▆▃▅▄▅▆▅▆▇▇</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▄▅▁▄▂▄▃▄▇▅▇▆▃▅▅▆▄▆▆▆▅▅▅▆▇▅▂▄▇█▆▆▅▄▅▄▆▆▄▇</td></tr><tr><td>val_auc</td><td>▁▄▅▆▆▆▆▇▇▇▇▇▆▇▇▇▇▇█▇▇▇▇▇█▇▆▇▇▇▆▇▆▆▆▆▆▆▆▆</td></tr><tr><td>val_f1</td><td>▅▅▁▄▂▅▅▅█▆█▇▄▇▆▆▅▇▆▆▅▆▆▇█▇▂▅▇█▆▇▆▆▅▆▆▆▆█</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▄▄▂▂▂▂▂▃▁▃▄▂▂▄▂▃▂▂▃▁▂▂▃▆▃▂▂▆▂▃▂▄▃▅▄▆▂</td></tr><tr><td>val_loss_step</td><td>▅▃▃▆▄▃▂▃▃▂▄▁▃▃▃▄▅▂▅▁▃▄▂▂▂▃▆▄▂▂▇▂▃▁▄▃▆▃█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8778</td></tr><tr><td>train_auc</td><td>0.94629</td></tr><tr><td>train_f1</td><td>0.87888</td></tr><tr><td>train_loss_epoch</td><td>0.30354</td></tr><tr><td>train_loss_step</td><td>0.40052</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.84161</td></tr><tr><td>val_auc</td><td>0.90892</td></tr><tr><td>val_f1</td><td>0.83375</td></tr><tr><td>val_loss_epoch</td><td>0.38111</td></tr><tr><td>val_loss_step</td><td>0.23935</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_2_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ltcdq0d2' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ltcdq0d2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231226_234325-ltcdq0d2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_000711-fouvexbz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fouvexbz' target=\"_blank\">GCN_2_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fouvexbz' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fouvexbz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_2\\max\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 5.2 K \n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "7.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.3 K     Total params\n",
      "0.029     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\torch_geometric\\utils\\scatter.py:93: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(f\"The usage of `scatter(reduce='{reduce}')` \"\n",
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▅▅▅▅▅▆▆▆▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇███▇████</td></tr><tr><td>train_auc</td><td>▁▄▅▅▅▅▅▅▅▆▆▆▅▆▆▆▆▆▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>train_f1</td><td>▁▄▄▅▅▅▅▆▅▆▆▆▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇███▇████</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▄▅▅▅▄▄▄▅▅▄▇▄▄▄▄▂▃▃▃▃▁▃▄▂▂▂▂▂▁▁▂▃▂▂▂▃▄▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█▆██▇██▇█▇▇▇▇█</td></tr><tr><td>val_auc</td><td>▁▂▂▂▂▂▂▃▃▃▃▃▄▃▃▅▅▆▆▇▇▇▇▇▇▇██▇█████▇█████</td></tr><tr><td>val_f1</td><td>▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████▇█████████▇██</td></tr><tr><td>val_loss_epoch</td><td>█▆▆▅▅▅▅▅▅▅▅▅▅▅▄▄▄▃▃▃▃▂▃▂▂▂▂▃▂▂▂▂▁▂▂▃▂▃▂▂</td></tr><tr><td>val_loss_step</td><td>█▇▇▆▇▆▇▆▆▅▆▅▆▆▄▇▅▅▅▄▄▄▆▅▃▄▆▃▅▄▃▃▁▄▂▇▅▆▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83648</td></tr><tr><td>train_auc</td><td>0.9018</td></tr><tr><td>train_f1</td><td>0.83979</td></tr><tr><td>train_loss_epoch</td><td>0.39366</td></tr><tr><td>train_loss_step</td><td>0.33213</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81797</td></tr><tr><td>val_auc</td><td>0.90668</td></tr><tr><td>val_f1</td><td>0.77551</td></tr><tr><td>val_loss_epoch</td><td>0.4125</td></tr><tr><td>val_loss_step</td><td>0.45592</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fouvexbz' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fouvexbz</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_000711-fouvexbz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_002904-kdj0j95c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kdj0j95c' target=\"_blank\">GraphConv_2_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kdj0j95c' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kdj0j95c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_2\\max\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 10.1 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "12.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "12.3 K    Total params\n",
      "0.049     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee074d187a814cb18ea4f0229a0c8354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▆▆▆▆▇▇▇▇▇██▇▇▇▇█▇█▇█▇▇██████████████</td></tr><tr><td>train_auc</td><td>▁▃▄▄▄▅▄▅▅▆▆▆▆▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇██████▇████</td></tr><tr><td>train_f1</td><td>▁▄▆▆▇▇▇▆▇▇▇▇▇██▇█▇▇█▇███▇▇██████████████</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▄▄▄▄▄▄▄▄▃▃▃▃▃▅▂▂▂▃▃▃▁▃▃▄▄▃▃▃▃▂▃▂▂▂▃▃▄▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▇▇▇▇▇▇█▇█▇█████████▇███▇▇██▇███▇█▇▇▇█▇▇</td></tr><tr><td>val_auc</td><td>▁▃▄▅▅▄▅▆▆▆▇▇▇█▇▇▇▇████████▇█▇██▇▇▇▇████▇</td></tr><tr><td>val_f1</td><td>▁▄▆▆▅▆▆▇▇█▇▇████▆█▇█▇███▇▇▇▇▆▇█▇▇▇▇▇▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▆▄▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▃▂▃▂▂▁▃▂▂▂▂▁▃▂</td></tr><tr><td>val_loss_step</td><td>█▇▅▇▇▅▃▇▄▄▅▃▄▅▄▄▅▃▆▄▃▆▃▃▃▂▇▅▃▄▇▁▅▄▆▄▅▃▇▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85714</td></tr><tr><td>train_auc</td><td>0.90629</td></tr><tr><td>train_f1</td><td>0.86028</td></tr><tr><td>train_loss_epoch</td><td>0.34742</td></tr><tr><td>train_loss_step</td><td>0.3741</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.78487</td></tr><tr><td>val_auc</td><td>0.89126</td></tr><tr><td>val_f1</td><td>0.79176</td></tr><tr><td>val_loss_epoch</td><td>0.43431</td></tr><tr><td>val_loss_step</td><td>0.30643</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_2_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kdj0j95c' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kdj0j95c</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_002904-kdj0j95c\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_005115-m7gz2p9v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/m7gz2p9v' target=\"_blank\">GCN_2_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/m7gz2p9v' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/m7gz2p9v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_2\\sum\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 5.2 K \n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "7.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.3 K     Total params\n",
      "0.029     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa5d97f4496489ea91afb3a8635b5ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇█▇▇███▇███▇</td></tr><tr><td>train_auc</td><td>▄▄▅▅▅▆▆▇▇▇▇▇▇█▇▇█▇▇▇▇▆▅▇█▇▇▇▆▄▁▁▆▅▅▅▇███</td></tr><tr><td>train_f1</td><td>▁▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇▇▇▇██▇▇▇██▇███▇</td></tr><tr><td>train_loss_epoch</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▂▁▂▂▂▂▁▂▁▂▁▂▂▂▂▁▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅█▇▇▇▆▆▇▇▇▇▆▇▆▆▇▆▇▆▇█▇▆▇▇▆▇▆▇▆▇▅█▇▆▅▅▅▆</td></tr><tr><td>val_auc</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇██▇█▇▆▇█▆▆█▇▇▇█▇▇▆▇▇█▆▅█▇█▇</td></tr><tr><td>val_f1</td><td>▁▄█▇▇▇▇▆▇▇▇▇▇█▇▇▇▆█▆▇▇█▇█▇▇▇▇▇▇▆▇█▇▇▇▄▇▇</td></tr><tr><td>val_loss_epoch</td><td>▇▅▄▄▅▃▂▁▂▂▃▂▃▂▁▄▁▂▃▄▂▃▄▃▂▂▄▂▄▂▃▅▂▂▂▃▃█▄▂</td></tr><tr><td>val_loss_step</td><td>▅▄▆▆▇▅▄▁▁▁▄▃▄▄▂▅▁▂▃▅▄▅▆▅▃▄█▄▆▅▅█▁▅▄▄▅▇▄▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.82763</td></tr><tr><td>train_auc</td><td>0.88936</td></tr><tr><td>train_f1</td><td>0.82578</td></tr><tr><td>train_loss_epoch</td><td>0.39562</td></tr><tr><td>train_loss_step</td><td>0.51669</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81797</td></tr><tr><td>val_auc</td><td>0.91005</td></tr><tr><td>val_f1</td><td>0.7979</td></tr><tr><td>val_loss_epoch</td><td>0.36562</td></tr><tr><td>val_loss_step</td><td>0.29138</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/m7gz2p9v' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/m7gz2p9v</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_005115-m7gz2p9v\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_011430-7e3yju9j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7e3yju9j' target=\"_blank\">GraphConv_2_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7e3yju9j' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7e3yju9j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_2\\sum\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 10.1 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "12.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "12.3 K    Total params\n",
      "0.049     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇██▇████</td></tr><tr><td>train_auc</td><td>▄▄▂▂▂▁▁▂▃▄▅▆▆▆▅▆▆▆▆▅▅▅▅▆▆▆▆▆▇▇█████▇▇███</td></tr><tr><td>train_f1</td><td>▁▃▅▅▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇█▇▇██▇████</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▁▁▁▂▁▂▂▂▁▁▁▁▂▂▂▂▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▇▅▅▆▆▇▇▅▃▄▅▅▄▅▄▅▆▆▄▂▄▅▅▅▄▄▃▅▆▅▄█▇▅▇▅▇▅</td></tr><tr><td>val_auc</td><td>▂▃▁▄▄▂▂▅▅▆▆▇▇▇▇▇█▇▇▇▆▇▇██▇▇▇██▇█████████</td></tr><tr><td>val_f1</td><td>▁▆▇▆▅▆▆▇▇▆▆▅▆▆▅▅▅▆▆▆▅▃▄▆▆▇▄▄▄▇▆▄▆██▆▇▅▇▆</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▃▂▂▂▂▂▁▂▁▂▂▁▁▁▁▂▁▁▁▂▁▁▁▂▁▂▁▂▁▂▁▁▁▂▂▄▁</td></tr><tr><td>val_loss_step</td><td>▆▃▂▄▃▂▂▂▂▂▃▁▂▂▂▂▂▂▃▁▂▂▂▂▁▂▃▂▂▂▃▁▂▁▂▂▃▂█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86364</td></tr><tr><td>train_auc</td><td>0.88852</td></tr><tr><td>train_f1</td><td>0.86562</td></tr><tr><td>train_loss_epoch</td><td>0.34908</td></tr><tr><td>train_loss_step</td><td>0.46129</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82506</td></tr><tr><td>val_auc</td><td>0.89488</td></tr><tr><td>val_f1</td><td>0.80928</td></tr><tr><td>val_loss_epoch</td><td>0.39052</td></tr><tr><td>val_loss_step</td><td>0.26668</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_2_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7e3yju9j' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7e3yju9j</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_011430-7e3yju9j\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_013659-xk9o7vfj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/xk9o7vfj' target=\"_blank\">GCN_2_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/xk9o7vfj' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/xk9o7vfj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_2\\attention\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 5.2 K \n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "7.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.4 K     Total params\n",
      "0.030     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇▇▆▇▇▅▇██▇▇▇██▇▇█▇███████▇▇▇▇███▇██</td></tr><tr><td>train_auc</td><td>▁▇▇▇▇▇▇▇▇▇▆▇▇█▇▇██████▇██████████▇██████</td></tr><tr><td>train_f1</td><td>▁▇▇▇▇▇▇▇▇▇▆▇██▇▇███▇▇█▇████████▇▇▇███▇██</td></tr><tr><td>train_loss_epoch</td><td>█▃▃▃▃▃▃▃▂▂▄▃▃▂▂▂▂▂▂▂▂▂▃▂▁▂▁▂▁▁▁▁▂▂▂▁▂▂▂▂</td></tr><tr><td>train_loss_step</td><td>▅▄▄▄▄▄▃▃▅▃▄▃█▁▃▂▃▁▃▃▃▂▃▄▂▂▂▂▃▄▄▃▃▃▃▃▄▄▂▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▆▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇█▇▆█▇▇▇▇▇█▇█▆▇▆▆▇█▆▇▇</td></tr><tr><td>val_auc</td><td>▁▆▇▇▇▇▆▇▆▇▆▇▆▇▇▇▇▇▇▇▇████▇████▇▇▇▇██▇█▇█</td></tr><tr><td>val_f1</td><td>▁▄▆▇▇█████▇█▇▇▇▇████▆▆▇▇▇▇▇██▇█▆█▇▅▇█▆▇▆</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▂▂▂▂▂▂▂▃▂▃▁▂▂▂▂▃▃▂▁▂▁▂▂▂▂▁▁▂▁▃▃▂▁▁▂▂▁</td></tr><tr><td>val_loss_step</td><td>█▄▆▄▄▄▃▄▄▄▄▃▇▂▄▄▅▃▇▇▄▃▅▂▃▄▅▅▁▄▄▂▅▄▃▃▃▅▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85714</td></tr><tr><td>train_auc</td><td>0.92343</td></tr><tr><td>train_f1</td><td>0.85798</td></tr><tr><td>train_loss_epoch</td><td>0.36006</td></tr><tr><td>train_loss_step</td><td>0.4256</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81797</td></tr><tr><td>val_auc</td><td>0.92669</td></tr><tr><td>val_f1</td><td>0.78431</td></tr><tr><td>val_loss_epoch</td><td>0.33738</td></tr><tr><td>val_loss_step</td><td>0.31968</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/xk9o7vfj' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/xk9o7vfj</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_013659-xk9o7vfj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_020034-lise3lsy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/lise3lsy' target=\"_blank\">GraphConv_2_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/lise3lsy' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/lise3lsy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_2\\attention\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 10.1 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "12.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "12.3 K    Total params\n",
      "0.049     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▅▆▆▆▆▇▅▆▇▇▆▇▇▇▆▇▇▇█▇██▇▇▇▇███▇██▇▇▇█</td></tr><tr><td>train_auc</td><td>▁▅▅▆▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇███████████▇██████</td></tr><tr><td>train_f1</td><td>▁▄▆▆▅▆▆▆▆▇▆▆▇▇▆▇▇▇▇▇▇▇█▇██▇▇▇▇███▇██▇█▇█</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▄▄▃▃▃▂▄▂▃▂▃▂▂▂▃▂▂▂▁▁▂▁▁▁▂▂▂▁▁▂▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>▇█▇▆█▄▇▆▃▄▆▄▇▃▆▄▃█▄▅▃▅▂▅▅▂▂▁▃▅▄▄▅▃▅▅▄▃▄▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▂▂▆▅▇▇▂▇▅▇▇▆▅▇▆▆▇▇▇▅▇█▇▇▅▇▇▇▇▇▇▇█▇▁█▇▆▆▆</td></tr><tr><td>val_auc</td><td>▁▂▆▅▇▆▆▇▇█▆▇▇█▇█▇▇▇▇▆█▇▇▇▇▇▆▇▇█▇▇▇▆▇▇▇▇▇</td></tr><tr><td>val_f1</td><td>▄▂▇▅▇█▂█▅▇██▆▇▇▇▇█▇▆▇█▇▇▅▇▇▇▇▇█▇█▇▁█▇▆█▇</td></tr><tr><td>val_loss_epoch</td><td>█▇▃▃▂▃▆▄▄▂▂▄▃▂▂▂▃▁▂▄▅▂▂▄▃▃▃▃▃▄▂▃▂▃▅▃▂▄▅▄</td></tr><tr><td>val_loss_step</td><td>▇▇▅▅▄▄▅▆▆▄▃▇▃▄▂▅▆▁▅▆▇▃▂█▄▅▃▄▅▆▂▄▃▄▃▃▃▂▇▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.89906</td></tr><tr><td>train_auc</td><td>0.95593</td></tr><tr><td>train_f1</td><td>0.90052</td></tr><tr><td>train_loss_epoch</td><td>0.27422</td></tr><tr><td>train_loss_step</td><td>0.30895</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82033</td></tr><tr><td>val_auc</td><td>0.90899</td></tr><tr><td>val_f1</td><td>0.80208</td></tr><tr><td>val_loss_epoch</td><td>0.43895</td></tr><tr><td>val_loss_step</td><td>0.52342</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_2_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/lise3lsy' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/lise3lsy</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_020034-lise3lsy\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_022323-3cum6cb9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/3cum6cb9' target=\"_blank\">GCN_2_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/3cum6cb9' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/3cum6cb9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_2\\attention2\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 5.2 K \n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "11.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "11.5 K    Total params\n",
      "0.046     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4d8783b14944b90ac6d7d87b2e30587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇▇▇██▇█▇▇███</td></tr><tr><td>train_auc</td><td>▁▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇█▇▇▇▇██▇████</td></tr><tr><td>train_f1</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇█▇▇█▇▇▇▇████▇▇███</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▄▃▂▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▂▂▂▂▁▂▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>▅▄▄▄▃▄▄▄▃▃▃▂▃▄▂▂▅▂▄▄▅▄█▁▅▂▃▆▃▅▃▄▃▅▇▃▃▄▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▃▁▇▇▇▆▇█▆▆█▇▆▇▇▆▇▇▇▅▇█▇▇▇▇▇▇▇▆▇▇▇▇▇█▇▆▇▆</td></tr><tr><td>val_auc</td><td>▁▅▆▆▅▅▆▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇███▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>val_f1</td><td>▃▁▇▇█▇██▇▇█▇▇██▇█▇▇▆██▇█▇▇█▇█▇█▇█▇██▇▆▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▇▂▃▃▃▂▂▂▂▂▂▃▂▂▂▂▂▂▃▂▂▁▃▂▁▂▂▁▂▂▂▂▂▂▁▂▄▁▂</td></tr><tr><td>val_loss_step</td><td>▆▆▃▄▂▄▂▁▃▂▄▃▅▃▄▄▃▄▃▅▅▄▂▄▃▂▂▄▁▄▃▃▃▃▃▂▄█▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86954</td></tr><tr><td>train_auc</td><td>0.93609</td></tr><tr><td>train_f1</td><td>0.86962</td></tr><tr><td>train_loss_epoch</td><td>0.3281</td></tr><tr><td>train_loss_step</td><td>0.35171</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80851</td></tr><tr><td>val_auc</td><td>0.92522</td></tr><tr><td>val_f1</td><td>0.79699</td></tr><tr><td>val_loss_epoch</td><td>0.36283</td></tr><tr><td>val_loss_step</td><td>0.40953</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/3cum6cb9' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/3cum6cb9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_022323-3cum6cb9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_024612-tdv9di4c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tdv9di4c' target=\"_blank\">GraphConv_2_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tdv9di4c' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tdv9di4c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_2\\attention2\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 10.1 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "16.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "16.5 K    Total params\n",
      "0.066     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇███▇▇▇█████████████</td></tr><tr><td>train_auc</td><td>▁▆▆▆▇▇▇▇▇▇▇▇█▇▇▇███▇▇████▇██████████████</td></tr><tr><td>train_f1</td><td>▁▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇███▇▇▇█████████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▃▃▂▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>▇▅█▅▄▅▆▄▃▃▄▄▅▃▄▄▂▄▄▅▄▃▃▃▂▂▄▁▃▂▃▃▃▂▄▃▅▃▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▇▆▅▆▇▇███▆▇▆▇▆▇▇▅▆█▅▇▆▆▇▇▅▆▆▇▇▆▇▇▅▇▅▇▆▇</td></tr><tr><td>val_auc</td><td>▁▆▇▇▇██████▇████▇▇███▇█████▇▇▇██▇▇██▇▇▇▇</td></tr><tr><td>val_f1</td><td>▁▇▆▅▆█▇███▇▇▆█▇▇▇▆▆█▇▇▆▇█▇▆▇▇▇▇▇▇▇▇▇▅▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▂▄▁▂▂▂▂▃▂▃▂▄▁▂▃▂▂▇▃▃▂▂▃▃▂▃▂▄▂▄▅▃▅▃▂▅▃</td></tr><tr><td>val_loss_step</td><td>▅▃▅▂▅▁▃▃▄▂▃▂▄▂▅▁▂▂▂▃█▃▃▃▂▅▃▂▁▂▆▂▄▆▁█▁▂▇▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8902</td></tr><tr><td>train_auc</td><td>0.95114</td></tr><tr><td>train_f1</td><td>0.89211</td></tr><tr><td>train_loss_epoch</td><td>0.27542</td></tr><tr><td>train_loss_step</td><td>0.21589</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82506</td></tr><tr><td>val_auc</td><td>0.9112</td></tr><tr><td>val_f1</td><td>0.80319</td></tr><tr><td>val_loss_epoch</td><td>0.40319</td></tr><tr><td>val_loss_step</td><td>0.38584</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_2_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tdv9di4c' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tdv9di4c</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_024612-tdv9di4c\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "548a09bf5577423face91dddbc3168eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666883975, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_030900-5t4358s6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5t4358s6' target=\"_blank\">GCN_3_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5t4358s6' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5t4358s6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_2\\mean\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 832   \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "986       Trainable params\n",
      "0         Non-trainable params\n",
      "986       Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cb9f165e0a64a4ebdaedcba67705cde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▇▇▇▇▇▇█████████████████████████████████</td></tr><tr><td>train_auc</td><td>▁▇▇▇▇▇██████████████████████████████████</td></tr><tr><td>train_f1</td><td>▁▇██████████████████████████████████████</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▃▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▂▂▁▂▁▁▁▂▁▂</td></tr><tr><td>train_loss_step</td><td>█▅▃▄▄▄▃▁▃▂▆▂▂▃▃▂▄▂▅▂▃▂▅▃▄▅▂▃▂▂▃▃▄▃▁▁▄▂▃▇</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▆▇█▇▇▇██▇▇▇██▆▇▇█▇█▇▇█████▇▇▇▇▇▇█▇▇▇▇█</td></tr><tr><td>val_auc</td><td>▁▄▆▅▆▇▇▆██▇▇█▇▇▇▇▆▆▇▇▇█▇▇▇██▇▇█▇█▇▇▇▇▇▇▆</td></tr><tr><td>val_f1</td><td>▁▆▇▇█▇▇████████▇█▇███▇████████▇█▇████▇▇█</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▃▂▂▃▁▁▂▂▁▁▂▁▄▂▂▂▂▂▂▁▁▁▂▁▁▁▁▂▂▂▃▂▂▂▃▃▂</td></tr><tr><td>val_loss_step</td><td>█▄▄▅▄▃▄▁▃▂▄▃▃▄▂▆▃▂▄▄▆▃▁▃▂▃▁▂▂▂▂▃▂▄▂▃▃▅▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.82408</td></tr><tr><td>train_auc</td><td>0.8959</td></tr><tr><td>train_f1</td><td>0.82874</td></tr><tr><td>train_loss_epoch</td><td>0.42265</td></tr><tr><td>train_loss_step</td><td>0.60347</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83215</td></tr><tr><td>val_auc</td><td>0.91179</td></tr><tr><td>val_f1</td><td>0.81558</td></tr><tr><td>val_loss_epoch</td><td>0.3904</td></tr><tr><td>val_loss_step</td><td>0.4118</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5t4358s6' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5t4358s6</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_030900-5t4358s6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_033127-24qyspzn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/24qyspzn' target=\"_blank\">GraphConv_3_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/24qyspzn' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/24qyspzn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_2\\mean\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 1.6 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▇▇▇▇█▇▇███▇█▇████████████████████████</td></tr><tr><td>train_auc</td><td>▁▅▇▇▇▇█▇████████████████████████████████</td></tr><tr><td>train_f1</td><td>▁▄▆▇▇▇▇▇▇▇██▇▇█▇████████████████████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▂▃▂▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▁▂▁▂▁▁▁▁▁▁▁▁▂▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▆▅▅▄▄▄▃▄▃▄▄▄▄▃▂▂▄▃▄▂▃▅▃▄▃▄▄▄▄▃▅▃▁▃▄▂▄▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▄▅▆▆▅▆▇▇▇▆▆▆▆▆▇▇▇▇▆▇▇▇██▄▇▇█▇▇▇▇▅▇█▆█▇</td></tr><tr><td>val_auc</td><td>▁▄▆▇▇▇▇▇███▇███████████████▇██████▇█████</td></tr><tr><td>val_f1</td><td>▃▅▁▄▅▆▃▅▇▇▇▅▆▄▇▆▇▇▆▆▇▇▇██▇▃█▇█▇▇▇▇▄▇█▇█▇</td></tr><tr><td>val_loss_epoch</td><td>█▅▄▃▂▁▃▂▁▂▂▃▂▂▁▂▃▂▁▂▁▂▁▂▁▂▂▁▂▂▂▂▂▁▂▂▁▂▁▁</td></tr><tr><td>val_loss_step</td><td>█▆▅▅▅▁▆▅▃▅▄█▆▅▁▄▇▅▃▄▃▅▄▃▃▅▄▃▄▅▄▄▄▃▃▅▃▅▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86009</td></tr><tr><td>train_auc</td><td>0.92682</td></tr><tr><td>train_f1</td><td>0.86148</td></tr><tr><td>train_loss_epoch</td><td>0.34441</td></tr><tr><td>train_loss_step</td><td>0.2505</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.8227</td></tr><tr><td>val_auc</td><td>0.91555</td></tr><tr><td>val_f1</td><td>0.79893</td></tr><tr><td>val_loss_epoch</td><td>0.36011</td></tr><tr><td>val_loss_step</td><td>0.32144</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/24qyspzn' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/24qyspzn</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_033127-24qyspzn\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_035220-rtgtjk1p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/rtgtjk1p' target=\"_blank\">GCN_3_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/rtgtjk1p' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/rtgtjk1p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_2\\max\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 832   \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "986       Trainable params\n",
      "0         Non-trainable params\n",
      "986       Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▂▂▄▅▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇█▇█▇▇█████</td></tr><tr><td>train_auc</td><td>▁▁▁▂▃▄▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇███▇▇█▇██▇████████</td></tr><tr><td>train_f1</td><td>▃▁▄▄▄▄▅▆▆▅▇▇▆▇▇▇▇▇▇▇█▇█▇▇▇▇▇▇▇█▇█▇█████▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▅▄▄▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▂▂▂▁▁▁▁▂▂</td></tr><tr><td>train_loss_step</td><td>█▆▆▆▆▅▄▃▅▃█▄▅▅▃▃▅▄▅▃▄▄▂▄▃▃▂▂▃▃▃▄▃▃▁▂▆▂▃▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▁▁▁▁▁▂▇█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▁▁▁▁</td></tr><tr><td>val_auc</td><td>▁▂▂▆▇▇▇████████████████████████████████▇</td></tr><tr><td>val_f1</td><td>▁▁▁▁▁▁▂▇█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▁▁▁▁</td></tr><tr><td>val_loss_epoch</td><td>███▇▇▆▆▅▄▅▄▄▆▅▅▅▄▄▄▄▄▄▃▄▄▃▃▁▃▃▂▂▄▂▂▁▂▃▂▄</td></tr><tr><td>val_loss_step</td><td>▇▇▇▇▇▆▆▆▄▇▅▅▇▆█▇▅▅▇▆▆▃▄▄▆▄▃▁▆▆▂▂▃▃▄▂▅▆▃█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.71074</td></tr><tr><td>train_auc</td><td>0.75968</td></tr><tr><td>train_f1</td><td>0.72159</td></tr><tr><td>train_loss_epoch</td><td>0.5808</td></tr><tr><td>train_loss_step</td><td>0.61083</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.55556</td></tr><tr><td>val_auc</td><td>0.78354</td></tr><tr><td>val_f1</td><td>0.0</td></tr><tr><td>val_loss_epoch</td><td>0.61739</td></tr><tr><td>val_loss_step</td><td>0.70989</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/rtgtjk1p' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/rtgtjk1p</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_035220-rtgtjk1p\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7442e612cb4447a8ad701eae152c864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333330477276, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_041341-ow58f6uh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ow58f6uh' target=\"_blank\">GraphConv_3_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ow58f6uh' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ow58f6uh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_2\\max\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 1.6 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▂▄▅▄▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇█▇▇██▇▇███</td></tr><tr><td>train_auc</td><td>▃▂▂▂▂▁▁▂▂▃▂▂▂▂▄▄▃▅▅▆▆▆▆▆▇▇▇▆▇▇▇▇▇███▇███</td></tr><tr><td>train_f1</td><td>▁▂▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇█▇▇██</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▄▃▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▂▁▁▂▁▁▁▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▆▆▅▅▅▄▄▄▂▃▆▃▃▃▂▂▃▃▃▃▄▃▃▃▃▃▂▃▂▃▂▁▃▂▃▃▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▅▆▆▆▇██▇▇▇██████▇███████▇██▇██▇█████▇█</td></tr><tr><td>val_auc</td><td>▃▄▃▂▂▁▂▁▂▁▄▄▅▇▆▇▇███████████████████████</td></tr><tr><td>val_f1</td><td>▁▃▃▄▄▄▆█▇▆▆▄▇▇▇▇▇▇▆▆███▇██▇█▇▇▇█▇████▇▇█</td></tr><tr><td>val_loss_epoch</td><td>█▇▆▅▅▅▄▄▄▄▃▃▃▃▂▃▃▃▃▃▃▃▂▂▃▃▂▂▃▃▂▂▂▁▂▂▂▂▂▂</td></tr><tr><td>val_loss_step</td><td>█▇▇▅▅▄▅▅▅▅▄▆▄▅▃▄▆▅▄▄▅▅▄▃▄▄▃▄▅▅▄▄▄▁▃▃▃▄▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.79988</td></tr><tr><td>train_auc</td><td>0.83756</td></tr><tr><td>train_f1</td><td>0.80901</td></tr><tr><td>train_loss_epoch</td><td>0.45201</td></tr><tr><td>train_loss_step</td><td>0.38041</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81087</td></tr><tr><td>val_auc</td><td>0.8701</td></tr><tr><td>val_f1</td><td>0.78947</td></tr><tr><td>val_loss_epoch</td><td>0.51108</td></tr><tr><td>val_loss_step</td><td>0.55052</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ow58f6uh' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ow58f6uh</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_041341-ow58f6uh\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_043429-e38wpzx5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/e38wpzx5' target=\"_blank\">GCN_3_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/e38wpzx5' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/e38wpzx5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_2\\sum\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 832   \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "986       Trainable params\n",
      "0         Non-trainable params\n",
      "986       Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20c40806482047a794a25fa765204359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.013 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.080711…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇██████▇▇██████▇</td></tr><tr><td>train_auc</td><td>▁▃▅▆▇█▇▆▅▅▆▅▆▆▅▃▅▅▅▆▆▅▅█▇▇▆▇▆▆█▇▆▆▇▆▅▆▇▇</td></tr><tr><td>train_f1</td><td>▁▃▅▅▆▇▇▇▇▇▇▇▇█▇▇▇▇███▇██▇██████████████▇</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▂▂▂▂▂▂▂▁▃▃▁▂▂▂▂▁▃▁▂▁▆▂▂▂▂▂▂▁▂▂▂▂▁▁▂▁▁▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▇▇▆▇▇▇▇██▇██▇▇▇██████▇█████████▇██▇███▇</td></tr><tr><td>val_auc</td><td>▁▇▇▇▇█████████▇█▇▆█▇██▇████████▇████████</td></tr><tr><td>val_f1</td><td>▁▇▇▇▇█████▇██▇█▇████████████████▇██████▇</td></tr><tr><td>val_loss_epoch</td><td>█▅▄▄▄▃▂▂▂▂▂▂▂▃▂▄▂▂▂▂▂▂▂▂▂▂▁▂▂▁▂▂▂▂▂▂▂▂▂▃</td></tr><tr><td>val_loss_step</td><td>█▅▅▅▆▄▃▂▄▃▃▃▃▆▃▅▄▄▄▄▆▂▂▃▃▃▁▂▃▂▂▃▂▂▂▄▄▂▂▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.80815</td></tr><tr><td>train_auc</td><td>0.7294</td></tr><tr><td>train_f1</td><td>0.81566</td></tr><tr><td>train_loss_epoch</td><td>0.43947</td></tr><tr><td>train_loss_step</td><td>0.64032</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80851</td></tr><tr><td>val_auc</td><td>0.90641</td></tr><tr><td>val_f1</td><td>0.75229</td></tr><tr><td>val_loss_epoch</td><td>0.42641</td></tr><tr><td>val_loss_step</td><td>0.48235</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/e38wpzx5' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/e38wpzx5</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_043429-e38wpzx5\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_045551-mevjvluz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/mevjvluz' target=\"_blank\">GraphConv_3_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/mevjvluz' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/mevjvluz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_2\\sum\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 1.6 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7b7a62def13404c9b39ccaa24785ee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▃▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇██▇█▇▇███████████</td></tr><tr><td>train_auc</td><td>▂▃▁▁▂▃▅▄▄▄▄▆▅▅▆▆▆▆▅▇▆▆▆▆▆▅▅▄▄▄▄▄█▆▇▆▆▅▆▅</td></tr><tr><td>train_f1</td><td>▁▃▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇██▇███████</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▂▂▂▂▂▁▂▂▁▁▂▂▂▁▁▂▁▁▁▁▂▁▁▁▁▂▂▁▁▂▁▁▁▂▁▂▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▇▆███▇▇█▇████████████▇███▇██▇▇████████▇</td></tr><tr><td>val_auc</td><td>▁▁▁▃▅▆▇▇▇▇▇▇█████████████▇██████████████</td></tr><tr><td>val_f1</td><td>▁▅▅▇▇▇▆▅▆▅▆▇▇▇██▇▇▇█▆▇▆▇█▇▄▇█▆▆█▇▇▆▇█▇▇▅</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▂▂▁▁▁▁▂▁▁▂▁▁▁▁▁▁▁▁▁▂▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▅▅▄▄▂▄▃▃▄▃▅▄▄▁▃▅▅▂▃▃▃▄▂▂▃▂▂▂▃▂▃▄▁▁▅▂▄▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83471</td></tr><tr><td>train_auc</td><td>0.64836</td></tr><tr><td>train_f1</td><td>0.83834</td></tr><tr><td>train_loss_epoch</td><td>0.40874</td></tr><tr><td>train_loss_step</td><td>0.27884</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80851</td></tr><tr><td>val_auc</td><td>0.89282</td></tr><tr><td>val_f1</td><td>0.75964</td></tr><tr><td>val_loss_epoch</td><td>0.40303</td></tr><tr><td>val_loss_step</td><td>0.31988</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/mevjvluz' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/mevjvluz</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_045551-mevjvluz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_051634-jks9rjhk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jks9rjhk' target=\"_blank\">GCN_3_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jks9rjhk' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jks9rjhk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_2\\attention\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 832   \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "1.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.0 K     Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▇▇▇▇▇▇▇▇▇██████████▇██████████████████</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇▇████████████████████████████████</td></tr><tr><td>train_f1</td><td>▁▇▇▇████████████████████████████████████</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▃▃▃▃▃▂▂▂▂▁▂▂▂▂▂▂▁▁▂▂▁▁▂▁▂▁▁▂▁▁▁▂▂▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▅▅▄▅▃▆▄▅▄▃▁▂▆▃▃▆▅▃▅▃▇▃▄▄▄▇▃▃▄▃▃▄▃▂▃▃▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▄▆▇▇▇▇██████▇█▇████▇█▇█▇████▇█▇▆▆██▆██</td></tr><tr><td>val_auc</td><td>▁▅▇▇▇▇▇▇▇▇█████████▇████████████████████</td></tr><tr><td>val_f1</td><td>▁▅▅▇▇▇▇▇████████▇████▇█▇█▇████▇█▇▇▇██▆██</td></tr><tr><td>val_loss_epoch</td><td>█▆▆▃▃▂▃▂▂▂▂▂▂▂▂▁▃▂▁▂▂▂▁▂▂▂▁▁▁▁▃▂▃▄▃▂▁▅▁▂</td></tr><tr><td>val_loss_step</td><td>█▆▇▃▃▂▅▄▄▃▃▅▅▃▅▃▃▃▁▄▄▁▃▅▄▅▁▂▃▂▄▄▆▇▄▃▂▇▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.82763</td></tr><tr><td>train_auc</td><td>0.90047</td></tr><tr><td>train_f1</td><td>0.83141</td></tr><tr><td>train_loss_epoch</td><td>0.4003</td></tr><tr><td>train_loss_step</td><td>0.2838</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83452</td></tr><tr><td>val_auc</td><td>0.92057</td></tr><tr><td>val_f1</td><td>0.81771</td></tr><tr><td>val_loss_epoch</td><td>0.35839</td></tr><tr><td>val_loss_step</td><td>0.36014</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jks9rjhk' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jks9rjhk</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_051634-jks9rjhk\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bae8f98b660448cf9e2388eddd341780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333330477276, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_053755-eyy99cg7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/eyy99cg7' target=\"_blank\">GraphConv_3_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/eyy99cg7' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/eyy99cg7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_2\\attention\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 1.6 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "1.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9db0f0770d3435daf64945dc92c3140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇███▇███████████████▇██▇████</td></tr><tr><td>train_auc</td><td>▁▅▆▇▇▇▇▇▇██▇▇███████████████████████████</td></tr><tr><td>train_f1</td><td>▁▄▅▆▇▇▇▇▇▇▇▇▇███▇▇██████████████▇██▇████</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▃▃▃▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▁▂▁▁▁▁▁▂▁▂▂▁▁▂▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▅▄▃▅▄▄▃▄▃▄▁▃▃▃▆▁▄▃▂▃▄▃▃▃▄▂▃▄▁▂▃▃▃▄▄▂▂▆</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇▇██████▇██▇████</td></tr><tr><td>val_auc</td><td>▁▅▇▆▇▇▇▇▇▇▇▇▇▇▇▇████▇██▇████████████████</td></tr><tr><td>val_f1</td><td>▁▆▇▇▇▇▇█▇▇▇██▇▇▇██████▇█▇███████▇██▇████</td></tr><tr><td>val_loss_epoch</td><td>█▅▄▄▃▄▃▂▂▃▃▂▃▃▃▄▂▁▂▂▂▂▂▂▃▂▁▁▁▁▁▁▂▂▁▂▂▂▂▂</td></tr><tr><td>val_loss_step</td><td>█▆▆▃▅▆▃▅▄▄▅▂▅▄▄▅▂▂▂▄▄▃▁▃▅▃▂▂▂▂▂▁▁▅▁▅▃▅▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85655</td></tr><tr><td>train_auc</td><td>0.92392</td></tr><tr><td>train_f1</td><td>0.85731</td></tr><tr><td>train_loss_epoch</td><td>0.3692</td></tr><tr><td>train_loss_step</td><td>0.59149</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83688</td></tr><tr><td>val_auc</td><td>0.92155</td></tr><tr><td>val_f1</td><td>0.82353</td></tr><tr><td>val_loss_epoch</td><td>0.36479</td></tr><tr><td>val_loss_step</td><td>0.42155</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/eyy99cg7' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/eyy99cg7</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_053755-eyy99cg7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_055846-uakqkmir</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/uakqkmir' target=\"_blank\">GCN_3_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/uakqkmir' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/uakqkmir</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_2\\attention2\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 832   \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇▇████▇█████▇█████▇████████████████</td></tr><tr><td>train_auc</td><td>▁▇▇▇████████████████████████████████████</td></tr><tr><td>train_f1</td><td>▁▇█▇████████████████████████████████████</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▁▁▂▂▁▂▁▂▁▂▂▁▂▁▂▂</td></tr><tr><td>train_loss_step</td><td>█▅▆▃▂▄▄▃▃▃▃▂▃▃▄▄▄▆▂▂▃▁▅▃▄▃▂▇▃▃▄▄▂▇▂▁▃▅▄▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▇▇███▇████▇███████▇▇██▇███▇▇▆█▇█▇██▇█▇▇</td></tr><tr><td>val_auc</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇█████▇█▇██▇▇▇██▇▇▇▇████████</td></tr><tr><td>val_f1</td><td>▁█▇████████▇███████▇▇██████▇█▆██████▇███</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▂▂▂▂▁▂▁▂▂▁▁▁▁▂▁▁▂▂▁▁▁▁▃▁▂▂▅▃▃▂▃▂▁▁▁▁▃</td></tr><tr><td>val_loss_step</td><td>█▃▃▃▃▃▂▁▅▂▅▅▂▃▂▂▄▃▃▃▁▂▃▁▂▅▂▃▃▄▆▄▃▆▅▂▁▃▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84711</td></tr><tr><td>train_auc</td><td>0.90974</td></tr><tr><td>train_f1</td><td>0.84809</td></tr><tr><td>train_loss_epoch</td><td>0.40031</td></tr><tr><td>train_loss_step</td><td>0.54653</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81087</td></tr><tr><td>val_auc</td><td>0.92017</td></tr><tr><td>val_f1</td><td>0.81395</td></tr><tr><td>val_loss_epoch</td><td>0.41801</td></tr><tr><td>val_loss_step</td><td>0.46014</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/uakqkmir' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/uakqkmir</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_055846-uakqkmir\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d939e6930455451aa96b1d46148b2f38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_062019-h9o71xox</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/h9o71xox' target=\"_blank\">GraphConv_3_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/h9o71xox' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/h9o71xox</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_2\\attention2\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 1.6 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▇▇▇▇▇▇▇█▇▇██████████████████▇████████</td></tr><tr><td>train_auc</td><td>▁▅▇▇▇▇▇▇█▇██████████████████████████████</td></tr><tr><td>train_f1</td><td>▁▅▅▆▇▇▇▇▇▇█▇▇▇██▇█▇▇██▇▇██████▇▇█▇█▇██▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▁▂▂</td></tr><tr><td>train_loss_step</td><td>██▄▃▄▃▄▂▂▃▃▂▁▄▂▃▂▆▄▃▂▂▁▂▁▂▂▃▂▂▂▄▃▂▃▃▁▃▁▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▃▆▄▃▇▆▆▆▆▅▅▇▆▅▆▆▇▇▇█▆▇█▇█▆▇▆▇▅▆▆▆▅▅▇▄▅</td></tr><tr><td>val_auc</td><td>▁▅▆▇▇▇▇▇▇▇██▇▇█▇████████████████████▇███</td></tr><tr><td>val_f1</td><td>▁▄▁▇▃▁█▆▇▇▇▅▄▆▆▄▇▅▇█▇▇▇▆███▆▇▆▇▆▇█▅▇▄▇▂▄</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▂▃▃▃▂▂▂▂▂▃▂▃▂▃▂▁▃▃▂▂▂▂▂▂▂▂▂▂▁▂▃▂▃▃▃▃▃</td></tr><tr><td>val_loss_step</td><td>█▄▃▃▅▄▅▃▃▄▂▅▄▃▆▃▆▄▃▆▆▄▃▅▄▄▄▄▄▃▂▁▃▅▂▅▄▅▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.866</td></tr><tr><td>train_auc</td><td>0.92683</td></tr><tr><td>train_f1</td><td>0.86916</td></tr><tr><td>train_loss_epoch</td><td>0.35664</td></tr><tr><td>train_loss_step</td><td>0.41487</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81087</td></tr><tr><td>val_auc</td><td>0.91621</td></tr><tr><td>val_f1</td><td>0.76331</td></tr><tr><td>val_loss_epoch</td><td>0.41937</td></tr><tr><td>val_loss_step</td><td>0.53998</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/h9o71xox' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/h9o71xox</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_062019-h9o71xox\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_064118-l0shwnla</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/l0shwnla' target=\"_blank\">GCN_3_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/l0shwnla' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/l0shwnla</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_2\\mean\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 2.7 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "3.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.2 K     Total params\n",
      "0.013     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇▇▇▇▇▇▇███▇▇██▇██▇█▇███▇█████▇███▇█</td></tr><tr><td>train_auc</td><td>▁▇▇▇▇▇█▇▇▇██████████████████████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▇▇▇▇▇▇▇█▇█▇▇▇▇▇██▇▇▇█▇█▇▇▇███▇███▇█</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▃▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▁▂▂▂▂</td></tr><tr><td>train_loss_step</td><td>█▅▆▇▃▅▄▅▄▆▄▄▃▃▄▆▂▇▅▅▅▄▁▅▃▅▃▇▃▃▃▅▅▃▄▆▃▃▅▆</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▁▆▆▅▇▇▇▇▇▇▇▇▆▆█▆▇▇▇▇▇▆▇▇▇▇▆▇▇█▆▇▇█▇█▇▇▇</td></tr><tr><td>val_auc</td><td>▁▆▆▆▇▇▇▇▇▇▇▇▇▇▆▇▆▇▇▇▇▆▇▇▇▇▆▆▇█▇▇█▇▇█▇██▇</td></tr><tr><td>val_f1</td><td>▂▁▆▇▆█▇▇▇█▇▇▇▆▆█▇▇███▇▆█▇█▇▆███▆█▇█▇█▇██</td></tr><tr><td>val_loss_epoch</td><td>█▆▃▂▃▂▂▃▂▁▂▃▁▃▂▁▂▂▂▂▁▂▃▂▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▁</td></tr><tr><td>val_loss_step</td><td>█▄▃▄▅▄▅▆▄▁▄▆▃▆▂▁▂▄▇▅▃▆▇▅▆▅▄▅▆▅▄▄▅▆▄▅▃▅▅▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84829</td></tr><tr><td>train_auc</td><td>0.91704</td></tr><tr><td>train_f1</td><td>0.85289</td></tr><tr><td>train_loss_epoch</td><td>0.37616</td></tr><tr><td>train_loss_step</td><td>0.4639</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81797</td></tr><tr><td>val_auc</td><td>0.91906</td></tr><tr><td>val_f1</td><td>0.79467</td></tr><tr><td>val_loss_epoch</td><td>0.3392</td></tr><tr><td>val_loss_step</td><td>0.25259</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/l0shwnla' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/l0shwnla</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_064118-l0shwnla\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_070240-hzfcmszz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hzfcmszz' target=\"_blank\">GraphConv_3_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hzfcmszz' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hzfcmszz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_2\\mean\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 5.2 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "5.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.7 K     Total params\n",
      "0.023     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇████▇█▇█████████▇███</td></tr><tr><td>train_auc</td><td>▁▆▆▇▇▇▇▇█▇▇██▇▇█████████████████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████▇█████████▇███</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▄▃▅▃▄▃▃▂▃▃▄▂▂▄▃▄▃▂▂▂▃▃▃▃▃▂▄▃▃▃▃▁▂▂▁▄▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▇▇▇█▇█████▇██████▇██▇▇███▇██▇█████▇████</td></tr><tr><td>val_auc</td><td>▁▅▆▇▇▇▇█▇▇██▇█▇▇▇▇▇███▇█████████████████</td></tr><tr><td>val_f1</td><td>▁▇▆▇▇▇▇▇███▇▇█▆▇█▇▇▇▇▆▇▇▇▇▆██▆███▇█▅█▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▂▂▃▂▂▃▂▂▂▂▁▂▂▂▂▂▂▂▂▂▁▂▂▂▂▁▂▁▁▂▃▂▂▂▂▂▁</td></tr><tr><td>val_loss_step</td><td>█▅▄▃▄▆▄▄▆▅▅▄▄▃▅▃▄▄▄▄▅▅▄▃▄▅▃▄▁▄▁▂▃█▂▃▃▄▅▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.88666</td></tr><tr><td>train_auc</td><td>0.94316</td></tr><tr><td>train_f1</td><td>0.88915</td></tr><tr><td>train_loss_epoch</td><td>0.31148</td></tr><tr><td>train_loss_step</td><td>0.35156</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82742</td></tr><tr><td>val_auc</td><td>0.91172</td></tr><tr><td>val_f1</td><td>0.80323</td></tr><tr><td>val_loss_epoch</td><td>0.33971</td></tr><tr><td>val_loss_step</td><td>0.1623</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hzfcmszz' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hzfcmszz</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_070240-hzfcmszz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_072337-9r0455na</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9r0455na' target=\"_blank\">GCN_3_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9r0455na' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9r0455na</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_2\\max\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 2.7 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "3.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.2 K     Total params\n",
      "0.013     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f786b3a752394bdfa2640ba699bf0081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▄▅▅▆▆▆▆▆▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇██▇███▇████▇██</td></tr><tr><td>train_auc</td><td>▃▄▃▁▂▁▂▂▃▃▃▃▃▂▃▄▄▄▄▅▅▆▅▆▆▅▆▇▆▆▆▇▅▇▇▇█▇▇▇</td></tr><tr><td>train_f1</td><td>▁▃▃▄▅▅▆▅▆▅▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇██▇███▇███████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▆▅▇▅▅▆▅▄▅▃▃▄▅▅▄█▃▃▃▃▂▃▂▃▁▃▂▁▂▄▂▁▁▂▂▃▃▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▁▆▆▆▆▆▇▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇██▇▇▇▇▇▇▇▇▇▇▇▇▇▇█</td></tr><tr><td>val_auc</td><td>▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▄▇▅██████████████████████</td></tr><tr><td>val_f1</td><td>▃▃▆▆▆▆▆▆▆▆▆▆▁▆▆▇▄▆▇▅▅▇▇██▆▇██▇▇▆▇▇▇▇▇█▇█</td></tr><tr><td>val_loss_epoch</td><td>██▆▆▅▅▅▅▄▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▁▂▂▁</td></tr><tr><td>val_loss_step</td><td>██▆▆▅▅▆▅▅▄▄▅▃▃▃▄▃▃▄▃▃▃▄▃▃▃▃▃▂▁▂▄▅▄▃▂▂▃▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77981</td></tr><tr><td>train_auc</td><td>0.71113</td></tr><tr><td>train_f1</td><td>0.79472</td></tr><tr><td>train_loss_epoch</td><td>0.46882</td></tr><tr><td>train_loss_step</td><td>0.57305</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81324</td></tr><tr><td>val_auc</td><td>0.88158</td></tr><tr><td>val_f1</td><td>0.7882</td></tr><tr><td>val_loss_epoch</td><td>0.43429</td></tr><tr><td>val_loss_step</td><td>0.4089</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9r0455na' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9r0455na</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_072337-9r0455na\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_074445-twutefxf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/twutefxf' target=\"_blank\">GraphConv_3_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/twutefxf' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/twutefxf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_2\\max\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 5.2 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "5.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.7 K     Total params\n",
      "0.023     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▄▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇████▇██▇█▇█</td></tr><tr><td>train_auc</td><td>▁▁▃▃▃▃▄▄▄▅▅▅▆▅▅▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███</td></tr><tr><td>train_f1</td><td>▁▃▄▄▅▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█████████▇█▇█</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▂▁▁▁▁▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▅▅▄▄▄▃▃▃▃▃▄▃▃▂▃▄▃▂▂▃▂▂▂▂▂▁▃▂▂▂▂▁▂▂▂▃▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▃▃▄▆▇▇▇▇█▇▆▇▇▇▇███▇███████▇█▇█▇▇█▆▆█▇▇</td></tr><tr><td>val_auc</td><td>▁▄▄▅▆▇▇▇▇▇▇▇▇▇▇▇███▇▇██▇██▇█████████████</td></tr><tr><td>val_f1</td><td>▁▄▄▄▄▆▇▆▇▇█▇▄▇▆▆▇▇▇▇▄██▇████▆█▇▇▇▇█▇▇██▇</td></tr><tr><td>val_loss_epoch</td><td>█▇▇▆▆▅▄▄▄▄▄▃▄▃▄▃▃▃▂▃▄▂▃▃▂▂▂▂▂▂▁▂▂▃▂▂▂▂▂▁</td></tr><tr><td>val_loss_step</td><td>███▆▆▇▅▄▅▆▆▄▆▃▆▄▄▅▃▅▅▄▅▄▃▄▄▄▄▄▁▅▄▇▄▃▄▃▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84534</td></tr><tr><td>train_auc</td><td>0.90239</td></tr><tr><td>train_f1</td><td>0.85097</td></tr><tr><td>train_loss_epoch</td><td>0.37774</td></tr><tr><td>train_loss_step</td><td>0.44458</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80378</td></tr><tr><td>val_auc</td><td>0.87952</td></tr><tr><td>val_f1</td><td>0.78772</td></tr><tr><td>val_loss_epoch</td><td>0.41981</td></tr><tr><td>val_loss_step</td><td>0.32835</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/twutefxf' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/twutefxf</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_074445-twutefxf\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_080544-bzhq6be1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/bzhq6be1' target=\"_blank\">GCN_3_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/bzhq6be1' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/bzhq6be1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_2\\sum\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 2.7 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "3.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.2 K     Total params\n",
      "0.013     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e02d4e2ad01486091bde7b5ad9adfae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███▇▇▇▇███▇█▇████████▇█</td></tr><tr><td>train_auc</td><td>▇▃▅▄▅▆▆▄▃▆▆▅▅▅▅▄▄▄▄▆▇█▇▆▇▄▁▂▅▇▇▆▅▆▅▅▅▃▄▇</td></tr><tr><td>train_f1</td><td>▁▄▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇██▇█▇▇███▇███▇█</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▃▃▂▂▂▂▂▂▂▂▂▂▂▃▁▃▂▂▂▂▁▂▂▂▁▂▂▂▂▂▂▂▂▂▁▂▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▅▁▅▇▇▇▇▅▆█▆▇▆▅▅▆▅▆▇▇▆▅▅▆▅▇▆▆▅▇▅▆▅▅▇▇█▇▆▆</td></tr><tr><td>val_auc</td><td>▆▂▂▂▂▇▄▁▂▅▃▇▄▂▂▁▂▃▃▆▇█▇█▇▂▁▁▄▇▅█▆▅▂▄▅▁▁▄</td></tr><tr><td>val_f1</td><td>▆▁▅▇▇▇▇▆▆█▆▇▆▅▅▇▅▇▇▇▇▆▆▆▅▇▆▆▆▇▆▇▅▅█▇█▇▆▆</td></tr><tr><td>val_loss_epoch</td><td>▇█▆▄▃▄▄▅▄▂▄▄▄▆▆▂▅▃▃▂▃▅▆▆▇▂▃▃▄▃▃▂▆▅▂▅▁▂▅▂</td></tr><tr><td>val_loss_step</td><td>▅▃▄▄▃▃▄▅▃▁▃▆▃▆▅▂▂▄▄▂▃▆▆█▆▅▂▃▅▃▄▂▄▄▄▇▂▃▇▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84593</td></tr><tr><td>train_auc</td><td>0.57572</td></tr><tr><td>train_f1</td><td>0.85263</td></tr><tr><td>train_loss_epoch</td><td>0.40278</td></tr><tr><td>train_loss_step</td><td>0.43091</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80615</td></tr><tr><td>val_auc</td><td>0.49679</td></tr><tr><td>val_f1</td><td>0.74691</td></tr><tr><td>val_loss_epoch</td><td>0.39205</td></tr><tr><td>val_loss_step</td><td>0.33494</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/bzhq6be1' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/bzhq6be1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_080544-bzhq6be1\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_082832-akjvsuz2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/akjvsuz2' target=\"_blank\">GraphConv_3_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/akjvsuz2' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/akjvsuz2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_2\\sum\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 5.2 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "5.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.7 K     Total params\n",
      "0.023     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇█▇▇▇▇▇▇█▇▇▇████▇▇█████</td></tr><tr><td>train_auc</td><td>▄▃▁▂▃▃▂▄▂▃▃▅▃▁▁▂▂▁▃▁▃▄▄▁▂▅▅▆▃▅▃▁▂▁▃▆█▆▃▁</td></tr><tr><td>train_f1</td><td>▁▃▄▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇█▇▇▇▇▇▇█▇▇▇████▇██▇███</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▆▇▇▇▇▇▇▇▇▇▇███████████████████████▇███</td></tr><tr><td>val_auc</td><td>▄▅▅▅▆▅▆▆▅▇▇█▅▅▁▄▄▃▇▁███▃▆██▇▇▇▇▆▃▅████▃▄</td></tr><tr><td>val_f1</td><td>▁▄▆▆▇▆▇▇▆▇▇▇▇█▇██▇███▇███▇▇████▇▇██▇▇███</td></tr><tr><td>val_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▂▂▁▂▂▁▂▂▂▂▂▁▁▂▁▁▁▁▁▂▂▁▁▁▂▁▂▁▂▁▁▁▂▁▁▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86009</td></tr><tr><td>train_auc</td><td>0.50887</td></tr><tr><td>train_f1</td><td>0.86293</td></tr><tr><td>train_loss_epoch</td><td>0.366</td></tr><tr><td>train_loss_step</td><td>0.42513</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.8227</td></tr><tr><td>val_auc</td><td>0.6266</td></tr><tr><td>val_f1</td><td>0.821</td></tr><tr><td>val_loss_epoch</td><td>0.39182</td></tr><tr><td>val_loss_step</td><td>0.18813</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/akjvsuz2' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/akjvsuz2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_082832-akjvsuz2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_085116-4yqjpv8o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4yqjpv8o' target=\"_blank\">GCN_3_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4yqjpv8o' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4yqjpv8o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_2\\attention\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 2.7 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "3.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.3 K     Total params\n",
      "0.013     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇██▇▇▇████████▇▇████▇█</td></tr><tr><td>train_auc</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇███▇███████████████████████</td></tr><tr><td>train_f1</td><td>▁▅▅▇▇▆▇▆▇▇▆▇▇▇▇▇▇▇▇▇█▇▇▇█▇█████▇▇▇▇██▇▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▃▂▃▂▂▃▂▃▂▂▂▁▁▂▁▂▂▂▁▂▂▁▁▁▁▁▁▁▁▂▁▁▂▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▆▄▃▄▅▄▄▅▅▇▄█▅▆▄▅▆▃▂▁▃▆▅▃▂▄█▃▅▂▃▅▃▂▅▃▃▁▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▇▇▆▇▇▇▇▇▆█▆▇▇█▇██▇▇█▆▆█▇▇▇█▇▇▇██▇██▇▇▇█</td></tr><tr><td>val_auc</td><td>▁▆▇▇▇▇▇▇▆▇▇█▇████▇▇▇▇▇▇▇▇▇██▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>val_f1</td><td>▁▇▇▆▇▇▇█▇▇█▆▇▇█▇██▇▇█▇▆▇█▇▇█▇▇███▇██▇███</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▄▃▂▃▂▂▄▂▄▂▂▂▂▂▂▂▃▁▃▅▂▂▂▁▂▂▂▂▂▂▂▂▂▂▃▃▂</td></tr><tr><td>val_loss_step</td><td>▇▅▄▃▃▄▇▅▃▆▅▅▄▅▃▄▃▅▅▆▁▄█▄▅▄▃▄▄▄▅▄▃▅▃▃▃▂▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84593</td></tr><tr><td>train_auc</td><td>0.91543</td></tr><tr><td>train_f1</td><td>0.84436</td></tr><tr><td>train_loss_epoch</td><td>0.38052</td></tr><tr><td>train_loss_step</td><td>0.43643</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82742</td></tr><tr><td>val_auc</td><td>0.9165</td></tr><tr><td>val_f1</td><td>0.81425</td></tr><tr><td>val_loss_epoch</td><td>0.36353</td></tr><tr><td>val_loss_step</td><td>0.35661</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4yqjpv8o' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4yqjpv8o</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_085116-4yqjpv8o\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_091436-80mw1037</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/80mw1037' target=\"_blank\">GraphConv_3_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/80mw1037' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/80mw1037</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_2\\attention\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 5.2 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "5.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.7 K     Total params\n",
      "0.023     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "162502f1dc894a9fa81d5aeee66b7c18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▇▇▇▇▇▇▇█▇███▇█▇██▇███████████████████</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇▇█▇▇▇████████████████████████████</td></tr><tr><td>train_f1</td><td>▁▆▆▇▇▇▇▇▇▇▇▇█▇█▇█▇██▇███████████████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▂▂▁▂▁▁▁▁▁▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▇▃▃▆▄▃▄▄▅▄▁▄▄▃▄▂▁▃▂▃▁▅▆▄▄▆▄▄▃▃▄▃▃▃▄▃▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▆▇▇▇█▇▆█▇██▇▇▇▇▇▇▇▆▇▇█▇▇▆██▇████▇▇▇▇█▇</td></tr><tr><td>val_auc</td><td>▁▆▆▇▇▇▇▇████▇████▇████▇██▇██████████████</td></tr><tr><td>val_f1</td><td>▁▅▃▇▆▆█▅▂▇▆▇▇▇▆▅▄▃▆▆▄▆▆█▄▅▂██▇▇█▇▅▆▅▅▃▇▅</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▃▂▂▂▃▃▂▂▂▂▂▃▁▁▄▂▁▃▁▂▃▃▂▂▂▂▁▂▃▂▃▂▃▃▃▂▂</td></tr><tr><td>val_loss_step</td><td>█▅▃▅▄▄▄▇▅▆▄▅▄▆▆▃▁▅▄▂▇▁▄▆▃▃▁▃▄▁▄▆▅▆▃▅▄▄▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87013</td></tr><tr><td>train_auc</td><td>0.94106</td></tr><tr><td>train_f1</td><td>0.87254</td></tr><tr><td>train_loss_epoch</td><td>0.31108</td></tr><tr><td>train_loss_step</td><td>0.31234</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82033</td></tr><tr><td>val_auc</td><td>0.91077</td></tr><tr><td>val_f1</td><td>0.78652</td></tr><tr><td>val_loss_epoch</td><td>0.40553</td></tr><tr><td>val_loss_step</td><td>0.38425</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/80mw1037' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/80mw1037</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_091436-80mw1037\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_093635-m11aecx1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/m11aecx1' target=\"_blank\">GCN_3_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/m11aecx1' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/m11aecx1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_2\\attention2\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 2.7 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "4.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.3 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▇▇▇▇▇▇▇█▇█▇█▇▇▇▇▇▇▇███▇██▇██▇▇▇▇▇▇█▇█</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇█▇▇▇█▇▇▇▇██▇▇█▇███████████▇████████</td></tr><tr><td>train_f1</td><td>▁▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇██▇██▇▇▇▇▇▇█▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▁▂▂▁▂▂▁▂▁▂▁▁▁▁▂▂</td></tr><tr><td>train_loss_step</td><td>██▄▄▄▅▇▄▄▄▄▆▄▄▄▄▅▃▄▄▄▄▆▅▅▅▄▁▃▄▄▃▇▅▃▄▅▄▄▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▆▇▇▄▇▅▆▆▅▇▆▇▇▇▅▇▇▆▇▆▇▇█▆▇▇▆▇▇▇▇█▇▇▇▇▇▆</td></tr><tr><td>val_auc</td><td>▁▅▆▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆█▇▇▆▆▇▇▇▇▇▆▇▇▆▇▇</td></tr><tr><td>val_f1</td><td>▁▂▆▇▇▄▇▄▆▆▅▇▆█▇▇▆███▇▇▇▇██▇██▇▇██▇▇▇▇▇█▆</td></tr><tr><td>val_loss_epoch</td><td>█▅▃▂▁▄▂▅▂▃▃▁▂▁▂▂▃▂▂▃▁▂▂▃▂▃▁▃▃▃▂▂▂▂▂▂▂▁▂▃</td></tr><tr><td>val_loss_step</td><td>▇▇▄▃▁▄▄▇▂▅▄▂▃▂▄▂▄▃▄▄▂▄▃▆▄▃▂▅▄█▃▃▃▃▃▂▄▁▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84829</td></tr><tr><td>train_auc</td><td>0.91595</td></tr><tr><td>train_f1</td><td>0.85101</td></tr><tr><td>train_loss_epoch</td><td>0.37124</td></tr><tr><td>train_loss_step</td><td>0.35093</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81087</td></tr><tr><td>val_auc</td><td>0.91992</td></tr><tr><td>val_f1</td><td>0.74843</td></tr><tr><td>val_loss_epoch</td><td>0.39723</td></tr><tr><td>val_loss_step</td><td>0.3086</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/m11aecx1' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/m11aecx1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_093635-m11aecx1\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_095931-j2chgs1w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/j2chgs1w' target=\"_blank\">GraphConv_3_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/j2chgs1w' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/j2chgs1w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_2\\attention2\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 5.2 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "6.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.8 K     Total params\n",
      "0.027     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇████▇████████████</td></tr><tr><td>train_auc</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇███████████████████████</td></tr><tr><td>train_f1</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇███▇█████████████████</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▂▁▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>▆▅▃▄▄▃▄▄▃▄▄▃▂▁▃▂▂▂▂▄▂▃█▁▂▃▃▆▃▂▁▂▂▂▂▁▁▂▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁███▇▇█▇██▇██▇█▇█▇▇██▇█▇██▇██████████▇▇▇</td></tr><tr><td>val_auc</td><td>▁▅▆▇▇▇▇▇██▇███▇▇██▇▇▇█████▇█████████▇▇▇█</td></tr><tr><td>val_f1</td><td>▁▇▇▇▇▆█▅█▇▆█▇▆▇▆█▆▇▇█▆▇▅▇▆▅▇██▇▇▇█▇█▇▅▅▅</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▂▄▂▃▃▁▂▂▂▂▂▂▂▂▃▂▂▃▂▂▃▂▂▃▁▂▃▂▁▃▃▂▄▂▂▃▂</td></tr><tr><td>val_loss_step</td><td>█▄▅▅▄▃▇█▃▅▄▄▄▃▃▃▄▅▅▃▆▅▅▄▅▆▅▂▅▇▃▁▆▆▅█▄▄▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.88076</td></tr><tr><td>train_auc</td><td>0.94641</td></tr><tr><td>train_f1</td><td>0.88228</td></tr><tr><td>train_loss_epoch</td><td>0.30395</td></tr><tr><td>train_loss_step</td><td>0.38838</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80615</td></tr><tr><td>val_auc</td><td>0.91288</td></tr><tr><td>val_f1</td><td>0.76023</td></tr><tr><td>val_loss_epoch</td><td>0.395</td></tr><tr><td>val_loss_step</td><td>0.33091</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/j2chgs1w' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/j2chgs1w</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_095931-j2chgs1w\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_102155-btbjfgzm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/btbjfgzm' target=\"_blank\">GCN_3_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/btbjfgzm' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/btbjfgzm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_2\\mean\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 9.5 K \n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "11.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "11.6 K    Total params\n",
      "0.046     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇██▇▇▇██████▇█████</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇███████████████████</td></tr><tr><td>train_f1</td><td>▁▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█████▇▇███████▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▃▃▂▂▂▃▂▂▃▂▂▃▃▂▂▂▂▁▁▂▂▁▁▂▂▁▁▁▁▁▁▂▂▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▆▆▆▇▄▅▆▆▅▃▄▆▆▇█▇▅▅▅▅▄▁▆▅▆▄▆▄▄▆▅▆▆▃▆▆▅▅▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▂▆▆▇▇▆▆█▇▇█▆▇▇▇▇▇█▇▆█▇▇▇██▇▇█▇█▇██▇▇█▇▇</td></tr><tr><td>val_auc</td><td>▁▄▅▆▅▆▆▆▆▆▇▆▅▆▆▅▅▄▄▆▅▆▇▆▆▇▇▆▇▅▇▆▆▅▆▇▆█▅▇</td></tr><tr><td>val_f1</td><td>▁▂▇▇▇▇▇▇█▇▇█▇█▇██▇█▇▆██▇▇███▇█▇█▇███▇█▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▆▂▂▂▁▂▂▁▁▁▁▂▁▂▁▁▂▁▁▃▁▁▂▁▁▁▁▁▁▁▁▂▁▁▁▂▁▂▂</td></tr><tr><td>val_loss_step</td><td>█▆▄▃▂▂▂▃▂▁▃▂▂▂▂▂▁▂▂▁▄▁▂▂▁▂▂▂▂▂▃▁▂▂▂▂▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85714</td></tr><tr><td>train_auc</td><td>0.92634</td></tr><tr><td>train_f1</td><td>0.86076</td></tr><tr><td>train_loss_epoch</td><td>0.34644</td></tr><tr><td>train_loss_step</td><td>0.24483</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.79669</td></tr><tr><td>val_auc</td><td>0.92139</td></tr><tr><td>val_f1</td><td>0.72785</td></tr><tr><td>val_loss_epoch</td><td>0.40684</td></tr><tr><td>val_loss_step</td><td>0.30328</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/btbjfgzm' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/btbjfgzm</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_102155-btbjfgzm\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da0906c141fd44d4ad13bc2791546fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_104647-iemkml2r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/iemkml2r' target=\"_blank\">GraphConv_3_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/iemkml2r' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/iemkml2r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_2\\mean\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 18.5 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "20.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.6 K    Total params\n",
      "0.083     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b33aac30917347fdaae8bc56ec8b51f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇▇▇██▇▇█▇▇████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇███████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇▇▇██▇▇█▇▇██▇█</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▄▄▃▃▃▃▃▂▂▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▁▁▁▂▂▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▅▇▄▃▄▆▄▅▃▂█▄▂▄▃▂▁▄▄▃█▃▄▅▂▅▂▂▄▂▁▃▁▂▂▃▆▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▆▇▇▆▇█▇▇▇█▇▇█▇█▆█▇▇▆▇▇▆▇█▇██▇▆▇▇▇▇▇▇▇▇</td></tr><tr><td>val_auc</td><td>▁▄▇▇▇▆▇▇▇▇▆▇▇▇███▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▇▅▆▆▇</td></tr><tr><td>val_f1</td><td>▄▁▆▇▆▅▇▇▇▇▇█▇▇█▇█▆█▇█▇▆█▇▇█▇█▇▇▇▇▇▆▇▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▇▂▂▁▃▁▁▁▂▁▂▃▂▁▂▁▁▂▃▃▃▂▂▅▅▁▁▁▂▁█▅▃▃▂▂▂▅▃</td></tr><tr><td>val_loss_step</td><td>▅▆▂▃▃▄▃▂▃▄▁▄▅▃▃▃▂▂▃▅▅▂▃▂▅█▃▂▁▂▂█▇▃▂▂▃▂▆▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.89374</td></tr><tr><td>train_auc</td><td>0.95776</td></tr><tr><td>train_f1</td><td>0.89535</td></tr><tr><td>train_loss_epoch</td><td>0.26221</td></tr><tr><td>train_loss_step</td><td>0.24449</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81797</td></tr><tr><td>val_auc</td><td>0.9115</td></tr><tr><td>val_f1</td><td>0.79245</td></tr><tr><td>val_loss_epoch</td><td>0.43102</td></tr><tr><td>val_loss_step</td><td>0.56723</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/iemkml2r' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/iemkml2r</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_104647-iemkml2r\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_111124-5iagj25i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5iagj25i' target=\"_blank\">GCN_3_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5iagj25i' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5iagj25i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_2\\max\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 9.5 K \n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "11.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "11.6 K    Total params\n",
      "0.046     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "539b4ced53ca466ea80ed06b9fa7289c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▅▅▅▅▆▅▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████</td></tr><tr><td>train_auc</td><td>▂▂▃▁▃▂▂▂▃▃▅▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇█▇██████████</td></tr><tr><td>train_f1</td><td>▁▃▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇████████████</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▅▇▄▄▅▅▄▄▃▃▂▂▃▃▃▂▂▃▃▂▁▃▃▂▂▁▂▂▂▃▄▃▁▂▁▃▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▅▅▅▆▆▆▆▆▇▇▇▆▇▇▇██▇▇▇██▇█▇▇▇▇▇█▇▇▇██▇▇█</td></tr><tr><td>val_auc</td><td>▅▆▁▁▇▄▁▇▇███████████████████████████████</td></tr><tr><td>val_f1</td><td>▁▇▇▇▇████████▇██████▇███████████████████</td></tr><tr><td>val_loss_epoch</td><td>█▇▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▁▄▂▂▂▂▂▂▂▁▁▂▁▂▂▁▂▂▁▂▁</td></tr><tr><td>val_loss_step</td><td>██▇▆▆▆▆▆▅▄▄▄▄▅▄▄▃▃▂▁▇▃▃▂▂▃▆▃▂▂▅▂▃▄▃▃▄▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.81995</td></tr><tr><td>train_auc</td><td>0.88404</td></tr><tr><td>train_f1</td><td>0.8297</td></tr><tr><td>train_loss_epoch</td><td>0.39627</td></tr><tr><td>train_loss_step</td><td>0.35611</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80851</td></tr><tr><td>val_auc</td><td>0.88386</td></tr><tr><td>val_f1</td><td>0.76791</td></tr><tr><td>val_loss_epoch</td><td>0.42322</td></tr><tr><td>val_loss_step</td><td>0.36205</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5iagj25i' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5iagj25i</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_111124-5iagj25i\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_113654-hg7gnxd5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hg7gnxd5' target=\"_blank\">GraphConv_3_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hg7gnxd5' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hg7gnxd5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_2\\max\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 18.5 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "20.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.6 K    Total params\n",
      "0.083     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇███▇██████▇█</td></tr><tr><td>train_auc</td><td>▁▄▅▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇█▇██▇██▇████████████</td></tr><tr><td>train_f1</td><td>▁▄▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇███▇██████▇█</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▂▁▁▂▁▁▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▄▅▄▃▄▆▄▄▃▄▃▄▃▄▃▄▂▄▃▅▃▃▃▄▄▂▂▂▃▂▂▄▃▂▁▃▄▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▆▇▇▇▆▇▇▇▇▇▇▆▇▇▆▇▇▇</td></tr><tr><td>val_auc</td><td>▁▃▅▅▅▆▇▆▇▇▇▇▇▇▇▇▇██▇▇▇▇▇█▇█▇█▇▇▇█████▇██</td></tr><tr><td>val_f1</td><td>▁▄▆▆▅▇▇▇▇▆▆▇▇▇▇▆▅███▇▇▄██▇▇███▇██▇█▇▇██▇</td></tr><tr><td>val_loss_epoch</td><td>█▅▄▄▄▄▃▃▃▃▂▂▂▃▂▄▂▂▂▂▂▂▄▁▁▂▂▂▁▁▂▃▁▂▁▂▁▂▂▂</td></tr><tr><td>val_loss_step</td><td>█▆▆▅▆▆▅▅▆▄▂▄▅▄▄█▃▃▃▅▅▃▅▁▃▅▂▄▁▂▄▆▃▃▂▃▂▃▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86128</td></tr><tr><td>train_auc</td><td>0.9167</td></tr><tr><td>train_f1</td><td>0.86471</td></tr><tr><td>train_loss_epoch</td><td>0.34497</td></tr><tr><td>train_loss_step</td><td>0.39252</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.8156</td></tr><tr><td>val_auc</td><td>0.89846</td></tr><tr><td>val_f1</td><td>0.805</td></tr><tr><td>val_loss_epoch</td><td>0.41223</td></tr><tr><td>val_loss_step</td><td>0.41055</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hg7gnxd5' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hg7gnxd5</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_113654-hg7gnxd5\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_120213-hlzgzjev</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hlzgzjev' target=\"_blank\">GCN_3_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hlzgzjev' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hlzgzjev</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_2\\sum\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 9.5 K \n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "11.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "11.6 K    Total params\n",
      "0.046     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇█▇█▇███▇██▇███</td></tr><tr><td>train_auc</td><td>▅▃▂▁▁▁▄▅▅▄▅▆▇▅▆▇▇████████▆▅▆▇▇▇▆▅▆▆▇▇█▅▅</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇████▇█▇█████▇██▇███</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▂▂▂▃▂▂▂▂▃▂▂▂▃▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▁▆▆▆▆▆▆▆▇▆▇▇▇▇█▆▆▇▇▇▇▅▇▅█▇▇▇▅▇▇▄▇▆▅▆▇▆▅</td></tr><tr><td>val_auc</td><td>▆▄▂▁▁▁▅██▇██████████████████████▇█████▇▇</td></tr><tr><td>val_f1</td><td>▁▁▆▇▇▇▇▆▇▇▆▇▇▇▇█▆▇▇▇▇▇▆▇▆█▇▇█▆█▇▅▇▇▆▆▇▆▆</td></tr><tr><td>val_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▂▁▂▁▁▁▁▂▁▁▂▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▂▁▂▂▁▁▂▂▁▂▁▁▁▂▁▁▁▁▁▂▁▂▁▁▁▁▁▁▂▁▁▂▁▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8412</td></tr><tr><td>train_auc</td><td>0.64196</td></tr><tr><td>train_f1</td><td>0.84672</td></tr><tr><td>train_loss_epoch</td><td>0.37209</td></tr><tr><td>train_loss_step</td><td>0.21929</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.70922</td></tr><tr><td>val_auc</td><td>0.8328</td></tr><tr><td>val_f1</td><td>0.53232</td></tr><tr><td>val_loss_epoch</td><td>0.70556</td></tr><tr><td>val_loss_step</td><td>0.58739</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hlzgzjev' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hlzgzjev</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_120213-hlzgzjev\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c4ca4ed58ee4af9842ff9aee9725ba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666883975, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_122449-rnqw8hje</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/rnqw8hje' target=\"_blank\">GraphConv_3_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/rnqw8hje' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/rnqw8hje</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_2\\sum\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 18.5 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "20.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.6 K    Total params\n",
      "0.083     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇███▇███████████▇█</td></tr><tr><td>train_auc</td><td>▃▂▃▃▄▄▄▄▄▄▄▄▄▄▄▃▁▅▆▄▃▃▂▄▄▆▆▆▆▆▅▃▅▅▅▆▅▅▇█</td></tr><tr><td>train_f1</td><td>▁▃▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇▇███████████▇█</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▂▂▂▁▁▂▂▁▁▁▁▂▁▁▁▁▁▁▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▇██████████████████████████████████████</td></tr><tr><td>val_auc</td><td>▁▆▇▇▇▇▇███████▇▆▇███▅█▇█████████████████</td></tr><tr><td>val_f1</td><td>▁▇██▇▆▇▇▇█▇▇█▆▇▇▇▇█▇█▇▇█▇██▇██▇█▇▇▆█▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▂▂▂▂▂▂▂▂▂▁▁▃▂▂▂▁▁▂▃▂▁▂▁▂▃▂▂▁▂▂▂▂▁▂▁▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86423</td></tr><tr><td>train_auc</td><td>0.86423</td></tr><tr><td>train_f1</td><td>0.86628</td></tr><tr><td>train_loss_epoch</td><td>0.3414</td></tr><tr><td>train_loss_step</td><td>0.21363</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82979</td></tr><tr><td>val_auc</td><td>0.90124</td></tr><tr><td>val_f1</td><td>0.80749</td></tr><tr><td>val_loss_epoch</td><td>0.43223</td></tr><tr><td>val_loss_step</td><td>0.40984</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/rnqw8hje' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/rnqw8hje</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_122449-rnqw8hje\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6801d93c25a24877b8d70d365787a574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666883975, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_124730-j14qy9sk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/j14qy9sk' target=\"_blank\">GCN_3_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/j14qy9sk' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/j14qy9sk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_2\\attention\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 9.5 K \n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "11.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "11.7 K    Total params\n",
      "0.047     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▅▇▆▇▇▇▇▇▆▇▇▆▇▇▇▇██▇▇███▇▇▇██▇▇█▇█████▇</td></tr><tr><td>train_auc</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▆▇█▇████▇███▇█▇██▇██▇██████</td></tr><tr><td>train_f1</td><td>▁▆▅▇▆▇▇▇▇▇▆▇▇▆▇▇▇▇██▇▇███▇▇▇██▇▇█▇█████▇</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▂▃▃▃▃▂▂▃▂▂▄▂▂▂▂▁▁▂▂▂▂▂▂▂▂▂▁▂▁▂▂▂▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▆▄▅▃▅▄▃▅▅▃▂▃▃▄▅▃▃▃▆▅▆▃▄▃▆▃▄▂▄▄▄▅▂▄▁▃▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▂▅▅▆█▇▇▇▇▇▇▇▆▇▆▇█▇▆▇█▇▇▇▆█▇▇██▇█▇█▇▆▇▆▇</td></tr><tr><td>val_auc</td><td>▁▅▆▇▇▇▇█▇▇███▆▇▇▇▇▇█▇▇█▇▇█▇▇█▇▇█▇▆▇█▇▇▇█</td></tr><tr><td>val_f1</td><td>▁▂▅▆▇█▇▇▇▇▇▇▇▇█▇██▇▇▇█▇▇▇▆█▇▇██▇███▇▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>▆█▄▄▃▂▂▁▂▂▂▃▂▃▂▃▁▂▂▃▂▂▂▂▁▄▁▂▂▂▁▂▁▂▁▂▂▂▂▂</td></tr><tr><td>val_loss_step</td><td>▇█▇▅▅▄▄▁▄▃▅▅▄▆▄▄▃▄▄▄▅▄▅▅▂▄▃▅▆▃▃▅▄▅▂▃▂▆▄▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85419</td></tr><tr><td>train_auc</td><td>0.92834</td></tr><tr><td>train_f1</td><td>0.85714</td></tr><tr><td>train_loss_epoch</td><td>0.34483</td></tr><tr><td>train_loss_step</td><td>0.3171</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.79905</td></tr><tr><td>val_auc</td><td>0.9239</td></tr><tr><td>val_f1</td><td>0.73186</td></tr><tr><td>val_loss_epoch</td><td>0.43225</td></tr><tr><td>val_loss_step</td><td>0.54817</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/j14qy9sk' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/j14qy9sk</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_124730-j14qy9sk\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_131218-b3vy6gwu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/b3vy6gwu' target=\"_blank\">GraphConv_3_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/b3vy6gwu' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/b3vy6gwu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_2\\attention\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 18.5 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "20.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.7 K    Total params\n",
      "0.083     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36863a81b45a49728ff90205aa4e8cfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▇▆▇▇▇▇▇▇▇▇▇█▇▇▇████████▇███████████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇██▇█▇████████▇███████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇█▇▇█▇▇▇████████▇███████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▂▁▂▁▁▁▁▁▂▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>██▅▆▄▄▃▅▄▄▄▃▄▅▅▄▆▅▃▅▃▃▄▂▄▄▃▃▄▁▃▃▄▃▃▅▂▃▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▂▁▃▄▄▅▅▆▆▆▆▇▇▇▇████▇▇█▅▆▇▆▆▅▅▅▆▆▆▅▆▅▅▄▇▆</td></tr><tr><td>val_auc</td><td>▁▆▆▆▇▇▇▇▇▇▇▇█▇▇▇█▇█▇▇▇▆▇▇▇▇▇▇▆▇▆▇▇▆▇▆▆▇▆</td></tr><tr><td>val_f1</td><td>▃▁▇▆▆▇▄▇▇▇▅▇█▇▇████▇▆█▅▇█▆█▆▅▆▇▆▇▅▆▅▆▄▇▆</td></tr><tr><td>val_loss_epoch</td><td>█▄▅▂▃▃▃▁▂▁▄▄▂▂▁▁▁▂▂▂▄▂▆▂▃▃▃▃▃▅▄▆▂▅▂▅▆▅▃▃</td></tr><tr><td>val_loss_step</td><td>▆▃▆▂▃▂▄▁▄▂▅█▄▂▂▂▂▄▄▂▄▂▆▂▅▁▂▂▃▄▄█▃▃▂▄▃▄▄▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.89197</td></tr><tr><td>train_auc</td><td>0.95135</td></tr><tr><td>train_f1</td><td>0.89329</td></tr><tr><td>train_loss_epoch</td><td>0.28062</td></tr><tr><td>train_loss_step</td><td>0.25901</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.8227</td></tr><tr><td>val_auc</td><td>0.90346</td></tr><tr><td>val_f1</td><td>0.79452</td></tr><tr><td>val_loss_epoch</td><td>0.4251</td></tr><tr><td>val_loss_step</td><td>0.29961</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/b3vy6gwu' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/b3vy6gwu</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_131218-b3vy6gwu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_133503-fvdzw6ej</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fvdzw6ej' target=\"_blank\">GCN_3_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fvdzw6ej' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fvdzw6ej</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_2\\attention2\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 9.5 K \n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "15.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.8 K    Total params\n",
      "0.063     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6340b8e9a0d440b892c5e877c2c752fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▇▇▅▇▆▇▇▇▇▇▆▇▇▇▇▇█▇▇▇▇▇▇▇▇▇█▇██▇▇██▇</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▇▇▆▇▆▇▇▇▇▇▇▇▇▇█▇█▇█▇█████▇█████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▇▇▅▇▅▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇█▇▇████▇▇██▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▃▃▃▂▃▄▃▄▃▂▂▃▂▃▂▂▂▁▂▂▂▂▂▂▂▂▂▁▂▁▂▁▂▁▂▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▅▆▅▇▃▅▆▄▃▆▄▁▆▃▄▄▃▆▅▄▄▄▄▄▄▄▅▃▄▂▅▃▄▃▃▃▃▅▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▁▅▇▇▆▆▆▇▇▆▇██▇▇▇▇██▇▇▇▇▇▇█▇█▇█▇▇▇▇▇▆▇▇▇</td></tr><tr><td>val_auc</td><td>▁▅▅▆▆▆▅▆▇▆▇▅▅▆▆▆▄▆▇▇▆▇▇▇▆██▇▇▇█▇▇▆▆▅▇▇▇▄</td></tr><tr><td>val_f1</td><td>▁▁▅▇▇▆▆▇▇▇▇██████▇██▇██▇█████▇█▇▇█▇█▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▇▄▂▂▂▃▂▂▁▂▁▁▁▁▂▂▂▁▁▁▁▁▂▁▁▁▁▁▂▁▁▁▁▂▂▂▂▂▂</td></tr><tr><td>val_loss_step</td><td>█▇▄▂▃▃▃▂▃▂▃▂▂▁▂▃▃▁▂▂▁▂▃▂▁▁▂▂▂▂▂▂▂▂▂▃▁▂▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85891</td></tr><tr><td>train_auc</td><td>0.93269</td></tr><tr><td>train_f1</td><td>0.85982</td></tr><tr><td>train_loss_epoch</td><td>0.33092</td></tr><tr><td>train_loss_step</td><td>0.21512</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80851</td></tr><tr><td>val_auc</td><td>0.91163</td></tr><tr><td>val_f1</td><td>0.76106</td></tr><tr><td>val_loss_epoch</td><td>0.40281</td></tr><tr><td>val_loss_step</td><td>0.44353</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fvdzw6ej' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fvdzw6ej</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_133503-fvdzw6ej\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_140048-01rui0qb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/01rui0qb' target=\"_blank\">GraphConv_3_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/01rui0qb' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/01rui0qb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_2\\attention2\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 18.5 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "24.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.8 K    Total params\n",
      "0.099     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aa62fa1952c4605ad24abdf55b1eaf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▆▆▆▆▇▆▇▇▇▇▇█▇▇▇▇▇▇▇▇█▇██████████▇▇█▇</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇▇▇██▇██████████▇██</td></tr><tr><td>train_f1</td><td>▁▅▅▆▆▇▆▆▇▆▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇▇██▇██████▇▇█▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▃▃▃▃▃▃▃▂▂▂▃▁▂▂▂▂▂▃▂▂▁▁▂▂▂▂▁▁▁▂▁▁▂▂▁▂</td></tr><tr><td>train_loss_step</td><td>▆▆▃▄▂▂▃▃▃▃▁▂▂▂▂▁▁▃▂▂▁▂█▂▁▃▅▅▂▁▃▄▄▃▁▁▁▂▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁█▇▇▇█▇█████▇▇▇▇▇█▇▇███▇██▇██████▇█▇███▇</td></tr><tr><td>val_auc</td><td>▁▆▆▆▆▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇▇▇▇▇▆█▇█▇</td></tr><tr><td>val_f1</td><td>▁▇▇▃▆▇▇█▇▇▇▇▄▅▇▇▇▇▇▅▇▇▆▇▆████▇▇█▇▆▇▇▇▆▆█</td></tr><tr><td>val_loss_epoch</td><td>█▂▂▃▅▃▃▁▂▁▂▂▂▃▄▃▃▁▃▁▃▄▃▃▂▂▄▃▂▂▃▂▂▂▂▄▃▂▄▃</td></tr><tr><td>val_loss_step</td><td>▆▃▃▃█▅▆▂▃▁▃▂▂▂▄▄▃▁▄▁▄▄▄▅▂▃▃▂▁▃▄▂▂▁▃▃▇▂▆▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87603</td></tr><tr><td>train_auc</td><td>0.95026</td></tr><tr><td>train_f1</td><td>0.87574</td></tr><tr><td>train_loss_epoch</td><td>0.28816</td></tr><tr><td>train_loss_step</td><td>0.30007</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81797</td></tr><tr><td>val_auc</td><td>0.91528</td></tr><tr><td>val_f1</td><td>0.81967</td></tr><tr><td>val_loss_epoch</td><td>0.42396</td></tr><tr><td>val_loss_step</td><td>0.43862</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/01rui0qb' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/01rui0qb</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_140048-01rui0qb\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_142317-xk9az3mh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/xk9az3mh' target=\"_blank\">GCN_4_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/xk9az3mh' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/xk9az3mh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_2\\mean\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 1.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e271e611b8d54b58a2d5becfc711c134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇███▇███▇███████████████████████████</td></tr><tr><td>train_auc</td><td>▁▇▇▇██▇█▇█▇█▇█▇█████████████████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▇▇▇▇▇█▇█▇▇▇▇▇█▇█████▇██▇██▇▇████▇███</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▁▂▂▂▂▂▂▂▂▁▂▂▁▁▂▁▁▂▁▁▂▁▁▂▁▂▂▁▁▁▂▁▂▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▃▄▂▃▃▃▅▄▄▅▆▂▃▃▂▁▃▃▄▄▃▃▄▄▂▄▄▄▄▅▅▄▄▃▅▃▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁█▄▅▇▆▇▇▇▆▇▇▇▆▆▇▇▆██▆▇█▆▇█▇▇▇▇█▇▆▇▇▇▇▇█▆</td></tr><tr><td>val_auc</td><td>▁▅▆▇▇▇▇▇▇▇▆▆▆▇▆▇▇▇█▇█▇▇▇▇▇▇▇████▇███████</td></tr><tr><td>val_f1</td><td>▁█▅▆▇▆▇▇▇▆▇▇▇▇▇▇█▆██▇▇█▆▇█▇█▇▇█▇▇▇█▇▇▇█▆</td></tr><tr><td>val_loss_epoch</td><td>█▂▇▄▂▅▂▂▁▅▂▂▂▃▂▁▁▄▁▁▄▂▁▆▂▂▃▁▃▃▂▃▄▃▁▃▃▃▁▄</td></tr><tr><td>val_loss_step</td><td>▇▃▆▄▂▇▄▂▂▆▅▄▁▅▂▁▄▆▄▃▄▅▃█▂▅▅▂▃▆▅▆▅▃▂█▅▄▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83589</td></tr><tr><td>train_auc</td><td>0.89845</td></tr><tr><td>train_f1</td><td>0.83781</td></tr><tr><td>train_loss_epoch</td><td>0.39487</td></tr><tr><td>train_loss_step</td><td>0.27762</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.7565</td></tr><tr><td>val_auc</td><td>0.91872</td></tr><tr><td>val_f1</td><td>0.63604</td></tr><tr><td>val_loss_epoch</td><td>0.4719</td></tr><tr><td>val_loss_step</td><td>0.4525</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/xk9az3mh' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/xk9az3mh</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_142317-xk9az3mh\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_144531-8s0ubu4q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8s0ubu4q' target=\"_blank\">GraphConv_4_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8s0ubu4q' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8s0ubu4q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_2\\mean\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 2.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.3 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77f68d89b1db4273adc64ea1dca95451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇█████████████████▇█</td></tr><tr><td>train_auc</td><td>▁▅▆▇▇▇▇▇████████████████████████████████</td></tr><tr><td>train_f1</td><td>▁▄▅▆▇▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇█████▇███▇███████▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▃▃▃▂▂▂▂▂▂▂▂▁▂▂▁▂▁▁▁▂▁▁▁▁▁▂▁▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>██▇▄▅▄▄▅▃▄▄▃▅▃▄▄▅▄▂▆▄▃▂▃▃▃▂▄▄▄▄▂▃▃▃▅▃▁▃▆</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▇▇▇▇▇▇▇▇▇█▇▇▇▇▇██▇▇█▇▇█▇██▇▇██▇▇██▇████</td></tr><tr><td>val_auc</td><td>▁▅▆▇▇▇▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>val_f1</td><td>▁▄▆▇▆▆▅▅▆▅▇▇▆▆▇▆▇▇▆▆█▆▆▇▇██▇▆▇▇▆▆▇▆▆▆▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▂▂▁▁▂▂▃▁▁▂▂▁▁▁▂▂▁▂▂▁</td></tr><tr><td>val_loss_step</td><td>█▄▅▃▄▃▂▃▃▃▄▃▃▅▃▃▄▄▂▂▄▃▂▁▄▃▅▁▃▃▄▂▂▂▃▃▄▃▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85596</td></tr><tr><td>train_auc</td><td>0.92308</td></tr><tr><td>train_f1</td><td>0.8583</td></tr><tr><td>train_loss_epoch</td><td>0.36455</td></tr><tr><td>train_loss_step</td><td>0.48629</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83215</td></tr><tr><td>val_auc</td><td>0.91899</td></tr><tr><td>val_f1</td><td>0.82206</td></tr><tr><td>val_loss_epoch</td><td>0.34392</td></tr><tr><td>val_loss_step</td><td>0.21471</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8s0ubu4q' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8s0ubu4q</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_144531-8s0ubu4q\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bb9b10467c648609f8dbe5098bdc25c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_150704-eyg4eo5c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/eyg4eo5c' target=\"_blank\">GCN_4_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/eyg4eo5c' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/eyg4eo5c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_2\\max\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 1.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d603bc92039410c948b2523786c5e17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▂▁▁▃▅▆▆▅▆▆▇▇▇▇▇▇▇▇▇▇▇██▇██████▇███████▇█</td></tr><tr><td>train_auc</td><td>▁▁▂▃▄▅▆▆▇▇▇▇▇▇▇▇████▇███████████████████</td></tr><tr><td>train_f1</td><td>▁▂▁▁▂▂▂▁▄▄▄▅▅▅▅▄▅▆▆▅▆▇▇▆▇▇█▇▇█▇▇███▇▇█▇█</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▇▇▆▅▄▄▅▆▃▅▄▅▃▅▄▁▄▃▅▂▄▂▄▂▄▅▅▂▄▄▄▄▃▄▄▃▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▁▁██▇███▇▄▆▆▇▅▅▄█▇▄▄▅▇▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄</td></tr><tr><td>val_auc</td><td>▁▁▅▇██▆▆▆█████▇▇███▇▇▇▇▇▇▆▆▆▅▅▆▆▅▆▅▅▅▅▄▅</td></tr><tr><td>val_f1</td><td>▇▇▇██▆████▁▆▅▇▂▂▂█▇▂▁▃▇▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_epoch</td><td>███▇▆▅▄▅▄▄▅▃▃▃▃▃▄▂▂▃▂▁▁▂▁▂▂▃▁▃▄▂▃▁▃▃▃▃▃▂</td></tr><tr><td>val_loss_step</td><td>▆▆▆▅▅▄▃▄▄▃▄▄▄▃▃▃▅▂▃▃▃▁▂▄▁▂▂▄▁▄█▄▃▁▅▄▃▄▅▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.72373</td></tr><tr><td>train_auc</td><td>0.76601</td></tr><tr><td>train_f1</td><td>0.756</td></tr><tr><td>train_loss_epoch</td><td>0.56349</td></tr><tr><td>train_loss_step</td><td>0.57988</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.55556</td></tr><tr><td>val_auc</td><td>0.78008</td></tr><tr><td>val_f1</td><td>0.0</td></tr><tr><td>val_loss_epoch</td><td>0.58948</td></tr><tr><td>val_loss_step</td><td>0.55593</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/eyg4eo5c' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/eyg4eo5c</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_150704-eyg4eo5c\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1394655f3464155af3089b9f7d5c240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333330477276, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_152919-p33epqlu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/p33epqlu' target=\"_blank\">GraphConv_4_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/p33epqlu' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/p33epqlu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_2\\max\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 2.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.3 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "101a4ae09bed4ffd8f334589022f2232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▃▄▄▄▅▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇██▇███▇▇█████▇▇███</td></tr><tr><td>train_auc</td><td>▁▁▂▂▂▃▃▄▄▅▅▆▅▆▆▆▆▆▆▇▇▇▇█▇▇▇▇▇▇█▇█▇██████</td></tr><tr><td>train_f1</td><td>▁▃▃▄▅▅▅▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇█▇█▇█▇▇▇█▇█▇▇████</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▅▄▄▅▅▄▃▄▃▃▄▃▃▃▄▃▂▄▃▂▂▃▂▃▃▂▃▂▄▂▂▃▂▃▂▁▄▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▁▃▄▅▄▅▅▆▇▇▇▆▆▇▆█▇▇▆▇▆▄▆▅▅▆▆▇▆▃▅▄▅▃▅▆▅▄▅</td></tr><tr><td>val_auc</td><td>▁▃▄▅▆▆▆▇▇▇███▇███████████▇█▇████████████</td></tr><tr><td>val_f1</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▆▆▇▅█▇▇▆▇▅▄▆▅▅▅▆▇▆▃▅▄▄▃▅▆▅▄▅</td></tr><tr><td>val_loss_epoch</td><td>█▇▆▄▃▅▃▃▃▂▂▂▃▃▂▃▁▂▃▃▂▃▄▁▃▂▂▁▁▂▇▄▃▃▅▂▃▂▅▃</td></tr><tr><td>val_loss_step</td><td>▇▆▇▄▄▆▄▄▆▃▄▄▄▅▄▄▄▄▅▄▅▅▅▁▃▄▃▁▅▄█▆▄▅▆▃▇▃▇▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.7863</td></tr><tr><td>train_auc</td><td>0.85015</td></tr><tr><td>train_f1</td><td>0.79617</td></tr><tr><td>train_loss_epoch</td><td>0.46794</td></tr><tr><td>train_loss_step</td><td>0.45132</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.6383</td></tr><tr><td>val_auc</td><td>0.86806</td></tr><tr><td>val_f1</td><td>0.70746</td></tr><tr><td>val_loss_epoch</td><td>0.60736</td></tr><tr><td>val_loss_step</td><td>0.60385</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/p33epqlu' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/p33epqlu</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_152919-p33epqlu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63d3ef540297457ba14a78be4b38651d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_155034-sk5y1ndd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/sk5y1ndd' target=\"_blank\">GCN_4_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/sk5y1ndd' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/sk5y1ndd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_2\\sum\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 1.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇███▇▇██▇▇▇▇████████</td></tr><tr><td>train_auc</td><td>█▅▃▃▂▂▁▂▁▁▂▃▃▄▄▄▄▄▄▃▃▃▅▅▃▄▅▄▃▂▃▃▄▄▃▃▃▅▄▅</td></tr><tr><td>train_f1</td><td>▁▅▆▆▇▇▇▇▇█▇▇▇▇▇▇▇█▇▇▇███▇██████▇████████</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▂▂▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▃▃▂▂▂▃▄▃▃▃▄▂▂▂▂▁▃▂▃▃▂▂▃▂▁▃▃▃▂▃▃▃▂▂▃▃▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▆▆▆▆▆▅▇▆▅▆▆▇▇▅▆▅▇█▆▆▇█▇▇▇██▅▇█▆▆▇▆▅▇▇▆</td></tr><tr><td>val_auc</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_f1</td><td>▁▆▇▆▆▆▇▆▇▇▆▇▇▇█▆▇▆▇█▆▇▇█▇▇▇██▆▇█▇▆▇▆▆▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▅▃▄▄▄▂▄▂▃▇▅▂▂▁▅▄▇▂▁▆▄▂▁▂▂▂▁▂▇▂▂▃▃▂▅▆▂▃▂</td></tr><tr><td>val_loss_step</td><td>▅▄▃▅▅▄▃▄▃▄█▆▁▄▂▃▆▇▃▃▄▇▄▄▂▄▃▃▄█▆▄▄▃▃▇▅▅▅▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.82822</td></tr><tr><td>train_auc</td><td>0.32661</td></tr><tr><td>train_f1</td><td>0.83679</td></tr><tr><td>train_loss_epoch</td><td>0.40867</td></tr><tr><td>train_loss_step</td><td>0.26349</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.77778</td></tr><tr><td>val_auc</td><td>0.09916</td></tr><tr><td>val_f1</td><td>0.69281</td></tr><tr><td>val_loss_epoch</td><td>0.43737</td></tr><tr><td>val_loss_step</td><td>0.39482</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/sk5y1ndd' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/sk5y1ndd</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_155034-sk5y1ndd\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9345aed5d5784c4e9fc76c01dafd4e14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333330477276, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_161303-x7v9vszx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/x7v9vszx' target=\"_blank\">GraphConv_4_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/x7v9vszx' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/x7v9vszx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_2\\sum\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 2.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.3 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▂▃▄▅▅▅▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇███▇█████</td></tr><tr><td>train_auc</td><td>█▇▆▆▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▂▂▁▁▁▂▂▂▂</td></tr><tr><td>train_f1</td><td>▁▂▃▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█████████</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▂▂▂▂▂▂▁▁▁▁▂▁▁▁▂▁▁▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▆▁▃▄▅▅▆▆▇▇▇█▇█▇▇▇▇███▇█▇▇▇██▇▇████▇▇█▇█▇</td></tr><tr><td>val_auc</td><td>█▆▄▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_f1</td><td>▃▁▂▃▄▅▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▆█▇</td></tr><tr><td>val_loss_epoch</td><td>█▇▅▄▄▄▄▃▃▂▃▂▃▃▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▁▁▁▂▂▂▂▂▁</td></tr><tr><td>val_loss_step</td><td>█▄▄▃▄▄▃▂▃▂▃▂▃▄▃▂▃▃▃▂▃▃▂▂▂▃▂▂▂▃▂▂▂▂▃▂▃▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.82822</td></tr><tr><td>train_auc</td><td>0.22273</td></tr><tr><td>train_f1</td><td>0.83457</td></tr><tr><td>train_loss_epoch</td><td>0.42105</td></tr><tr><td>train_loss_step</td><td>0.59962</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.8156</td></tr><tr><td>val_auc</td><td>0.10493</td></tr><tr><td>val_f1</td><td>0.80102</td></tr><tr><td>val_loss_epoch</td><td>0.37763</td></tr><tr><td>val_loss_step</td><td>0.2219</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/x7v9vszx' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/x7v9vszx</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_161303-x7v9vszx\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_163435-du7ooryl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/du7ooryl' target=\"_blank\">GCN_4_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/du7ooryl' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/du7ooryl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_2\\attention\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 1.1 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▆▇▇▇▇▇██▇█▇▇▇███▇██▇███▇████████████▇█</td></tr><tr><td>train_auc</td><td>▁▄▇▇▇▇████▇██▇██████████████████████████</td></tr><tr><td>train_f1</td><td>▁▂▅▆▆▇▇▇▇▇▇▇▇▇▇██▇▇▇▇▇▇▇▇▇█▇█▇▇▇█▇▇███▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▁▂▂▂▂▂▂▂▁▂▁▂▁▂▂▁▁▁▂▂</td></tr><tr><td>train_loss_step</td><td>▆▆▅▂▃▂▃▂▃▂▃▂▆▃▂▂▁▄▃▁▂▂▄▂▃▁▃█▁▂▂▃▁▃▁▂▂▂▁▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▇▅▇▇▇▇█▆▇▇█▇█▇▇▇▇▇▇▇█▇██▇█▆█▇▇▇▇█▇▇██▇</td></tr><tr><td>val_auc</td><td>▁▅▇▇█████████████████████▇██████████████</td></tr><tr><td>val_f1</td><td>▁▄▇▅▇▇▇▇█▇▇▇█▇█▇▇▇▇▇█▇█▇██▇█▇█▇▇▇▇██▇██▇</td></tr><tr><td>val_loss_epoch</td><td>█▆▂▅▁▂▂▃▂▃▂▂▂▂▂▂▃▁▂▂▂▃▁▂▁▁▂▁▄▁▂▂▁▃▁▂▄▁▁▂</td></tr><tr><td>val_loss_step</td><td>▇▅▃▆▁▃▂▃▃▄▃▃▃▄▄▃▆▂▃▃▄▅▂▂▂▁▂▃▄▃▃▂▂▃▃▄█▃▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83294</td></tr><tr><td>train_auc</td><td>0.8978</td></tr><tr><td>train_f1</td><td>0.83911</td></tr><tr><td>train_loss_epoch</td><td>0.41652</td></tr><tr><td>train_loss_step</td><td>0.5364</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.79196</td></tr><tr><td>val_auc</td><td>0.91797</td></tr><tr><td>val_f1</td><td>0.71795</td></tr><tr><td>val_loss_epoch</td><td>0.4065</td></tr><tr><td>val_loss_step</td><td>0.38181</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/du7ooryl' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/du7ooryl</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_163435-du7ooryl\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_165639-lar2eo4p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/lar2eo4p' target=\"_blank\">GraphConv_4_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/lar2eo4p' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/lar2eo4p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_2\\attention\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 2.1 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "2.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.3 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f2c13eabaf44542a655ea34ad4acb3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▆▆▆▇▇▇▇▇▇▇▇▇▇█▇█▇████▇███████████████</td></tr><tr><td>train_auc</td><td>▁▄▅▆▆▇▇▇▇▇██████████████▇███████████████</td></tr><tr><td>train_f1</td><td>▁▂▄▅▅▆▇▇▇▇▇▇▇▇▇▇█▇▇▇██▇█▇███████████▇███</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▂▁▁▁▁▁▁▁▂▁▁▂▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>██▇▅▆▆▄▃▄▃▅▄▃▂▂▄▃▅▁▄▃▃▃▂▃▂▁▃▃▂▄▂▄▁▃▃▆▂▃▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆█▇▇▇███▇████████▇█▇███▇█▇▇█████▇██████</td></tr><tr><td>val_auc</td><td>▁▄▆▆▇▇▇▇█▇▇█████████████████████████████</td></tr><tr><td>val_f1</td><td>▁▅▇▄▅▅▇▇▇▇▇▇█▆▇█▇▇▆▆▆▇▇▆▅▇▅▅▇▆▆▇█▅▆▇▆█▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▆▄▄▃▃▂▂▂▃▂▂▃▂▁▂▁▁▁▂▂▁▂▂▂▁▃▃▂▃▃▁▂▃▂▁▂▂▂▂</td></tr><tr><td>val_loss_step</td><td>█▇▅▅▄▇▄▅▃▅▅▄▇▂▃▃▁▁▃▄▃▃▄▃▃▁▃▅▆▅▇▁▄▆▄▃▄▄▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85478</td></tr><tr><td>train_auc</td><td>0.92039</td></tr><tr><td>train_f1</td><td>0.85813</td></tr><tr><td>train_loss_epoch</td><td>0.37521</td></tr><tr><td>train_loss_step</td><td>0.45366</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82506</td></tr><tr><td>val_auc</td><td>0.91326</td></tr><tr><td>val_f1</td><td>0.80829</td></tr><tr><td>val_loss_epoch</td><td>0.3982</td></tr><tr><td>val_loss_step</td><td>0.47677</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/lar2eo4p' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/lar2eo4p</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_165639-lar2eo4p\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1e0f43a3989435dbbe302c63678dfd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_171812-9a65qvlu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9a65qvlu' target=\"_blank\">GCN_4_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9a65qvlu' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9a65qvlu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_2\\attention2\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 1.1 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "1.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇█▇▇███▇████▇████▇█████████████████</td></tr><tr><td>train_auc</td><td>▁▆▇█▇███████████████████████████████████</td></tr><tr><td>train_f1</td><td>▁▃▆▇▇▇▇▇▇▇▇▇▇▇██▇▇█▇██▇█▇██▇▇███▇███████</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▂▂▂▂▂▂▂▂▁▂▂▁▁▂▂▂▂▁▁▂▁▁▁▁▂▂▁▂▁▂▁▁▁▁▁▂▂</td></tr><tr><td>train_loss_step</td><td>█▅▄▄▄▄▁▃▃▆▄▄▁▂▂▂▄▁▃▅▄▃▆▆▄▁▂▄▄▃▁▁▂▃▃▂▃▃▁▇</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▅▆▆▇▇▇█▇▆▇▇█▇▇█▆▅█▇█▇█▇█▇██▇█▆██▇▆██▆█</td></tr><tr><td>val_auc</td><td>▁▆▆▇▇▇▆▇▇▇▇█▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇</td></tr><tr><td>val_f1</td><td>▁▇▆▇▇▇▇▇█▇▇▇▇█▇▇█▇▆█▇█▇█▇█▇██▇█▇█▇▇▇▇█▆█</td></tr><tr><td>val_loss_epoch</td><td>█▄▄▃▃▂▂▂▂▂▃▂▃▁▄▂▂▄▆▁▃▁▂▁▄▁▃▂▁▄▁▄▁▂▂▄▂▂▅▁</td></tr><tr><td>val_loss_step</td><td>▇▅▄▃▃▃▂▃▃▅▃▄▄▂▅▂▅▂█▃▄▁▂▂▆▂▃▃▂▆▂▃▁▃▂▂▂▃▅▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83117</td></tr><tr><td>train_auc</td><td>0.90023</td></tr><tr><td>train_f1</td><td>0.83601</td></tr><tr><td>train_loss_epoch</td><td>0.42017</td></tr><tr><td>train_loss_step</td><td>0.622</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80851</td></tr><tr><td>val_auc</td><td>0.91689</td></tr><tr><td>val_f1</td><td>0.77054</td></tr><tr><td>val_loss_epoch</td><td>0.369</td></tr><tr><td>val_loss_step</td><td>0.33593</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9a65qvlu' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9a65qvlu</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_171812-9a65qvlu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_174011-26n80m2n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/26n80m2n' target=\"_blank\">GraphConv_4_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/26n80m2n' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/26n80m2n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_2\\attention2\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 2.1 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "2.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▇▇▇▇▇▇▇▇█▇▇█▇▇▇█████████▇▇▇██████████</td></tr><tr><td>train_auc</td><td>▁▆▆▇▇▇▇▇██▇█████████████████████████████</td></tr><tr><td>train_f1</td><td>▁▄▅▆▇▇▇▇▇▇▇█▇▇█▇▇▇██▇▇████▇▇▇▇▇██████▇██</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▂▂▂▂▂▁▁▂▁▁▂▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▅▃▃▂▂▂▃▂▂▄▄▃▂▃▄▃▃▁▃▂▂▂▂▃▂▃▂▂▂▂▁▂▃▃▃▂▁▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▇███▇██▇▇▇█▇▇▇█▇████████▇███▇███▇▇▇▇█▇▇</td></tr><tr><td>val_auc</td><td>▁▅▇▇▇███▇▇██████████████████████████████</td></tr><tr><td>val_f1</td><td>▁▆▇▇▆▆▇▇▄▇▇█▆▆▆▇▇▇▇▇▇▆███▅█▇█▆███▆▆▆▇▇▆▆</td></tr><tr><td>val_loss_epoch</td><td>█▄▂▃▂▂▂▂▂▂▂▂▂▂▁▂▂▁▂▂▁▁▂▂▂▂▂▂▂▁▂▂▂▁▂▂▂▂▃▂</td></tr><tr><td>val_loss_step</td><td>▇▅▃▄▃▅▄▄▃▃▂▃▃▂▁▄▅▂▃▅▂▁▃▃▃▄▃▂▂▂▃▃▃▂▃▅▃▅█▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85891</td></tr><tr><td>train_auc</td><td>0.92255</td></tr><tr><td>train_f1</td><td>0.86288</td></tr><tr><td>train_loss_epoch</td><td>0.36325</td></tr><tr><td>train_loss_step</td><td>0.44806</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80851</td></tr><tr><td>val_auc</td><td>0.91023</td></tr><tr><td>val_f1</td><td>0.79494</td></tr><tr><td>val_loss_epoch</td><td>0.39472</td></tr><tr><td>val_loss_step</td><td>0.4615</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/26n80m2n' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/26n80m2n</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_174011-26n80m2n\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_180309-frfvbf99</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/frfvbf99' target=\"_blank\">GCN_4_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/frfvbf99' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/frfvbf99</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_2\\mean\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 3.8 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇██▇███▇▇█▇█</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇▇▇██▇▇▇██████████████████████████</td></tr><tr><td>train_f1</td><td>▁▆▆▇▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇██▇▇▇▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▁▂▁▁▁▂▂▂▂▁▁▁▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▆▅▅▂▄▃▃▄▂▄▅▃▆▄▄▂▃▂▃▁▃▇▁▃▂▃▁▄▄▃▃▄▃▂▂▃▄▃▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▄▁▃▆▄▅▅▃▆▅▆▃▇▆▆▆▇▅▆▅▇▇▅▆▇▄▇▃▇▆▅▅▇▄▇▆█▆▃▆</td></tr><tr><td>val_auc</td><td>▁▆▇▇▇▇█▇▇▇▇▇████▇▇▇▇▇███▇▇▇▇██▇███▇▇▇▇▇▆</td></tr><tr><td>val_f1</td><td>▆▁▃▆▄▆▆▃▆▅▇▃▇▆▇▆▇▆▇▅▇▇▅▇▇▄▇▃▇▆▅▅▇▄▇▆█▇▃▆</td></tr><tr><td>val_loss_epoch</td><td>█▅▆▂▃▂▂▆▂▄▁▆▁▂▂▃▂▃▂▄▁▁▄▂▂▄▂▅▁▂▃▂▁▄▃▄▃▂▅▃</td></tr><tr><td>val_loss_step</td><td>▇▄█▄▃▂▄▆▂▆▂▆▂▂▃▄▃▅▂▆▁▁▄▄▆▇▅▃▁▁▄▁▂▆▇▇▇▅▃▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86423</td></tr><tr><td>train_auc</td><td>0.92376</td></tr><tr><td>train_f1</td><td>0.86628</td></tr><tr><td>train_loss_epoch</td><td>0.36284</td></tr><tr><td>train_loss_step</td><td>0.4239</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81797</td></tr><tr><td>val_auc</td><td>0.9084</td></tr><tr><td>val_f1</td><td>0.77681</td></tr><tr><td>val_loss_epoch</td><td>0.42265</td></tr><tr><td>val_loss_step</td><td>0.56588</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/frfvbf99' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/frfvbf99</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_180309-frfvbf99\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_182913-x8gnuxg4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/x8gnuxg4' target=\"_blank\">GraphConv_4_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/x8gnuxg4' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/x8gnuxg4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_2\\mean\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 7.3 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "7.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.9 K     Total params\n",
      "0.031     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7fc64f261594ab5ac7cbb97f8cc1dec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.013 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.080610…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇▇▇▇▇█▇▇███████████████████████████</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇▇▇██▇▇███████████████████████████</td></tr><tr><td>train_f1</td><td>▁▆▇▇▇▇▇▇███▇▇███████████████████████████</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▂▁▁▂▁▁▁▁▂▂▂</td></tr><tr><td>train_loss_step</td><td>█▆▅▃▃▄▃▂▃▂▃▄▂▃▂▄▂▄▃▃▃▃▁▂▅▄▂▁▃▃▁▂▂▃▄▃▂▃▁▆</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▇▇▇▇▇▇▇█▇▇▇█▇▇▇▇▇▇▇█▇██▇█▇██▇████▇▇█▇▇█</td></tr><tr><td>val_auc</td><td>▁▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████▇███▇█████▇▇▇█</td></tr><tr><td>val_f1</td><td>▁▇▇▇▇▇▇▇█▆▇▇▇▇▇▆▄▇▅▆▇▆▇▇██▇▇█▇▇█▇██▇▇▇▆▇</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▂▂▂▂▃▂▂▃▂▁▃▂▂▃▂▂▂▃▂▃▁▃▁▂▂▂▂▁▂▂▄▄▃▂▁▃▂</td></tr><tr><td>val_loss_step</td><td>▅▃▂▂▂▄▂▂▄▃▄▂▁▃▂▄▅▂▂▄▅▂▆▂▄▁▁▃▃▃▂▃▃█▄▅▂▂▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87072</td></tr><tr><td>train_auc</td><td>0.93598</td></tr><tr><td>train_f1</td><td>0.87648</td></tr><tr><td>train_loss_epoch</td><td>0.33909</td></tr><tr><td>train_loss_step</td><td>0.53167</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82979</td></tr><tr><td>val_auc</td><td>0.9155</td></tr><tr><td>val_f1</td><td>0.81347</td></tr><tr><td>val_loss_epoch</td><td>0.38372</td></tr><tr><td>val_loss_step</td><td>0.36162</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/x8gnuxg4' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/x8gnuxg4</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_182913-x8gnuxg4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_185540-p9clp1lc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/p9clp1lc' target=\"_blank\">GCN_4_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/p9clp1lc' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/p9clp1lc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_2\\max\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 3.8 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1972f8808ae544bc878cd77735322599",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▂▃▆▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇███████▇█████</td></tr><tr><td>train_auc</td><td>▁▂▁▃▅▅▆▆▇▇▇▇▇█▇▇▇▇▇▇██▇█▇███▇███▇████▇██</td></tr><tr><td>train_f1</td><td>▁▃▂▄▄▃▄▅▅▅▆▆▆▆▇▆▇▇▆▇▇█▇▇▇▇▇██▇▇███▇██▇██</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▃▃▃▂▃▂▂▂▂▁▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▅▅▄▄▄▅▄▃▄▃▁▄▄▄▂▁▄▄▃▃▅▂▃▃▃▅▃▃▃▄▃▄▃▃▄▄▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▁▁▇▇▇▇██▇▇▇▇▇▄▄▄▆▇▄▄▄▆▄▄▃▄▄▅█▆▅▇▇▄██▇██</td></tr><tr><td>val_auc</td><td>▁▁▆▆▇▇▇▇▇▇▇▇▇▆▆▆▇▇▇▇▆▆▆▆▆▇▆▆▆▇▇█▇▇███▇▇█</td></tr><tr><td>val_f1</td><td>▇▇▇██████████▇▁▁▁▆█▁▁▁▇▂▁▁▂▁▄█▆▄██▁█▇▇██</td></tr><tr><td>val_loss_epoch</td><td>██▇▆▄▄▄▄▄▃▃▂▂▂▂▂▂▂▁▂▃▃▂▂▂▃▃▃▂▁▂▂▂▂▃▂▂▂▂▂</td></tr><tr><td>val_loss_step</td><td>██▇▇▅▅▆▅▅▅▄▄▄▃▄▃▄▃▁▄▄▄▅▃▄▅▆▅▂▃▁▂▄▄▆▃▃▃▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.72963</td></tr><tr><td>train_auc</td><td>0.77778</td></tr><tr><td>train_f1</td><td>0.75869</td></tr><tr><td>train_loss_epoch</td><td>0.54723</td></tr><tr><td>train_loss_step</td><td>0.52275</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.7305</td></tr><tr><td>val_auc</td><td>0.81587</td></tr><tr><td>val_f1</td><td>0.74554</td></tr><tr><td>val_loss_epoch</td><td>0.54897</td></tr><tr><td>val_loss_step</td><td>0.54739</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/p9clp1lc' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/p9clp1lc</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_185540-p9clp1lc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_192035-s98vu53x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/s98vu53x' target=\"_blank\">GraphConv_4_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/s98vu53x' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/s98vu53x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_2\\max\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 7.3 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "7.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.9 K     Total params\n",
      "0.031     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▄▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇███▇█▇████████████</td></tr><tr><td>train_auc</td><td>▁▂▃▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██▇█▇████████████</td></tr><tr><td>train_f1</td><td>▁▁▄▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇███▇█▇████████████</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▅▄▃▃▃▃▃▃▂▃▂▂▃▃▂▄▃▂▃▂▂▁▃▃▂▂▂▂▂▂▂▂▂▃▂▂▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▆▆▇▇▇▇▇▆█▇▇▇▇▇▇█▇▆▆▇▇▇▇▅▇▇▇▆▇█▇▇▇█▇▇▇█</td></tr><tr><td>val_auc</td><td>▁▂▄▅▅▆▆▇▆▇▇▇▇▇▇▇▇▇█▇█▇▇█████▇███▇███▇█▇█</td></tr><tr><td>val_f1</td><td>▁▆▇▇▇▇▇▇▇▇███▇▇▇▇█▇▇▆█▇▇█▅▇█▇▆▇██▇███▇██</td></tr><tr><td>val_loss_epoch</td><td>██▆▆▅▅▄▄▅▄▄▄▄▄▄▄▃▂▂▃▃▃▃▂▂▃▂▂▂▃▂▁▂▂▃▁▁▁▂▁</td></tr><tr><td>val_loss_step</td><td>█▇▆▅▅▅▄▄▆▄▅▅▄▅▃▄▅▂▂▄▅▄▇▄▃▄▃▃▃▃▂▂▅█▃▃▂▁▅▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83294</td></tr><tr><td>train_auc</td><td>0.88774</td></tr><tr><td>train_f1</td><td>0.8402</td></tr><tr><td>train_loss_epoch</td><td>0.40234</td></tr><tr><td>train_loss_step</td><td>0.35855</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81324</td></tr><tr><td>val_auc</td><td>0.8787</td></tr><tr><td>val_f1</td><td>0.79587</td></tr><tr><td>val_loss_epoch</td><td>0.44532</td></tr><tr><td>val_loss_step</td><td>0.46411</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/s98vu53x' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/s98vu53x</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_192035-s98vu53x\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f90709b3ea7b4105a8d19be8f08cebf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_194412-rig1sz8o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/rig1sz8o' target=\"_blank\">GCN_4_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/rig1sz8o' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/rig1sz8o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_2\\sum\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 3.8 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a551f58a7184fad80e736b8520b0821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇██▇████▇█████▇██</td></tr><tr><td>train_auc</td><td>▄▅▅▆▆▆▆▅▆▆▆▆▄▄▅▆▇▇██▇▇▇██▆▁▃▅▆▆▇▄▁▄▅▆▇█▆</td></tr><tr><td>train_f1</td><td>▁▄▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇██▇████▇█████▇██</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▂▂▂▁▂▁▁▂▁▂▁▂▁▁▁▂▁▁▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▂▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▇▆▇▇▇▇█▆▇▇▇█▆█▇█▇▇▇▇▇▇▇▆▇▇██▇▇▆▇█▇▆▇▇▅</td></tr><tr><td>val_auc</td><td>▆▇████████████████████████▁█████▇▇██████</td></tr><tr><td>val_f1</td><td>▁▇▇▇▇▇▇▇█▇▇▇▇█▆█▇█▇▇▇▇▇█▇▇▇▇██▇▇▆██▇▆▇▇▆</td></tr><tr><td>val_loss_epoch</td><td>█▂▂▂▂▂▂▂▂▄▂▂▂▂▃▁▂▂▂▂▁▁▂▁▂▄▃▂▁▁▂▂▃▂▂▂▄▂▃▅</td></tr><tr><td>val_loss_step</td><td>█▃▄▄▃▃▃▄▃█▃▃▃▃▄▂▃▄▃▄▁▂▃▃▆▅▅▂▂▂▄▂▂▄▄▅▅▄▃█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83707</td></tr><tr><td>train_auc</td><td>0.72404</td></tr><tr><td>train_f1</td><td>0.84336</td></tr><tr><td>train_loss_epoch</td><td>0.41969</td></tr><tr><td>train_loss_step</td><td>0.48917</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.75177</td></tr><tr><td>val_auc</td><td>0.90045</td></tr><tr><td>val_f1</td><td>0.62898</td></tr><tr><td>val_loss_epoch</td><td>0.5766</td></tr><tr><td>val_loss_step</td><td>0.73885</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/rig1sz8o' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/rig1sz8o</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_194412-rig1sz8o\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da9149dca960404299a7413b50a26fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_200627-3m5jtz27</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/3m5jtz27' target=\"_blank\">GraphConv_4_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/3m5jtz27' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/3m5jtz27</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_2\\sum\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 7.3 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "7.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.9 K     Total params\n",
      "0.031     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇██▇▇█████████████████</td></tr><tr><td>train_auc</td><td>▂▄▄▄▃▃▃▁▁▂▁▂▂▂▃▁▂▃▂▄▄▃▄▆▇▅▅▃▃▃▃▅▆▅▇▄▃▃▅█</td></tr><tr><td>train_f1</td><td>▁▂▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇██▇▇█████████████████</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▂▅▄▄▄▅▅▅▆▆▆▇▇▆▇▇▇▆▇▇▇█▇▇▇▇▇█▇████▇▇█▇▇▇</td></tr><tr><td>val_auc</td><td>▄▃▄▅▅▅▅▄▅▆▁▄▃▆▇▆▇▆▇▇▇▆▇██▇▇▆▇█▇█▆▇▇▅▆▇▇█</td></tr><tr><td>val_f1</td><td>▁▂▄▃▄▄▅▅▅▆▆▆▇▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇█▇██▇▇▇▇█▇▆▇</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▂▂▃▂▂▂▂▂▂▁▁▂▂▁▁▁▂▁▁▂▁▁▁▁▂▁▂▁▁▁▂▁▁▁▂▁▁</td></tr><tr><td>val_loss_step</td><td>█▄▃▃▃▄▃▃▄▃▄▂▂▃▃▃▂▃▂▄▃▂▅▂▃▂▁▃▃▄▂▃▃▄▂▃▂▃▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84652</td></tr><tr><td>train_auc</td><td>0.76816</td></tr><tr><td>train_f1</td><td>0.85227</td></tr><tr><td>train_loss_epoch</td><td>0.40617</td></tr><tr><td>train_loss_step</td><td>0.66934</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.7896</td></tr><tr><td>val_auc</td><td>0.88142</td></tr><tr><td>val_f1</td><td>0.79634</td></tr><tr><td>val_loss_epoch</td><td>0.50614</td></tr><tr><td>val_loss_step</td><td>0.43146</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/3m5jtz27' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/3m5jtz27</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_200627-3m5jtz27\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_203001-kbt559ed</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kbt559ed' target=\"_blank\">GCN_4_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kbt559ed' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kbt559ed</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_2\\attention\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 3.8 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.018     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇█▇▇▇▇▇▇▇█▇▇▇██████▇██████▇███████▇</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇█▇▇▇▇▇█▇██▇██████████████████████▇</td></tr><tr><td>train_f1</td><td>▁▅▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████▇██████▇███████▇</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▃▂▂▂▂▂▃▂▂▂▂▁▂▂▂▂▁▂▂▂▂▁▁▂▂▁▁▂▁▁▂▁▂▁▂▃</td></tr><tr><td>train_loss_step</td><td>█▄▅▃▅▅▂▃▃▃▄▅▅▂▂▃▄▃▃▃▂▃▅▆▂▃▁▃▅▃▅▁▂▂▂▃▂▂▃▇</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▇▇▆███▇▇▇██▆▇█▆▆▅▇▆▇█▇██▇▇▇█▅▇█▇▇▅▇▆█▇█</td></tr><tr><td>val_auc</td><td>▁▅▆▇▇▇▇█▇▇▇▇▇▇▇████▇█▇██▇█▇█▇██▇█▇▇▇██▇▇</td></tr><tr><td>val_f1</td><td>▄▇▇▄▇█▇▇▇▆▇▇▄▇█▄▄▁▆▄▅▇▆█▇▆▆▆▇▂▆█▆▆▂▅▃█▆█</td></tr><tr><td>val_loss_epoch</td><td>█▂▂▄▂▂▁▁▂▂▂▂▆▁▂▅▃▇▂▄▂▂▂▁▂▃▂▃▁▇▂▂▂▂▅▄▆▁▃▂</td></tr><tr><td>val_loss_step</td><td>▇▂▄▄▃▃▂▂▃▂▂▃▇▂▃▅▄▆▂▆▂▂▃▁▂▄▂▅▂▅▃▃▁▃▅▆█▃▅▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.82468</td></tr><tr><td>train_auc</td><td>0.89139</td></tr><tr><td>train_f1</td><td>0.82642</td></tr><tr><td>train_loss_epoch</td><td>0.4285</td></tr><tr><td>train_loss_step</td><td>0.57769</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83452</td></tr><tr><td>val_auc</td><td>0.91987</td></tr><tr><td>val_f1</td><td>0.80978</td></tr><tr><td>val_loss_epoch</td><td>0.36278</td></tr><tr><td>val_loss_step</td><td>0.32181</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kbt559ed' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kbt559ed</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_203001-kbt559ed\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_205548-5a94cgix</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5a94cgix' target=\"_blank\">GraphConv_4_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5a94cgix' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5a94cgix</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_2\\attention\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 7.3 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "7.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.9 K     Total params\n",
      "0.032     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇██▇█▇▇▇▇▇▇█▇▇█▇▇██▇████████</td></tr><tr><td>train_auc</td><td>▁▅▆▇▇▇▇▇▇▇███████▇██████████████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▇▇▆▇▇▇▇▇▇███▇█▇▇▇██▇████▇▇██▇████████</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▄▃▃▃▃▂▃▂▂▂▂▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▂▂▂▂▁▂▂</td></tr><tr><td>train_loss_step</td><td>█▇▆▅▅▅▄▄▄▅▃▄▃▇▄▂▃█▃▃▄▃▂▃▃▂▃▁▃▄▃▂▃▃▃▃▂▂▂▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▁▇▇▅▅▇▇▇▇▇▇▇▇▆▇█▇▇▇▇▇▇▇▇▇▇▇███▇███▇▆▇▇█</td></tr><tr><td>val_auc</td><td>▁▃▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇▇███▇█████▇██</td></tr><tr><td>val_f1</td><td>▁▂▆▄▅▅▇▇▅▆▇▅▇▇▄▇█▆▅▇▅▇▇▆▇▇▇▄▇▇█▆▇▇█▇▃▆▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▇▃▄▅▄▃▂▂▂▂▂▂▂▄▃▂▂▂▃▂▁▃▂▂▂▁▃▁▂▂▂▁▂▂▂▃▂▂▂</td></tr><tr><td>val_loss_step</td><td>█▇▅▇▅▅▆▄▄▃▅▃▄▁█▇▄▃▃▄▃▂▄▃▅▆▁▆▁▂▃▃▃▄▆▃▆▂▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.866</td></tr><tr><td>train_auc</td><td>0.93441</td></tr><tr><td>train_f1</td><td>0.87095</td></tr><tr><td>train_loss_epoch</td><td>0.3394</td></tr><tr><td>train_loss_step</td><td>0.41319</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83452</td></tr><tr><td>val_auc</td><td>0.9163</td></tr><tr><td>val_f1</td><td>0.81081</td></tr><tr><td>val_loss_epoch</td><td>0.38203</td></tr><tr><td>val_loss_step</td><td>0.37577</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5a94cgix' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5a94cgix</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_205548-5a94cgix\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_211830-gv4i04ur</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gv4i04ur' target=\"_blank\">GCN_4_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gv4i04ur' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gv4i04ur</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_2\\attention2\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 3.8 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "5.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.4 K     Total params\n",
      "0.022     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▇▆▇█▇▇▇▇█▇███▇▇▇█▇██████▇▇████▇█▇████</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇█▇█▇▇█▇██████████████████████▇████</td></tr><tr><td>train_f1</td><td>▁▆▆▇▆▆▇▇▇▇▇▇▇▇▇█▇▇▇▇▇██▇▇▇█▇▇███▇▇█▇▇███</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▃▃▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▁▂▂▂▁▂▂▂▁▂▁▂▁▂▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▃▃▃▄▁▅▄▃▂▃▅▅▄▃▄▂▃▃▃▅▃▂▅▁▃▃▄▁▄▃▄▂▄▄▃▃▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▅▄▃▁▅▃▅▇█▆▅▆▇▇▇▇▄▅█▆▇▆██▇▇▇▇▇▇▇▅▅▇▄▆▅▇▆█</td></tr><tr><td>val_auc</td><td>▁▆▇▇▇▇▇▇███████▇█▇▇▇▇▆█▇▇▆▇██▇▇▇▇██▇▇███</td></tr><tr><td>val_f1</td><td>▇▅▃▁▅▄▅▇█▆▅▆█▇█▇▄▅█▇▇▆██▇▇▇▇▆▇▇▅▅▇▄▆▇▆▆█</td></tr><tr><td>val_loss_epoch</td><td>█▄▅▇▃▃▃▂▂▂▃▂▁▂▂▂▄▃▂▂▂▃▂▂▂▃▁▁▃▂▁▄▃▂▅▃▄▂▂▂</td></tr><tr><td>val_loss_step</td><td>▇▅▅▇▅▃▄▃▄▃▄▄▃▄▄▃▆▆▄▅▃▄▅▄▃▆▁▂▆▃▂▅▄▄█▄▆▃▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85183</td></tr><tr><td>train_auc</td><td>0.92431</td></tr><tr><td>train_f1</td><td>0.84925</td></tr><tr><td>train_loss_epoch</td><td>0.34919</td></tr><tr><td>train_loss_step</td><td>0.28289</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83924</td></tr><tr><td>val_auc</td><td>0.92356</td></tr><tr><td>val_f1</td><td>0.83495</td></tr><tr><td>val_loss_epoch</td><td>0.36953</td></tr><tr><td>val_loss_step</td><td>0.38548</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gv4i04ur' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gv4i04ur</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_211830-gv4i04ur\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_214117-vdjpfb5d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/vdjpfb5d' target=\"_blank\">GraphConv_4_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/vdjpfb5d' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/vdjpfb5d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_2\\attention2\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 7.3 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "8.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.9 K     Total params\n",
      "0.036     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇▇▇▇███▇█▇██▇███▇██████████████████</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇▇▇███▇███████████████████████████</td></tr><tr><td>train_f1</td><td>▁▆▇▇▇▇▇▇▇███▇███████████████████████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▃▂▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▁▁▂▁▁▂▂▂▁▂▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▅▄▄▄▄▄▅▄▃▃▄▄▄▄▅▃▄▄▅▃▃▃▃▄▃▅▃▂▃▄▃▄▃▄▃▃▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇█▇█▇▇█▇▇▇▇█▇▆██▇█▇██▇</td></tr><tr><td>val_auc</td><td>▁▆▇▇▇▇▇█▇█▇██▇███▇███████▇▇▇████████████</td></tr><tr><td>val_f1</td><td>▁▇▇▇▇▇▇▇▇▇▆█▇▇▆▇▇▇▇▇▇▇█▆▇▆▇▅▇█▇▃█▇▇▇▇██▇</td></tr><tr><td>val_loss_epoch</td><td>█▂▃▂▂▂▂▂▄▃▂▂▂▂▂▂▂▁▂▂▄▂▂▂▃▃▂▃▂▁▂▃▂▂▃▂▂▂▁▂</td></tr><tr><td>val_loss_step</td><td>█▄▅▅▄▄▃▅▅▄▄▆▆▄▄▆▄▂▄▃▇▅▃▆▇▇▁▆▃▁▃▂▄▃▅▅▄▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86777</td></tr><tr><td>train_auc</td><td>0.93164</td></tr><tr><td>train_f1</td><td>0.86931</td></tr><tr><td>train_loss_epoch</td><td>0.32317</td></tr><tr><td>train_loss_step</td><td>0.12617</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81324</td></tr><tr><td>val_auc</td><td>0.91349</td></tr><tr><td>val_f1</td><td>0.81055</td></tr><tr><td>val_loss_epoch</td><td>0.38096</td></tr><tr><td>val_loss_step</td><td>0.24075</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/vdjpfb5d' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/vdjpfb5d</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_214117-vdjpfb5d\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae27526bc9fe4133b591caf716cfdf5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_220344-ssm50nfl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ssm50nfl' target=\"_blank\">GCN_4_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ssm50nfl' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ssm50nfl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_2\\mean\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 13.8 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.9 K    Total params\n",
      "0.064     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▇▇▇▇▇▆▇▇▇▇▇▇▇▇█▇▇▇▇▇██▇▇▇██▇█▇██▇█▇▇</td></tr><tr><td>train_auc</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇█▇▇▇▇████▇██▇██▇</td></tr><tr><td>train_f1</td><td>▁▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇█▇█▇█▇▇█▇██▇█▇██▇█▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▃▂▂▂▃▂▃▂▃▂▂▂▂▂▂▁▂▂▂▂▂▁▂▂▂▂▂▂▂▁▂▁▁▂▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▄▆▇▅▇▂▅▃▅▄▅▅▄▃▃▄▁▅▅▄▃█▃▂▅▄▃▄▃▃▂▆▃▆▄▂▄▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▆▆▆▅▆▇▆▇▆▇▇▆▅▆█▅▇▇▇█▇█▆▇█▇█▇██▇██▇███▇</td></tr><tr><td>val_auc</td><td>▁▅▅▆▇▇▆▄▆▆▆▆▅▇▆▇▇█▆▆▇▇▇██▆█▇▇▇▇█▄▇▇▆█▇▇▇</td></tr><tr><td>val_f1</td><td>▁▄▇▆▇▆▇▇▆▇▆█▇▇▆▇█▆▇█▇█▇█▆██▇█▇██▇██▇████</td></tr><tr><td>val_loss_epoch</td><td>█▅▃▄▃▄▃▂▄▂▃▁▂▂▄▃▁▄▂▁▂▁▂▁▃▁▁▂▂▂▂▁▂▁▂▂▁▂▂▁</td></tr><tr><td>val_loss_step</td><td>█▄▃▅▃▇▅▄▅▂▅▃▂▂▆▄▂▆▂▂▃▂▃▃▃▁▂▃▅▃▄▁▂▁▄▂▁▄▄▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85478</td></tr><tr><td>train_auc</td><td>0.92373</td></tr><tr><td>train_f1</td><td>0.85478</td></tr><tr><td>train_loss_epoch</td><td>0.36018</td></tr><tr><td>train_loss_step</td><td>0.3276</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82506</td></tr><tr><td>val_auc</td><td>0.92182</td></tr><tr><td>val_f1</td><td>0.79096</td></tr><tr><td>val_loss_epoch</td><td>0.36018</td></tr><tr><td>val_loss_step</td><td>0.33029</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ssm50nfl' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ssm50nfl</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_220344-ssm50nfl\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_222629-s76hmvhz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/s76hmvhz' target=\"_blank\">GraphConv_4_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/s76hmvhz' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/s76hmvhz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_2\\mean\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 26.9 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "29.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "29.0 K    Total params\n",
      "0.116     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇███▇███▇██</td></tr><tr><td>train_auc</td><td>▁▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇███▇█▇█▇███████████████</td></tr><tr><td>train_f1</td><td>▁▅▅▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇███▇█▇█▇██</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▃▂▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▂▁▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▅▄▅▅▄▄▅▄▄▅▄▃▃▅▄▄▁▃▃▃▃▃▄▄▄▃▄▃▄▃▃▄▃▃▃▄▄▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▇▇▇▇██▇▇▇▇▇█▇▇█▇█▇▆█▇▇▇█▇████▇█▇█▇████▇</td></tr><tr><td>val_auc</td><td>▁▆▇▇█▇█▇▇█▇▇▇█▇█▇▇▇▇███▇█▇▇▇▇▇▇▇█▇▇██▇██</td></tr><tr><td>val_f1</td><td>▁▆▇▇▇█▇▇▇▆▇▇▇█▆█▇▇▇▁▇▇▆▇▆▄▇▇▇▇▄█▇▇▇██▇█▆</td></tr><tr><td>val_loss_epoch</td><td>█▂▁▃▂▄▂▂▃▂▃▃▂▂▃▁▄▄▂▆▂▂▃▂▂▄▃▃▃▄▄▂▂▃▄▄▂▂▃▄</td></tr><tr><td>val_loss_step</td><td>▆▃▁▅▃▅▄▁▆▃▅▄▂▁▃▂▄▇▃▇▃▂▅▃▃▄▃▃▆█▃▂▂▂▆█▃▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.89492</td></tr><tr><td>train_auc</td><td>0.95673</td></tr><tr><td>train_f1</td><td>0.89723</td></tr><tr><td>train_loss_epoch</td><td>0.25693</td></tr><tr><td>train_loss_step</td><td>0.21981</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81087</td></tr><tr><td>val_auc</td><td>0.91086</td></tr><tr><td>val_f1</td><td>0.77143</td></tr><tr><td>val_loss_epoch</td><td>0.45299</td></tr><tr><td>val_loss_step</td><td>0.4753</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/s76hmvhz' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/s76hmvhz</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_222629-s76hmvhz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_225007-mw4z78tz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/mw4z78tz' target=\"_blank\">GCN_4_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/mw4z78tz' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/mw4z78tz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_2\\max\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 13.8 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.9 K    Total params\n",
      "0.064     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▅▅▅▅▅▅▆▆▆▆▇▇▆▇▇▇▇▇▇▇█▇█▇▇███▇▇███████</td></tr><tr><td>train_auc</td><td>▂▃▂▂▁▂▃▄▃▃▄▅▆▆▆▆▇▇▇▇▇▇▇▇▇██▇█▇█▇▇███▇███</td></tr><tr><td>train_f1</td><td>▁▂▄▄▅▅▅▅▅▆▆▆▆▇▇▆▇▇▇▇▇▇▇█▇█▇▇███▇▇███████</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▄▄▄▄▄▆▄▃▃▄▄▃▂▃▅▂▃▃▂▁▂▂▃▃▁▃▂▃▁▂▃▂▃▁▂▂▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▆▆▆▆▆▆▆▄▆▅▇▆▆▅▆▇▇▇▇▇▇██▆▇▇▇████▇▇▇▇▇▇▇</td></tr><tr><td>val_auc</td><td>▇▇▇▁▁▆▇▇▇▇█▇████████████████████████████</td></tr><tr><td>val_f1</td><td>▁▇▇▇██▇█▇▄▆▅▇▇▇▅▇▇▇▇▇▇▇██▇██████████████</td></tr><tr><td>val_loss_epoch</td><td>█▇▅▆▅▅▅▅▅▅▄▅▃▃▄▄▂▃▂▃▃▃▃▂▁▂▂▁▂▁▂▁▁▁▂▂▂▃▄▃</td></tr><tr><td>val_loss_step</td><td>▇▆▅▆▅▄▆▄▆▅▅█▄▃▆▄▃▄▂▂▅▄▆▆▁▃▃▂▅▁▄▂▁▁▄▂▄▆█▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.81523</td></tr><tr><td>train_auc</td><td>0.8786</td></tr><tr><td>train_f1</td><td>0.82246</td></tr><tr><td>train_loss_epoch</td><td>0.40541</td></tr><tr><td>train_loss_step</td><td>0.36191</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.76123</td></tr><tr><td>val_auc</td><td>0.88425</td></tr><tr><td>val_f1</td><td>0.76888</td></tr><tr><td>val_loss_epoch</td><td>0.50123</td></tr><tr><td>val_loss_step</td><td>0.5874</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/mw4z78tz' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/mw4z78tz</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_225007-mw4z78tz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_231334-gi5gx64p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gi5gx64p' target=\"_blank\">GraphConv_4_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gi5gx64p' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gi5gx64p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_2\\max\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 26.9 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "29.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "29.0 K    Total params\n",
      "0.116     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a348c9eeb1483687a264670ecfcd4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇█████████████▇█</td></tr><tr><td>train_auc</td><td>▁▃▄▃▃▃▃▄▃▃▂▃▃▄▄▄▄▄▅▆▆▆▇▅▅▆▅▇▇██▇▇▇▆▇██▆▆</td></tr><tr><td>train_f1</td><td>▁▃▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇█████████████▇█</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▂▁▁▁▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▅▄▅▄▄▄▄▅▃▄▃▂▃▄▃▃▃▃▃▂▂▃▃▃▃▂▁▂▂▃▂▄▂▃▂▃▃▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▅▆▇█▇▇▇▇████▇█▇██▇▇███████▇▇▇▇▇▇▇█▇▇▇█</td></tr><tr><td>val_auc</td><td>▆▆▆▇▇██▇▅▇▆███▆▁▁▇▇▇█████████▇██▇███████</td></tr><tr><td>val_f1</td><td>▁▂▅▅▇▇▇▇▆▇▇▇█▇▅▇▇▇▇▆▆████▇█▇▇▇▇▇▇▇███▇▇█</td></tr><tr><td>val_loss_epoch</td><td>█▇▅▅▄▄▃▂▄▃▃▃▂▃▃▃▄▃▂▃▃▂▂▂▂▂▂▂▂▄▂▂▂▃▂▃▂▁▂▁</td></tr><tr><td>val_loss_step</td><td>▇▆▅▆▅▅▄▂▆▄▅▄▃▃▄▃▄▆▂▅▄▃▅▄▃▅▂▃▄█▂▁▃▄▄▇▄▁▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85596</td></tr><tr><td>train_auc</td><td>0.7681</td></tr><tr><td>train_f1</td><td>0.86215</td></tr><tr><td>train_loss_epoch</td><td>0.33941</td></tr><tr><td>train_loss_step</td><td>0.226</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83215</td></tr><tr><td>val_auc</td><td>0.89565</td></tr><tr><td>val_f1</td><td>0.81748</td></tr><tr><td>val_loss_epoch</td><td>0.39534</td></tr><tr><td>val_loss_step</td><td>0.35337</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gi5gx64p' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gi5gx64p</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_231334-gi5gx64p\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_233624-24n3b7c8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/24n3b7c8' target=\"_blank\">GCN_4_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/24n3b7c8' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/24n3b7c8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_2\\sum\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 13.8 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.9 K    Total params\n",
      "0.064     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇█▇█▇█▇█████████</td></tr><tr><td>train_auc</td><td>▄▂▁▃▃▃▁▁▁▃▂▃▅▆▅▄▄▅▆▅▄▃▂▄▆██▇▆▇███▇▆██▇█▆</td></tr><tr><td>train_f1</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇█▇█▇█▇████████▇</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▃▃▂▃▁▂▁▁▂▂▂▂▂▂▂▁▂▂▂▁▃▁▁▂▂▂▁▁▂▁▂▂▂▁▁▂▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▆▁▄▅▅▆▅▄▃▅▆▄▄▆▅▇▆▄▅▆▂▆▃▅▅▅▅▅▃▄▃▇▆█▅▆█▅▅▆</td></tr><tr><td>val_auc</td><td>▅▂▂▅▃▁▁▁▂▅▅███▇█████▇▇▁▇█▇█▇▇███████████</td></tr><tr><td>val_f1</td><td>▇▁▄▆▆▆▅▅▄▅▆▅▅▆▅▇▆▅▅▆▃▆▄▆▅▆▆▅▄▅▄▇▇█▆▆█▅▆▆</td></tr><tr><td>val_loss_epoch</td><td>▃▅▆▃▄▃▄▅█▃▄▇▆▃▃▂▃▅▄▂▇▄█▃▄▃▃▃▆▃▆▂▂▂▄▂▁▄▄▂</td></tr><tr><td>val_loss_step</td><td>▂▂▄▂▃▃▅▄▆▂▄▇▅▂▃▂▁▄▂▂▅▃█▂▂▂▃▁▆▂▆▁▂▁▅▁▁▂▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8412</td></tr><tr><td>train_auc</td><td>0.76134</td></tr><tr><td>train_f1</td><td>0.84092</td></tr><tr><td>train_loss_epoch</td><td>0.38476</td></tr><tr><td>train_loss_step</td><td>0.24896</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.75414</td></tr><tr><td>val_auc</td><td>0.8842</td></tr><tr><td>val_f1</td><td>0.64384</td></tr><tr><td>val_loss_epoch</td><td>0.50475</td></tr><tr><td>val_loss_step</td><td>0.38326</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/24n3b7c8' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/24n3b7c8</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_233624-24n3b7c8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_000012-6k3zjpds</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6k3zjpds' target=\"_blank\">GraphConv_4_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6k3zjpds' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6k3zjpds</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_2\\sum\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 26.9 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "29.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "29.0 K    Total params\n",
      "0.116     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▆▅▆▆▆▆▆▆▇▇▇▇▇▇▇█▇▇▇█▇█▇▇▇█▇████▇█████</td></tr><tr><td>train_auc</td><td>▁▁▁▂▃▃▃▃▄▄▄▄▅▆▆▆▆▆▆▆▅▄▅▅▅▄▄▅▆▆▇▇██████▇▇</td></tr><tr><td>train_f1</td><td>▁▄▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█▇▇▇█████▇█▇████▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▂▂▂▂▂▂▂▁▂▂▁▂▂▂▂▁▁▁▁▁▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▇▇▆▇▇▇▇▇▇█▇███████████████▇▇████▇███▇▇</td></tr><tr><td>val_auc</td><td>▃▁▄▆▇▇▇▇▇███████████▇▇███▇███▇█████████▇</td></tr><tr><td>val_f1</td><td>▁▂▆▆▆▆▆▇▇▇▇▇▇▇▇███▇█▇▇▇████▇▇▇█▇▇▇▇▇▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▄▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▄▂▂▂▃▂▂▂▂▂▂▁▁▁▁▁▂▂▂▁▂▂▁▁▁▂▂▂▂▁▁▁▁▂▃▂▁▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86777</td></tr><tr><td>train_auc</td><td>0.89446</td></tr><tr><td>train_f1</td><td>0.86931</td></tr><tr><td>train_loss_epoch</td><td>0.31756</td></tr><tr><td>train_loss_step</td><td>0.27069</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81324</td></tr><tr><td>val_auc</td><td>0.89147</td></tr><tr><td>val_f1</td><td>0.81235</td></tr><tr><td>val_loss_epoch</td><td>0.48609</td></tr><tr><td>val_loss_step</td><td>0.48276</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6k3zjpds' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6k3zjpds</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_000012-6k3zjpds\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_002525-aujmsb2k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/aujmsb2k' target=\"_blank\">GCN_4_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/aujmsb2k' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/aujmsb2k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_2\\attention\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 13.8 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "16.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "16.0 K    Total params\n",
      "0.064     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇████▇█▇▇▇▇█▇█</td></tr><tr><td>train_auc</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇█▇█▇██▇▇███▇████████████▇█</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▇▆▆▇▇▇▇▇▇▇▆▇▆▇▇▇▇▇▇▇▇▇█▇█▇▇█▇▇▇▇█▇█</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▃▃▃▃▂▂▂▂▃▂▂▂▂▃▂▂▃▂▂▂▂▂▂▁▁▂▂▂▁▂▂▂▂▂▂▁</td></tr><tr><td>train_loss_step</td><td>▇▅▄▃▄▃▃▂▄▃▄▃█▄▄▃▃▅▅▂▂▄▇▃▄▁▇▄▂▃▃▄▂▆▄▄▃▃▄▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▁▇▇▆▆▅▆▇▆▇▄▆█▇█▇▅▆▇▇█▇██▇█▇▇▇█▅▇▇█▇▇▇█▇</td></tr><tr><td>val_auc</td><td>▁▅▇▇▆▇▆▇▇▆▇▇▇█▇▇▇▇▆▇▇▇▇██▇█▇▇▇█▇█▇██▇▇▇█</td></tr><tr><td>val_f1</td><td>▁▂▇▇▇▇▆▇█▆▇▅▇█▇█▇▆▆███▇██▇█▇▇▇█▅▇▇█▇▇▇█▇</td></tr><tr><td>val_loss_epoch</td><td>▆█▂▂▃▂▄▂▁▃▂▆▂▁▂▂▂▃▃▁▁▂▁▁▁▂▂▂▁▁▁▅▁▄▁▂▂▂▂▁</td></tr><tr><td>val_loss_step</td><td>▅█▂▂▃▂▄▂▁▂▃▇▃▁▄▂▂▄▃▁▁▄▁▂▁▂▄▂▁▁▃▃▂▅▂▃▂▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8595</td></tr><tr><td>train_auc</td><td>0.92556</td></tr><tr><td>train_f1</td><td>0.86275</td></tr><tr><td>train_loss_epoch</td><td>0.33909</td></tr><tr><td>train_loss_step</td><td>0.21232</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.8227</td></tr><tr><td>val_auc</td><td>0.92764</td></tr><tr><td>val_f1</td><td>0.77204</td></tr><tr><td>val_loss_epoch</td><td>0.36753</td></tr><tr><td>val_loss_step</td><td>0.30653</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/aujmsb2k' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/aujmsb2k</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_002525-aujmsb2k\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_005021-acxmmdml</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/acxmmdml' target=\"_blank\">GraphConv_4_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/acxmmdml' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/acxmmdml</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_2\\attention\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 26.9 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "29.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "29.1 K    Total params\n",
      "0.116     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇██▇▇▇███████████████▇██████</td></tr><tr><td>train_auc</td><td>▁▆▆▇▇▇▇▇▇▇▇▇████████████████████████████</td></tr><tr><td>train_f1</td><td>▁▄▅▆▆▇▇▇▇▇▇▇▇▇█▇▇▇█▇▇█▇██▇█████▇█▇███▇██</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▃▂▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▁▂▂▂▂▂▁▁▁▂▁▂</td></tr><tr><td>train_loss_step</td><td>█▆▅▅▅▄▄▅▂▄▄▃▃▃▂▄▃▅▁▄▄▄█▃▃▄▂▃▂▂▃▃▃▂▁▃▂▄▃▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▇▆▆▆▆▇▇▇▇▇▇███▇██▇█▇▇▇▇▇▇▆█▇▇▆▇▇▆█▇▇▇█</td></tr><tr><td>val_auc</td><td>▁▆▇▇█▇▇████████████████████████▇██▇██▇█▇</td></tr><tr><td>val_f1</td><td>▁▇▇▆▅▆▇██▆██▇███▇██▆█▇▇▇▇▇▇▅▇▆█▆█▇▆██▇█▇</td></tr><tr><td>val_loss_epoch</td><td>█▄▂▆▄▃▂▂▂▂▃▂▂▂▁▁▂▁▂▃▁▂▃▃▃▂▄▄▃▃▂▄▂▂▇▂▃▄▂▅</td></tr><tr><td>val_loss_step</td><td>█▄▃▇▅▄▄▅▆▄▅▃▄▃▂▄▁▁▄▅▁▃▇▇▄▅█▄▅▂▇▃▃▃█▂▃▇▃▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87603</td></tr><tr><td>train_auc</td><td>0.93934</td></tr><tr><td>train_f1</td><td>0.87603</td></tr><tr><td>train_loss_epoch</td><td>0.32228</td></tr><tr><td>train_loss_step</td><td>0.43184</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83924</td></tr><tr><td>val_auc</td><td>0.90507</td></tr><tr><td>val_f1</td><td>0.80233</td></tr><tr><td>val_loss_epoch</td><td>0.51662</td></tr><tr><td>val_loss_step</td><td>0.49358</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/acxmmdml' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/acxmmdml</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_005021-acxmmdml\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_011442-gejpfchb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gejpfchb' target=\"_blank\">GCN_4_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gejpfchb' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gejpfchb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_2\\attention2\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 13.8 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "20.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.1 K    Total params\n",
      "0.080     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇██▇▇████▇███▇██▇█</td></tr><tr><td>train_auc</td><td>▁▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇▇██▇▇▇████▇▇██▇██▇█</td></tr><tr><td>train_f1</td><td>▁▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇██▇▇████▇▇██▇████</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▃▃▃▃▃▃▂▃▂▂▂▂▂▃▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▃▂▁▂▁</td></tr><tr><td>train_loss_step</td><td>▅█▆▃▆▆▆▅▃▅▅▅▅▄▃▇▄▆▃▃▅▄▄▃▄▃▃▂▂▄▂▂▄▄▆▄▄▂▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▂▃▄▆▅▇▇▆▇▆▇▆▇▇▆▇▇▆▇▇▇▇█▇█▇▇▇▆█▇▇▆▇▇▇▇▇▆</td></tr><tr><td>val_auc</td><td>▁▅▆▇▇█▆▇▇██▆▇▆▇▆▇▆▅▆▆▆▇▇▇▇█▇▇██▆▇▆▇██▅▆▇</td></tr><tr><td>val_f1</td><td>▁▃▄▅▆▅▇█▇▇▇█▇██▇██▇▇▇▇▇█▇█▇█▇▇█▇█▇█▇▇▇█▇</td></tr><tr><td>val_loss_epoch</td><td>█▅▅▄▂▃▂▁▂▁▂▁▂▁▁▃▁▁▂▂▂▁▂▁▂▁▂▁▂▂▁▂▁▂▁▂▂▂▁▂</td></tr><tr><td>val_loss_step</td><td>█▄▅▆▂▃▄▁▂▂▂▃▄▂▂▅▃▁▂▃▂▁▄▂▂▂▂▃▃▂▂▁▃▂▂▃▂▃▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86482</td></tr><tr><td>train_auc</td><td>0.92909</td></tr><tr><td>train_f1</td><td>0.86521</td></tr><tr><td>train_loss_epoch</td><td>0.33814</td></tr><tr><td>train_loss_step</td><td>0.19848</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.77069</td></tr><tr><td>val_auc</td><td>0.92175</td></tr><tr><td>val_f1</td><td>0.6734</td></tr><tr><td>val_loss_epoch</td><td>0.43753</td></tr><tr><td>val_loss_step</td><td>0.37131</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gejpfchb' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gejpfchb</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_011442-gejpfchb\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_013935-k1iuqeys</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/k1iuqeys' target=\"_blank\">GraphConv_4_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/k1iuqeys' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/k1iuqeys</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_2\\attention2\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 26.9 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "33.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "33.2 K    Total params\n",
      "0.133     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▇▆▇▇▇▇▇▇▇▇█▇▇▇██▇▇▇▇█▇▇▇████▇█▇█▇▇█</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇█▇████████████████████</td></tr><tr><td>train_f1</td><td>▁▅▅▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇██▇▇▇▇▇▇▇▇███▇▇█▇█▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▃▃▃▂▃▃▂▂▂▂▂▂▂▂▂▂▁▂▂▁▂▁▂▂▁▁▁▁▁▁▂▁▁▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▆▇▅▄▅▃▄▂▃▄▃▂▄▄▂▃▅▁▁▃▃▆▂▂▃▃▂▃▂▂▁▂▃▄▃▄▅▄▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▂▅▆▅▃▆▆▅▆▆█▆▆▆▇▄▆▄▇█▆█▇▄▆▆▁█▇▇▆▆▃▆▇▅▄▇</td></tr><tr><td>val_auc</td><td>▁▆▆▆▆▇▇▇▇▇█▇▇▇████▇▇█████▇██▇▇▇███▇▇▇█▇▇</td></tr><tr><td>val_f1</td><td>▃▂▄▆▆▅▁▆▆▄▅▇█▅▆▆▇▆▅▃▆▇▆▇▇▂▆▅▅█▇▇▇▇▁▇▆▆▅▆</td></tr><tr><td>val_loss_epoch</td><td>█▄▅▃▃▅▄▃▃▃▁▃▃▁▂▂▂▄▃▄▂▂▄▁▂▄▃▃▇▄▂▃▃▃▇▅▂▄▆▃</td></tr><tr><td>val_loss_step</td><td>▇▅▄▃▄█▄▅▄▄▂▄▄▂▃▂▂▄▅▃▃▁▆▁▄▂▄▅▆▅▂▄▄▂▃▇▂▃▆▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.89669</td></tr><tr><td>train_auc</td><td>0.9559</td></tr><tr><td>train_f1</td><td>0.8996</td></tr><tr><td>train_loss_epoch</td><td>0.27083</td></tr><tr><td>train_loss_step</td><td>0.28198</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83924</td></tr><tr><td>val_auc</td><td>0.90865</td></tr><tr><td>val_f1</td><td>0.81111</td></tr><tr><td>val_loss_epoch</td><td>0.40955</td></tr><tr><td>val_loss_step</td><td>0.29868</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/k1iuqeys' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/k1iuqeys</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_013935-k1iuqeys\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_020404-4mcm2c9f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4mcm2c9f' target=\"_blank\">GCN_2_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4mcm2c9f' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4mcm2c9f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_3\\mean\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 528   \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "682       Trainable params\n",
      "0         Non-trainable params\n",
      "682       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45eb33fb4b564a3995c9cdb5c761e998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇▇█▇███▇▇▇███▇██▇</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇▇▇▇█▇▇██▇█▇██████▇███████████████</td></tr><tr><td>train_f1</td><td>▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████▇▇█████▇▇▇███▇██▇</td></tr><tr><td>train_loss_epoch</td><td>█▃▃▂▃▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>train_loss_step</td><td>█▄▅▄▂▄▄▃▆▅▅▇▆▃▃▅▂▅▅▂▃▃▂▃▁▄▃▅▅▃▄▄▄▃▃▆▄▄▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▂▇▆▇▇▇▇▇█▇█▆▆▇▆█▆█▇▆▇███▅▆▇██▇█▇▇▇████▇</td></tr><tr><td>val_auc</td><td>▁▅▇▇▇▇▇▇██▇█▇▇▇▇▇██▇▇▇███▇▇██████████▇██</td></tr><tr><td>val_f1</td><td>▂▁▇▆▇▇▇▇▆█▆█▅▇▇▇█▅▇▇▆████▆▆▇██▇█▇█▇██▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▄▂▂▃▃▂▂▂▂▂▂▃▂▂▂▁▂▂▂▂▁▂▂▁▃▂▂▂▂▂▁▂▂▂▁▂▂▁▂</td></tr><tr><td>val_loss_step</td><td>█▆▄▅▆▇▂▄▂▄▄▅█▄▅▃▂▃▄▄▄▁▄▂▁▃▅▄▃▃▄▂▄▂▄▂▄▅▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.82468</td></tr><tr><td>train_auc</td><td>0.89509</td></tr><tr><td>train_f1</td><td>0.81495</td></tr><tr><td>train_loss_epoch</td><td>0.40479</td></tr><tr><td>train_loss_step</td><td>0.33176</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.84397</td></tr><tr><td>val_auc</td><td>0.91305</td></tr><tr><td>val_f1</td><td>0.83902</td></tr><tr><td>val_loss_epoch</td><td>0.37511</td></tr><tr><td>val_loss_step</td><td>0.35377</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4mcm2c9f' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4mcm2c9f</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_020404-4mcm2c9f\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abebb7418e4f4496a6fe18762a3e2eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666495924, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_022633-okg8o5dh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/okg8o5dh' target=\"_blank\">GraphConv_2_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/okg8o5dh' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/okg8o5dh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_3\\mean\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 992   \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▇▇▇█▇█▇█████████▇████████████████████</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇██▇█▇▇█████████████████████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇▇██████▇███████</td></tr><tr><td>train_loss_epoch</td><td>█▅▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂▁▁▂▁▂▁▁▂▁▁▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▄▄▄▃▅▄▂▄▅▄▃▄▃▃▃▄▃▃▃▅▂▃▃▂▂▃▃▅▂▂▃▂▂▁▂▃▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▅████▇█▇██▇▇▇▇█▇▇███▇▇█▇▇▇███▇█▇▇█▇▇▇█</td></tr><tr><td>val_auc</td><td>▁▆▇███████████▇█████████████████████████</td></tr><tr><td>val_f1</td><td>▁▅▁▇▇▇█▆█▇▇█▆▇▇▆▇▇▇██▇▇▇▇▇▆▇▇▇▇▆█▆▇█▅▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▂▁▁▁▂▂▁▂▁▂▁▃▁▁▁▃▁▃▂▂▁▁▂▂▁▂▁▂▁▂▂▁▁▂▁▃▂</td></tr><tr><td>val_loss_step</td><td>█▄▂▄▂▃▃▄▄▁▅▂▄▂▇▂▁▂█▂▆▆▃▂▂▆▄▂▃▂▄▃▃▂▁▂▄▂▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85773</td></tr><tr><td>train_auc</td><td>0.93106</td></tr><tr><td>train_f1</td><td>0.85508</td></tr><tr><td>train_loss_epoch</td><td>0.33384</td></tr><tr><td>train_loss_step</td><td>0.22764</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.84634</td></tr><tr><td>val_auc</td><td>0.90991</td></tr><tr><td>val_f1</td><td>0.83791</td></tr><tr><td>val_loss_epoch</td><td>0.41356</td></tr><tr><td>val_loss_step</td><td>0.51271</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_2_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/okg8o5dh' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/okg8o5dh</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_022633-okg8o5dh\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0868d04a08a145d5985c4b31ac734145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_024958-8vfam8we</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8vfam8we' target=\"_blank\">GCN_2_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8vfam8we' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8vfam8we</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_3\\max\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 528   \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "682       Trainable params\n",
      "0         Non-trainable params\n",
      "682       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▃▆▆▇▆▇▇▇█▇▇▇▇▇▇▇▇████▇▇████▇█████████▇</td></tr><tr><td>train_auc</td><td>▁▁▂▄▅▅▅▆▄▅▆▃▅▅▆▆▆▆▆▇▅▇▇▆▆▇▇▆▆▆▇▆▇▇▇▇██▇▆</td></tr><tr><td>train_f1</td><td>▁▄▄▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇████▇▇████▇▇█████▇██▇</td></tr><tr><td>train_loss_epoch</td><td>█▃▃▂▂▂▂▂▂▂▂▂▂▁▂▁▁▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▅▄▄▅▄▃▆▄▃▃▃▄▃▃▄▂▂▃▃▂▂▁▃▂▃▃▃▃▃▂▄▂▂▂▂▄▂▁▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁█▇█▇██████████████▇█████▇██▇███████████</td></tr><tr><td>val_auc</td><td>▁▄▃▃▁▁▂▃▂▃▂▂▂▄▅▅▅▅▆▆▆▆▇█▆▇▇▇▆▇█▇█▆▅▄▆▅▄▃</td></tr><tr><td>val_f1</td><td>▁███████████████████████████████████████</td></tr><tr><td>val_loss_epoch</td><td>█▇▆▄▄▄▃▂▂▁▃▃▂▃▂▂▃▃▃▃▃▂▁▁▂▂▂▂▁▂▁▂▂▂▂▁▂▂▁▂</td></tr><tr><td>val_loss_step</td><td>██▇▅▆▇▄▄▂▁▆▅▄▆▄▄▅▅▆▇▇▄▂▂▂▄▄▃▂▅▃▄▇▇▄▂▄▆▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.71783</td></tr><tr><td>train_auc</td><td>0.68101</td></tr><tr><td>train_f1</td><td>0.71446</td></tr><tr><td>train_loss_epoch</td><td>0.58549</td></tr><tr><td>train_loss_step</td><td>0.59606</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.68322</td></tr><tr><td>val_auc</td><td>0.73509</td></tr><tr><td>val_f1</td><td>0.71368</td></tr><tr><td>val_loss_epoch</td><td>0.59483</td></tr><tr><td>val_loss_step</td><td>0.57051</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8vfam8we' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8vfam8we</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_024958-8vfam8we\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_031229-0z323g5v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0z323g5v' target=\"_blank\">GraphConv_2_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0z323g5v' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0z323g5v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_3\\max\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 992   \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▃▅▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇█▇▇██▇█████████</td></tr><tr><td>train_auc</td><td>▁▂▃▃▄▄▅▄▅▄▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇█▇▇██▇█▇███████</td></tr><tr><td>train_f1</td><td>▁▂▃▅▅▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇██▇▇▇█▇█████████████</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▃▃▃▃▃▃▂▂▃▂▂▂▂▂▂▁▁▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▆▆▅▄▄▄▄▄▄▃▂▄▂▂▃▄▃▂▃▃▃▂▂▂▁▃▂▃▂▂▂▁▁▁▂▂▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▅▇▆▇▇▇▇▇▇▇▇▇▇▇█▇▇██████████████▇██▇███</td></tr><tr><td>val_auc</td><td>▁▄▅▆▇▇▇▇▇▇█▇▇▇█▇████████▇▇▇▇█████████▇██</td></tr><tr><td>val_f1</td><td>▁▂▅▆▅▆▇▇▇▇▇▆▆▆▅▃▇▇▅▆▇▇▇▇██▆▇▇▆▇▆▇▆▆▇▆▇▇█</td></tr><tr><td>val_loss_epoch</td><td>█▇▅▄▃▂▃▂▂▂▃▂▂▂▂▂▁▂▂▁▂▂▁▁▂▁▂▂▁▂▂▂▁▂▁▁▁▁▁▂</td></tr><tr><td>val_loss_step</td><td>█▇▅▅▃▃▃▃▃▂▅▄▄▂▅▂▂▂▃▃▄▄▃▂▃▂▃▄▂▂▃▄▂▄▁▃▂▂▂▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.82881</td></tr><tr><td>train_auc</td><td>0.87813</td></tr><tr><td>train_f1</td><td>0.82759</td></tr><tr><td>train_loss_epoch</td><td>0.41493</td></tr><tr><td>train_loss_step</td><td>0.36018</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80615</td></tr><tr><td>val_auc</td><td>0.87403</td></tr><tr><td>val_f1</td><td>0.82018</td></tr><tr><td>val_loss_epoch</td><td>0.50459</td></tr><tr><td>val_loss_step</td><td>0.66904</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_2_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0z323g5v' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0z323g5v</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_031229-0z323g5v\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_033508-z5sgulid</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/z5sgulid' target=\"_blank\">GCN_2_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/z5sgulid' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/z5sgulid</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_3\\sum\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 528   \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "682       Trainable params\n",
      "0         Non-trainable params\n",
      "682       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▅▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇█▇██▇▇▇█▇███▇█▇█▇▇██▇</td></tr><tr><td>train_auc</td><td>▅▃▁▂▂▃▄▄▅▅▄▃▄▄▅▅▅▅▇▆▆▅▄▅▅▄▅▇▇█▇▆▆▆▅▆▇█▇█</td></tr><tr><td>train_f1</td><td>▁▄▄▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇█▇██▇███▇██▇▇███▇▇██▇</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▂▂▂▂▂▂▃▂▃▃▂▂▁▂▂▂▂▁▂▁▂▂▁▂▁▂▂▂▁▂▂▂▂▃▂▂▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▇▇▇▇▇▇████████████▇▇██▇█▇▇▇█▇████████▆▇</td></tr><tr><td>val_auc</td><td>▇▂▁▂▂▇██▇█▇▇███████████▇▇███████████████</td></tr><tr><td>val_f1</td><td>▁▆▅▆▆▇▅▇██▇▇▇███▇▇▇▇▆▇█▇▇▇▆▇█▇█████▇██▃▆</td></tr><tr><td>val_loss_epoch</td><td>█▂▂▂▂▂▁▂▂▂▂▂▂▂▂▁▁▁▁▂▁▁▂▁▁▁▁▁▁▂▁▁▂▁▂▁▁▂▁▁</td></tr><tr><td>val_loss_step</td><td>█▃▃▃▄▅▂▃▂▃▃▃▅▃▃▂▁▂▂▂▃▁▃▂▁▂▂▂▂▂▃▂▃▁▃▂▂▃▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.81641</td></tr><tr><td>train_auc</td><td>0.71586</td></tr><tr><td>train_f1</td><td>0.80838</td></tr><tr><td>train_loss_epoch</td><td>0.43766</td></tr><tr><td>train_loss_step</td><td>0.41794</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.84397</td></tr><tr><td>val_auc</td><td>0.90745</td></tr><tr><td>val_f1</td><td>0.83333</td></tr><tr><td>val_loss_epoch</td><td>0.41035</td></tr><tr><td>val_loss_step</td><td>0.38223</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/z5sgulid' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/z5sgulid</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_033508-z5sgulid\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe4144f1a5ee4a348c2163b01b18d331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_035632-4b2hoofg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4b2hoofg' target=\"_blank\">GraphConv_2_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4b2hoofg' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4b2hoofg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_3\\sum\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 992   \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▆▆▇▇▇▇▇▇▇▇▇█▇▇▇▇██▇███▇██▇██████████</td></tr><tr><td>train_auc</td><td>▇██▆▅▄▄▃▃▃▂▂▂▂▂▂▂▂▃▁▁▂▁▁▂▂▁▂▁▂▂▁▂▂▁▁▁▁▁▂</td></tr><tr><td>train_f1</td><td>▁▅▅▆▆▆▇▇▇▇▇▇▇▇▇█▇▇▇██████▇▇██▇██████████</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▂▂▃▂▁▂▂▂▁▂▂▂▂▁▁▁▂▂▁▁▂▁▁▂▂▂▁▁▁▂▁▁▁▁▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▂▅▅▄▅▆▆▆▆█▇██▇██▇▆▇▇▇▇▇▇▇▇▆▆▆▇▆▆▆▆▇▆▆▇▇</td></tr><tr><td>val_auc</td><td>█▇▆▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_f1</td><td>▁▅▆▆▆▆▇▇▆▆▇██████▇▇▇██▇▇█▇█▇▇▆▇▆▆▇▇▇▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▇▅▆▅▄▄▅▄▂▅▃▃▂▅▁▁▃▅▁▄▄▂▁▂▄▃▂▂▂▄▃▃▃▂▃▃▃▅▅</td></tr><tr><td>val_loss_step</td><td>▅▅▃▅▃▃▃▅▄▁▇▃▅▂▇▂▂▃█▁▇▅▃▁▃▆▅▃▃▂▆▃▄▄▁▄▄▃▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84416</td></tr><tr><td>train_auc</td><td>0.24765</td></tr><tr><td>train_f1</td><td>0.84248</td></tr><tr><td>train_loss_epoch</td><td>0.38018</td></tr><tr><td>train_loss_step</td><td>0.324</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.84634</td></tr><tr><td>val_auc</td><td>0.09443</td></tr><tr><td>val_f1</td><td>0.84108</td></tr><tr><td>val_loss_epoch</td><td>0.43805</td></tr><tr><td>val_loss_step</td><td>0.61029</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_2_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4b2hoofg' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4b2hoofg</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_035632-4b2hoofg\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_041809-x81c4w12</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/x81c4w12' target=\"_blank\">GCN_2_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/x81c4w12' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/x81c4w12</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_3\\attention\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 528   \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "699       Trainable params\n",
      "0         Non-trainable params\n",
      "699       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c36ddc5c0b4448d1a0d891c054e6bf13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇▇█▇█▇███▇▇████▇</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇██▇██████████████████▇█████</td></tr><tr><td>train_f1</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇██▇▇██▇▇████████▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▃▃▂▃▃▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▂▁▂▂▂▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▆▄▅▂▅▄▅▄▄▄▅▁▄▄▄▃▄▃▃▃▃▅▄▅▄▅▄▇▄▃▄▃▄▃▄▃▄▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▂▇▆▇▇▇▇▇▇▇█▇▇▆▇█▇█▇▇▇▇▅█▇▇▇▇▇█▇▇█▇█▇▇▆█</td></tr><tr><td>val_auc</td><td>▁▅▇▆▇▇▇▇▇▇███▇██▇██▇█▇▇███▇▇▇▇████▇█▇▇▇█</td></tr><tr><td>val_f1</td><td>▅▁▇▆▇▇▇▇▇███▇▇▇█▇▇█▇▇▇▇▆██▇▇▇▇█▇██▇█▆▇▆█</td></tr><tr><td>val_loss_epoch</td><td>█▄▂▃▂▂▂▂▂▂▂▂▂▂▃▂▂▂▂▁▁▂▂▄▂▂▁▁▂▂▁▂▂▂▁▂▂▂▂▁</td></tr><tr><td>val_loss_step</td><td>█▄▃▆▁▃▅▂▄▂▃▂▃▆▆▄▃▂▃▂▃▄▄▆▅▂▂▂▄▅▂▂▃▆▁▅▃▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83589</td></tr><tr><td>train_auc</td><td>0.91087</td></tr><tr><td>train_f1</td><td>0.83333</td></tr><tr><td>train_loss_epoch</td><td>0.37604</td></tr><tr><td>train_loss_step</td><td>0.2617</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.86052</td></tr><tr><td>val_auc</td><td>0.91915</td></tr><tr><td>val_f1</td><td>0.86052</td></tr><tr><td>val_loss_epoch</td><td>0.3421</td></tr><tr><td>val_loss_step</td><td>0.23443</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/x81c4w12' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/x81c4w12</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_041809-x81c4w12\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_043930-9lq8pz1k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9lq8pz1k' target=\"_blank\">GraphConv_2_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9lq8pz1k' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9lq8pz1k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_3\\attention\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 992   \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▇▇▇▇▇▇██▇█▇██▇██████████████████▇████</td></tr><tr><td>train_auc</td><td>▁▅▇▇▇▇▇▇▇███████████████████████████████</td></tr><tr><td>train_f1</td><td>▁▄▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇█▇▇▇▇█████████▇▇▇██</td></tr><tr><td>train_loss_epoch</td><td>█▅▃▃▂▂▂▂▃▂▁▂▂▂▁▂▂▂▁▁▁▂▁▂▁▂▂▁▂▁▁▁▂▂▁▂▁▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▇▄▄▄▃▃▃▅▄▃▄▄▄▄▄▃▅▃▅▃▃▂▄▃▃▃▃▃▄▃▂▅▂▃▃▁▄▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▇███▇▇██▇▇▇██▇▇▇▇█▇▇▇███▇▇█▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>val_auc</td><td>▁▅▇█████████▇▇███▇███▇▇████▇▇█▇▇▇████▇▇█</td></tr><tr><td>val_f1</td><td>▁▅▅▇▇▇▆▆▇▇▆▆▅▇█▇▇▇▇█▆▆▆▇██▇▆▇▄▇▇▅▆▆▅▆▅▆▇</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▁▂▂▂▂▂▂▂▁▃▂▁▂▂▂▂▂▄▃▂▂▃▁▂▂▂▃▁▂▃▂▂▂▂▂▃▂</td></tr><tr><td>val_loss_step</td><td>█▄▅▁▄▅▄▄▄▃▃▂▄▅▂▄▃▃▄▂▅▆▃▅▆▂▃▃▄▇▁▄▄▄▃▅▄▂▅▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86068</td></tr><tr><td>train_auc</td><td>0.92523</td></tr><tr><td>train_f1</td><td>0.86068</td></tr><tr><td>train_loss_epoch</td><td>0.35411</td></tr><tr><td>train_loss_step</td><td>0.36428</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82979</td></tr><tr><td>val_auc</td><td>0.90399</td></tr><tr><td>val_f1</td><td>0.82857</td></tr><tr><td>val_loss_epoch</td><td>0.38725</td></tr><tr><td>val_loss_step</td><td>0.32407</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_2_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9lq8pz1k' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9lq8pz1k</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_043930-9lq8pz1k\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_050045-tr9yizqq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tr9yizqq' target=\"_blank\">GCN_2_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tr9yizqq' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tr9yizqq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_3\\attention2\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 528   \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "963       Trainable params\n",
      "0         Non-trainable params\n",
      "963       Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇█▇█▇████▇▇▇██████▇▇</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇▇▇███▇█████████████████████</td></tr><tr><td>train_f1</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇█▇█▇██▇▇▇▇▇▇████▇██</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▂▃▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▂▂▂▁▁▁▁▂▂▂</td></tr><tr><td>train_loss_step</td><td>█▅▄▃▃▄▂▃▃▂▃▄▄▅▁▅▂▆▃▂▄▂▇▃▂▄▂▂▂▁▃▂▄▃▄▄▄▂▄▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▇▆▇▆█▇▆▇▅▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇</td></tr><tr><td>val_auc</td><td>▁▆▇▇▇█▇▇▇▇▇▇▇█▇███▇█▇██▇▇▇▇▇███▇▇█▇▇███▇</td></tr><tr><td>val_f1</td><td>▁▂▇▅▇▆██▆▇▅██▇█▇██▇▆▇▇█▇▇▇▇▇▆██▇█▇█▇██▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▃▁▂▂▂▂▂▂▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▃▂▁▂▁▂</td></tr><tr><td>val_loss_step</td><td>█▅▅▅▂▃▄▅▃▃▅▄▆▃▅▃▄▄▃▄▃▅▄▅▃▄▄▄▁▄▄▃▃▄▆▄▁▄▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83117</td></tr><tr><td>train_auc</td><td>0.90949</td></tr><tr><td>train_f1</td><td>0.83391</td></tr><tr><td>train_loss_epoch</td><td>0.38631</td></tr><tr><td>train_loss_step</td><td>0.32081</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.84161</td></tr><tr><td>val_auc</td><td>0.91128</td></tr><tr><td>val_f1</td><td>0.83855</td></tr><tr><td>val_loss_epoch</td><td>0.37904</td></tr><tr><td>val_loss_step</td><td>0.37018</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tr9yizqq' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tr9yizqq</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_050045-tr9yizqq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_052155-2bgf31sb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/2bgf31sb' target=\"_blank\">GraphConv_2_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/2bgf31sb' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/2bgf31sb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_3\\attention2\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 992   \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "1.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.4 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇▇▇▇█▇██▇███████▇██████████████████</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇▇████████████████████████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇███▇▇▇██▇████▇██▇▇███▇██</td></tr><tr><td>train_loss_epoch</td><td>█▅▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▂▂▂▁▁▂▁▁▁▂▁▁▂▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▆▅▄▃▃▅▃▅▂▅▂▄▅▃▃▄▂▃▄▃▁▄▃▄▅▂▂▄▂▂▃▂▂▂▃▃▃▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▇▇▇█▆█▇▇█▇▇▇▇▇▇█▇█▇██▇▇▇█▇███▇█▇██▇▇█▇</td></tr><tr><td>val_auc</td><td>▁▅▇▇▇█▇█████▇▇████████████████▇█████▇▇█▇</td></tr><tr><td>val_f1</td><td>▁▁▅▇▆▇▃▇▆▆▇▇▇▆▇▅▆▇▆▇▆█▇▅▇▆▇▆██▇▆█▄▇▇▅▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▂▂▁▂▂▃▁▁▂▂▂▂▁▂▃▂▂▁▂▁▂▂▂▂▂▂▁▁▂▂▂▁▁▃▂▃▃</td></tr><tr><td>val_loss_step</td><td>█▅▄▅▅▃▃▄▇▄▂▅▅▄▃▂▄█▅▄▂▃▃▃▃▃▃▄▆▃▂▆▃▃▁▃▆▄▆▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85537</td></tr><tr><td>train_auc</td><td>0.92581</td></tr><tr><td>train_f1</td><td>0.85443</td></tr><tr><td>train_loss_epoch</td><td>0.35283</td></tr><tr><td>train_loss_step</td><td>0.50309</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82979</td></tr><tr><td>val_auc</td><td>0.90352</td></tr><tr><td>val_f1</td><td>0.8371</td></tr><tr><td>val_loss_epoch</td><td>0.4525</td></tr><tr><td>val_loss_step</td><td>0.59488</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_2_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/2bgf31sb' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/2bgf31sb</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_052155-2bgf31sb\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_054402-ccirj03m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ccirj03m' target=\"_blank\">GCN_2_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ccirj03m' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ccirj03m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_3\\mean\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 1.6 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇█▇███▇▇▇██▇█▇▇███▇▇██▇▇█</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇▇▇▇▇█▇▇▇██▇███▇███▇▇█▇████▇▇█████</td></tr><tr><td>train_f1</td><td>▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████▇█▇██▇█▇▇███▇▇███▇█</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▃▂▂▂▂▂▃▂▂▂▂▂▁▂▁▂▂▂▂▂▁▂▂▂▂▂▂▂▁▂▂▂▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▄▅▆▇▄▄▄▆▄▅▅▆▅▅▆▂▄▃▅▄▄█▃▄▂▅▂▂▄▅▄▄▂▄▅▇▇▅▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▁▆▇▇▆▇▇▇▆█▆██▇█████▇█▇▇█▇███▇▇▇█▇▇▇▇▇▇▇</td></tr><tr><td>val_auc</td><td>▁▆▇▇▇▇▇▇▇▇▇██▇▇▇██▇███▇▇█▇███▇▇███████▇▇</td></tr><tr><td>val_f1</td><td>▅▁▇▇▇▇▇█▇▇█▆████████▇██▇█████▇▇▇███▇▇██▇</td></tr><tr><td>val_loss_epoch</td><td>█▇▂▂▂▂▂▂▂▃▂▃▂▂▂▂▂▂▂▂▂▁▂▂▃▃▁▂▁▂▂▁▂▂▂▂▁▂▃▂</td></tr><tr><td>val_loss_step</td><td>▇█▃▄▂▃▃▃▃▅▂▄▃▄▂▃▄▄▂▄▅▁▄▃▆▅▂▃▂▃▂▂▄▅▂▃▃▃▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84357</td></tr><tr><td>train_auc</td><td>0.916</td></tr><tr><td>train_f1</td><td>0.83949</td></tr><tr><td>train_loss_epoch</td><td>0.3621</td></tr><tr><td>train_loss_step</td><td>0.20943</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.84161</td></tr><tr><td>val_auc</td><td>0.91461</td></tr><tr><td>val_f1</td><td>0.82952</td></tr><tr><td>val_loss_epoch</td><td>0.3976</td></tr><tr><td>val_loss_step</td><td>0.4668</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ccirj03m' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ccirj03m</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_054402-ccirj03m\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_060536-f7tazg2m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/f7tazg2m' target=\"_blank\">GraphConv_2_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/f7tazg2m' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/f7tazg2m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_3\\mean\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 3.0 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "3.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 K     Total params\n",
      "0.014     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60bfcb8d2c484646bf57ee5b4db668c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇██▇▇█▇██▇███████▇█▇</td></tr><tr><td>train_auc</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████▇██▇█████▇██████████</td></tr><tr><td>train_f1</td><td>▁▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇█▇█▇▇██▇▇█▇█▇▇███████▇█▇</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▁▂▂▂▁▂▁▂▂▂▁▂▁▁▁▁▁▁▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▇▄▃▂▃▃▃▂▄▃▂▂▂▃▂▁▆▁▃▂▁▃▃▂▂▃▃▂▂▃▄▃▂▂▃▂▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▅▆▇▇█▇▇▆▇▇▇▆▆▇▇▇▆█▇▇█▇▇▇▆▇█▇▅▇▇▇▇▇▆▇▇▇</td></tr><tr><td>val_auc</td><td>▁▅▆▇▇▇██▇▇▇▇▇▇▇▇█▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇</td></tr><tr><td>val_f1</td><td>▁▄▅▆▇▇██▇▆███▆▆▇▇█▆█▇▇█▇▇▇▆▇██▅▇▇▇▇▇▆▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▂▂▃▂▃▃▂▃▄▂▃▂▁▁▃▂▃▂▄▁▂▃▃▂▂▃▃▄▃▄▂▃▄▄▃▂▂</td></tr><tr><td>val_loss_step</td><td>▆▄▃▃▃▄▃▅▅▂▄▇▃▅▄▂▁▅▃▆▃█▂▃▄▄▃▂▄▄▅▃▆▃▄▇▆▄▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86364</td></tr><tr><td>train_auc</td><td>0.94186</td></tr><tr><td>train_f1</td><td>0.86323</td></tr><tr><td>train_loss_epoch</td><td>0.302</td></tr><tr><td>train_loss_step</td><td>0.25714</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83924</td></tr><tr><td>val_auc</td><td>0.90345</td></tr><tr><td>val_f1</td><td>0.8381</td></tr><tr><td>val_loss_epoch</td><td>0.39622</td></tr><tr><td>val_loss_step</td><td>0.35112</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_2_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/f7tazg2m' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/f7tazg2m</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_060536-f7tazg2m\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97537f3f57704cca8cd2076b352b7887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_062642-jz83soed</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jz83soed' target=\"_blank\">GCN_2_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jz83soed' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jz83soed</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_3\\max\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 1.6 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▅▇▆▆▆▆▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇██▇██▇██▇████████</td></tr><tr><td>train_auc</td><td>▁▂▄▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇██▇██▇█████</td></tr><tr><td>train_f1</td><td>▁▂▄▆▅▅▅▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇███▇████</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▃▃▃▃▃▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▂▁▁▂▁▁▂▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▇▆▆▆▅▄▄▆▆▅█▅▃▃▅▆▃▃▄▆▄▃▄▃▄▁▃▃▃▃▄▂▄▄▅▅▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇█▇▇▇▇▇▇▇▇▇█▇▇▇▇▇</td></tr><tr><td>val_auc</td><td>▁▃▃▂▃▃▃▃▄▄▄▄▅▆▅▆▆▆▇▇▇▇██▆▇▇▇▇▇█▇▇▇▇▆▇▇▇▇</td></tr><tr><td>val_f1</td><td>▁▂██████████████████████████████████████</td></tr><tr><td>val_loss_epoch</td><td>█▇▆▅▅▅▄▄▄▄▄▄▃▃▄▃▃▃▂▃▃▃▄▂▂▁▁▂▂▂▂▁▂▂▁▂▁▁▃▂</td></tr><tr><td>val_loss_step</td><td>▇▇▆▅▅▆▄▅▆▅▄▆▄▃▅▄▄▅▁▄▅▅▄▅▄▁▂▄▃▅▅▂▆▄▂█▃▄█▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.76505</td></tr><tr><td>train_auc</td><td>0.83013</td></tr><tr><td>train_f1</td><td>0.77463</td></tr><tr><td>train_loss_epoch</td><td>0.48812</td></tr><tr><td>train_loss_step</td><td>0.3944</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.6974</td></tr><tr><td>val_auc</td><td>0.79965</td></tr><tr><td>val_f1</td><td>0.74603</td></tr><tr><td>val_loss_epoch</td><td>0.55111</td></tr><tr><td>val_loss_step</td><td>0.61311</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jz83soed' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jz83soed</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_062642-jz83soed\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_064754-7jhcsrfn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7jhcsrfn' target=\"_blank\">GraphConv_2_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7jhcsrfn' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7jhcsrfn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_3\\max\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 3.0 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "3.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 K     Total params\n",
      "0.014     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▄▅▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇████████</td></tr><tr><td>train_auc</td><td>▁▂▃▃▄▄▃▃▄▄▄▅▅▅▆▇▆▆▆▇▆▇▇▇▆▆▇▇████▇▇█▇████</td></tr><tr><td>train_f1</td><td>▁▂▄▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇████████</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▆▅▅▄▃▅▅▃▄▃▃▃▃▃▂▃▄▂▄▂▄▃▅▃▃▁▂▃▃▃▃▃▂▂▄▂▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▅▆▇▇▇▇█▇█▇▇▇▇▇▇▆▇▇█▆▇▇█▇▇█▇▇▇▇▇▇▇▇▇▇██</td></tr><tr><td>val_auc</td><td>▁▄▅▆▇▇█▇▇▇█▇▇▇████████▇██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>val_f1</td><td>▁▄▆▆▇▇█▇█▆█▇▇▆▇▇▇▇▆▇█▅▇▇█▇▇██▇▇▇▇▇▇▇█▆██</td></tr><tr><td>val_loss_epoch</td><td>█▇▅▃▃▂▂▃▃▂▂▂▁▂▂▁▂▁▁▁▁▃▁▂▁▁▂▁▃▂▂▂▁▁▁▂▁▂▂▁</td></tr><tr><td>val_loss_step</td><td>█▇▇▄▅▃▃▅▅▂▅▅▁▄▄▃▄▃▂▃▃▆▂▅▃▃▄▃▆▅▄▆▂▃▂▄▃▃▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84829</td></tr><tr><td>train_auc</td><td>0.85622</td></tr><tr><td>train_f1</td><td>0.85032</td></tr><tr><td>train_loss_epoch</td><td>0.3719</td></tr><tr><td>train_loss_step</td><td>0.31824</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80378</td></tr><tr><td>val_auc</td><td>0.85985</td></tr><tr><td>val_f1</td><td>0.80742</td></tr><tr><td>val_loss_epoch</td><td>0.44525</td></tr><tr><td>val_loss_step</td><td>0.34172</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_2_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7jhcsrfn' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7jhcsrfn</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_064754-7jhcsrfn\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_070819-4k4u2htx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4k4u2htx' target=\"_blank\">GCN_2_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4k4u2htx' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4k4u2htx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_3\\sum\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 1.6 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▆▇▇▇▇▇▇▇▇▇▇▇█▇███▇▇▇▇█▇██▆▇██▇██▇███</td></tr><tr><td>train_auc</td><td>▁▁▂▃▃▄▆▅▆▇▇▇▇█▇███▇▇▇▇▆▇█▇▇▇▇▆▄▅▆▅▅▅▄▄▅▄</td></tr><tr><td>train_f1</td><td>▁▃▅▆▆▆▆▇▇▇▇▇▇▇▇▇█▇▇▇█▇▇▇▇█▇██▇▇██▇▇█▇█▇█</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▂▃▂▂▂▂▂▂▂▂▃▂▂▂▁▂▁▂▂▂▂▁▂▁▂▁▁▂▂▂▂▁▂▂▂▂▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▇▇▇▇▇████▇██▆▇▇▄▇▇█▇▇▇▇███▇▇█████▇▇█▆▇</td></tr><tr><td>val_auc</td><td>▁▆▇▇▇██████████████████████████████████▇</td></tr><tr><td>val_f1</td><td>▂▃▇▇▇▇▆██▇█▇██▅▇▇▁▇▇█▇▇▇▇▇██▇▆█▇███▆▇█▆▇</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▂▁▂▂▂▂▃▂▂▂▂▂▂▄▃▂▂▃▁▃▂▃▃▁▂▁▂▂▁▂▂▂▂▁▂▂▃</td></tr><tr><td>val_loss_step</td><td>▇▄▂▃▁▃▃▂▃▇▂▃▂▃▂▃▆▅▂▅▅▁▆▃▆█▂▃▁▁▂▁▄▄▂▄▂▄▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.82999</td></tr><tr><td>train_auc</td><td>0.75679</td></tr><tr><td>train_f1</td><td>0.82545</td></tr><tr><td>train_loss_epoch</td><td>0.39609</td></tr><tr><td>train_loss_step</td><td>0.26776</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.85106</td></tr><tr><td>val_auc</td><td>0.89273</td></tr><tr><td>val_f1</td><td>0.85246</td></tr><tr><td>val_loss_epoch</td><td>0.43024</td></tr><tr><td>val_loss_step</td><td>0.54186</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4k4u2htx' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4k4u2htx</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_070819-4k4u2htx\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_072909-9n92hgt1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9n92hgt1' target=\"_blank\">GraphConv_2_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9n92hgt1' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9n92hgt1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_3\\sum\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 3.0 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "3.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 K     Total params\n",
      "0.014     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇██▇██████████</td></tr><tr><td>train_auc</td><td>▂▁▂▃▅▅▅▆▅▅▆▅▄▅▄▅▆▆▇▇▇▇▇▇█▆▄▃▅▆██▇▇▇▅▆▇▇▄</td></tr><tr><td>train_f1</td><td>▁▃▄▅▆▆▆▇▆▇▇▇▇▇▇▇▇▇█▇▇██▇██▇██▇███████▇██</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▂▁▁▁▁▂▁▁▁▂▁▁▁▁▂▁▁▁▂▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▆▇▆▇▇██▇███████▇████▇▇███▇██▇▇▇█▇▇█▇█▇</td></tr><tr><td>val_auc</td><td>▂▁▅▆▆▆▇▇▇█▇▇▇▇█████████████▇▇▇▇▇▇▇▇▇▇▇▇▆</td></tr><tr><td>val_f1</td><td>▁▆▇▇▇▇▇██▇██████████████████████████████</td></tr><tr><td>val_loss_epoch</td><td>█▂▂▂▂▂▂▂▂▁▂▂▁▂▁▁▁▂▂▂▁▃▁▁▁▂▁▁▁▂▂▂▂▂▁▂▂▂▁▁</td></tr><tr><td>val_loss_step</td><td>█▄▄▃▄▅▃▅▅▂▄▅▂▅▃▂▁▅▃▅▂█▂▃▃▄▃▃▂▃▂▃▅▅▃▇▅▄▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85478</td></tr><tr><td>train_auc</td><td>0.70872</td></tr><tr><td>train_f1</td><td>0.85444</td></tr><tr><td>train_loss_epoch</td><td>0.36513</td></tr><tr><td>train_loss_step</td><td>0.36752</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83924</td></tr><tr><td>val_auc</td><td>0.87616</td></tr><tr><td>val_f1</td><td>0.84038</td></tr><tr><td>val_loss_epoch</td><td>0.3998</td></tr><tr><td>val_loss_step</td><td>0.35056</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_2_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9n92hgt1' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9n92hgt1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_072909-9n92hgt1\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_075008-qokih90c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qokih90c' target=\"_blank\">GCN_2_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qokih90c' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qokih90c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_3\\attention\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 1.6 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "2.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.2 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇█▇▇▇███▇██▇▇██▇</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇█▇███▇█████████████</td></tr><tr><td>train_f1</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇██▇▇▇███▇██▇███▇</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▃▃▂▂▂▃▂▂▂▂▂▂▂▂▂▂▁▂▁▂▂▂▁▂▁▂▂▁▁▁▁▁▂▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▆█▃▅▁▄▆▂▃▂▅▃▄▃▃▂▄▄▄▂▄▂▂▅▃▃▄▃▃▄▄▄▃▃▁▄▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▂▁▆▆█▇▅▆▆▆▅█▆▇▇▅▆▇▆█▇▆▆▆▆▅▇▆▇▆▆▇▇▅▄▇▆█▄▇</td></tr><tr><td>val_auc</td><td>▁▅▇▇██▇▇▇█▇████▇▇▇█▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇██▇</td></tr><tr><td>val_f1</td><td>▄▁▇▆██▅▇▇▇▆████▇▆▇▇██▆▇▇▆▇▇▇█▇▆█▇▇▆▇▇█▆█</td></tr><tr><td>val_loss_epoch</td><td>█▄▂▂▂▂▂▃▂▃▃▁▂▁▂▃▃▁▂▂▂▃▃▂▂▃▂▂▂▂▄▂▃▂▃▂▂▂▄▃</td></tr><tr><td>val_loss_step</td><td>█▄▃▃▄▅▄▆▄▄█▂▃▁▃▃▇▁▄▃▃██▃▃▄▃▃▄▆█▃▇▁▂▄▄▅▇▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84416</td></tr><tr><td>train_auc</td><td>0.92327</td></tr><tr><td>train_f1</td><td>0.84135</td></tr><tr><td>train_loss_epoch</td><td>0.3518</td></tr><tr><td>train_loss_step</td><td>0.2926</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.84161</td></tr><tr><td>val_auc</td><td>0.91383</td></tr><tr><td>val_f1</td><td>0.85011</td></tr><tr><td>val_loss_epoch</td><td>0.41643</td></tr><tr><td>val_loss_step</td><td>0.47641</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qokih90c' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qokih90c</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_075008-qokih90c\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_081239-4vpohqoh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4vpohqoh' target=\"_blank\">GraphConv_2_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4vpohqoh' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4vpohqoh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_3\\attention\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 3.0 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "3.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 K     Total params\n",
      "0.014     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇███▇█▇▇██▇██▇▇█▇██</td></tr><tr><td>train_auc</td><td>▁▅▆▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇▇███████████████▇██</td></tr><tr><td>train_f1</td><td>▁▆▅▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇███▇█▇▇██▇██▇▇█▇██</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▃▂▂▃▂▂▂▂▂▂▂▂▃▂▂▂▂▂▁▂▂▂▂▂▁▂▂▁▂▂▂▂▃▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▇▆▄▃▄▅▄▃▄▆▃▄▆▅▃▅▄▄▅▃▄▅▃▂▄▁▂▄▂▂▃▃▄▄▃▂▃▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▅█▇▇██▇▆▆▆▆▆▇██▇▆▇▇▆▇▆▇▇▇▇█▆▇▆▇▇▇██▅▇▇</td></tr><tr><td>val_auc</td><td>▁▆█▇▇█▇██▇▆▇▇█████▇█▇▇▇█▇▇▇█▇▇█▇▇█▇▇█▇▇▇</td></tr><tr><td>val_f1</td><td>▁▁▆▇▇▇██▅▅▇▆▅▄▅▇██▄▆▇▃▆▅▇▇█▆█▅▆▆▇▇▇██▂▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▂▂▁▂▂▂▂▃▂▂▂▂▂▃▂▃▂▃▃▄▃▂▂▃▂▃▅▁▄▂▂▂▁▂▃▃▄</td></tr><tr><td>val_loss_step</td><td>▇▃▆▃▃▁▂▄▂▃▂▁▂▄▂▅▅▄▅▃▅▆▇▅▄▄▃▄▄█▁▃▂▃▃▁▄▄▂▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87662</td></tr><tr><td>train_auc</td><td>0.94271</td></tr><tr><td>train_f1</td><td>0.87611</td></tr><tr><td>train_loss_epoch</td><td>0.30696</td></tr><tr><td>train_loss_step</td><td>0.36398</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83924</td></tr><tr><td>val_auc</td><td>0.89651</td></tr><tr><td>val_f1</td><td>0.83962</td></tr><tr><td>val_loss_epoch</td><td>0.46112</td></tr><tr><td>val_loss_step</td><td>0.57264</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_2_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4vpohqoh' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4vpohqoh</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_081239-4vpohqoh\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_083732-vjiyx5ge</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/vjiyx5ge' target=\"_blank\">GCN_2_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/vjiyx5ge' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/vjiyx5ge</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_3\\attention2\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 1.6 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "3.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.2 K     Total params\n",
      "0.013     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▆▇▇▇█▇▇▇▇▇██▇█▇█▇▇█▇▇██</td></tr><tr><td>train_auc</td><td>▁▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇████▇▇██████▇██▇███</td></tr><tr><td>train_f1</td><td>▁▆▆▆▇▆▆▆▇▇▇▇▇▇▇▇▇▆▇▇▇█▇▇▇▇▇▇█▇█▇█▇▇█▇▇██</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▄▃▃▃▃▂▂▃▂▂▂▂▂▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▂▁▂▂</td></tr><tr><td>train_loss_step</td><td>▅▅▅▄▃▄▃▂▃▃▃▂▁▅▂▃▃█▂▃▂▂▃▄▃▃▂▁▂▄▂▁▂▂▂▃▃▃▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▇▇▆▇▃█▄▇▇▆▇▇▅▆▇▇▆▇▆▇▆▇█▅▆▆▅▄▆▆▇▇▇▆▅▅▇▆</td></tr><tr><td>val_auc</td><td>▁▆▇██▇██▇█▇█▇██▇██████▇▇█▇█▇▆▇███▇▇▇▇▇██</td></tr><tr><td>val_f1</td><td>▁▆▇▇▆▇▃█▄█▇▆▇█▅▇█▇▅█▇▇▇▇█▆▇▆▅▆▇▇██▇▅▆▇▇▆</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▂▂▃▃▁▂▃▂▁▁▃▂▂▂▁▁▂▃▂▂▃▂▂▂▃▄▄▃▂▁▁▁▂▂▃▂▁</td></tr><tr><td>val_loss_step</td><td>█▄▄▅▅▇▅▃▄▇▄▁▁▇▃▃▄▃▃▅▆▃▃▇▅▃▄▅▇█▇▆▃▃▃▃▆▆▆▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85773</td></tr><tr><td>train_auc</td><td>0.9303</td></tr><tr><td>train_f1</td><td>0.85815</td></tr><tr><td>train_loss_epoch</td><td>0.3425</td></tr><tr><td>train_loss_step</td><td>0.40719</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.84397</td></tr><tr><td>val_auc</td><td>0.91555</td></tr><tr><td>val_f1</td><td>0.83582</td></tr><tr><td>val_loss_epoch</td><td>0.35305</td></tr><tr><td>val_loss_step</td><td>0.24852</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/vjiyx5ge' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/vjiyx5ge</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_083732-vjiyx5ge\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_090239-5cl61jr4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5cl61jr4' target=\"_blank\">GraphConv_2_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5cl61jr4' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5cl61jr4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_3\\attention2\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 3.0 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "4.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.6 K     Total params\n",
      "0.019     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇▇█▇█▇▇██████▇████</td></tr><tr><td>train_auc</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████▇███████████████████</td></tr><tr><td>train_f1</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇██▇███▇▇███████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▃▃▃▃▂▃▂▂▂▃▂▂▂▁▂▂▂▁▂▂▂▂▁▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▅▄▄▄▄▄▄▃▄▄▃▄▃▄▅▂▃▄▂▃▃▄▃▄▃▄▂▃▂▅▃▃▄▃▃▃▄▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▅▇█▇█▇▆▅██▆▄▇▇▇▆▇▅▆█▆▅▅▇▇▆▇▆▇▆▆▇▇▇▇▇▆▅</td></tr><tr><td>val_auc</td><td>▁▆▇█▇██▇▇██▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▆█▇▇▇▆▆▇▇▆▇▇▆</td></tr><tr><td>val_f1</td><td>▂▁▄██▇█▆▇▇██▆▂███▅▇▆▅█▆▅▅▇▇▇▆▆▇▇▆▇█▇▇▇▇▄</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▂▁▁▂▁▂▃▁▂▁▄▂▁▄▄▁▃▃▆▁▃▂▃▂▃▂▃▃▃▄▂▅▃▂▃▃▄</td></tr><tr><td>val_loss_step</td><td>▆▄▅▆▃▃▄▂▃▃▃▅▃▄▄▂▆▄▃▄▆█▂▅▂▄▃▃▅▄▄▂▆▁▇▄▃▄▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87544</td></tr><tr><td>train_auc</td><td>0.94821</td></tr><tr><td>train_f1</td><td>0.87493</td></tr><tr><td>train_loss_epoch</td><td>0.28446</td></tr><tr><td>train_loss_step</td><td>0.17967</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81087</td></tr><tr><td>val_auc</td><td>0.89486</td></tr><tr><td>val_f1</td><td>0.79487</td></tr><tr><td>val_loss_epoch</td><td>0.44808</td></tr><tr><td>val_loss_step</td><td>0.45542</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_2_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5cl61jr4' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5cl61jr4</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_090239-5cl61jr4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_092533-ex0y6fya</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ex0y6fya' target=\"_blank\">GCN_2_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ex0y6fya' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ex0y6fya</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_3\\mean\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 5.2 K \n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "7.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.3 K     Total params\n",
      "0.029     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇▇▇▇▇█▇▇▇█▇▇▇█</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇▇▇████▇▇█▇▇▇█</td></tr><tr><td>train_f1</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇████▇█▇▇█▇█▇█▇▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▃▃▃▃▃▂▂▂▂▂▂▂▂▂▃▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▁▂▂▂▁▂▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▄▃▅▂▅▃▃▇▃▂▄▄▁▄▄▃▂▄▄▅▂▄▁▁▃▂▂▂▃▄▄▃▃▃▂▃▄▄▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▆█████▇▇▇▇▇▇▇▆▇▇▇▆▅▇▇▅█▇▇▇▆█▇█▇▇▇▇▅▇▇▆</td></tr><tr><td>val_auc</td><td>▁▅▇▇██▇▇██▇▇▇▇▇█▇▇▇▇███▇▇▇▇█▇█▇██▇███▇▇▇</td></tr><tr><td>val_f1</td><td>▃▁▅▇██▇▇▆▇▆▆▇▇▆▇▇▆▇▅▆▇▇▄▇▇▇▇▄▇▇█▇▇▆▇▆▇▇▄</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▂▂▂▂▂▂▁▂▂▂▄▂▃▂▂▁▂▄▂▁▃▂▂▃▂▂▂▂▁▁▁▂▁▃▁▁▃</td></tr><tr><td>val_loss_step</td><td>█▅▄▃▄▄▅▂▆▂▅▂▃█▅▃▄▃▂▂█▅▂▆▅▂▇▃▃▅▄▂▁▂▄▁▂▁▂▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8536</td></tr><tr><td>train_auc</td><td>0.92569</td></tr><tr><td>train_f1</td><td>0.8515</td></tr><tr><td>train_loss_epoch</td><td>0.34678</td></tr><tr><td>train_loss_step</td><td>0.27682</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82033</td></tr><tr><td>val_auc</td><td>0.91564</td></tr><tr><td>val_f1</td><td>0.8</td></tr><tr><td>val_loss_epoch</td><td>0.4078</td></tr><tr><td>val_loss_step</td><td>0.4708</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ex0y6fya' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ex0y6fya</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_092533-ex0y6fya\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_094743-ch1acamc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ch1acamc' target=\"_blank\">GraphConv_2_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ch1acamc' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ch1acamc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_3\\mean\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 10.1 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "12.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "12.3 K    Total params\n",
      "0.049     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3813be9715a74bc79ad767a47460a75a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇█▇▇█▇██▇▇▇█▇██▇████▇████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇█▇▇▇▇█▇▇█▇█▇██▇███████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▇▆▆▇▇▇█▇▇▇█▇▇█▇██▇▇▇█▇██▇████▇▇███</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▃▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▂▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▃▅▂▄▄▄▃▃▄▂▇▃▄▂▃▄▂▅▄▄▁▃▃▃▄▆▄▂▃▃▂▁▄▄▄▃▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▄▇▇█▆▆▆▇▇▆▇▆▇▆▇▇▇▅▆▆▆▅▆▇▅▆▆▇▄▅▆▆▆▅▅▅▅▆</td></tr><tr><td>val_auc</td><td>▁▆▇█▇█▇▇▅▆▆▆▆▆▅▆▅▆▆▄▆▅▆▅▅▃▅▅▄▆▅▄▄▆▆▂▂▅▄▄</td></tr><tr><td>val_f1</td><td>▁▄▄▆▇█▆▆▇▇█▇▇▆▇▇▇▇▇▆▇▇▇▆▇▇▆▆▆▇▅▆▇▇▆▇▆▆▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▃▄▄▁▁▁▁▂▃▆▃▂▅▁▃▅▁▂▅▂▅▄▅▃▅▅▃▅▃▃▃▄▆▂▆▆▅▄▇</td></tr><tr><td>val_loss_step</td><td>▅▄▄▇▄▄▃▃▃▅▇▅▃▅▁▄▅▂▃▅▂▅▅▆▄▅▄▂▅▅▃▃▃█▃▄▆▄▃▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.88666</td></tr><tr><td>train_auc</td><td>0.9586</td></tr><tr><td>train_f1</td><td>0.8853</td></tr><tr><td>train_loss_epoch</td><td>0.26195</td></tr><tr><td>train_loss_step</td><td>0.22084</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82033</td></tr><tr><td>val_auc</td><td>0.89434</td></tr><tr><td>val_f1</td><td>0.82805</td></tr><tr><td>val_loss_epoch</td><td>0.49843</td></tr><tr><td>val_loss_step</td><td>0.60649</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_2_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ch1acamc' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ch1acamc</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_094743-ch1acamc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_100957-4o2y7l92</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4o2y7l92' target=\"_blank\">GCN_2_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4o2y7l92' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4o2y7l92</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_3\\max\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 5.2 K \n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "7.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.3 K     Total params\n",
      "0.029     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47e3c6999db4401fa692d819cbef042b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▅▆▅▆▆▆▆▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇█▇██▇██████</td></tr><tr><td>train_auc</td><td>▁▄▅▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▆▇▇▇▇██▇█████████████</td></tr><tr><td>train_f1</td><td>▁▄▅▆▅▆▅▆▅▆▆▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇█▇██▇██████</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▂▂▃▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▄▅▅▅▄▄▅▅▄▄▅▄▄▄▄▂▅▅▃▄▄▃▃▄▃▃▂▃▃▃▂▄▃▃▃▃▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▆▅▇▇█▇▇█▇█▇▇█▇█▇███▇██</td></tr><tr><td>val_auc</td><td>▁▁▂▁▁▂▂▂▂▃▃▃▃▃▄▄▅▅▅▆▆▇▇▇▇▇▇▇▇▇▇█████████</td></tr><tr><td>val_f1</td><td>▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████████</td></tr><tr><td>val_loss_epoch</td><td>█▇▆▆▆▆▆▆▆▅▅▅▆▅▅▅▅▅▄▄▃▄▃▃▃▃▃▂▃▃▂▂▁▃▂▂▂▂▁▂</td></tr><tr><td>val_loss_step</td><td>██▆█▆▇▇▇▆▆▅▆▇▇▇▆▆▆▄▅▄▆▄▆▆▅▅▄▄▅▄▅▁▅▃▃▄▅▃▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.82527</td></tr><tr><td>train_auc</td><td>0.90466</td></tr><tr><td>train_f1</td><td>0.8267</td></tr><tr><td>train_loss_epoch</td><td>0.37956</td></tr><tr><td>train_loss_step</td><td>0.21474</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.79433</td></tr><tr><td>val_auc</td><td>0.8841</td></tr><tr><td>val_f1</td><td>0.79036</td></tr><tr><td>val_loss_epoch</td><td>0.44718</td></tr><tr><td>val_loss_step</td><td>0.55815</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4o2y7l92' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4o2y7l92</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_100957-4o2y7l92\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_103225-ai9riz64</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ai9riz64' target=\"_blank\">GraphConv_2_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ai9riz64' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ai9riz64</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_3\\max\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 10.1 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "12.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "12.3 K    Total params\n",
      "0.049     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████</td></tr><tr><td>train_auc</td><td>▃▃▄▃▂▁▁▁▂▄▃▃▂▃▄▅▅▅▅▅▆▆▇▅▆▅▆▇▇▇▇▇▇▆█▆▇███</td></tr><tr><td>train_f1</td><td>▁▄▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇██▇████████████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▂▁▂▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▃▄▂▄▃▃▃▃▃▂▃▂▃▂▂▂▂▃▃▃▁▂▂▂▂▄▂▂▂▃▂▂▂▂▂▂▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▆▇█▇▇▆▇▇▇▇▇▆█▇█▇▇▆▇█▇█▇▇▇█▇▇▇▇▇██▇▇▇▆▆</td></tr><tr><td>val_auc</td><td>▇▇▇▄▂▁▂▃▄▃▄▆▇█▇███▇▇█████▇██████████████</td></tr><tr><td>val_f1</td><td>▁▁▅▆▇▄▅▄▇▆▇▇▅▄▇▇██▇▆▇█▇█▇▆▆▇▇▇▇▇▇██▇██▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▆▄▃▃▃▂▃▂▂▃▂▂▂▁▂▂▂▃▃▂▂▁▂▃▃▂▁▄▂▂▂▄▃▂▃▃▃▄▄</td></tr><tr><td>val_loss_step</td><td>▇▆▅▅▅▄▂▆▃▃▆▄▄▃▂▃▃▁▅▅▂▄▂▅▄▆▅▂█▅▄▂▆▆▃▃▅▃▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85065</td></tr><tr><td>train_auc</td><td>0.86266</td></tr><tr><td>train_f1</td><td>0.85161</td></tr><tr><td>train_loss_epoch</td><td>0.33742</td></tr><tr><td>train_loss_step</td><td>0.27257</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.77305</td></tr><tr><td>val_auc</td><td>0.86725</td></tr><tr><td>val_f1</td><td>0.80165</td></tr><tr><td>val_loss_epoch</td><td>0.53738</td></tr><tr><td>val_loss_step</td><td>0.57627</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_2_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ai9riz64' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ai9riz64</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_103225-ai9riz64\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_105546-sonqdpc2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/sonqdpc2' target=\"_blank\">GCN_2_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/sonqdpc2' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/sonqdpc2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_3\\sum\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 5.2 K \n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "7.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.3 K     Total params\n",
      "0.029     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▆▇▇█▇▇▇▇▇▆▇▆▇█▇▇██▇▇▇█▇▇██▇█▇█▇▇▇███</td></tr><tr><td>train_auc</td><td>▃▂▂▃▄▄▄▅▄▅▄▅▆▅▄▄▃▄▅▁▄▅▅▅▇▇▇▇▇█▇▇▇▆▇▇▇██▆</td></tr><tr><td>train_f1</td><td>▁▄▅▆▆▇▇█▇▇▇▇▇▆▇▆▇█▇▇██▇▇▇▇█▇██▇█▇█▇▇▇███</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▂▂▂▁▂▁▁▂▁▁▁▁▁▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▆▇▇▇███▇▇▇█▇█▇███████▇███▇████▇▅▇█▆█▇█</td></tr><tr><td>val_auc</td><td>▁▄▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇███▇█▇█▇█▇█▇▇██▇</td></tr><tr><td>val_f1</td><td>▁▄▄▅▆▇▇▇▇▆▆▆▇▇▇▆▇█▇▇█▇█▆▇▇▇▇█▇▇▇▇▅▆█▆▇▇█</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▃▂▂▂▂▁▂▁▁▁▃▂▂▂▁▂▂</td></tr><tr><td>val_loss_step</td><td>█▄▄▂▅▃▄▂▆▃▄▂▃▄▄▃▄▅▂▂▆▅▃▇▄▄▅▄▁▄▃▂▂▂▄▁▂▂▃▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83235</td></tr><tr><td>train_auc</td><td>0.83963</td></tr><tr><td>train_f1</td><td>0.82746</td></tr><tr><td>train_loss_epoch</td><td>0.38947</td></tr><tr><td>train_loss_step</td><td>0.27909</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.86052</td></tr><tr><td>val_auc</td><td>0.90276</td></tr><tr><td>val_f1</td><td>0.86118</td></tr><tr><td>val_loss_epoch</td><td>0.44479</td></tr><tr><td>val_loss_step</td><td>0.59799</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/sonqdpc2' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/sonqdpc2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_105546-sonqdpc2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_111929-it68ur6e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/it68ur6e' target=\"_blank\">GraphConv_2_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/it68ur6e' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/it68ur6e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_3\\sum\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 10.1 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "12.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "12.3 K    Total params\n",
      "0.049     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▆▇▇▇██▇█▇▇▇▇████▇████▇█</td></tr><tr><td>train_auc</td><td>▄▂▁▁▂▄▄▄▄▅▄▅▅▅▅▅▆▆▆▆▇▇▇▆▆▆▇▇▇▇▇▇█▇██████</td></tr><tr><td>train_f1</td><td>▁▃▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▆▇▇▇██▇█▇▇█▇███▇▇████▇█</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▁▂▁▂▁▂▁▁▂▁▂▁▁▁▁▁▁▂▂▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▅▅▆▆▇█▇▇█▇▇▇███▆▇▇██▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>val_auc</td><td>▇▂▁▁▄▇▇███████▇█████████████████████████</td></tr><tr><td>val_f1</td><td>▁▅▆▆▇▆▇█▇▇█▇█▇███▇▇▇██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▂▂▃▂▂▂▂▁▂▃▂▁▂▁▁▂▂▁▂▂▃▂▃▁▃▂▁▂▂▁▁▂▂▂▂▂▂▂▃</td></tr><tr><td>val_loss_step</td><td>█▃▃▅▄▃▂▂▂▃▆▃▂▃▁▂▃▁▂▄▂▅▃▆▁▅▃▁▄▅▂▂▂▄▂▃▃▂▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87367</td></tr><tr><td>train_auc</td><td>0.91141</td></tr><tr><td>train_f1</td><td>0.87307</td></tr><tr><td>train_loss_epoch</td><td>0.32684</td></tr><tr><td>train_loss_step</td><td>0.33426</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83924</td></tr><tr><td>val_auc</td><td>0.89564</td></tr><tr><td>val_f1</td><td>0.84259</td></tr><tr><td>val_loss_epoch</td><td>0.4842</td></tr><tr><td>val_loss_step</td><td>0.72719</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_2_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/it68ur6e' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/it68ur6e</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_111929-it68ur6e\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_114301-7y2p9ti6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7y2p9ti6' target=\"_blank\">GCN_2_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7y2p9ti6' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7y2p9ti6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_3\\attention\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 5.2 K \n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "7.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.4 K     Total params\n",
      "0.030     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b92361c4cc844e1099b9513428a04cf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▇▆▆▇▇▇▇▆▇▇▆▇▇▇█▇▇▇▇▇▇█▇█▇█▇▇▇▇▇▇▇▇▇██</td></tr><tr><td>train_auc</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇██▇▇█████████████████</td></tr><tr><td>train_f1</td><td>▁▆▇▇▆▆▇▇▇▇▆▇▇▇▇▇▇█▇▇██▇▇██████▇▇▇██▇▇███</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▃▃▂▂▂▂▂▂▂▃▂▂▂▂▂▂▁▂▃▁▁▂▂▁▁▁▁▂▂▂▁▁▂▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▄▆▄▄▅▅▅▄▅▄▁▄▂▂▄▁▄▄▂▃▃▂▂▄▃▂▁▃▃▃▄▄▃▄▆▃▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▇█▇█▆█▇▆▆█▇▇▇▇▆▆▇▆▇▇▇▇▇▆▇▇▇▆█▇▇▇▇▇▆▇▆▇</td></tr><tr><td>val_auc</td><td>▁▅▇█▆▇██▇▇█▇▇▇▇▇▇▇▇█▇▇▇▇█▇▇▇▇▇█▇█▇▇▇▅▇▇▇</td></tr><tr><td>val_f1</td><td>▁▇▇█▇█▇█▇▇▇████▇▇▇█▇▇██▇█▇█▇▇▇███▇██▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▁▄▂▂▂▂▃▃▁▃▂▃▃▃▃▂▂▃▂▂▂▁▂▂▃▃▃▂▂▂▃▂▂▃▂▃▂</td></tr><tr><td>val_loss_step</td><td>▇▅▃▂█▄▂▃▄▄▆▁▄▄▆▆▅▄▃▄▅▃▃▄▁▂▂▄▅▄▃▄▅▄▁▄▄▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86895</td></tr><tr><td>train_auc</td><td>0.93811</td></tr><tr><td>train_f1</td><td>0.86707</td></tr><tr><td>train_loss_epoch</td><td>0.32012</td></tr><tr><td>train_loss_step</td><td>0.31068</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82506</td></tr><tr><td>val_auc</td><td>0.90701</td></tr><tr><td>val_f1</td><td>0.8271</td></tr><tr><td>val_loss_epoch</td><td>0.40239</td></tr><tr><td>val_loss_step</td><td>0.40324</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7y2p9ti6' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7y2p9ti6</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_114301-7y2p9ti6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_120738-dlckwnge</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/dlckwnge' target=\"_blank\">GraphConv_2_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/dlckwnge' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/dlckwnge</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_3\\attention\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 10.1 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "12.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "12.3 K    Total params\n",
      "0.049     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▆▆▇▇▇▆▇▇▇▆▇█▇▇▇▇▇▇▇▇█▇▇█▇██████████</td></tr><tr><td>train_auc</td><td>▁▃▆▆▆▆▇▇▇▇▆▇▇▇▇▇██▇█▇▇█▇████████████████</td></tr><tr><td>train_f1</td><td>▁▄▆▆▆▆▇▇▇▇▆▇▇▇▆▇█▇▇▇▇▇▇▇▇█▇▇█▇████████▇█</td></tr><tr><td>train_loss_epoch</td><td>█▇▄▅▄▄▃▃▂▂▄▂▂▃▃▂▂▂▂▂▂▂▂▂▂▁▁▂▁▂▁▁▁▁▁▂▁▁▂▂</td></tr><tr><td>train_loss_step</td><td>██▅▄▄▅▅▄▂▄▃▃▃▃▃▃▄▅▃▄▃▄▂▃▂▁▃▄▃▄▂▄▃▄▄▃▄▂▃▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▂▅▇▆▇▆██▇▇▇▇██▇▇█▇▅▅██▆▇▇█▇▆▇▇█▇▇▇▇▇▇▇▇</td></tr><tr><td>val_auc</td><td>▁▁▄▇▆▆██▇▇▆▅▆▇▆▆▇▇▅▆▆▆▆▅▅▅▇▆▆▆▅▆▇▆▆▆▅▅▅▆</td></tr><tr><td>val_f1</td><td>▁▂▆▇▇▇▆██▇█████▇▇█▇▆▆██▇█▇██▇▇▇█▇▇▇██▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>▇▆▃▁▂▁▁▁▁▃▃▃▄▁▂▂▂▂▂▆▅▄▄▂▅▄▂▂▄▃▄▅▄▃▄▄█▆▄▂</td></tr><tr><td>val_loss_step</td><td>▄▄▂▁▂▂▁▂▂▅▄▄▅▁▃▃▂▂▁▇▄▆▅▂▅▄▁▃▃▃▃▅▅▃▄▄█▆▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8843</td></tr><tr><td>train_auc</td><td>0.94926</td></tr><tr><td>train_f1</td><td>0.88263</td></tr><tr><td>train_loss_epoch</td><td>0.29649</td></tr><tr><td>train_loss_step</td><td>0.42626</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.8156</td></tr><tr><td>val_auc</td><td>0.89117</td></tr><tr><td>val_f1</td><td>0.8134</td></tr><tr><td>val_loss_epoch</td><td>0.42612</td></tr><tr><td>val_loss_step</td><td>0.27531</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_2_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/dlckwnge' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/dlckwnge</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_120738-dlckwnge\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_123005-uwc230y4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/uwc230y4' target=\"_blank\">GCN_2_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/uwc230y4' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/uwc230y4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_3\\attention2\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 5.2 K \n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "11.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "11.5 K    Total params\n",
      "0.046     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "954737bc85d246908bbf4977e8e7ed5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▇▆▇▆▇▇▇▆▇▇▆▇▇▇▇▇█▇▇██▇████▇██████████</td></tr><tr><td>train_auc</td><td>▁▅▆▇▆▇▇▇▇▇▇▇▇▆▇▇█▇▇█████████████▇███████</td></tr><tr><td>train_f1</td><td>▁▆▇▇▆▇▇▇▇▇▆▇▇▇▇▇▇▇▇█▇▇██▇████▇██▇███████</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▄▃▃▂▂▃▂▃▂▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▂▁▂▂</td></tr><tr><td>train_loss_step</td><td>▅▃▄▇▄▂▃▅▃▃▅▃▇▂▄█▃▁▅▆▂▃▄▃▂▄▂▂▅▃▃▆▄▃▂▃▄▆▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▇▆▆█▇██▇▇█▇█▇██▇▇▇█▇▇▇▇▇▆▇▇▇▇███▇▇▇█▇▇</td></tr><tr><td>val_auc</td><td>▁▄▆▆▄▇▆▇▇▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇█▇██▇▇▇██▇▇███▇</td></tr><tr><td>val_f1</td><td>▁▆▇▆▇████▇█████████▇██▇█▇█▆▇█▇█████▇████</td></tr><tr><td>val_loss_epoch</td><td>█▄▂▃▃▂▂▁▁▂▂▂▃▂▂▂▂▂▂▂▂▁▂▂▁▂▃▂▃▃▂▁▂▁▃▂▁▁▂▁</td></tr><tr><td>val_loss_step</td><td>█▄▂▆▃▅▃▂▃▃▅▄▃▄▆▇▅▃▇▅▃▁▃▄▃▅▇▅▅█▃▃▅▃▄▄▁▃▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86482</td></tr><tr><td>train_auc</td><td>0.93553</td></tr><tr><td>train_f1</td><td>0.86409</td></tr><tr><td>train_loss_epoch</td><td>0.32451</td></tr><tr><td>train_loss_step</td><td>0.33856</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.84397</td></tr><tr><td>val_auc</td><td>0.92054</td></tr><tr><td>val_f1</td><td>0.84722</td></tr><tr><td>val_loss_epoch</td><td>0.3486</td></tr><tr><td>val_loss_step</td><td>0.28641</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/uwc230y4' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/uwc230y4</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_123005-uwc230y4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_125357-tdcn70m5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tdcn70m5' target=\"_blank\">GraphConv_2_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tdcn70m5' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tdcn70m5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_3\\attention2\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 10.1 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "16.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "16.5 K    Total params\n",
      "0.066     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇██▇▇▇█▇▇▇█▇▇█▇</td></tr><tr><td>train_auc</td><td>▁▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇████▇███▇▇██████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇██▇▇▇█▇▇▇█▇▇█▇</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▃▃▃▃▄▃▂▃▂▃▂▂▂▁▂▂▂▂▂▂▂▂▂▁▁▂▁▂▂▂▂▂▁▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>▇▄▃▄▃▃▅▂▅▂▃▄█▂▂▂▃▂▃▃▄▂▄▃▃▁▄▁▃▂▃▂▃▂▁▂▄▃▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▇▇█▅▇█▇▇▇▇▇▅▇▇▇▇▆▇▇▇▅▅▆▇▇▆▇▇▇▇▆▇▇▇▇▆▇▆▇</td></tr><tr><td>val_auc</td><td>▁▇██▇▇▇▇▇█▇▆▇▅▆▇▆▇▆▅▇▇▇▆▅▆▆▆▆▆▇█▆▅▆▅▇█▆▅</td></tr><tr><td>val_f1</td><td>▁▆▇█▅▇█▇█▇▇▇▆█▇█▇▆▇██▆▆▆▇▇▆▇▇▇▇▆▇█▇▇▆▇▆▇</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▂▃▃▃▁▃▂▃▃▄▄▃▄▄▃▄▆▄▅▅▆▄▄▅▅▅▃▅▄█▆▄▆▄▄▄▅</td></tr><tr><td>val_loss_step</td><td>▄▂▃▂▂▃▃▁▃▂▃▃▄▂▂▂▂▃▂▂▃▄▄▅▂▃▃▃▃▂▅▃█▄▁▂▄▃▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.88489</td></tr><tr><td>train_auc</td><td>0.95726</td></tr><tr><td>train_f1</td><td>0.88372</td></tr><tr><td>train_loss_epoch</td><td>0.26506</td></tr><tr><td>train_loss_step</td><td>0.29782</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83215</td></tr><tr><td>val_auc</td><td>0.89124</td></tr><tr><td>val_f1</td><td>0.83753</td></tr><tr><td>val_loss_epoch</td><td>0.46816</td></tr><tr><td>val_loss_step</td><td>0.46653</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_2_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tdcn70m5' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tdcn70m5</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_125357-tdcn70m5\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_131956-qvkrndyg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qvkrndyg' target=\"_blank\">GCN_3_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qvkrndyg' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qvkrndyg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_3\\mean\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 832   \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "986       Trainable params\n",
      "0         Non-trainable params\n",
      "986       Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▇▇▇▇▇▇█▇█▇████████████████████████████▇</td></tr><tr><td>train_auc</td><td>▁▇▇▇█▇▇█████████████████████████████████</td></tr><tr><td>train_f1</td><td>▁▇▇▇████████████████████████████████████</td></tr><tr><td>train_loss_epoch</td><td>█▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▂▂▁▂▂▂▂▁▁▂▂▂▂▁▁▂▁▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>▇▅▂▃▄▄▄▃▃▃▂▂▃▃▂▃▃▁▃▃▂▃▂▂▃▃▁▄▄▃▄▂▃▂▁▃▃▁▄█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▆▇▇█▇█▇████▇██▇███▇███▇███▇▇█▇███▇▇█▆▇</td></tr><tr><td>val_auc</td><td>▁▄▆▇▇▇▇▇▇█▇█▇██▇▇▇█▇████████▇██▇▇▇▇▇█▇▇█</td></tr><tr><td>val_f1</td><td>▁▇▇▇██▇█▇████▇██████▇███████▇▇█████▇██▇█</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▂▂▂▂▂▃▂▂▁▂▂▂▂▃▂▂▁▂▂▂▂▂▃▂▂▃▃▂▂▁▂▁▂▂▂▃▃</td></tr><tr><td>val_loss_step</td><td>█▅▅▃▄▆▃▅▆▄▄▂▄▂▄▄▆▄▄▂▄▃▄▄▃▇▄▄▅▄▂▃▁▅▂▃▃▄▅▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.817</td></tr><tr><td>train_auc</td><td>0.89358</td></tr><tr><td>train_f1</td><td>0.81722</td></tr><tr><td>train_loss_epoch</td><td>0.43365</td></tr><tr><td>train_loss_step</td><td>0.72995</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82506</td></tr><tr><td>val_auc</td><td>0.91394</td></tr><tr><td>val_f1</td><td>0.80628</td></tr><tr><td>val_loss_epoch</td><td>0.42136</td></tr><tr><td>val_loss_step</td><td>0.55692</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qvkrndyg' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qvkrndyg</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_131956-qvkrndyg\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_134250-c7n60y9k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/c7n60y9k' target=\"_blank\">GraphConv_3_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/c7n60y9k' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/c7n60y9k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_3\\mean\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 1.6 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▇▇▇▇▇▇▇▇▇███▇█▇██▇▇██▇██▇██▇█████████</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇▇▇▇▇█▇███████████████████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▇▇▇▇▇▇▇▇▇█▇█▇▇▇▇█▇▇▇█▇▇█▇▇▇▇█▇████▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▃▃▂▂▃▃▂▂▂▂▂▂▂▂▁▂▂▁▂▂▂▂▁▁▂▁▂▂▁▁▁▂▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▅▃▄▅▅▄▂▃▃▂▂▃▂▃▂▂▃▃▃▂█▄▃▂▄▁▃▄▂▃▅▂▅▁▃▃▃▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▅▅▆▆▆█▇▇▇██▇▇█▇▇▇▇▇▇▇▇▇█▇▇▆▇█▇▇▇▇█▇██▇</td></tr><tr><td>val_auc</td><td>▁▇▇██████████████████████████████▇██████</td></tr><tr><td>val_f1</td><td>▁▄▅▅▅▅▆▇▇▇▇██▇▇█▇▇▇▇▇▇▇▇▇█▇▇▆██▇█▇██▇███</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▄▃▃▂▁▃▂▂▂▂▁▂▁▁▂▂▁▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▁▁▂▃</td></tr><tr><td>val_loss_step</td><td>█▆▄▇▄▅▆▃█▄▄▃▅▃▄▃▁▄▅▃▅▃▄▄▃▄▅▂▃▄▄▄▄▃▃▆▃▁▅▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87544</td></tr><tr><td>train_auc</td><td>0.94104</td></tr><tr><td>train_f1</td><td>0.87373</td></tr><tr><td>train_loss_epoch</td><td>0.3242</td></tr><tr><td>train_loss_step</td><td>0.45974</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82506</td></tr><tr><td>val_auc</td><td>0.89663</td></tr><tr><td>val_f1</td><td>0.82791</td></tr><tr><td>val_loss_epoch</td><td>0.4592</td></tr><tr><td>val_loss_step</td><td>0.56578</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/c7n60y9k' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/c7n60y9k</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_134250-c7n60y9k\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_140553-oa8uosol</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/oa8uosol' target=\"_blank\">GCN_3_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/oa8uosol' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/oa8uosol</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_3\\max\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 832   \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "986       Trainable params\n",
      "0         Non-trainable params\n",
      "986       Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▂▃▄▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇█████▇█▇█▇▇▇</td></tr><tr><td>train_auc</td><td>▁▂▂▂▃▄▆▇▇▇▇▇▇▇▇█▇██████████████████████▇</td></tr><tr><td>train_f1</td><td>▁▁▁▂▂▄▅▅▅▆▆▆▆▆▇▆▇▇▇▇▇▇██▇▇▇▇█████▇█▇█▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▅▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▁▂▂▁▁▁▁▁▂▁▁▁▂▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▆▆▆▆▆▅▃▄▅▅▄▁▄▅▄▅▃▄▄▅▃▃▃▄▅▃▃▃▃▃▃▂▃▃▃▄▄▄▇</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▁▁▁▁▁██▃▅▇██▅▇███████▇██▇▇▇███▇▇███▇██▇</td></tr><tr><td>val_auc</td><td>▁▂▃▆▇▇▇▇██████████████████████████████▇█</td></tr><tr><td>val_f1</td><td>▁▁▁▁▁▁█▇▄▅▇██▆▇▇▇███████████████▇███████</td></tr><tr><td>val_loss_epoch</td><td>██▇▇▇▆▅▅▅▅▄▄▄▄▅▅▃▃▃▃▃▂▃▂▃▃▁▂▂▁▁▂▂▂▂▂▁▁▁▂</td></tr><tr><td>val_loss_step</td><td>██▇▇▇▇▆▆▆▇▅▅▅▆▇█▃▃▅▅▅▄▅▃▄▆▁▅▄▃▂▂▂▄▅▅▄▃▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.73022</td></tr><tr><td>train_auc</td><td>0.76451</td></tr><tr><td>train_f1</td><td>0.74959</td></tr><tr><td>train_loss_epoch</td><td>0.57543</td></tr><tr><td>train_loss_step</td><td>0.73046</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.67612</td></tr><tr><td>val_auc</td><td>0.74585</td></tr><tr><td>val_f1</td><td>0.71399</td></tr><tr><td>val_loss_epoch</td><td>0.58701</td></tr><tr><td>val_loss_step</td><td>0.59857</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/oa8uosol' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/oa8uosol</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_140553-oa8uosol\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5eeb3669f2a48728446a9d431be5381",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_142742-v6loz83i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/v6loz83i' target=\"_blank\">GraphConv_3_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/v6loz83i' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/v6loz83i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_3\\max\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 1.6 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▂▄▅▅▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇█▇▇▇█▇█▇█▇███</td></tr><tr><td>train_auc</td><td>▁▁▂▃▃▃▅▄▆▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇██▇███▇█████████</td></tr><tr><td>train_f1</td><td>▁▂▃▄▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇█▇▇██▇█▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▂▂▁▂▁▂▁▁▁▁▂▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▅▄▅▄▃▄▃▄▃▂▂▄▂▃▂▃▄▂▂▂▄▃▂▄▄▁▂▃▃▂▂▂▂▁▂▂▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▆▇▇▇▆▇▇▆▇▇█▇▇▇▇▇▇▇▆▇█▇▇█▆▇█████▇██████</td></tr><tr><td>val_auc</td><td>▁▄▄▇▇▇▇█████████████████▇▇████████████▇▇</td></tr><tr><td>val_f1</td><td>▂▄▅▅▅▅▃▅▆▃▄▇▇▇▆▆▄▅▅▅▁▆█▆▆▇▁▆██▇▇█▅██▇▇██</td></tr><tr><td>val_loss_epoch</td><td>█▇▆▅▄▄▃▃▃▃▃▃▂▂▂▂▂▃▂▂▃▂▃▂▂▂▃▁▂▂▃▁▂▂▂▂▂▂▂▃</td></tr><tr><td>val_loss_step</td><td>█▇▆▆▃▃▅▃▅▄▅▅▃▁▃▃▂▄▂▃▆▂▄▃▂▃▅▂▂▄▄▁▃▂▃▃▂▁▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.81405</td></tr><tr><td>train_auc</td><td>0.87175</td></tr><tr><td>train_f1</td><td>0.81328</td></tr><tr><td>train_loss_epoch</td><td>0.44253</td></tr><tr><td>train_loss_step</td><td>0.50415</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.79669</td></tr><tr><td>val_auc</td><td>0.84222</td></tr><tr><td>val_f1</td><td>0.80365</td></tr><tr><td>val_loss_epoch</td><td>0.54409</td></tr><tr><td>val_loss_step</td><td>0.6072</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/v6loz83i' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/v6loz83i</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_142742-v6loz83i\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_144935-wxsf7bqa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wxsf7bqa' target=\"_blank\">GCN_3_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wxsf7bqa' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wxsf7bqa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_3\\sum\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 832   \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "986       Trainable params\n",
      "0         Non-trainable params\n",
      "986       Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇████▇</td></tr><tr><td>train_auc</td><td>▁▄▅▆▇▆▇▇▇▇▇▇▇▇▇██▇▇█▇███▇▇██████████████</td></tr><tr><td>train_f1</td><td>▁▄▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇▇██▇██▇██▇████▇</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▃▂▃▃▃▂▂▂▂▂▃▂▂▂▂▁▂▂▂▂▄▂▂▂▁▂▂▂▃▂▂▂▁▂▂▁▂▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▆▆▇▇▇█▆▇███▇██▇███▆█▇██▇███▇▇█████▇█▇▇</td></tr><tr><td>val_auc</td><td>▁▆▇▇████████████████████████████████████</td></tr><tr><td>val_f1</td><td>▁▇▆▇▇▇▇█▆████▇██▇███▇█▇██████▇▇█████▇███</td></tr><tr><td>val_loss_epoch</td><td>█▅▄▃▃▃▂▂▄▂▂▂▃▂▂▂▄▂▂▁▃▁▃▂▂▃▃▂▃▂▂▂▁▂▁▂▃▂▂▃</td></tr><tr><td>val_loss_step</td><td>█▆▅▃▅▆▃▄█▄▅▃▆▃▅▅▇▄▃▃▅▂▄▄▄█▆▄▆▄▃▃▁▅▂▃▄▄▅█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8111</td></tr><tr><td>train_auc</td><td>0.8649</td></tr><tr><td>train_f1</td><td>0.81154</td></tr><tr><td>train_loss_epoch</td><td>0.45249</td></tr><tr><td>train_loss_step</td><td>0.74361</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83215</td></tr><tr><td>val_auc</td><td>0.90593</td></tr><tr><td>val_f1</td><td>0.81266</td></tr><tr><td>val_loss_epoch</td><td>0.46062</td></tr><tr><td>val_loss_step</td><td>0.63907</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wxsf7bqa' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wxsf7bqa</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_144935-wxsf7bqa\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_151106-04z5n78g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/04z5n78g' target=\"_blank\">GraphConv_3_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/04z5n78g' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/04z5n78g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_3\\sum\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 1.6 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▃▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇▇▇███████</td></tr><tr><td>train_auc</td><td>▄▂▂▁▂▂▄▄▄▅▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇▇██</td></tr><tr><td>train_f1</td><td>▁▂▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇██▇▇███████</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▂▂▂▂▂▁▂▁▁▁▁▂▁▁▂▁▁▁▂▁▁▁▁▁▁▂▁▁▂▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▃▁▃▃▃▄▅▅▄▅▆▄▇▅▆▇▇▇▇▇▇▇▇▇▆█▇█▆▇█▆█▇▇▆▇█▇▇</td></tr><tr><td>val_auc</td><td>▅▃▂▁▁▆▇▇████████████████████████████████</td></tr><tr><td>val_f1</td><td>▆▁▄▄▃▄▅▅▄▅▆▅▇▆▆▇▇▇▇▇▇▇█▇▆███▆██▆█▇▇▆▇█▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▄▃▃▃▂▄▃▂▃▂▂▂▂▁▂▂▁▂▁▂▂▂▁▂▁▁▁▁▂▁▂▁▃▁▁▂▂</td></tr><tr><td>val_loss_step</td><td>█▆▄▆▃▄▅▃█▄▄▅▃▃▃▃▁▄▃▂▅▃▄▄▃▃▄▂▁▂▁▄▃▂▁▆▂▂▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83471</td></tr><tr><td>train_auc</td><td>0.79158</td></tr><tr><td>train_f1</td><td>0.83471</td></tr><tr><td>train_loss_epoch</td><td>0.39596</td></tr><tr><td>train_loss_step</td><td>0.46269</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82506</td></tr><tr><td>val_auc</td><td>0.9054</td></tr><tr><td>val_f1</td><td>0.80108</td></tr><tr><td>val_loss_epoch</td><td>0.46567</td></tr><tr><td>val_loss_step</td><td>0.54745</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/04z5n78g' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/04z5n78g</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_151106-04z5n78g\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77bd93970e85405ca7bc179bb86e3b3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_153128-6fpct8rq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6fpct8rq' target=\"_blank\">GCN_3_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6fpct8rq' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6fpct8rq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_3\\attention\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 832   \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "1.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.0 K     Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇█▇▇████▇▇█▇██████████████▇█████▇███</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇█▇▇████████████████████████████████</td></tr><tr><td>train_f1</td><td>▁▇▇█████████████████████████████████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▂▂▁▂▁▁▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▃▂▄▅▄▅▂▃▅▃▅▃▄▄▂▃█▃▂▃▂▅▁▃▄▇▃▂▂▁▃▃▂▂▃▃▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▄▇▅▇▆▇████▇███▇█▇▇▇█████████▇█▇█▇▅█▇██</td></tr><tr><td>val_auc</td><td>▁▅▆▇▇▇▇▇█████████████████████████▇███▇██</td></tr><tr><td>val_f1</td><td>▁▆▅▇▆▇▇▇████████▇███▇█████████▇█▇██▆█▇██</td></tr><tr><td>val_loss_epoch</td><td>█▅▆▃▄▂▃▂▂▁▁▂▂▁▃▂▂▂▂▂▂▁▂▁▂▁▂▂▁▂▂▁▂▁▂▅▂▃▂▂</td></tr><tr><td>val_loss_step</td><td>█▇▄▆▅▄▄▄▄▃▄▅▄▃▇▄▅▄▄▄▃▃▄▃▄▂▇▆▂▅▂▂▅▁▄█▄▄▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.81995</td></tr><tr><td>train_auc</td><td>0.90553</td></tr><tr><td>train_f1</td><td>0.82006</td></tr><tr><td>train_loss_epoch</td><td>0.38455</td></tr><tr><td>train_loss_step</td><td>0.33874</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.84397</td></tr><tr><td>val_auc</td><td>0.91005</td></tr><tr><td>val_f1</td><td>0.83417</td></tr><tr><td>val_loss_epoch</td><td>0.40774</td></tr><tr><td>val_loss_step</td><td>0.49024</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6fpct8rq' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6fpct8rq</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_153128-6fpct8rq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_155253-wcyvs6wt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wcyvs6wt' target=\"_blank\">GraphConv_3_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wcyvs6wt' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wcyvs6wt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_3\\attention\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 1.6 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "1.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▇▇▇▇▇▇▇▇▇▇▇███▇██▇████▇███████▇▇██████</td></tr><tr><td>train_auc</td><td>▁▄▇▇▇▇█▇▇███▇███▇███████████████████████</td></tr><tr><td>train_f1</td><td>▁▄▆▆▇▇▇▇▇▇▇▇▇██▇▆▇▇▇█▇▇▇▇▇██████▇▇█▇████</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▃▃▃▂▂▂▂▂▂▂▂▁▂▂▂▂▁▁▁▂▂▂▂▁▁▁▁▁▁▂▂▁▁▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▇▅▄▄▅▃▃▃▃▄▄▁▃▂▂▅▁▄▄▄▃▃▃▃▄▃▂▃▃▃▃▄▄▂▄▄▃▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▇▅▇▇▇▇██▇███▇█▇█████▇█▇██▇█▇██▇█▇█▇█▇█</td></tr><tr><td>val_auc</td><td>▁▅▇▇▇███▇████████████▇██▇██▇▇▇█▇██▇█████</td></tr><tr><td>val_f1</td><td>▁▇▇▅▇▇▇▇██████▇█▇███████▇████▇██▇███████</td></tr><tr><td>val_loss_epoch</td><td>█▅▃▅▂▃▃▃▁▂▁▁▁▁▂▁▂▁▂▂▂▂▂▁▂▃▂▃▂▂▂▂▂▂▂▂▂▁▂▂</td></tr><tr><td>val_loss_step</td><td>█▅▄▅▄▅▅█▂▄▂▂▁▃▃▃▄▂▃▃▄▃▄▂▃▆▃▆▃▃▃▂▃▄▃▅▃▁▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85773</td></tr><tr><td>train_auc</td><td>0.9294</td></tr><tr><td>train_f1</td><td>0.85314</td></tr><tr><td>train_loss_epoch</td><td>0.34572</td></tr><tr><td>train_loss_step</td><td>0.28266</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82979</td></tr><tr><td>val_auc</td><td>0.90229</td></tr><tr><td>val_f1</td><td>0.82938</td></tr><tr><td>val_loss_epoch</td><td>0.40504</td></tr><tr><td>val_loss_step</td><td>0.41651</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wcyvs6wt' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wcyvs6wt</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_155253-wcyvs6wt\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f260021850c94c9b95d44a13ee269f7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333330477276, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_161312-0gt9jvfi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0gt9jvfi' target=\"_blank\">GCN_3_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0gt9jvfi' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0gt9jvfi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_3\\attention2\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 832   \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇▇▇█████████▇██████████████████████</td></tr><tr><td>train_auc</td><td>▁▇▇▇████████████████████████████████████</td></tr><tr><td>train_f1</td><td>▁▇▇█████████████████████████████████████</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▂▂▂▂▂▁▂▂▂▂▂▂▁▂▂▂▂▁▂▂▁▂▁▂▁▁▁▁▂▂▁▂▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>▇▃▄▄▃▄▄▄▃▄▃▄█▃▂▃▃▃▃▂▄▂▄▄▂▂▂▃▂▂▁▃▂▃▂▂▄▃▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▆████▇███▅▇█▆█▇▇▇▇▆▇█▇█▇▇▆█▇▇▆█▅▇█▅▇█▇</td></tr><tr><td>val_auc</td><td>▁▄▅▆▆▇▇▇▇▇▇▇▇▇▇▇██▇▇█▇▇█▇█▇█▇█▇█▇▇█▇▇▇▇█</td></tr><tr><td>val_f1</td><td>▁▇▆████▇███▆██▆█▇▇██▇▇███▇█▇███▇█▇██▆███</td></tr><tr><td>val_loss_epoch</td><td>█▃▄▂▁▂▁▂▂▂▂▅▁▂▃▂▁▂▂▂▃▂▂▃▁▂▃▃▁▂▂▂▂▄▂▁▅▂▂▂</td></tr><tr><td>val_loss_step</td><td>▇▄▅▄▁▃▁▃▃▅▃█▂▄▂▃▂▄▃▃▃▄▃▄▁▂▆▅▃▃▃▃▃▅▄▂▃▃▆▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8477</td></tr><tr><td>train_auc</td><td>0.91519</td></tr><tr><td>train_f1</td><td>0.8442</td></tr><tr><td>train_loss_epoch</td><td>0.3738</td></tr><tr><td>train_loss_step</td><td>0.34857</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.8227</td></tr><tr><td>val_auc</td><td>0.91564</td></tr><tr><td>val_f1</td><td>0.83516</td></tr><tr><td>val_loss_epoch</td><td>0.39734</td></tr><tr><td>val_loss_step</td><td>0.37405</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0gt9jvfi' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0gt9jvfi</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_161312-0gt9jvfi\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_163326-gwqoia91</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gwqoia91' target=\"_blank\">GraphConv_3_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gwqoia91' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gwqoia91</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_3\\attention2\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 1.6 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d50a2aefaca42cbb574eb3b0968d32b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▇▇▇▇▇▇█▇▇▇▇▇██▇███▇▇▇█████▇██████████</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇█████▇███████████████████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇▇▇▇█▇███▇███▇▇████▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▃▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▁▂▂▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>▇▆▄▃▃▄▃▃▃▃▂▂▃▃▃▄▂▂▃▂▃▂▃▃▂▁▂█▂▄▂▂▃▃▃▂▃▂▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▆▇▇▇█▇█▇██▆█▇▇█▆█▇▇▇▇▆███▇████▇▇███▇▇█</td></tr><tr><td>val_auc</td><td>▁▇▇█████████████████████▇██████▇█▇██████</td></tr><tr><td>val_f1</td><td>▁▅▆▇█▇███▇█▇▆█▇▇█▆██▇▇█▆███▇█████████▇▇█</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▂▂▁▁▁▂▁▁▁▃▂▂▂▁▃▁▂▁▂▂▄▂▂▁▃▂▁▂▂▂▁▁▄▂▃▂▂</td></tr><tr><td>val_loss_step</td><td>▇▅▄▄▄▃▄▃▅▃▄▃▄▆▅▄▂▅▃▃▂▄▄▆▄▅▂▃▄▃▄▃▄▁▂█▅▃▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85006</td></tr><tr><td>train_auc</td><td>0.9277</td></tr><tr><td>train_f1</td><td>0.84935</td></tr><tr><td>train_loss_epoch</td><td>0.34421</td></tr><tr><td>train_loss_step</td><td>0.28715</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83215</td></tr><tr><td>val_auc</td><td>0.89864</td></tr><tr><td>val_f1</td><td>0.8345</td></tr><tr><td>val_loss_epoch</td><td>0.42717</td></tr><tr><td>val_loss_step</td><td>0.48039</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gwqoia91' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gwqoia91</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_163326-gwqoia91\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_165354-hx8rdnx4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hx8rdnx4' target=\"_blank\">GCN_3_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hx8rdnx4' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hx8rdnx4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_3\\mean\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 2.7 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "3.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.2 K     Total params\n",
      "0.013     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇██▇█▇▇▇▇██▇▇</td></tr><tr><td>train_auc</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████▇████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▇▆▆▇▆▇▇▆▇▇▇▇▇▆▇▇█▇▇▇█▆▇█▇█▇▇▇▇▇█▇█</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▃▃▃▂▂▂▃▂▃▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▂▂▁▂▂▁▁▂▂▂▁▁▂</td></tr><tr><td>train_loss_step</td><td>██▄▅▅▅▃▄▄▃▆▄▁▃▃▄▃▁▂▄▃▅▂▃▃▅▃▄▄▄▄▄▄▄▄▂▅▄▄▇</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▁▇▅▆▇▄▆▅▇▇▅▇▆▇█▇▇▆▇▅█▇▆▆▇▇▆▇▇▆▇▇▆▅▆▆▇▅▅</td></tr><tr><td>val_auc</td><td>▁▆▇█▇▇▇█▇▇█▇█▇▇███▇█▇██▇▇█▇▇▇▇▇█▇▇█▇▇▇▇▇</td></tr><tr><td>val_f1</td><td>▂▁▇▆▇▇▄▇▅▇█▆▇▇▇█▇█▆▇▇█▇▇▇█▇▇▇▇▇▇█▆▇▆▇▇▇▆</td></tr><tr><td>val_loss_epoch</td><td>█▆▃▃▃▂▄▃▂▃▂▃▂▂▃▁▂▁▂▂▄▁▂▃▃▂▂▃▂▁▃▁▃▃▃▂▂▁▅▄</td></tr><tr><td>val_loss_step</td><td>▇▆▇▅▆▅▅▆▄▆▅▅▆▃▆▃▅▂▅▄▆▄▄▅▆▆▅▅▄▁▅▃▇▆▅▃▅▃██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84947</td></tr><tr><td>train_auc</td><td>0.91842</td></tr><tr><td>train_f1</td><td>0.85387</td></tr><tr><td>train_loss_epoch</td><td>0.36275</td></tr><tr><td>train_loss_step</td><td>0.53745</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.8156</td></tr><tr><td>val_auc</td><td>0.91097</td></tr><tr><td>val_f1</td><td>0.79255</td></tr><tr><td>val_loss_epoch</td><td>0.43465</td></tr><tr><td>val_loss_step</td><td>0.58944</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hx8rdnx4' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hx8rdnx4</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_165354-hx8rdnx4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef02452ed45d4970a7ae949a9e8b5b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333330477276, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_171434-wt0bdf73</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wt0bdf73' target=\"_blank\">GraphConv_3_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wt0bdf73' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wt0bdf73</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_3\\mean\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 5.2 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "5.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.7 K     Total params\n",
      "0.023     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5e23875661940d6b12dd6cf0927f101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇█▇██████▇████████</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>train_f1</td><td>▁▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████▇████████</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▃▃▃▂▂▂▃▃▂▃▂▂▂▂▂▂▂▂▂▁▂▂▁▁▂▁▁▂▂▁▂▂▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▄▅▅▂▃▃▃▄▄▃▅▃▃▁▂▂▄▃▂▁▂▃▄▂▂▂▃▂▃▂▁▄▄▃▃▂▁▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▇█████████████▇██▇██▇▇▇▇██▇█▇█▇▇██████</td></tr><tr><td>val_auc</td><td>▁▆▇████▇███████▇▇██▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇▇▇█</td></tr><tr><td>val_f1</td><td>▁▅▇████▇███▇█▇▇▇▇█▇▇██▇▇▇▇█▇▆▇▇▇▇▇██▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▂▁▂▁▃▃▁▂▁▂▁▂▂▄▂▁▃▂▃▃▃▂▄▃▂▃▃▂▂▁▂▁▂▂▂▂▃</td></tr><tr><td>val_loss_step</td><td>█▄▆▄▃▆▃▆▇▂▅▂▃▃▄▂▇▆▂█▂▅▆▄▁▆▆▃▆▆▃▄▂▂▁▅▄▄▂▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87662</td></tr><tr><td>train_auc</td><td>0.94665</td></tr><tr><td>train_f1</td><td>0.87387</td></tr><tr><td>train_loss_epoch</td><td>0.29946</td></tr><tr><td>train_loss_step</td><td>0.35674</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83215</td></tr><tr><td>val_auc</td><td>0.90571</td></tr><tr><td>val_f1</td><td>0.83527</td></tr><tr><td>val_loss_epoch</td><td>0.44689</td></tr><tr><td>val_loss_step</td><td>0.53773</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wt0bdf73' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wt0bdf73</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_171434-wt0bdf73\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_173541-zqli5oi4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zqli5oi4' target=\"_blank\">GCN_3_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zqli5oi4' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zqli5oi4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_3\\max\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 2.7 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "3.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.2 K     Total params\n",
      "0.013     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18476b7b87034c0cbb943c608266d0e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▃▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇█▇▇▇▇▇████▇████</td></tr><tr><td>train_auc</td><td>▂▃▃▃▂▂▂▂▂▁▂▃▃▂▃▄▂▃▄▄▄▄▆▆▆▇▆▆▅▆▇▇▆▆▆▇▇█▇█</td></tr><tr><td>train_f1</td><td>▁▂▃▄▅▅▆▅▅▆▅▆▆▇▆▆▇▇▇▇▇▇▇▇▇█▇▇▇▇▇████▇████</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▄▃▄▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▁▂▂▂▁▂▂▂▂▂▁▁▁▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▆▆▆▄▅▆▄▅▅▅▄▅▅▄▄▆▂▃▄▃▁▃▂▄▂▃▃▃▃▃▃▂▄▁▁▃▄▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▁▆▆▆▆▆▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▆▇▇▇▆▇▆▇▇▇▆▇▇▆▆▇██</td></tr><tr><td>val_auc</td><td>▄▃▆▇▃▃▄▂▁▁▁▂▆▄▆▆▅▇▇▇████████████████████</td></tr><tr><td>val_f1</td><td>▁▁▅▄▄▄▄▅▅▅▄▅▄▆▆▆▆▇▆▄▆▇▆▇▆▇▆▇▆▇▇▆▆▆▆▆▆▆█▇</td></tr><tr><td>val_loss_epoch</td><td>██▇▆▆▅▆▅▅▅▅▄▄▄▄▃▃▂▃▂▂▃▃▂▃▁▅▁▄▁▂▂▃▂▃▂▃▂▂▁</td></tr><tr><td>val_loss_step</td><td>▇▇▆▅▆▄▆▆▆▅▅▄▃▄▃▂▃▂▅▃▂▆▃▃▄▂█▂▃▁▂▂▆▃▇▁▃▁▆▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.79752</td></tr><tr><td>train_auc</td><td>0.76482</td></tr><tr><td>train_f1</td><td>0.80545</td></tr><tr><td>train_loss_epoch</td><td>0.45071</td></tr><tr><td>train_loss_step</td><td>0.50063</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.73286</td></tr><tr><td>val_auc</td><td>0.84571</td></tr><tr><td>val_f1</td><td>0.7631</td></tr><tr><td>val_loss_epoch</td><td>0.49975</td></tr><tr><td>val_loss_step</td><td>0.49882</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zqli5oi4' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zqli5oi4</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_173541-zqli5oi4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_180131-a8g4eo51</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/a8g4eo51' target=\"_blank\">GraphConv_3_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/a8g4eo51' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/a8g4eo51</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_3\\max\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 5.2 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "5.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.7 K     Total params\n",
      "0.023     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▄▄▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███▇████████████████</td></tr><tr><td>train_auc</td><td>▁▁▂▂▃▄▄▄▄▄▄▅▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███▇██████</td></tr><tr><td>train_f1</td><td>▁▂▄▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███▇████████████████</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▅▆▅▄▄▃▄▃▃▃▅▃▄▃▂▂▃▃▂▂▅▂▃▂▃▂▂▂▃▁▂▃▂▂▂▁▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▆▆▆▆▇▇▇▇▇▇▇▇▇█▇▇▇▆▇██▇▇▆▇█▇▇████▇███▇█</td></tr><tr><td>val_auc</td><td>▁▄▅▃▆▇▇██████▇▇▇▇██████▇▇▇████████▇█████</td></tr><tr><td>val_f1</td><td>▁▅▇▇▇▇█▇█▇▇▇▇▇▇█▇▇▇▆▆██▇█▆▇█▇▇█▇██████▇█</td></tr><tr><td>val_loss_epoch</td><td>█▇▆▅▄▄▄▃▄▃▄▃▃▃▃▂▃▂▂▃▂▂▃▃▃▃▃▂▂▂▂▁▂▁▂▁▂▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▇▆▆▄▅▆▄▆▄▅▂▄▃▄▂▆▃▂▅▁▃▆▅▂▄▅▁▆▂▂▂▂▁▁▂▆▁▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8412</td></tr><tr><td>train_auc</td><td>0.87779</td></tr><tr><td>train_f1</td><td>0.84204</td></tr><tr><td>train_loss_epoch</td><td>0.38126</td></tr><tr><td>train_loss_step</td><td>0.40722</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.79196</td></tr><tr><td>val_auc</td><td>0.87665</td></tr><tr><td>val_f1</td><td>0.80269</td></tr><tr><td>val_loss_epoch</td><td>0.43872</td></tr><tr><td>val_loss_step</td><td>0.47151</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/a8g4eo51' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/a8g4eo51</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_180131-a8g4eo51\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_182636-y6a3eq2d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/y6a3eq2d' target=\"_blank\">GCN_3_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/y6a3eq2d' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/y6a3eq2d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_3\\sum\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 2.7 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "3.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.2 K     Total params\n",
      "0.013     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇█▇█▇▇█▇████████▇████</td></tr><tr><td>train_auc</td><td>▂▁▄▄▄▅▅▆▆▆▇▆▇▆▆▆▇▇▇▇▇▇▇▇▅▆▇▇▇▇▇▇▇██▇▇██▇</td></tr><tr><td>train_f1</td><td>▁▃▆▆▆▆▇▇▇▆▇█▇▇▇▇▇▇▇▇█▇█▇▇█▇████████▇████</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▁▂▂▂▂▂▂▁▂▁▂▂▂▂▂▂▂▂▂▂▂▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▂▆▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▆▇█▆▆███▇█▇▇▇█▇▇▇█▇</td></tr><tr><td>val_auc</td><td>▂▁▇▇▇▇▇██████████████████████▇████▇██▇▇█</td></tr><tr><td>val_f1</td><td>▁▃▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▆▇██▇▇█▇▆█████▇▇▇█▇▇▇██</td></tr><tr><td>val_loss_epoch</td><td>█▆▃▃▄▃▃▃▂▂▂▄▃▂▃▂▄▃▃▁▂▂▂▁▄▃▁▂▁▁▁▂▂▂▂▂▂▂▂▃</td></tr><tr><td>val_loss_step</td><td>▇▅▆▅▆▅▅▅▄▄▄▇▅▃▅▃▇▄▅▄▄▅▄▄█▇▄▅▄▁▄▄▆▅▄▃▅▃▄▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84238</td></tr><tr><td>train_auc</td><td>0.85077</td></tr><tr><td>train_f1</td><td>0.84285</td></tr><tr><td>train_loss_epoch</td><td>0.37564</td></tr><tr><td>train_loss_step</td><td>0.42154</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.8227</td></tr><tr><td>val_auc</td><td>0.89806</td></tr><tr><td>val_f1</td><td>0.8062</td></tr><tr><td>val_loss_epoch</td><td>0.4687</td></tr><tr><td>val_loss_step</td><td>0.67478</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/y6a3eq2d' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/y6a3eq2d</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_182636-y6a3eq2d\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_184756-aj4s2epb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/aj4s2epb' target=\"_blank\">GraphConv_3_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/aj4s2epb' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/aj4s2epb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_3\\sum\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 5.2 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "5.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.7 K     Total params\n",
      "0.023     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8352ad68775e4ac88562b5633ba6f6fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.013 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.080634…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇███▇█████████</td></tr><tr><td>train_auc</td><td>▁▁▁▂▂▂▃▃▄▄▅▅▆▆▅▅▄▄▄▅▅▄▄▅▅▅▃▄▅▆▅▆▇▆▆▇▇▇█▇</td></tr><tr><td>train_f1</td><td>▁▂▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇███▇█████████</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▂▂▂▁▁▁▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▄▆▅▆▆▆▆▆▆▆▇▇▇▇▇█████▇█████████████▇███</td></tr><tr><td>val_auc</td><td>▂▁▁▄▅▆▆▇▇███████▇▇▇██▇▇███▇█████████████</td></tr><tr><td>val_f1</td><td>▁▃▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█▇██▇██▇██████▇▇██▇▇██</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▃▂▂▂▂▁▂▂▂▂▁▂▁▂▁▂▂▁▂▁▂▂▂▁▂▂▂▂▂▁▁▁▁▁▂▂▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85419</td></tr><tr><td>train_auc</td><td>0.78586</td></tr><tr><td>train_f1</td><td>0.85306</td></tr><tr><td>train_loss_epoch</td><td>0.36757</td></tr><tr><td>train_loss_step</td><td>0.50776</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83688</td></tr><tr><td>val_auc</td><td>0.89716</td></tr><tr><td>val_f1</td><td>0.83916</td></tr><tr><td>val_loss_epoch</td><td>0.47865</td></tr><tr><td>val_loss_step</td><td>0.57798</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/aj4s2epb' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/aj4s2epb</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_184756-aj4s2epb\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_190824-zma329tu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zma329tu' target=\"_blank\">GCN_3_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zma329tu' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zma329tu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_3\\attention\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 2.7 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "3.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.3 K     Total params\n",
      "0.013     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▇▇▇▇▆▇▇▇▇▇▇█▇▇▇▇█▇▇▇█▇█▇▇▇█▇█▇▇▇██▇▇</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇█▇▇▇▇█▇▇█████████████████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▇▇▆▇▆▇▆▇▇▇▇█▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇█▇▇▇█▇▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▃▂▂▂▂▃▂▂▂▃▂▁▂▂▂▂▁▂▂▁▁▂▁▂▂▁▁▂▂▁▂▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▄▄▆▆▅▄▅▅▆▂▄▄▄▃▃▄▃▃▁▄▃▃▄▄▂▇▂▃▁▄▃▃▃▃▃▃▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▄▇▇▇▆█▆▇▇▅█▇▇▆▇▇█▇▇█▇▇█▅▇▅▆▇▇▇▇██▆█▇██</td></tr><tr><td>val_auc</td><td>▁▆▇▇▇▇▆▇█▇▇▇▇▇▇▇██▇▇▇▇▇▇▇▇▇▆▇▇▇▆▇▇▇▇▇▇▇▇</td></tr><tr><td>val_f1</td><td>▁▆▄▇▇█▆█▇█▇▅███▇▇██▇███▇█▇▇▇▇▇▇████▇█▇██</td></tr><tr><td>val_loss_epoch</td><td>█▃▅▂▂▂▃▁▃▂▂▄▂▁▂▃▂▃▁▃▂▂▂▂▂▄▂▄▃▂▂▂▃▂▁▂▂▁▂▁</td></tr><tr><td>val_loss_step</td><td>▇▅█▃▂▆▄▁▄▅▂▇▃▂▄▅▆▆▃█▄▅▃▆▅▄▂▅▆▅▅▄█▃▃▁▃▂▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84593</td></tr><tr><td>train_auc</td><td>0.92239</td></tr><tr><td>train_f1</td><td>0.84114</td></tr><tr><td>train_loss_epoch</td><td>0.35452</td></tr><tr><td>train_loss_step</td><td>0.33627</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.8487</td></tr><tr><td>val_auc</td><td>0.90918</td></tr><tr><td>val_f1</td><td>0.84615</td></tr><tr><td>val_loss_epoch</td><td>0.36725</td></tr><tr><td>val_loss_step</td><td>0.29882</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zma329tu' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zma329tu</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_190824-zma329tu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0b333eb608b406eb5a6c123cda92b90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_192946-5ylc1s2f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5ylc1s2f' target=\"_blank\">GraphConv_3_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5ylc1s2f' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5ylc1s2f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_3\\attention\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 5.2 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "5.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.7 K     Total params\n",
      "0.023     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e73b9d82da43476d93384e258336c2bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇████▇█▇█████████</td></tr><tr><td>train_auc</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███▇████████████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇██▇███████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▃▃▄▃▃▃▂▂▃▂▂▂▂▂▂▂▂▂▁▂▂▂▁▁▂▂▂▂▁▂▁▂▁▂▁▂</td></tr><tr><td>train_loss_step</td><td>█▆█▆▃▆▄▄▃▅▄▃▆▂▃▄▅▂▃▃▄▅▁▄▂▂▂▃▅▃▄▃▄▄▃▃▃▅▂▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▃▇█▅▅▆▇▇▇▆▅▇▆▇▇▇▅▆▇▇▆▆▆▅▆▇▆▆▅▇▅▅█▇▇▇▇▇</td></tr><tr><td>val_auc</td><td>▁▆▆▇█████▇▇▇█▇▇▇▇█▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇</td></tr><tr><td>val_f1</td><td>▃▅▁▇█▃▆▇▆▇▇▅▄▇▆▇▇▅▃▆▆▆▆▆▆▄▄▇▇▅▅▇▃▃▇▇▇▆▆▅</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▁▂▄▃▂▂▂▃▂▃▁▂▂▁▂▃▄▄▁▄▁▂▂▄▄▃▃▂▃▂▄▃▂▃▃▄▃</td></tr><tr><td>val_loss_step</td><td>▇▄▃▂▆▆▅▅▄▄▅▃▄▂▂▄▂▃▃▆▇▁█▂▃▁▄▆▅▆▃▇▂▄▆▃▆▆█▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8719</td></tr><tr><td>train_auc</td><td>0.9411</td></tr><tr><td>train_f1</td><td>0.87045</td></tr><tr><td>train_loss_epoch</td><td>0.31544</td></tr><tr><td>train_loss_step</td><td>0.35903</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.8227</td></tr><tr><td>val_auc</td><td>0.90379</td></tr><tr><td>val_f1</td><td>0.79893</td></tr><tr><td>val_loss_epoch</td><td>0.43645</td></tr><tr><td>val_loss_step</td><td>0.4218</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5ylc1s2f' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5ylc1s2f</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_192946-5ylc1s2f\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f991f53c3e3e4a868c636f0e986250e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_195012-0rsmsxmp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0rsmsxmp' target=\"_blank\">GCN_3_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0rsmsxmp' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0rsmsxmp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_3\\attention2\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 2.7 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "4.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.3 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02bd34283b0f4973bc2411c402dcf0e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇██▇▇▇█▇▇█▇█▇▇</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇▇▇█▇▇▇▇▇▇█▇▇▇██▇██▇████████▇█████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▇▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇▇▇▇▇▇█▇█▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▂▂▂▂▁▁▂▁▂▁▂▂</td></tr><tr><td>train_loss_step</td><td>█▅▃▅▄▃▆▂▆▄▅▂▃▆▃▂▄▅▃▃▃▄▁▄▅▂▄▄▂▃▃▃▃▃▂▃▁▂▃▆</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▃▄▃██▅▇▂▆▇▇▆▇▇▆▆▁▅▇▇▆▁▆▇▇▆▄▇▇▇▃▇▅▅▆▆▂▁▄█</td></tr><tr><td>val_auc</td><td>▁▆▇▇▇▇▇▇▇████▇▇▇▇█▇▇▇▇▇▇█▇▇▇▇▆▆▇▆▇▆▆▇▇▇█</td></tr><tr><td>val_f1</td><td>▄▄▃██▅▇▂▆▇▇▆█▇▇▇▁▆▇▇▇▁▆▇▇▇▄█▇▇▃▇▅▆▆▇▂▁▆█</td></tr><tr><td>val_loss_epoch</td><td>█▃▄▂▂▄▂▃▁▁▁▂▁▂▃▁▆▁▁▂▃▅▂▂▂▁▃▁▃▂▃▂▂▃▂▂▆▄▄▂</td></tr><tr><td>val_loss_step</td><td>▆▄▅▄▄█▅▃▃▃▃▅▃▄▅▂▇▁▃▃▄▅▄▅▃▂▃▃▆▅▃▃▃▅▄▃▆▁▆▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85006</td></tr><tr><td>train_auc</td><td>0.91963</td></tr><tr><td>train_f1</td><td>0.84754</td></tr><tr><td>train_loss_epoch</td><td>0.36938</td></tr><tr><td>train_loss_step</td><td>0.50415</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.85343</td></tr><tr><td>val_auc</td><td>0.91249</td></tr><tr><td>val_f1</td><td>0.85514</td></tr><tr><td>val_loss_epoch</td><td>0.39023</td></tr><tr><td>val_loss_step</td><td>0.42155</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0rsmsxmp' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0rsmsxmp</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_195012-0rsmsxmp\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_201101-ehr86wvv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ehr86wvv' target=\"_blank\">GraphConv_3_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ehr86wvv' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ehr86wvv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_3\\attention2\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 5.2 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "6.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.8 K     Total params\n",
      "0.027     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇███████████████████████</td></tr><tr><td>train_auc</td><td>▁▆▆▇▇▇▇▇▇▇▇▇████▇███████████████████████</td></tr><tr><td>train_f1</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇██▇███████████████████████</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▃▃▃▃▂▃▂▂▂▂▂▂▁▂▂▂▂▂▂▂▁▂▁▁▂▁▁▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▅▃▅▄▄▃▅▄▄▃▄▃▃▄▄▃▃▄▃▂▄▂▂▂▃▂▂▃▃▂▂▂▃▁▃▄▂▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▇███▇██▇█████▇▇▇▇█▇▇▇▇▇▆▇▇▇▇█▇▇█▇▇▇▇▇▇</td></tr><tr><td>val_auc</td><td>▁▆▇▇█▇▇██████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>val_f1</td><td>▁▆▇█▇█▇▇█▇▇███▇▇▇▆▇▇▇▅▇▅▇▄▆▇▆▆▇▇▆█▇▇▅▆▇▅</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▂▂▂▂▂▁▁▂▁▂▁▂▂▂▂▂▂▂▃▂▄▂▄▂▃▃▃▃▂▃▃▅▁▃▃▅▃</td></tr><tr><td>val_loss_step</td><td>▆▄▃▄▄▅▁▆▃▂▄▂▅▂▃▃▃▃▃▂▄▃▅▅▃▅▂▄▅▄▄▂▄▃█▂▂▃▇▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8843</td></tr><tr><td>train_auc</td><td>0.94573</td></tr><tr><td>train_f1</td><td>0.88375</td></tr><tr><td>train_loss_epoch</td><td>0.3082</td></tr><tr><td>train_loss_step</td><td>0.44482</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80378</td></tr><tr><td>val_auc</td><td>0.89882</td></tr><tr><td>val_f1</td><td>0.78553</td></tr><tr><td>val_loss_epoch</td><td>0.42781</td></tr><tr><td>val_loss_step</td><td>0.34514</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ehr86wvv' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ehr86wvv</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_201101-ehr86wvv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_203210-lq0hgpa0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/lq0hgpa0' target=\"_blank\">GCN_3_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/lq0hgpa0' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/lq0hgpa0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_3\\mean\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 9.5 K \n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "11.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "11.6 K    Total params\n",
      "0.046     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47a46fff6eac48ee8c1c329fdd42ad21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.013 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.080664…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇█▇█▇████▇▇▇█</td></tr><tr><td>train_auc</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇███▇███▇█▇██████████</td></tr><tr><td>train_f1</td><td>▁▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇█▇█▇█▇█▇████▇█▇█</td></tr><tr><td>train_loss_epoch</td><td>█▃▃▃▄▂▂▂▃▂▂▂▂▂▂▂▂▂▂▃▁▂▂▂▂▁▁▂▂▂▂▂▁▁▂▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>▄▃▂▃▃▃▂▃▃▄▃▃▃▂▃▄▂▂▃▃▂▄█▃▂▃▂▄▃▂▃▂▃▆▂▂▂▂▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▆▇▇▇█▇▇███▇██▇▇█▇▇▇▇█▇▆█████▇████▇█▇▇▇</td></tr><tr><td>val_auc</td><td>▁▃▇▇▇█▇██▆███▆▇▇▇█▆▇▇▇▆▇▆▇▇▆▆▄▆▇▆▇▆▇▆▇▆▄</td></tr><tr><td>val_f1</td><td>▁▄▇▇▇██████████▇▇████▇█▇██████████████▇█</td></tr><tr><td>val_loss_epoch</td><td>█▅▂▂▂▁▂▁▁▂▁▁▁▁▁▂▁▁▂▁▁▁▂▂▃▁▁▁▁▂▁▁▂▁▁▁▁▁▂▂</td></tr><tr><td>val_loss_step</td><td>█▇▃▃▄▂▄▃▂▃▂▂▂▁▃▃▂▂▄▂▂▂▃▂▃▂▃▃▂▃▂▃▃▂▂▃▃▂▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86423</td></tr><tr><td>train_auc</td><td>0.93234</td></tr><tr><td>train_f1</td><td>0.86565</td></tr><tr><td>train_loss_epoch</td><td>0.3294</td></tr><tr><td>train_loss_step</td><td>0.22602</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81087</td></tr><tr><td>val_auc</td><td>0.89457</td></tr><tr><td>val_f1</td><td>0.82063</td></tr><tr><td>val_loss_epoch</td><td>0.44624</td></tr><tr><td>val_loss_step</td><td>0.51006</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/lq0hgpa0' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/lq0hgpa0</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_203210-lq0hgpa0\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d67db96622044abac6de58afc90e006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_205949-7rg1jmaq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7rg1jmaq' target=\"_blank\">GraphConv_3_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7rg1jmaq' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7rg1jmaq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_3\\mean\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 18.5 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "20.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.6 K    Total params\n",
      "0.083     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇██▇█▇█▇█▇██▇█████</td></tr><tr><td>train_auc</td><td>▁▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇██████████████████</td></tr><tr><td>train_f1</td><td>▁▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇███▇█▇████████</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▂▂▁▂▁▂▁▁▂▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▅▆▇▆▅▅▄▄▅▃▄▄▄▇▃▅▃▅▃▆▂▂▄▄▂▃▃▅▃▁▅▁▄▂▁▄▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▇█████▇▇███▇█▇▇▇█▇▇▇▇███▇▇▇█▇██▇▇▇█▇█▇</td></tr><tr><td>val_auc</td><td>▁▇▇▇█▇▇▇▇▆▆▆▆▆▆▆▆▆▇▆▆▆▅▅▅▆▆▆▆▆▆▆▅▅▅▅▅▄▅▅</td></tr><tr><td>val_f1</td><td>▂▁▆██▇██▇▆▇██▇▇▆▇▇▇▇▆▇▅███▇▆▇█▆▇▇▇▅▅█▆█▆</td></tr><tr><td>val_loss_epoch</td><td>█▅▂▁▁▁▂▂▂▃▂▂▂▂▃▃▂▂▂▂▃▂▄▃▃▃▂▂▄▃▂▂▃▄▄▅▃▃▃▃</td></tr><tr><td>val_loss_step</td><td>█▆▆▃▄▃▄▄▄▅▃▄▅▃▅▅▄▃▄▃▅▄▅▅▄▃▃▃▇▅▁▃▆▅▅█▅▂▇▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.89197</td></tr><tr><td>train_auc</td><td>0.95718</td></tr><tr><td>train_f1</td><td>0.89101</td></tr><tr><td>train_loss_epoch</td><td>0.26111</td></tr><tr><td>train_loss_step</td><td>0.15003</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.8156</td></tr><tr><td>val_auc</td><td>0.88795</td></tr><tr><td>val_f1</td><td>0.81159</td></tr><tr><td>val_loss_epoch</td><td>0.4521</td></tr><tr><td>val_loss_step</td><td>0.43922</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7rg1jmaq' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7rg1jmaq</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_205949-7rg1jmaq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_212226-tui2tjnj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tui2tjnj' target=\"_blank\">GCN_3_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tui2tjnj' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tui2tjnj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_3\\max\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 9.5 K \n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "11.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "11.6 K    Total params\n",
      "0.046     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇█▇█▇█▇▇██████████▇▇██</td></tr><tr><td>train_auc</td><td>▁▁▃▂▃▃▃▅▄▅▅▅▅▆▆▇▇▇▇▇▇▇▇█▇███████████████</td></tr><tr><td>train_f1</td><td>▁▃▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇█▇█▇▇██████████▇▇██</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▅▅▄▃▃▄▃▄▃▄▃▃▄▃▂▃▂▃▃▃▅▃▃▁▃▃▃▃▂▂▃▃▂▁▁▁▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▅▅▅▅▅▅▅▅▅▅▆▆▆██▇▇█▇███▇██▇▇▇▇████▇█▇█▇</td></tr><tr><td>val_auc</td><td>▁▁▃▂▄▃▄▄▅▅▅▆▆▆▇▇██▇▇█▇█▇▇▇█▇█▇▇█▇███▇▇▇█</td></tr><tr><td>val_f1</td><td>▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████▇███████████████████</td></tr><tr><td>val_loss_epoch</td><td>█▇▆▆▆▆▆▆▅▅▅▅▄▃▄▃▂▂▂▂▃▂▁▁▂▁▂▂▂▂▂▂▂▁▂▂▂▂▂▁</td></tr><tr><td>val_loss_step</td><td>█▇▅█▇▇▆▆▅▅▅▅▅▃▅▆▅▃▄▄▅▂▂▂▂▂▆▂▅▄▅▃▂▁▃▆▃▁▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.82113</td></tr><tr><td>train_auc</td><td>0.88946</td></tr><tr><td>train_f1</td><td>0.82312</td></tr><tr><td>train_loss_epoch</td><td>0.40686</td></tr><tr><td>train_loss_step</td><td>0.29718</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.77541</td></tr><tr><td>val_auc</td><td>0.87175</td></tr><tr><td>val_f1</td><td>0.78555</td></tr><tr><td>val_loss_epoch</td><td>0.45141</td></tr><tr><td>val_loss_step</td><td>0.43187</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tui2tjnj' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tui2tjnj</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_212226-tui2tjnj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_214443-1ghhdzwv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1ghhdzwv' target=\"_blank\">GraphConv_3_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1ghhdzwv' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1ghhdzwv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_3\\max\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 18.5 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "20.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.6 K    Total params\n",
      "0.083     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████████</td></tr><tr><td>train_auc</td><td>▁▃▃▃▂▃▃▂▃▄▄▅▅▅▅▅▆▆▆▇▇▇▇▆▆▇▇▇█▇▇██▇▇█████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████████</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▅▅▆▄▅▅▄▄▄▅▅▃▃▅▃▆▃▃▃▃▂▃▂▃▂▂▃▄▂▄▄▄▆▃▂▃▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▆▆▆▇▆▆▆▇▅▇▇▇▇▆▇▆▇▇▆▆▆█▇█▇▇▇▆▇▆▇▅▇▇▆▅▇█</td></tr><tr><td>val_auc</td><td>▁▄▄▅▇▇▄▆▆▅▆▅▅▆▇▇▇▇▇▇▇▇████▇▇▇▆▇▇█▇██▇▇█▇</td></tr><tr><td>val_f1</td><td>▁▂▄▆▃▅▃▂▄▆▁▆▇▅▇▅▅▅▇▇▅▆▄█▇██▆▇▆▇▇▆▅▆▇▆▆▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▆▅▄▃▂▃▃▂▂▃▃▄▃▃▂▂▂▂▂▂▄▁▁▂▂▂▁▃▅▂▂▂▄▁▂▅▃▄▁</td></tr><tr><td>val_loss_step</td><td>▇▆▅▅▄▃▄▄▃▃▃▃▆▄▃▂▃▃▄▁▃▄▁▂▃▄▂▁▄▆▁▃▄▅▂▄▆▁█▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86305</td></tr><tr><td>train_auc</td><td>0.89058</td></tr><tr><td>train_f1</td><td>0.86417</td></tr><tr><td>train_loss_epoch</td><td>0.31766</td></tr><tr><td>train_loss_step</td><td>0.21739</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80851</td></tr><tr><td>val_auc</td><td>0.87305</td></tr><tr><td>val_f1</td><td>0.81379</td></tr><tr><td>val_loss_epoch</td><td>0.43825</td></tr><tr><td>val_loss_step</td><td>0.38013</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1ghhdzwv' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1ghhdzwv</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_214443-1ghhdzwv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_220729-ui13dnkz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ui13dnkz' target=\"_blank\">GCN_3_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ui13dnkz' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ui13dnkz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_3\\sum\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 9.5 K \n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "11.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "11.6 K    Total params\n",
      "0.046     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79616d94a95548698f53778e081ffddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇█▇███▇███▇████</td></tr><tr><td>train_auc</td><td>▆▅▃▄▃▂▁▁▂▂▂▁▁▁▁▁▁▃▄▃▄▃▃▃▆▆▄▅▆▅▂▂▄▅▆▆▇▇▇█</td></tr><tr><td>train_f1</td><td>▁▄▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇█▇█▇▇▇███▇█▇█▇█▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▃▁▁▁▁▁▁▁▁▁▂▂▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▂▅▆▅▆▆▆▆▇▆▅▇▇▆▇████▆▅█▆█▆▇▇█▇█▆▇█▆▆█▇▇█</td></tr><tr><td>val_auc</td><td>▇▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▁▂▁▁▁█▇▄▇█▃▁▁▃███████</td></tr><tr><td>val_f1</td><td>▁▂▆▆▆▇▇▆▇▇▇▆▇▇▇▇████▇▆█▇█▇█████▇▇█▇▇██▇█</td></tr><tr><td>val_loss_epoch</td><td>█▂▂▂▁▁▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▂▁▁▁▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▄▂▂▂▁▃▃▂▁▂▂▂▁▂▂▂▂▂▂▁▁▂▁▁▂▂▂▁▂▂▂▂▁▁▂▁▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84888</td></tr><tr><td>train_auc</td><td>0.79657</td></tr><tr><td>train_f1</td><td>0.85082</td></tr><tr><td>train_loss_epoch</td><td>0.3722</td></tr><tr><td>train_loss_step</td><td>0.31554</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82506</td></tr><tr><td>val_auc</td><td>0.9043</td></tr><tr><td>val_f1</td><td>0.80928</td></tr><tr><td>val_loss_epoch</td><td>0.43541</td></tr><tr><td>val_loss_step</td><td>0.45529</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ui13dnkz' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ui13dnkz</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_220729-ui13dnkz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_223105-8pzxajo8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8pzxajo8' target=\"_blank\">GraphConv_3_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8pzxajo8' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8pzxajo8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_3\\sum\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 18.5 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "20.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.6 K    Total params\n",
      "0.083     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e721434ac67d4aa88999282296f0c35a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▆▆▆▆▆▆▆▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇██▇████</td></tr><tr><td>train_auc</td><td>▃▁▁▂▃▄▄▅▆▆▆▅▅▆▆▅▆▅▆▆▆▆▅▆▇▇▇▇▆▇█▇▆▇▇▇▆▆▆▇</td></tr><tr><td>train_f1</td><td>▁▄▅▅▆▆▆▆▆▆▆▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇██▇████</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▂▂▂▂▂▂▂▂▂▂▁▂▁▂▂▁▂▁▂▁▂▁▁▂▁▁▁▁▂▁▁▂▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▅▆▆▇▇▆▆▆▆▅▇▇█▇█▇▇▇██▇▇▇▇█▇█▇▇▆▇▆▇▇▇▇▇▆</td></tr><tr><td>val_auc</td><td>▃▁▂▅▆███████████████████████████████▇███</td></tr><tr><td>val_f1</td><td>▁▁▃▅▅▅▅▄▃▅▅▂▇▆██▇▆▆▇▇█▇▇▇▇█▆█▆▇▅▇▇▆█▇▇▇▆</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▂▂▁▂▃▂▂▁▃▂▂▂▂▁▁▂▂▂▁▂▂▂▂▂▂▁▃▁▂▃▃▃▃▃▁▂▃</td></tr><tr><td>val_loss_step</td><td>█▅▅▃▃▂▄▆▂▃▁▆▄▃▄▂▂▂▄▃▂▃▂▅▄▃▂▂▃▅▁▂▄▅▁▇▅▁▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8719</td></tr><tr><td>train_auc</td><td>0.84364</td></tr><tr><td>train_f1</td><td>0.87137</td></tr><tr><td>train_loss_epoch</td><td>0.31008</td></tr><tr><td>train_loss_step</td><td>0.2995</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82506</td></tr><tr><td>val_auc</td><td>0.88958</td></tr><tr><td>val_f1</td><td>0.82126</td></tr><tr><td>val_loss_epoch</td><td>0.50128</td></tr><tr><td>val_loss_step</td><td>0.56423</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8pzxajo8' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8pzxajo8</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_223105-8pzxajo8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_225548-rs9w8slu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/rs9w8slu' target=\"_blank\">GCN_3_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/rs9w8slu' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/rs9w8slu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_3\\attention\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 9.5 K \n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "11.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "11.7 K    Total params\n",
      "0.047     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e19b363e935e4c8cae072dd7e0404bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▆▆▆▆▆▆▆▇▆▅▇▇▇▇▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▆▇██▇▇</td></tr><tr><td>train_auc</td><td>▁▅▆▇▇▆▇▇▇▆▇▇▇▆▇▇▇▇▇▇▇▆▇▇▇▇▇████▇█▇▇████▇</td></tr><tr><td>train_f1</td><td>▁▅▅▆▆▅▆▆▇▆▆▆▆▅▇▇▇▇▇▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▆▇██▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▃▄▃▃▃▄▃▃▃▄▂▃▃▂▂▂▃▄▂▂▂▂▂▂▂▂▂▃▃▂▃▂▁▁▂▂</td></tr><tr><td>train_loss_step</td><td>██▅▅▅▆▄▅▄█▆▆▃▅▆▅▆▆▆▅▄▆▃▅▆▃▅▆▅▂▅▄▅▇▂▄▃▄▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▂▄▅▇▇▆▇▇▇▇█▇▅▇█▆▇▆█▇█▇██▇▇▇▇█▇████▇█▇▇█</td></tr><tr><td>val_auc</td><td>▁▄▆▇█▇▇▇▇▆▇█▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▆▇█▇▇▇▇█▇▆▆▇▇</td></tr><tr><td>val_f1</td><td>▁▃▅▆▇▇▇█▇▇███▆▇█▇▇▆█▇████▇▇█▇████████▇▇█</td></tr><tr><td>val_loss_epoch</td><td>██▇▄▂▂▄▂▃▃▂▁▂▄▂▂▃▂▄▂▃▂▂▂▁▃▂▃▃▂▃▂▂▂▁▂▂▄▃▂</td></tr><tr><td>val_loss_step</td><td>▇▇█▇▃▃▆▄▄▆▃▁▂▄▃▃▂▅▆▅▄▅▃▂▂▃▄▅▄▃▅▂▄▄▂▃▃▆▄▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8477</td></tr><tr><td>train_auc</td><td>0.92737</td></tr><tr><td>train_f1</td><td>0.84912</td></tr><tr><td>train_loss_epoch</td><td>0.34171</td></tr><tr><td>train_loss_step</td><td>0.17311</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82506</td></tr><tr><td>val_auc</td><td>0.90687</td></tr><tr><td>val_f1</td><td>0.81218</td></tr><tr><td>val_loss_epoch</td><td>0.38214</td></tr><tr><td>val_loss_step</td><td>0.30417</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/rs9w8slu' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/rs9w8slu</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_225548-rs9w8slu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_231936-qanch3kx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qanch3kx' target=\"_blank\">GraphConv_3_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qanch3kx' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qanch3kx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_3\\attention\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 18.5 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "20.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.7 K    Total params\n",
      "0.083     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "452cb67b81ea470b83f4bf3abbae1e4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▅▆▆▆▆▆▇▇▇▇▆▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇████▇▇█</td></tr><tr><td>train_auc</td><td>▁▄▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇██▇▇█████████▇██</td></tr><tr><td>train_f1</td><td>▁▄▅▅▅▆▆▆▆▆▇▇▇▇▆▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇████▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▄▄▃▃▃▂▃▂▃▃▂▂▃▃▂▂▂▂▂▂▂▃▂▂▂▁▂▂▁▁▁▁▃▂▁</td></tr><tr><td>train_loss_step</td><td>█▇▆▆▇▅▅▄▄▅▆▄▄▃▅▂▄▃▅▃▃▄▄▄▃▃▃▂▂▂▅▁▂▃▄▆▁▃▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▁▅▅▆▆▅▇▇▇▆▇▇▇▆▅█▆▇▇▇▆█▆▅▇▇▅▇▇▇▇▇▇▅▆▇▅▆▆</td></tr><tr><td>val_auc</td><td>▁▄▆▄▆▇██▇█▇▇▇▇█▇▇▇▇▇█▇█▆▇██▇▇█▇▇▆█▇█▇▆▆▆</td></tr><tr><td>val_f1</td><td>▃▁▆▇▇▇▅▇▇▇▆█▇▇▇▆█▇█▇▇▇█▇▆▇█▇▇▇▇▇▇▆▅▆▇▅▇▆</td></tr><tr><td>val_loss_epoch</td><td>█▆▃█▂▃▄▃▂▃▄▃▃▃▄▄▂▂▁▃▁▃▂▄▅▃▃▆▅▂▂▂▃▃▅▃▄▆▃█</td></tr><tr><td>val_loss_step</td><td>▆▅▄▇▃▄▅▅▄▆▆▅▃▅▅▄▄▅▁▅▁▂▄▅▇▅▅▆▅▃▃▃▄▄▅▄▄▆▃█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.89374</td></tr><tr><td>train_auc</td><td>0.95982</td></tr><tr><td>train_f1</td><td>0.8926</td></tr><tr><td>train_loss_epoch</td><td>0.25384</td></tr><tr><td>train_loss_step</td><td>0.20109</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80615</td></tr><tr><td>val_auc</td><td>0.88625</td></tr><tr><td>val_f1</td><td>0.8</td></tr><tr><td>val_loss_epoch</td><td>0.55839</td></tr><tr><td>val_loss_step</td><td>0.74607</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qanch3kx' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qanch3kx</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_231936-qanch3kx\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eb7e72ec9e8404abd77ecf823a26d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_234155-zpp4nifo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zpp4nifo' target=\"_blank\">GCN_3_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zpp4nifo' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zpp4nifo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_3\\attention2\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 9.5 K \n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "15.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.8 K    Total params\n",
      "0.063     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▅▆▆▆▆▆▆▆▇▇▆▆▇▇▇▇▇█▆▇▇▇▇▇▇▇▇███▇▇▇█▇▇</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇█▇▇████▇████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▅▆▆▅▆▆▇▆▇▇▆▇▇▇▇▇▇█▆▇▇▇▇▇▇▇▇███▇▇▇██▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▃▃▄▃▃▄▃▃▃▃▂▃▂▂▂▂▂▂▂▂▃▂▂▂▂▂▂▂▂▁▂▂▂▃▂▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▅▅▅▇▄▄▅▅▅▄▅▅▄▅▅▆▂▄▃▅▃▄▄▄▄▅▃▅▅▅▄▄▄▇▄▅▄▅▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▅█▅█▇▇██▇▇▇████▇██▇▇█▇▇█▆██▆███▇▇█▇███</td></tr><tr><td>val_auc</td><td>▁▃▅▇▆▇█▇▇▇▇█▇▇▇▇▇▆▅▇▆▆▆▆▆▇▇▅▅▇▆▆▆▅▆▅▆▆▅▆</td></tr><tr><td>val_f1</td><td>▁▄▆█▆█▇▇██▇▇████████▇▇██▇█▇██▇██████████</td></tr><tr><td>val_loss_epoch</td><td>█▅▃▁▃▁▂▂▁▁▂▂▂▁▁▁▁▂▂▁▂▂▁▁▂▁▃▁▂▂▁▁▁▂▁▂▂▁▂▂</td></tr><tr><td>val_loss_step</td><td>█▅▄▂▃▂▄▃▂▃▅▃▁▂▃▃▂▂▃▃▃▄▂▂▂▂▄▁▃▄▃▂▃▂▂▃▃▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85537</td></tr><tr><td>train_auc</td><td>0.93957</td></tr><tr><td>train_f1</td><td>0.85232</td></tr><tr><td>train_loss_epoch</td><td>0.30351</td></tr><tr><td>train_loss_step</td><td>0.13943</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.84161</td></tr><tr><td>val_auc</td><td>0.90808</td></tr><tr><td>val_f1</td><td>0.84876</td></tr><tr><td>val_loss_epoch</td><td>0.4132</td></tr><tr><td>val_loss_step</td><td>0.48065</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zpp4nifo' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zpp4nifo</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_234155-zpp4nifo\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_000410-9amdj6u7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9amdj6u7' target=\"_blank\">GraphConv_3_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9amdj6u7' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9amdj6u7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_3\\attention2\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 18.5 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "24.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.8 K    Total params\n",
      "0.099     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c645e594ebf345158518225fa4d6666d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇███▇▇▇██▇████▇▇████▇██</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇██▇███▇▇██▇█████▇▇███▇██</td></tr><tr><td>train_f1</td><td>▁▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇███▇▇▇██▇████▇▇████▇██</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▂▂▂▁▁▂▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▅▂▄▄▄▅▅▃▃▄▁▄▄▃▃▁▄▃▂▂▅▂▃▃▃▃▃▂▁▄▄▄▃▁▂▄▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆█▇██▇█▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▆▇▆▇▇▇▆▆▇▆▇▇▇▆▆</td></tr><tr><td>val_auc</td><td>▁▄██▇▇█▇█▇▆▇▇▇▆▆▇▆▆▆▆▆▆▆▆▆▇▅▆▆▆▆▅▆▅▅▅▆▅▅</td></tr><tr><td>val_f1</td><td>▁▂▇▆▇█▆█▇▇▇▆▅▇▇▇▇▇▅▅▇▆▅▇▆▆▇▅▇▄▆▆▆▆▄▆▅▅▅▆</td></tr><tr><td>val_loss_epoch</td><td>█▄▁▂▂▂▃▁▂▂▂▂▃▁▂▄▂▅▆▃▂▃▃▃▂▆▃▅▃▃▄▄▅▂▄▆▃▂▄█</td></tr><tr><td>val_loss_step</td><td>▆▄▁▃▃▂▅▂▃▃▄▂▄▁▁▅▂▆▂▃▂▃▂▃▃▄▃▄▃▂▅▃▅▂▅█▃▃▅▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.90142</td></tr><tr><td>train_auc</td><td>0.96288</td></tr><tr><td>train_f1</td><td>0.89922</td></tr><tr><td>train_loss_epoch</td><td>0.24717</td></tr><tr><td>train_loss_step</td><td>0.23649</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.7896</td></tr><tr><td>val_auc</td><td>0.88314</td></tr><tr><td>val_f1</td><td>0.81023</td></tr><tr><td>val_loss_epoch</td><td>0.66304</td></tr><tr><td>val_loss_step</td><td>0.70424</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9amdj6u7' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9amdj6u7</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_000410-9amdj6u7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1c8521f5164492f8fa2df2d10249b44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_002534-g3tnair6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/g3tnair6' target=\"_blank\">GCN_4_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/g3tnair6' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/g3tnair6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_3\\mean\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 1.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇▇▇▇██▇▇█▇█▇████▇███████▇██████████</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇▇▇██▇████████████████████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▇▆▇▇█▇▇▇▇▇▇▇██▇▇▇█▇█▇█▇█▇▇▇█████▇█▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▃▂▂▂▃▃▃▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▁▁▂▁▂▁▁▂▂▂▁▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▅▆▃▄▄▃▄▅▂▄▃▄▃▂▄▃▄▁▂▃▃█▃▃▂▃▂▂▂▁▃▃▁▃▂▅▂▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▅▅▇▇▇▇▇█▆█▆███▇▆██▇▇▆▄▄█▆▅▆▄▆▄▆▇▇▇▆▇▇█</td></tr><tr><td>val_auc</td><td>▁▆▇▇▇▇▇▇▇▇██▇▇▇███▇▇▇▇▇▇█▇▇▇▇▇▇▇▆▇▇▇▆▆▆▇</td></tr><tr><td>val_f1</td><td>▁▇▆▆▇▇▇▇▇█▆█▆███▇▆██▇▇▇▅▅█▇▆▇▄▇▅▇▇█▇▇▇▇█</td></tr><tr><td>val_loss_epoch</td><td>▆▂▃▃▂▂▂▂▂▁▃▁▃▁▁▁▃▃▂▂▂▂▂▆▆▁▃▃▃█▃▅▂▂▂▂▃▂▂▂</td></tr><tr><td>val_loss_step</td><td>▅▃▃▂▂▂▂▁▃▁▃▂▄▁▁▁▅▂▄▃▂▁▂▆▄▁▂▃▃█▄▅▂▂▃▂▃▂▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83353</td></tr><tr><td>train_auc</td><td>0.90578</td></tr><tr><td>train_f1</td><td>0.83114</td></tr><tr><td>train_loss_epoch</td><td>0.39379</td></tr><tr><td>train_loss_step</td><td>0.36561</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82979</td></tr><tr><td>val_auc</td><td>0.90412</td></tr><tr><td>val_f1</td><td>0.81818</td></tr><tr><td>val_loss_epoch</td><td>0.42097</td></tr><tr><td>val_loss_step</td><td>0.51625</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/g3tnair6' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/g3tnair6</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_002534-g3tnair6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_004737-kf58regu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kf58regu' target=\"_blank\">GraphConv_4_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kf58regu' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kf58regu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_3\\mean\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 2.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.3 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▇▇▇▇▇▇▇▇▇██▇▇█▇███▇█▇████████████████</td></tr><tr><td>train_auc</td><td>▁▆▆▇▇▇▇▇▇▇██████████████████████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇███████▇▇███████</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▁▂▁▂▁▁▂▂▂▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▄▃▂▃▃▆▃▄▄▁▃▂▂▄▄▂▁▂▂▂█▃▃▃▃▁▂▄▃▂▁▂▂▂▃▃▁▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▆▇▆█▆▇▇▇▇▇▇▆▇▇▇▆▆▇▇▄▆▆▆▇▇▇▆▆▆▇▆▆▇▇▇▆▆▆</td></tr><tr><td>val_auc</td><td>▁▄▇███▇▇█████████████▇█▇▇▇███▇██▇▇▇█▇▇▇█</td></tr><tr><td>val_f1</td><td>▁▄▆▇▆█▇▇█▆██▇▆▇▇█▇▆█▇▆▆▆▇█▇▇▆▆▆▇▇▇▇▇█▇▇▆</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▃▂▂▂▂▂▁▁▂▂▂▃▁▂▂▁▂▁▅▂▁▃▃▁▃▂▁▂▃▂▃▂▁▃▂▂▂</td></tr><tr><td>val_loss_step</td><td>▇▃▃▅▃▄▂▃▄▂▃▃▃▂█▂▅▂▁▃▂▄▅▁▄▅▂▆▃▁▄▅▃▄▄▂▄▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86187</td></tr><tr><td>train_auc</td><td>0.92769</td></tr><tr><td>train_f1</td><td>0.86251</td></tr><tr><td>train_loss_epoch</td><td>0.34904</td></tr><tr><td>train_loss_step</td><td>0.3762</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81324</td></tr><tr><td>val_auc</td><td>0.90701</td></tr><tr><td>val_f1</td><td>0.79898</td></tr><tr><td>val_loss_epoch</td><td>0.40411</td></tr><tr><td>val_loss_step</td><td>0.40361</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kf58regu' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kf58regu</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_004737-kf58regu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_011026-iaqmxkd4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/iaqmxkd4' target=\"_blank\">GCN_4_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/iaqmxkd4' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/iaqmxkd4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_3\\max\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 1.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▂▁▁▂▃▄▅▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇██▇███▇████████</td></tr><tr><td>train_auc</td><td>▂▁▂▂▃▅▆▆▆▇▇▇▇▇▇▇██▇▇█▇█▇███▇████████████</td></tr><tr><td>train_f1</td><td>▃▃▂▁▃▂▃▄▄▅▄▅▅▆▆▅▆▆▆▆▆▆▇▆▇██▇███▇▇▇██████</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▆▆▆▄▅▅▄▃▃▃▄▄▂▄▃▃▂▂▁▃▂▂▅▁▂▄▃▂▁▃▄▄▃▃▄▂▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▁▁▇██▇▇█▇▇█▇▇██████▇▇▇▇▇██▂▇▂▇███▆██▇▇█</td></tr><tr><td>val_auc</td><td>▆▁▂▆▇████████████████████████▇▇▇▇▇▆▆▆▇▇▇</td></tr><tr><td>val_f1</td><td>▇▇▇▇███████████████▇▇██▇███▂▇▁████▇█████</td></tr><tr><td>val_loss_epoch</td><td>████▇▆▆▅▅▅▄▅▅▄▄▄▃▄▃▄▃▂▂▂▂▃▁▂▃▃▃▃▂▃▁▂▁▂▄▃</td></tr><tr><td>val_loss_step</td><td>▇▇▆▆▆▅▅▅▆▅▄▆▆▄▅▄▄▅▅▅▅▂▅▄▃▅▂▃▅▅▆▄▃▅▁▃▁▅█▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.7438</td></tr><tr><td>train_auc</td><td>0.77952</td></tr><tr><td>train_f1</td><td>0.76541</td></tr><tr><td>train_loss_epoch</td><td>0.55239</td></tr><tr><td>train_loss_step</td><td>0.51647</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.68322</td></tr><tr><td>val_auc</td><td>0.75358</td></tr><tr><td>val_f1</td><td>0.73413</td></tr><tr><td>val_loss_epoch</td><td>0.60953</td></tr><tr><td>val_loss_step</td><td>0.6924</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/iaqmxkd4' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/iaqmxkd4</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_011026-iaqmxkd4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_013346-wcbiiao6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wcbiiao6' target=\"_blank\">GraphConv_4_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wcbiiao6' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wcbiiao6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_3\\max\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 2.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.3 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▂▃▄▄▅▅▅▅▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇███▇██▇█▇██</td></tr><tr><td>train_auc</td><td>▁▁▂▃▃▃▃▃▃▄▅▅▅▅▅▆▆▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇█▇▇▇██</td></tr><tr><td>train_f1</td><td>▁▂▂▄▅▅▅▆▅▆▇▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█████▇█▇▇█▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▄▅▄▅▄▄▄▄▄▃▄▃▄▃▄▂▃▃▃▃▆▄▃▄▃▂▃▃▃▂▂▂▂▃▃▃▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▂▄▅▆▅▆▆▅▅▆▆▆▆▆▇▇█▄█▇▆▄▄▆▅▃▆▄▆▅▆▅▅▄▇▇▆▅▄</td></tr><tr><td>val_auc</td><td>▁▃▄▄▅▅▆▆▅▇▇▇▇▆▇▇▇▇▇██████▇██████████▇██▇</td></tr><tr><td>val_f1</td><td>▁▂▄▅▅▅▆▆▅▄▆▆▆▆▆█▇█▅█▇▆▄▄▆▆▃▆▄▆▅▆▆▅▄▇▇▇▅▄</td></tr><tr><td>val_loss_epoch</td><td>█▇▆▅▄▅▄▄▄▄▄▃▂▃▄▂▃▁▄▁▂▃▅▄▃▃▅▃▅▃▄▃▃▅▅▂▂▃▄▄</td></tr><tr><td>val_loss_step</td><td>▇▆▆▆▅▇▆▅▅▅▅▃▄▅▇▄▅▁▅▃▄▃▆▄▃▄▄▅█▅▆▆▄▇█▄▄▆▆▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.80224</td></tr><tr><td>train_auc</td><td>0.84692</td></tr><tr><td>train_f1</td><td>0.80398</td></tr><tr><td>train_loss_epoch</td><td>0.46501</td></tr><tr><td>train_loss_step</td><td>0.3079</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.61466</td></tr><tr><td>val_auc</td><td>0.86081</td></tr><tr><td>val_f1</td><td>0.71252</td></tr><tr><td>val_loss_epoch</td><td>0.60959</td></tr><tr><td>val_loss_step</td><td>0.56273</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wcbiiao6' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wcbiiao6</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_013346-wcbiiao6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_015642-hw09y16s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hw09y16s' target=\"_blank\">GCN_4_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hw09y16s' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hw09y16s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_3\\sum\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 1.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇██▇▇▇▇▇█▇████▇</td></tr><tr><td>train_auc</td><td>▁▃▄▅▄▃▄▃▄▅▄▃▄▄▅▄▂▃▂▄▇▅█▆▇▆▅▅▇▄▇▆▆▇▇█▅▇▇▅</td></tr><tr><td>train_f1</td><td>▁▃▄▅▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇█▇▇█▇█▇▇▇█▇████▇</td></tr><tr><td>train_loss_epoch</td><td>█▃▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▄▃▄▄▃▃▄▂▃▃▃▃▃▃▂▂▂▂▂▃▄▂▂▂▃▂▂▂▁▃▂▁▂▂▃▂▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▅▆▇▇▆▅▆▆▆▆██▆▇▇▆▇▇█▆█▆▇▇▇▅▇▅▆▆▆█▇████▇</td></tr><tr><td>val_auc</td><td>▁▃▆▆▆▇▇▄█▇▇▇▇█████▇█████████████████████</td></tr><tr><td>val_f1</td><td>▁▄▆▇▇▇▇▅▇▆▇▆██▇▇▇▇█▇█▇█▇█▇█▆▇▆▇▇▆█▇████▇</td></tr><tr><td>val_loss_epoch</td><td>█▆▄▃▃▃▃▄▃▄▃▃▂▂▂▂▃▃▃▃▁▂▁▄▂▂▂▄▂▅▄▄▄▂▂▁▂▂▂▃</td></tr><tr><td>val_loss_step</td><td>▇▅▆▃▄▄▄▄▆▃▅▄▆▂▂▃█▃▇▄▂▂▁▇▅▃▂▄▃▇▅▆▃▂▄▂▆▃▃▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.81995</td></tr><tr><td>train_auc</td><td>0.60537</td></tr><tr><td>train_f1</td><td>0.82319</td></tr><tr><td>train_loss_epoch</td><td>0.41296</td></tr><tr><td>train_loss_step</td><td>0.35709</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.79196</td></tr><tr><td>val_auc</td><td>0.89873</td></tr><tr><td>val_f1</td><td>0.76087</td></tr><tr><td>val_loss_epoch</td><td>0.48055</td></tr><tr><td>val_loss_step</td><td>0.62857</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hw09y16s' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hw09y16s</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_015642-hw09y16s\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61919ebe80f34deebf90652b85c549e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_022023-fqq5f6tg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fqq5f6tg' target=\"_blank\">GraphConv_4_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fqq5f6tg' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fqq5f6tg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_3\\sum\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 2.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.3 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▂▃▄▄▆▅▅▆▆▆▆▆▇▇▇▇█▇▇▇▇▇██▇█▇███▇▇██████</td></tr><tr><td>train_auc</td><td>██▇▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▂▂▂▁▁▂▂▂▁▁▂▂▂▂▁▂▁▂▂</td></tr><tr><td>train_f1</td><td>▁▃▃▄▅▅▆▅▆▆▆▆▆▇▇▇▇▇█▇█▇▇▇██▇███▇███▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▄▅▆▆▆▆▆▇▇▇▇▇███▇██████████████████████</td></tr><tr><td>val_auc</td><td>█▇▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_f1</td><td>▁▇▇▇▇▇▇▇▇█▇█████████████████████████████</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▂▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▂▄▃▄▃▃▃▃▃▃▃▃▂▄▂▃▂▁▃▁▂▃▂▂▃▁▃▂▁▂▃▂▂▃▂▃▃▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.82822</td></tr><tr><td>train_auc</td><td>0.23668</td></tr><tr><td>train_f1</td><td>0.83266</td></tr><tr><td>train_loss_epoch</td><td>0.40701</td></tr><tr><td>train_loss_step</td><td>0.38777</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.8487</td></tr><tr><td>val_auc</td><td>0.09145</td></tr><tr><td>val_f1</td><td>0.84906</td></tr><tr><td>val_loss_epoch</td><td>0.39018</td></tr><tr><td>val_loss_step</td><td>0.37687</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fqq5f6tg' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fqq5f6tg</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_022023-fqq5f6tg\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_024312-y0ewpg1e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/y0ewpg1e' target=\"_blank\">GCN_4_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/y0ewpg1e' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/y0ewpg1e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_3\\attention\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 1.1 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇██████▇█████▇▇█</td></tr><tr><td>train_auc</td><td>▁▁▇▇▇▇▇█████████████████████████████████</td></tr><tr><td>train_f1</td><td>▁▃▅▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇█▇▇▇▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▇▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▂▁▁▁▁▁▁▁▁▁▁▂▁▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▇▄▃▄▂▂▄▄▃▂▁▂▄▃▂▄▄▆▂▃▄▂▂▂▃▂▃▂▂▁▂▂▄▁▃▃▂▂▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▇▅▆▆▆▇▇▇▅▇▇▆██▆██▅▇▇▇█▇▆▇▇▇▆▅▇█▄▆▆▇▆█▆</td></tr><tr><td>val_auc</td><td>▁▇▇▇▇███████████████████████████████████</td></tr><tr><td>val_f1</td><td>▁▄▇▆▆▇▇███▆▇▇▇██▆██▆█████▇███▇▆▇█▅▇▇█▆█▇</td></tr><tr><td>val_loss_epoch</td><td>█▆▃▅▃▄▃▂▂▁▆▃▂▃▁▁▄▁▁▅▂▂▂▁▁▃▂▂▁▃▅▂▂█▃▃▂▄▁▄</td></tr><tr><td>val_loss_step</td><td>█▆▅▆▃▅▅▃▃▁▇▄▄▅▃▂▄▁▃▇▂▅▄▂▂▄▃▅▁▄▆▄▄▆▇▃▅▇▂▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8353</td></tr><tr><td>train_auc</td><td>0.90901</td></tr><tr><td>train_f1</td><td>0.8377</td></tr><tr><td>train_loss_epoch</td><td>0.39101</td></tr><tr><td>train_loss_step</td><td>0.49754</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.74468</td></tr><tr><td>val_auc</td><td>0.90376</td></tr><tr><td>val_f1</td><td>0.67665</td></tr><tr><td>val_loss_epoch</td><td>0.49174</td></tr><tr><td>val_loss_step</td><td>0.50679</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/y0ewpg1e' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/y0ewpg1e</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_024312-y0ewpg1e\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_030556-20e82vvv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/20e82vvv' target=\"_blank\">GraphConv_4_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/20e82vvv' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/20e82vvv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_3\\attention\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 2.1 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "2.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.3 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▅▆▆▇▇▇▇▇█▇█▇▇█▇██▇███▇▇████▇█▇██████▇█</td></tr><tr><td>train_auc</td><td>▁▃▆▇▇▇▇▇▇▇█▇████████████████████████████</td></tr><tr><td>train_f1</td><td>▂▁▅▆▆▇▇▇▇▇█▇█▇▇▇▇██▇███▇▇████▇█▇████████</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▃▃▂▃▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▂▂▁▂▁▁▂▁▂▁▁▁▁▁▂▂▁</td></tr><tr><td>train_loss_step</td><td>██▆▆▅▄▃▄▄▅▂▄▂▃▄▃▃▁▄▃▄▂▃▄▂▂▃▅▃▃▃▄▃▁▃▃▄▃▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▆▇█▇▇██▇██▇█▇████████▇██▇█▇▇██▇███████</td></tr><tr><td>val_auc</td><td>▁▅▆▇▇███████████████████████████████████</td></tr><tr><td>val_f1</td><td>▁▂▅▆▇▇▇▇█▇█▇▆█▆▇▇▇▆█▇▇▇▆▆▇▆█▇▆▇▇▆█▇▇████</td></tr><tr><td>val_loss_epoch</td><td>█▆▅▃▃▂▂▂▁▂▂▁▂▁▂▂▂▁▂▂▂▁▂▂▂▁▃▁▂▂▂▂▁▂▂▃▁▂▂▂</td></tr><tr><td>val_loss_step</td><td>█▇█▆▆▄▅▄▃▅▃▃▅▃▅▆▆▄▄▅▅▃▄▄▅▄█▃▄▄▄▅▁▆▄▇▃▆▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85596</td></tr><tr><td>train_auc</td><td>0.92662</td></tr><tr><td>train_f1</td><td>0.85459</td></tr><tr><td>train_loss_epoch</td><td>0.35082</td></tr><tr><td>train_loss_step</td><td>0.35036</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.84161</td></tr><tr><td>val_auc</td><td>0.90862</td></tr><tr><td>val_f1</td><td>0.84668</td></tr><tr><td>val_loss_epoch</td><td>0.39362</td></tr><tr><td>val_loss_step</td><td>0.37449</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/20e82vvv' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/20e82vvv</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_030556-20e82vvv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_032749-0zhkddbm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0zhkddbm' target=\"_blank\">GCN_4_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0zhkddbm' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0zhkddbm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_3\\attention2\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 1.1 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "1.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇██▇▇████▇▇██████▇██</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇█▇█▇█████████████████████████████</td></tr><tr><td>train_f1</td><td>▁▃▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇█▇▇▇▇████▇▇██</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▂▁▂▁▁▂▂▂▂▁▁▁▁▂▂▁▂</td></tr><tr><td>train_loss_step</td><td>█▆▄▄▄▄▂▅▄▃▄▃▇▂▃▄▃▃▅▃▄▂▄▄▃▃▃▃▄▄▃▃▃▅▂▃▃▄▁▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▆▅▅▆▇▇▆▇▇▇▇▆▇▇▇▆▆█▇▇▆▇▇▇▇█▅▇▇▇▆▅▆██▇██</td></tr><tr><td>val_auc</td><td>▁▆▆▆▆▇▇▇▇▇█████████▇▇▇▇██▇▇█████▇█▇▇██▇█</td></tr><tr><td>val_f1</td><td>▁▄▇▅▆▆█▇▇██▇█▇█▇▇▇▆███▇▇▇▇██▆▇██▇▆▇██▇██</td></tr><tr><td>val_loss_epoch</td><td>█▇▄▆▅▄▃▂▃▃▂▂▁▃▂▃▃▃▃▂▂▂▃▂▂▃▂▁▄▂▂▂▂▄▄▁▂▃▁▂</td></tr><tr><td>val_loss_step</td><td>██▆▅▄▅▆▃▃▇▅▄▂▄▅▅▆▄▄▄▄▃▄▃▃▄▄▁▁▅▃▃▂▃█▃▅▆▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83825</td></tr><tr><td>train_auc</td><td>0.90208</td></tr><tr><td>train_f1</td><td>0.84107</td></tr><tr><td>train_loss_epoch</td><td>0.40685</td></tr><tr><td>train_loss_step</td><td>0.48952</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83452</td></tr><tr><td>val_auc</td><td>0.90703</td></tr><tr><td>val_f1</td><td>0.82673</td></tr><tr><td>val_loss_epoch</td><td>0.4055</td></tr><tr><td>val_loss_step</td><td>0.42782</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0zhkddbm' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0zhkddbm</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_032749-0zhkddbm\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_034911-2wqq30j2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/2wqq30j2' target=\"_blank\">GraphConv_4_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/2wqq30j2' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/2wqq30j2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_3\\attention2\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 2.1 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "2.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▇▇▇▇▇▇▇▇██▇▇█▇███████▇███▇██████▇████</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇▇▇▇▇█████████████████████████████</td></tr><tr><td>train_f1</td><td>▁▄▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇███▇██▇▇███▇███▇██▇████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▁▁▁▁▁▁▂▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▄▄▄▄▃▂▄▃▂▂▅▃▁▂▄▄▁▁▂▃▁▃▂▃▂▃▁▂▂▃▂▂▂▃▂▄▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▆▆▇██▇▇▇▇▇▇▇▆▆▆▆▇▇▆▆▇▆▇▆▇▇▆▇▆▇▆▆▆▆▆▆▇▆</td></tr><tr><td>val_auc</td><td>▁▆▇▇██████████████████████████▇▇▇▇▇▇▇▇██</td></tr><tr><td>val_f1</td><td>▁▁▅▅▇██▇▇▇▇▆▅▇▅▅▆▅▆▇▆▅▇▆▆▆▇▇▅▇▅▆▆▄▆▆▅▆▇▄</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▁▂▁▂▁▂▂▁▁▃▂▁▁▄▂▁▂▂▂▂▃▁▂▃▂▂▂▂▂▃▂▃▂▃▂▂▃</td></tr><tr><td>val_loss_step</td><td>█▆▅▁▃▃▅▄▅▄▂▃▇▃▂▁▆▄▃▄▂▃▅▅▃▃▇▄▂▃▃▅▅▄▅▄▄▁▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86128</td></tr><tr><td>train_auc</td><td>0.93534</td></tr><tr><td>train_f1</td><td>0.86136</td></tr><tr><td>train_loss_epoch</td><td>0.33022</td></tr><tr><td>train_loss_step</td><td>0.38595</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81087</td></tr><tr><td>val_auc</td><td>0.90971</td></tr><tr><td>val_f1</td><td>0.79275</td></tr><tr><td>val_loss_epoch</td><td>0.42919</td></tr><tr><td>val_loss_step</td><td>0.39507</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/2wqq30j2' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/2wqq30j2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_034911-2wqq30j2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_041223-2rkc12oj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/2rkc12oj' target=\"_blank\">GCN_4_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/2rkc12oj' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/2rkc12oj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_3\\mean\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 3.8 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2a002fb339043f18318879a73544468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇██▇██▇▇█▇█▇▇▇▇███▇██</td></tr><tr><td>train_auc</td><td>▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█████▇█████████████████</td></tr><tr><td>train_f1</td><td>▁▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇█▇▇▇▇▇▇▇▇██</td></tr><tr><td>train_loss_epoch</td><td>█▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▁▂▂▁▂▁▁▂▂▂▁▂▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▅▃▃▃▄▄▃▂▄▄▃▂▄▃▃▂▄▃▄▃▄▃▃▂▃▁▂▂▄▃▄▂▃▂▃▄▄▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▃▁▄▃▇▇▇▆▆▇▇▆▆██▇▇▇▇▅▃▇█▆██▇▆▇▄▃▇▄▇▇▂▇▇▅▄</td></tr><tr><td>val_auc</td><td>▁▆▇▇▇████▇▇▇█▇▇▇▇▇▆▇███▇▇▇▇▇▇▇█▆▇▇▇▇▇▇▇▇</td></tr><tr><td>val_f1</td><td>▄▁▄▄▇▇▇▆▇▇▇▆▆████▇▇▅▃▇█▇███▆▇▄▄▇▄▇▇▂▇▇▅▅</td></tr><tr><td>val_loss_epoch</td><td>▇▇▅▄▂▂▃▃▂▂▂▃▃▂▁▂▂▂▃▄█▁▂▃▂▁▂▃▁▆▆▂▄▁▂█▂▂▅▅</td></tr><tr><td>val_loss_step</td><td>▅▃▅▃▂▂▅▃▂▂▂▄▃▂▂▂▃▂▄▅█▁▄▃▄▂▁▂▁▅▆▂▂▁▃▅▃▄▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86895</td></tr><tr><td>train_auc</td><td>0.93387</td></tr><tr><td>train_f1</td><td>0.87078</td></tr><tr><td>train_loss_epoch</td><td>0.3315</td></tr><tr><td>train_loss_step</td><td>0.31472</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.75177</td></tr><tr><td>val_auc</td><td>0.89618</td></tr><tr><td>val_f1</td><td>0.69208</td></tr><tr><td>val_loss_epoch</td><td>0.51973</td></tr><tr><td>val_loss_step</td><td>0.5781</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/2rkc12oj' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/2rkc12oj</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_041223-2rkc12oj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec2ec77c678b46fa889d53a89a01d5b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666495924, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_043322-e4o15igk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/e4o15igk' target=\"_blank\">GraphConv_4_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/e4o15igk' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/e4o15igk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_3\\mean\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 7.3 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "7.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.9 K     Total params\n",
      "0.031     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▇▇▇▇▇▇▇▇▇▇▇█▇▇▇███▇█▇██▇██████████████</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇▇▇▇▇█████████████████████████████</td></tr><tr><td>train_f1</td><td>▁▆▇▇▇▇▇▇▇▇▇▇████████████████████████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▁▂▁▁▁▁▂▂</td></tr><tr><td>train_loss_step</td><td>█▅▄▄▄▄▅▃▄▂▄▃▂▃▃▄▅▄▃▃▁▂▄▂▃▃▄▂▃▂▃▂▂▂▂▃▃▃▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▇▇█▇██▇██▇█▇▇▆▇█▇█▆▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▆▇▇</td></tr><tr><td>val_auc</td><td>▁▆██████████▇▇▇████▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>val_f1</td><td>▁▆▇▇█▆██▇▇█▇█▇▇▄▇▇▆▇▄▆▇▇▇▅▆▄▂▆▆▆▇▇▇▇▇▃▆▅</td></tr><tr><td>val_loss_epoch</td><td>█▃▁▂▁▃▂▁▂▁▁▂▁▃▂▂▂▂▂▃▃▂▂▃▂▂▃▄▇▃▄▂▄▂▃▃▃▄▃▄</td></tr><tr><td>val_loss_step</td><td>▆▃▂▄▂▆▃▂▃▁▂▅▁▄▄▃▃▃▂▂▃▄▃▄▃▂▃▄█▃▆▃▆▂▃▄▂▂▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86541</td></tr><tr><td>train_auc</td><td>0.93934</td></tr><tr><td>train_f1</td><td>0.86806</td></tr><tr><td>train_loss_epoch</td><td>0.32234</td></tr><tr><td>train_loss_step</td><td>0.36961</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81797</td></tr><tr><td>val_auc</td><td>0.89716</td></tr><tr><td>val_f1</td><td>0.8</td></tr><tr><td>val_loss_epoch</td><td>0.47234</td></tr><tr><td>val_loss_step</td><td>0.56671</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/e4o15igk' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/e4o15igk</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_043322-e4o15igk\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "135145bbb03d408186dbb687f994ab36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_045330-ps7g9duy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ps7g9duy' target=\"_blank\">GCN_4_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ps7g9duy' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ps7g9duy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_3\\max\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 3.8 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▂▃▄▅▅▆▆▆▆▆▆▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇█▇████████</td></tr><tr><td>train_auc</td><td>▁▁▁▂▂▄▄▄▅▅▅▅▆▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇█▇▇███████</td></tr><tr><td>train_f1</td><td>▂▂▁▃▃▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇█▇▇▇▇▇██████████</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▄▄▃▃▃▃▃▃▃▂▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▇▆▅▆▄▄▅▄▄▅▅▁▄▄▄▃▄▄▄▄▄▄▂▃▂▃▃▁▁▄▄▃▂▁▂▁▂▃▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▁▁▆▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆█▇▆▇▆▇▇▇▇███▇</td></tr><tr><td>val_auc</td><td>▁▂▃▅▅▅▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇███▇████████▇████</td></tr><tr><td>val_f1</td><td>▁▁▁▄▄▄▄▄▄▅▄▅▅▅▅▅▅▅▆▅▅▅▆▆▅▆▆▇▇▆▇▆▇▇▇▅▆█▇▂</td></tr><tr><td>val_loss_epoch</td><td>███▇▆▆▆▅▅▅▅▅▄▄▅▄▄▄▃▄▄▄▄▃▃▃▃▂▂▂▁▂▂▁▂▁▂▂▁▃</td></tr><tr><td>val_loss_step</td><td>███▇▇▆▇▆▆▅▆▆▅▅▇▆▅▅▅▆▆▅▆▅▆▆▅▃▄▃▂▅▄▁▃▂▅▅▄▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.76682</td></tr><tr><td>train_auc</td><td>0.84516</td></tr><tr><td>train_f1</td><td>0.77233</td></tr><tr><td>train_loss_epoch</td><td>0.49716</td></tr><tr><td>train_loss_step</td><td>0.60054</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.7305</td></tr><tr><td>val_auc</td><td>0.84864</td></tr><tr><td>val_f1</td><td>0.67052</td></tr><tr><td>val_loss_epoch</td><td>0.55498</td></tr><tr><td>val_loss_step</td><td>0.66946</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ps7g9duy' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ps7g9duy</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_045330-ps7g9duy\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "639213f31218459c9ae61874ecf227c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666883975, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_051403-2jiwbxek</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/2jiwbxek' target=\"_blank\">GraphConv_4_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/2jiwbxek' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/2jiwbxek</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_3\\max\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 7.3 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "7.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.9 K     Total params\n",
      "0.031     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▃▅▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇██▇█████▇██</td></tr><tr><td>train_auc</td><td>▁▂▃▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████▇██▇███▇▇</td></tr><tr><td>train_f1</td><td>▂▁▄▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇▇█████▇████████</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▄▄▃▃▄▃▄▃▃▃▂▃▂▄▃▄▂▂▂▂▃▂▂▂▂▃▂▁▂▂▁▂▂▂▂▁▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▆▆▆▇▇▇▇▆█▇▇▆▇▇▇█▇▇███▇▇▇▇▇▇███▇▇▇▇████</td></tr><tr><td>val_auc</td><td>▃▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇████████▇███▇███▇███████</td></tr><tr><td>val_f1</td><td>▁▅▇▇▇▇▇▇▇▆███▆█▇▇██▇███▇▇▇▇██▇███▇██████</td></tr><tr><td>val_loss_epoch</td><td>██▆▅▄▅▄▃▃▄▄▄▃▄▄▃▃▂▃▃▂▃▃▃▃▂▃▂▃▂▂▂▃▂▂▂▂▁▂▂</td></tr><tr><td>val_loss_step</td><td>██▆▆▆▇▆▅▄▄▆▆▄▆▆▃▅▂▄▂▃▄▅▅▂▄▄▅▇▅▅▅▄▄▃▄▃▁▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.82704</td></tr><tr><td>train_auc</td><td>0.86008</td></tr><tr><td>train_f1</td><td>0.83228</td></tr><tr><td>train_loss_epoch</td><td>0.40538</td></tr><tr><td>train_loss_step</td><td>0.33373</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.78487</td></tr><tr><td>val_auc</td><td>0.85819</td></tr><tr><td>val_f1</td><td>0.77078</td></tr><tr><td>val_loss_epoch</td><td>0.48509</td></tr><tr><td>val_loss_step</td><td>0.54385</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/2jiwbxek' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/2jiwbxek</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_051403-2jiwbxek\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_053420-su1iun52</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/su1iun52' target=\"_blank\">GCN_4_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/su1iun52' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/su1iun52</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_3\\sum\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 3.8 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇█▇██▇▇▇█</td></tr><tr><td>train_auc</td><td>▁▃▃▄▄▄▅▆▅▅▆▆▇▇▆▇▇▇▆▅▅▅▆▆▇▆▅▇▇████▇████▇▇</td></tr><tr><td>train_f1</td><td>▁▄▅▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇▇█▇██▇▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▁▁▂▂▁▂▂▂▂▁▂▁▁▁▁▁▂▁▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▄▇▅▆▅▇▇▆▇▇▆▇▆▆▇▆▅▇▇▇▇▇▆▇▆▅██▇▆█▇▅▇▇▇▅▆</td></tr><tr><td>val_auc</td><td>▁▅▆▇▇▇██▇█▇▇█▇▇█▇▇█▇▇██▇████▇█▇█▆██▇▆▇█▇</td></tr><tr><td>val_f1</td><td>▄▃▁▆▃▅▃▆▇▅▆▇▅▆▄▅▇▄▂▇▆▅▆▇▄▆▄▁██▇▅█▆▂▆▆▆▃▄</td></tr><tr><td>val_loss_epoch</td><td>█▃▄▂▂▂▃▂▂▂▂▂▂▂▃▂▁▂▄▁▃▂▂▂▃▁▃▄▁▂▂▃▂▃▄▃▂▂▄▄</td></tr><tr><td>val_loss_step</td><td>█▂▅▂▃▂▆▄▂▂▂▃▄▃▄▂▂▃▆▂▇▂▅▂▃▂▃▄▁▃▄▃▃▃▅▄▂▃▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84061</td></tr><tr><td>train_auc</td><td>0.86364</td></tr><tr><td>train_f1</td><td>0.84211</td></tr><tr><td>train_loss_epoch</td><td>0.37992</td></tr><tr><td>train_loss_step</td><td>0.31058</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.76359</td></tr><tr><td>val_auc</td><td>0.89904</td></tr><tr><td>val_f1</td><td>0.70414</td></tr><tr><td>val_loss_epoch</td><td>0.52434</td></tr><tr><td>val_loss_step</td><td>0.53731</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/su1iun52' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/su1iun52</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_053420-su1iun52\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2f2e8c9be5b4d10b6c36a3a49c16a0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666883975, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_055444-yntz7ezv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yntz7ezv' target=\"_blank\">GraphConv_4_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yntz7ezv' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yntz7ezv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_3\\sum\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 7.3 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "7.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.9 K     Total params\n",
      "0.031     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇██▇███▇████</td></tr><tr><td>train_auc</td><td>▁▃▂▂▁▁▂▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▆▇██▇▇▇▆▆▆▆▇█</td></tr><tr><td>train_f1</td><td>▁▂▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▄▅▆▅▅▅▅▆▅▆▆▆▆▆▇▆▆▇▆▇█▆▇█▆▇▇▇▇▇█▇▇▇▆▇▇█</td></tr><tr><td>val_auc</td><td>▆▆▃▂▁▁▂▆▇▇████▇▇█▇██▇███████████████████</td></tr><tr><td>val_f1</td><td>▁▄▄▄▅▅▄▅▅▅▅▅▆▆▅▅▆▆▆▆▆▆█▆▇▇▆▆▇▆▇▇█▆▇▇▆▆▇█</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▃▂▂▂▂▃▂▃▂▁▂▂▂▂▁▂▁▁▁▁▂▁▁▁▂▂▂▂▁▁▁▁▂▂▁▂▂</td></tr><tr><td>val_loss_step</td><td>█▄▃▄▃▃▃▂▄▂▄▃▁▃▃▄▄▂▂▁▁▂▃▃▁▁▂▃▅▄▄▂▃▂▃▃▂▁▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84534</td></tr><tr><td>train_auc</td><td>0.76431</td></tr><tr><td>train_f1</td><td>0.84925</td></tr><tr><td>train_loss_epoch</td><td>0.38176</td></tr><tr><td>train_loss_step</td><td>0.63541</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.86998</td></tr><tr><td>val_auc</td><td>0.90519</td></tr><tr><td>val_f1</td><td>0.87239</td></tr><tr><td>val_loss_epoch</td><td>0.51325</td></tr><tr><td>val_loss_step</td><td>0.73975</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yntz7ezv' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yntz7ezv</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_055444-yntz7ezv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_061542-vtpildal</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/vtpildal' target=\"_blank\">GCN_4_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/vtpildal' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/vtpildal</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_3\\attention\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 3.8 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.018     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇███▇█▇███▇█▇██▇█▇█</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇▇▇█▇▇█▇██████████████████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇███▇█▇███▇█▇██▇█▇█</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▃▃▂▂▂▂▂▃▃▂▃▂▂▂▂▂▂▁▂▁▁▂▁▁▂▂▁▂▂▁▂▁▂▁▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▅▄▅▆▄▃▄▃▆▄▄▂▄▄▄▄▁▂▄▂▃▃▄▄▂▃▃▃▂▂▄▂▄▃▃▂▄▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▆▆▆█▇▃▇▅▇█▃▅▇▆▆▄█▇▇█▅▆▆▄▅▆▅▂▇▆▆▇▇▇▂▇▃▂</td></tr><tr><td>val_auc</td><td>▁▆▇▇▇█▇▇██▇▇▇██▇▇▇█▇████▇▇▇█▇▇▇▇█▇▇▇▇▆▇█</td></tr><tr><td>val_f1</td><td>▅▇▇▇▇█▇▃▇▆▇█▂▇█▆▆▄█▇▇█▅▆▆▄▅▆▅▂▇▆▇▇▇▇▂█▃▁</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▂▂▂▃▅▃▂▂▂▆▄▂▃▃▄▁▂▃▂▄▂▃▄▄▃▅█▃▃▂▂▂▂▇▂▆█</td></tr><tr><td>val_loss_step</td><td>▇▅▄▂▅▃▅▆▅▂▃▂▄▇▃▄▄▄▁▃▄▄▅▂▆▅▆▄▇▇▅▄▃▃▃▄█▂█▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84947</td></tr><tr><td>train_auc</td><td>0.92431</td></tr><tr><td>train_f1</td><td>0.8492</td></tr><tr><td>train_loss_epoch</td><td>0.34456</td></tr><tr><td>train_loss_step</td><td>0.22321</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.68085</td></tr><tr><td>val_auc</td><td>0.91005</td></tr><tr><td>val_f1</td><td>0.52962</td></tr><tr><td>val_loss_epoch</td><td>0.66119</td></tr><tr><td>val_loss_step</td><td>0.57901</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/vtpildal' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/vtpildal</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_061542-vtpildal\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_063642-7uoolenj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7uoolenj' target=\"_blank\">GraphConv_4_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7uoolenj' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7uoolenj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_3\\attention\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 7.3 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "7.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.9 K     Total params\n",
      "0.032     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f220fb731fa9412b8c0df7231c406ea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▆▆▇▆▇▇▇▇▇█▇███▇███████████████████████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▇▇▇▇▇▇▇█████████████████████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▇▇▇▇▇▇▇█████▇███████████████████████</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▄▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▂▁▂▁▁▁▁▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▆▄▄▃▃▄▂▃▃▂▄▄▂▂▃▁▃▂▂▂▄▁▁▂▄▃▂▂▂▂▂▂▃▁▂▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▆▆▇▇▆▇▇▇▆▆▇▇██▇▇▇▇▇▆█▇██▇▇▇█▇▇▇▇▇▇▇▇▇▆</td></tr><tr><td>val_auc</td><td>▁▃▆▆▇▇▇███▇███████████████▇███▇▇▇▇▇▇█▇▇█</td></tr><tr><td>val_f1</td><td>▁▆▇▇█▇▇█▇▇▇▇▇███▇▇██▇▇████▇██▇▇▇█▇▇▇█▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▆▃▂▂▂▂▃▂▂▃▃▂▃▂▁▃▃▃▁▂▄▂▃▂▁▂▂▂▂▂▃▄▃▂▂▁▄▄▃</td></tr><tr><td>val_loss_step</td><td>█▇▃▃▅▄▂▆▄▅▆▄▅▅▆▂▅▅▇▁▅▄▃▆▄▃▅▅▅▄▄▅█▅▂▄▂▅▇▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84888</td></tr><tr><td>train_auc</td><td>0.92963</td></tr><tr><td>train_f1</td><td>0.84852</td></tr><tr><td>train_loss_epoch</td><td>0.33663</td></tr><tr><td>train_loss_step</td><td>0.29072</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.7896</td></tr><tr><td>val_auc</td><td>0.9045</td></tr><tr><td>val_f1</td><td>0.81184</td></tr><tr><td>val_loss_epoch</td><td>0.44008</td></tr><tr><td>val_loss_step</td><td>0.24202</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7uoolenj' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7uoolenj</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_063642-7uoolenj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_065715-64rzgbhk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/64rzgbhk' target=\"_blank\">GCN_4_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/64rzgbhk' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/64rzgbhk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_3\\attention2\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 3.8 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "5.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.4 K     Total params\n",
      "0.022     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3db5d048e91444e4b4e40840c37b2ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.013 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.080261…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▇▆▇▇▇▇▇▇▇▇▇█▇▇▇▇████████▇███████▇████</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇▇█▇▇▇▇▇█▇██▇█████████████████████</td></tr><tr><td>train_f1</td><td>▁▆▇▇▆▆▇▇▇▇▇▇█▇█▇█▇▇████████▇████████████</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▂▂▁▂▂▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▅▂▄▃▃▂▃▄▄▁▁▅▅▂▃▄▁▃▁▄▂▂▄▄▂▃▂▄▂▁▃▂▂▃▃▃▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▃▆▂▁▆▄▆▇█▇▇▇▇▇█▅▇▆▆▅█▇▆▇▃▇▆▇▇▄▅▅▇▆▆▆▇▆▇▅</td></tr><tr><td>val_auc</td><td>▁▆▇▇▇▇▇▇██▇▇▇▇▇▇▇████▇▇▇█▇▇▇▇▆▇▇▆▇▇▇▇▆▇▇</td></tr><tr><td>val_f1</td><td>▆▇▂▁▆▄▇██▇▇▇▇▇█▆▇▆▇▅█▇▇█▃▇▆▇█▇▅▆▇▆▇▆█▇▇▆</td></tr><tr><td>val_loss_epoch</td><td>█▃▆▇▃▅▂▂▁▃▂▂▁▂▃▄▂▂▂▃▁▂▃▃▄▃▂▂▂▅▃▄▃▃▃▃▃▂▂▃</td></tr><tr><td>val_loss_step</td><td>█▆▆▇▆▆▂▃▂▆▅▂▁▃▇▆▄▂▄▄▁▃▃▆▄▇▁▄▄▄▃▆▆▆▅▅▇▃▁▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85301</td></tr><tr><td>train_auc</td><td>0.9294</td></tr><tr><td>train_f1</td><td>0.84882</td></tr><tr><td>train_loss_epoch</td><td>0.33726</td></tr><tr><td>train_loss_step</td><td>0.32427</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.7896</td></tr><tr><td>val_auc</td><td>0.90687</td></tr><tr><td>val_f1</td><td>0.75881</td></tr><tr><td>val_loss_epoch</td><td>0.42177</td></tr><tr><td>val_loss_step</td><td>0.41611</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/64rzgbhk' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/64rzgbhk</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_065715-64rzgbhk\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf68f4a9bc604cb38bd4d5dec449d8f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_071745-l8bcmdes</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/l8bcmdes' target=\"_blank\">GraphConv_4_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/l8bcmdes' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/l8bcmdes</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_3\\attention2\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 7.3 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "8.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.9 K     Total params\n",
      "0.036     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█▇█▇▇████████████</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇▇██▇███▇█████████████████████████</td></tr><tr><td>train_f1</td><td>▁▆▇▇▇▇█▇▇▇▇▇▇█▇█▇█▇▇██████▇█████████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▁▂▂▂▁▁▂▂▁▂▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▆▂▄▃▄▅▄▃▄▃▂▄▁▂▂█▂▂▃▁▄▂▂▄▄▄▂▂▄▄▂▃▃▂▃▃▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▇▆▇▆████▇█▇█▇█▇█▇▇▇█▇▇▆▆▇▆▇▇▇▇▇▇▇███▇▇▇</td></tr><tr><td>val_auc</td><td>▁▆██████▇▇█████▇█▇▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇█▇</td></tr><tr><td>val_f1</td><td>▁▆▂█▃████▇▆▇▇▆▇▇▆▆█▆█▆▇▂▁▆▆▅▇▆▆▄▇▃██▇▇▅▆</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▂▃▁▂▁▂▂▂▃▃▂▂▅▂▂▃▂▂▃▃▄▃▃▅▃▂▂▂▃▃▅▃▃▂▅▃▂</td></tr><tr><td>val_loss_step</td><td>▆▄▄▄▃▃▄▂▃▃▄▃▆▄▅█▃▄▅▃▄▄▄▄▂▄▄▅▂▂▂▄▄▇▃▄▄▇▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87249</td></tr><tr><td>train_auc</td><td>0.94554</td></tr><tr><td>train_f1</td><td>0.86925</td></tr><tr><td>train_loss_epoch</td><td>0.29748</td></tr><tr><td>train_loss_step</td><td>0.24699</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80378</td></tr><tr><td>val_auc</td><td>0.90217</td></tr><tr><td>val_f1</td><td>0.80831</td></tr><tr><td>val_loss_epoch</td><td>0.40388</td></tr><tr><td>val_loss_step</td><td>0.18694</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/l8bcmdes' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/l8bcmdes</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_071745-l8bcmdes\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_073808-e7diftls</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/e7diftls' target=\"_blank\">GCN_4_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/e7diftls' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/e7diftls</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_3\\mean\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 13.8 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.9 K    Total params\n",
      "0.064     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dda7c73d4e5e4f0181d78b67baaecc25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▇▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇</td></tr><tr><td>train_auc</td><td>▁▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇█████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▇▇▆▇▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▆▇▇█▇▇▇▇▇▇▇▇█▇█▇</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▄▃▃▃▃▃▃▂▃▃▃▃▃▂▂▂▃▂▃▃▂▂▂▂▂▂▂▂▂▂▁▂▂▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>▇▅▄▇▄▅▅▆▅█▄▆▇▆▆▅▇▄▅▆▄▅█▆▄▅▅▄▄▄▆▅▄▆▅▄▄▃▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▂▅▆▆▅▇▆▆▇▇▄▇▄▄▆█▅▅█▇▇▇█▅▄▇▇▇▆▇█▆▇█▅▇▅▇▇</td></tr><tr><td>val_auc</td><td>▁▄▆▅██▇█▇▅▇█▇█▇█▇▇█▇▅██▆▇▇▆▆▆▇▅▆▇▇▆▇▆▇▆▅</td></tr><tr><td>val_f1</td><td>▁▃▆▆▆▆▇▇▇██▅▇▅▅▇█▆▆██▇██▆▅██▇▇▇█▇▇█▆█▆██</td></tr><tr><td>val_loss_epoch</td><td>█▅▃▃▂▂▂▂▂▁▁▃▁▄▄▂▁▃▃▁▂▂▁▁▂▄▁▁▁▂▁▂▂▁▁▃▁▃▁▂</td></tr><tr><td>val_loss_step</td><td>█▅▄▅▃▅▄▃▃▃▃▅▂▄▅▃▃▅▂▂▃▃▃▂▂▅▂▃▂▄▂▄▃▂▁▄▂▃▁▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86246</td></tr><tr><td>train_auc</td><td>0.93541</td></tr><tr><td>train_f1</td><td>0.86006</td></tr><tr><td>train_loss_epoch</td><td>0.31375</td></tr><tr><td>train_loss_step</td><td>0.11872</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80851</td></tr><tr><td>val_auc</td><td>0.89392</td></tr><tr><td>val_f1</td><td>0.82581</td></tr><tr><td>val_loss_epoch</td><td>0.53503</td></tr><tr><td>val_loss_step</td><td>0.67532</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/e7diftls' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/e7diftls</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_073808-e7diftls\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_075840-lsb1tb2o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/lsb1tb2o' target=\"_blank\">GraphConv_4_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/lsb1tb2o' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/lsb1tb2o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_3\\mean\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 26.9 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "29.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "29.0 K    Total params\n",
      "0.116     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▆▆▆▆▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇███▇█▇██▇██</td></tr><tr><td>train_auc</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇██▇████████████████</td></tr><tr><td>train_f1</td><td>▁▅▅▅▆▆▆▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇██▇█▇█▇▇██</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▃▃▃▃▂▂▂▂▂▃▂▂▂▂▁▂▂▂▁▂▂▁▁▁▁▂▁▁▁▂▁▁▁▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▅▄▃▃▅▃▃▄▃▄▅▄▃▃▄▁▂▃▃▃▃▅▃▃▃▄▃▃▃▃▃▂▂▃▂▂▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▄▆▆██▇▆▆█▆█▇▆▅▇▅▆▄▇▅▅▆▆▅▅▅▆▆▆▄▅▄▇▆▅▄▆▇▁▆</td></tr><tr><td>val_auc</td><td>▁▆▇█▇▇▇▇█▇▇▇▅▆▇▇▆▇▆▆▆▆▆▆▆▇▆▆▆▆▇▆▆▆▅▆▆▆▅▆</td></tr><tr><td>val_f1</td><td>▆▆▇███▇▇█▇██▇▅▇▆▇▄▇▆▆▇▆▅▅▅▇▆▆▅▅▅█▆▅▄▇█▁▇</td></tr><tr><td>val_loss_epoch</td><td>▆▃▁▁▂▂▂▁▁▄▂▃▃▃▂▄▃▅▅▃▄▃▃▄▄▄▅▄▄▃▅▄▃▃▄▇▃▃█▄</td></tr><tr><td>val_loss_step</td><td>▄▄▁▂▃▃▃▁▂▄▂▃▃▂▃▅▄▄█▁▅▃▄▃▅▄▂▄▃▁▅▄▄▂▁▆▃▃▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.90319</td></tr><tr><td>train_auc</td><td>0.96362</td></tr><tr><td>train_f1</td><td>0.90073</td></tr><tr><td>train_loss_epoch</td><td>0.24861</td></tr><tr><td>train_loss_step</td><td>0.27544</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81087</td></tr><tr><td>val_auc</td><td>0.89388</td></tr><tr><td>val_f1</td><td>0.80296</td></tr><tr><td>val_loss_epoch</td><td>0.52015</td></tr><tr><td>val_loss_step</td><td>0.5236</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/lsb1tb2o' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/lsb1tb2o</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_075840-lsb1tb2o\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_081906-i1ksikjd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/i1ksikjd' target=\"_blank\">GCN_4_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/i1ksikjd' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/i1ksikjd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_3\\max\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 13.8 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.9 K    Total params\n",
      "0.064     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇█▇▇▇▇▇█▇███████▇████</td></tr><tr><td>train_auc</td><td>▁▂▂▁▁▂▃▃▃▂▃▄▄▃▄▄▅▅▆▆▆▆▆▆▆▆▇▇▆▇▇▇▇▇██████</td></tr><tr><td>train_f1</td><td>▁▂▅▅▅▅▅▆▆▆▆▇▆▇▇▇▇▇▇▇█▇▇▇▇██▇███████▇████</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▅▅▅▅▄▅▄▅▅▅▅▄▅▄▅▆▄▄▂▄▄▄▄▃▄▅▃▄▄▄▃▃▂▃▃▃▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▅▅▅▅▅▅▅▅▅▅▆▆▆▇█▇████████▇██▇██▇▇▆▇█▇▇█</td></tr><tr><td>val_auc</td><td>▁▄▄▄▄▄▄▄▄▅▅▅▆▇▇▇▇▇█▇▇▇▇▇▇▇█▇▇███▇█▇▇█▇██</td></tr><tr><td>val_f1</td><td>▁▇▇▇▇▇▇▇▇▇▇▇▇▇▆▇█▇██▇███████████▇████▇██</td></tr><tr><td>val_loss_epoch</td><td>█▇▆▆▅▆▆▅▆▆▅▆▅▄▄▄▂▄▂▂▂▂▂▁▁▂▁▂▂▁▁▂▁▂▄▂▂▃▂▂</td></tr><tr><td>val_loss_step</td><td>██▇▇▆▇▇▇▇▆▆▇▆▆▅▅▄▄▄▄▃▆▆▃▁▅▂▄▃▁▃▅▁▃▇▆▆▅▄▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.80638</td></tr><tr><td>train_auc</td><td>0.84642</td></tr><tr><td>train_f1</td><td>0.80863</td></tr><tr><td>train_loss_epoch</td><td>0.39676</td></tr><tr><td>train_loss_step</td><td>0.23531</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.7896</td></tr><tr><td>val_auc</td><td>0.86828</td></tr><tr><td>val_f1</td><td>0.76267</td></tr><tr><td>val_loss_epoch</td><td>0.48431</td></tr><tr><td>val_loss_step</td><td>0.55724</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/i1ksikjd' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/i1ksikjd</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_081906-i1ksikjd\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8608510111f495e918d1d076f1cbcbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_084036-pzkmbksq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/pzkmbksq' target=\"_blank\">GraphConv_4_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/pzkmbksq' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/pzkmbksq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_3\\max\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 26.9 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "29.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "29.0 K    Total params\n",
      "0.116     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▅▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇██████▇█▇██</td></tr><tr><td>train_auc</td><td>▁▂▃▃▃▄▃▅▄▅▅▅▅▆▆▆▇▆▆▆▇▇▆▇▇▇▇▆▇▇▇██▇▆▇█▇█▇</td></tr><tr><td>train_f1</td><td>▁▃▅▅▅▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇██████▇█▇██</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▅▅▄▄▄▃▄▄▃▃▃▃▄▃▄▁▂▃▂▃▂▂▂▂▂▂▃▂▁▂▃▂▂▃▂▂▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▅▆▇▇████▇▇▇▇▆█▇▇▇██▇▇▇███▇▆▇███▇▇▇██▇▇</td></tr><tr><td>val_auc</td><td>▂▅▅▃▆▇▁▇▇▇▇▇▆▇▇▅▆▇▇██▇█▇█▇█▇▇█████▇▇▇▇▇█</td></tr><tr><td>val_f1</td><td>▁▄▄▄▆▆▇▇▇█▅▅▇▆▃▇▇▇▅▆█▆▆▇█▇▇▆▆▆▇▇▇▇▆▇▇█▇▆</td></tr><tr><td>val_loss_epoch</td><td>█▅▅▄▄▃▃▂▂▄▄▃▄▅▃▃▅▄▃▁▃▄▂▃▂▄▁▃▆▂▁▂▂▄▅▄▃▃▅▃</td></tr><tr><td>val_loss_step</td><td>█▅▅▅▆▄▅▂▄▆█▅▄▅▆▆▇▆▇▃▆▂▅▅▁▅▁▆█▄▂▃▄▅▇▇▆▅▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87131</td></tr><tr><td>train_auc</td><td>0.84459</td></tr><tr><td>train_f1</td><td>0.87266</td></tr><tr><td>train_loss_epoch</td><td>0.33601</td></tr><tr><td>train_loss_step</td><td>0.39493</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.77778</td></tr><tr><td>val_auc</td><td>0.85504</td></tr><tr><td>val_f1</td><td>0.78829</td></tr><tr><td>val_loss_epoch</td><td>0.50809</td></tr><tr><td>val_loss_step</td><td>0.61884</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/pzkmbksq' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/pzkmbksq</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_084036-pzkmbksq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_090350-1bfttvv9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1bfttvv9' target=\"_blank\">GCN_4_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1bfttvv9' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1bfttvv9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_3\\sum\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 13.8 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.9 K    Total params\n",
      "0.064     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▆▆▇▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇█▇████▇█</td></tr><tr><td>train_auc</td><td>▆▄▂▂▂▃▃▃▄▅▂▂▂▂▁▁▃▃▃▄▃▁▁▂▁▂▃▂▃▆▆▆█▇▅▆▆▃▃▃</td></tr><tr><td>train_f1</td><td>▁▄▅▆▇▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇█▇██████</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▃▂▂▂▂▂▃▂▂▃▂▃▃▃▂▂▂▂▂▃▂▂▂▂▂▂▂▃▂▂▂▂▂▂▂▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▂▄▅▄▆▅▅▅▆▆▆▅▇▆▆▆▅▄▇▆▇▅█▅▇▆▆▆▆█▇▅▄█▇▅▄▆▆</td></tr><tr><td>val_auc</td><td>▆▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃█▇██▂▂▆▁▁▁</td></tr><tr><td>val_f1</td><td>▁▂▅▆▅▇▆▆▆▆▆▆▆▇▆▇▇▅▅▇▆▇▆█▆▇▇▇▆▆█▇▅▅██▆▅▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▆▃▃▃▂▃▂▂▂▃▂▂▁▂▂▂▄▄▁▂▃▃▁▂▂▂▂▂▂▁▂▂▃▁▁▃▄▂▂</td></tr><tr><td>val_loss_step</td><td>█▄▃▅▄▄▄▂▃▃▅▃▂▁▃▃▃▆▃▂▃▅▅▂▂▂▃▄▂▄▂▃▃▂▂▁▃▄▁▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85596</td></tr><tr><td>train_auc</td><td>0.27625</td></tr><tr><td>train_f1</td><td>0.85511</td></tr><tr><td>train_loss_epoch</td><td>0.3291</td></tr><tr><td>train_loss_step</td><td>0.10695</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.72577</td></tr><tr><td>val_auc</td><td>0.12073</td></tr><tr><td>val_f1</td><td>0.65269</td></tr><tr><td>val_loss_epoch</td><td>0.60939</td></tr><tr><td>val_loss_step</td><td>0.68385</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1bfttvv9' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1bfttvv9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_090350-1bfttvv9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_092705-4u114kg2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4u114kg2' target=\"_blank\">GraphConv_4_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4u114kg2' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4u114kg2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_3\\sum\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 26.9 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "29.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "29.0 K    Total params\n",
      "0.116     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c78d98b811bf401c8453562276b0263b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.013 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.080536…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇▇▇▇████</td></tr><tr><td>train_auc</td><td>▁▄▅▆▅▅▅▆▆▆▇▇▇▇▇▇▇██▇▇█▇▆▇█▇▇▆▄▅▅▅▃▄▆▆▇██</td></tr><tr><td>train_f1</td><td>▁▄▅▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇▇█▇████</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▃▁▄▄▅▆▅▆▇▆▇▇▇▇▇▇▇█████████▇██▇▇▇█▇▇▇▇▇▇▇</td></tr><tr><td>val_auc</td><td>▁▂▃▂▃▄▄▄▃▄▇▇▇▇▇▇▆▇▆██████▇██▇▇█▇▇▅▇▇▇▇▇█</td></tr><tr><td>val_f1</td><td>▁▃▄▄▅▆▅▇▇▆▇▇▇▇▇▇▇██▇██████▇▇█▇▇▇█▇▇▇▇▇▆▇</td></tr><tr><td>val_loss_epoch</td><td>▄█▂▃▃▃▃▂▂▂▂▂▂▂▂▂▃▂▄▁▂▂▁▁▂▂▃▃▂▃▂▂▃▂▂▃▃▄▂▄</td></tr><tr><td>val_loss_step</td><td>▃▄▂▃▄▃▃▃▁▃▂▄▄▃▃▃▄▃█▁▄▃▂▂▄▃▃▄▃▃▄▃▄▂▂▄▄▃▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87898</td></tr><tr><td>train_auc</td><td>0.88403</td></tr><tr><td>train_f1</td><td>0.87643</td></tr><tr><td>train_loss_epoch</td><td>0.31805</td></tr><tr><td>train_loss_step</td><td>0.27919</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.84397</td></tr><tr><td>val_auc</td><td>0.89654</td></tr><tr><td>val_f1</td><td>0.84211</td></tr><tr><td>val_loss_epoch</td><td>0.55837</td></tr><tr><td>val_loss_step</td><td>0.71842</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4u114kg2' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4u114kg2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_092705-4u114kg2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_094958-k0hgtb7f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/k0hgtb7f' target=\"_blank\">GCN_4_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/k0hgtb7f' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/k0hgtb7f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_3\\attention\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 13.8 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "16.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "16.0 K    Total params\n",
      "0.064     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▇▆▆▆▇▇▇▇▇▇▇▇▆▇▇▆▇▇▇▇▇▇▇▇▇████▇▇██▇█</td></tr><tr><td>train_auc</td><td>▁▆▇▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇█▇████▇██████▇██▇█</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▆▇▇▆▇▇▇▇▇▇▇▇▇████▇▇██▇█</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▄▃▃▄▃▂▂▂▃▃▂▂▃▃▂▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▂▂▂▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▅▄▃▇▅▃▅▄▄▂▃▅▁▃▃▃▇▄▂▁▂▁▂▁▂▆▆▃▂▁▂▃▃▂▂▃▂▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▂▁▇▄▆▅▅▆▇▆▅▇▅██▆█▇▆▇▅█▆▆███▇▅██▅▇▅█▆▅▇██</td></tr><tr><td>val_auc</td><td>▁▇█▆▆█▇▆█▇██▇▇█▆▇▇▅▆▆▇▇▇██▇▆▇▆▆▆▇▇▆▆▇▆▆▇</td></tr><tr><td>val_f1</td><td>▃▁▇▅▇▆▆▇█▇▆▇▅██▇█▇▇█▇█▇▆███▇▅██▆▇▆█▇▆███</td></tr><tr><td>val_loss_epoch</td><td>▄█▂▃▂▃▃▂▁▂▃▁▃▁▁▂▁▂▂▂▃▁▂▃▁▁▂▂▄▁▁▃▂▃▁▂▃▂▁▁</td></tr><tr><td>val_loss_step</td><td>▃█▃▃▂▃▂▃▂▃▄▂▃▂▂▂▂▃▃▂▃▂▃▄▃▂▄▃▄▂▂▃▂▄▁▃▄▂▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87249</td></tr><tr><td>train_auc</td><td>0.93881</td></tr><tr><td>train_f1</td><td>0.86925</td></tr><tr><td>train_loss_epoch</td><td>0.32141</td></tr><tr><td>train_loss_step</td><td>0.32692</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83452</td></tr><tr><td>val_auc</td><td>0.90054</td></tr><tr><td>val_f1</td><td>0.83092</td></tr><tr><td>val_loss_epoch</td><td>0.41125</td></tr><tr><td>val_loss_step</td><td>0.43151</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/k0hgtb7f' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/k0hgtb7f</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_094958-k0hgtb7f\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_101308-qhxlvfk0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qhxlvfk0' target=\"_blank\">GraphConv_4_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qhxlvfk0' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qhxlvfk0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_3\\attention\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 26.9 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "29.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "29.1 K    Total params\n",
      "0.116     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇███▇█████████▇██</td></tr><tr><td>train_auc</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███████▇████████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇██▇▇█████████▇██</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▃▃▃▂▃▃▂▃▂▃▂▂▂▂▂▂▂▂▂▁▁▂▂▁▂▂▂▁▁▁▁▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▄▄▄▄▅▄▃▄▅▄▅▃▄▃▂▂▂▃▂▃▂▃▂▂▂▂▂▄▃▂▃▂▁▂▃▃▂▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▇█▅▆▇▇█▇▇█▆█▆▆▇▆▅█▇▄▇▃▆▅▄▇█▃▇▅▆▆▇▆▆▆▃▅</td></tr><tr><td>val_auc</td><td>▁▅▇▇▇█▇████▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▆▆▇</td></tr><tr><td>val_f1</td><td>▂▄▇▇▅▆▆▇▇▇▆█▅▇▅▆▇▅▅█▇▄▇▂▅▅▄▇█▁▇▅▆▅▇▆▆▆▂▄</td></tr><tr><td>val_loss_epoch</td><td>▆▃▁▁▃▂▂▁▁▂▁▃▂▃▃▃▂▃▂▂▁▄▂▄▄▄▆▂▂▆▃▃▅▃▃▃▃▂█▅</td></tr><tr><td>val_loss_step</td><td>▅▂▂▃▃▂▃▃▁▄▂▅▃▄▄▆▄▂▃▃▂▆▃▂▅▄▆▄▂▃▂▂█▂▄▅▄▂▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.89374</td></tr><tr><td>train_auc</td><td>0.95758</td></tr><tr><td>train_f1</td><td>0.89157</td></tr><tr><td>train_loss_epoch</td><td>0.27282</td></tr><tr><td>train_loss_step</td><td>0.39508</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.77541</td></tr><tr><td>val_auc</td><td>0.88945</td></tr><tr><td>val_f1</td><td>0.72934</td></tr><tr><td>val_loss_epoch</td><td>0.60579</td></tr><tr><td>val_loss_step</td><td>0.68233</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qhxlvfk0' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qhxlvfk0</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_101308-qhxlvfk0\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_103500-hyalkdgj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hyalkdgj' target=\"_blank\">GCN_4_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hyalkdgj' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hyalkdgj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_3\\attention2\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 13.8 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "20.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.1 K    Total params\n",
      "0.080     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f372fd196ea45e190ef7a8feda50604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▅▇▆▇▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇█▇██▇██▇█▇▆▇█▇█</td></tr><tr><td>train_auc</td><td>▁▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇██▇█▇█████▇██▇████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▇▆▇▆▇▇▇▇▇▇▇█▇▇█▇▇█▇▇█▇██▇██▇██▆▇███</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▃▃▃▃▂▃▂▂▂▂▂▂▃▂▂▃▂▂▂▂▁▂▂▂▁▂▂▁▁▂▁▁▂▂▂▁▂</td></tr><tr><td>train_loss_step</td><td>█▆▄▇▄▄▃▄▅▄▅▃▁▄▄▅▃▃▂▄▃▃█▃▆▄▃▅▃▅▂▄▃▃▂▃▄▄▅█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▂▄▆▆▅▆██▅▇█▇▇█▆▆▇▅▇▇▇▆▇██▇▇▅▇██▇▅▆█▇▆▇▇</td></tr><tr><td>val_auc</td><td>▁▄▄▃▆▇▆▆██▇██▇▅▇▇▅▇▇▇▇▅▆▅▅▄▆▇▆▆▅▅▆▅▆▆▄▄▅</td></tr><tr><td>val_f1</td><td>▁▂▅▇▇▆▇██▆██▇██▆▆█▆▇▇█▇▇██▇█▆▇███▆▇██▇██</td></tr><tr><td>val_loss_epoch</td><td>█▆▃▂▂▃▂▁▁▃▁▁▂▁▁▂▂▁▄▂▁▂▂▂▁▁▁▁▄▂▁▁▂▃▂▁▁▂▂▁</td></tr><tr><td>val_loss_step</td><td>█▄▄▂▄▄▂▂▁▃▂▂▃▂▃▃▄▂▄▃▂▃▃▃▁▂▁▂▇▂▁▂▂▃▃▂▂▃▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.866</td></tr><tr><td>train_auc</td><td>0.93551</td></tr><tr><td>train_f1</td><td>0.86284</td></tr><tr><td>train_loss_epoch</td><td>0.3381</td></tr><tr><td>train_loss_step</td><td>0.5837</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82033</td></tr><tr><td>val_auc</td><td>0.89842</td></tr><tr><td>val_f1</td><td>0.80905</td></tr><tr><td>val_loss_epoch</td><td>0.39033</td></tr><tr><td>val_loss_step</td><td>0.29578</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hyalkdgj' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hyalkdgj</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_103500-hyalkdgj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_105721-73z9my66</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/73z9my66' target=\"_blank\">GraphConv_4_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/73z9my66' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/73z9my66</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_3\\attention2\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 26.9 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "33.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "33.2 K    Total params\n",
      "0.133     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▆▇▆▇▇▇▆▇▇▇▇▇▇▇▇███▇▇██▇▇██▇██████▇██</td></tr><tr><td>train_auc</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████▇███▇█████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇███▇▇██▇▇██▇██████▇██</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▃▃▃▃▂▃▂▃▂▂▂▂▂▂▂▂▂▁▁▂▂▂▁▂▁▁▁▂▁▁▂▂▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▆▆▅▄▄▃▄▃▄▄▄▃▃▃▃▄▃▂▃▄▄▃▃▁▄▂▅▃▄▃▃▂▃▄▂▄▃▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▇▄▆▇▇▇▆█▆██▇▇▇▇▇▆▆▆▅▆▆▇▆▆▆▆▇▇▆▆▆▆▆▄▆▆▆</td></tr><tr><td>val_auc</td><td>▁▇▇▇▇██▇▇█▇█▇▇█▇█▇▇▇█▇███▇█▇▇█▇▇▇▇▇█▇▇▇▇</td></tr><tr><td>val_f1</td><td>▁▆▆▆▇▇▆▇▇█▆██▇█▇██▇▆▅▅▇▆▇▆▇▇▆▇▇▆▇▆▆▇▆▆▆▅</td></tr><tr><td>val_loss_epoch</td><td>▅▃▂▅▁▂▂▂▃▂▂▁▂▂▂▂▂▁▂▂▃▃▂▁▂▄▃▂▂▁▂▃▃▃▂▁█▅▄▃</td></tr><tr><td>val_loss_step</td><td>▄▅▃▇▂▄▄▂▄▄▄▂▄▂▃▄▃▁▄▃▂▄▃▄▃▇▂▃▁▁▃▅▃▃▂▂█▇▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.88666</td></tr><tr><td>train_auc</td><td>0.94932</td></tr><tr><td>train_f1</td><td>0.88571</td></tr><tr><td>train_loss_epoch</td><td>0.28756</td></tr><tr><td>train_loss_step</td><td>0.32926</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80615</td></tr><tr><td>val_auc</td><td>0.88969</td></tr><tr><td>val_f1</td><td>0.78756</td></tr><tr><td>val_loss_epoch</td><td>0.47535</td></tr><tr><td>val_loss_step</td><td>0.57155</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/73z9my66' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/73z9my66</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_105721-73z9my66\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c2dd09f168c4f438fd6e88c2ba42009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666883975, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_111838-t4w76dui</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/t4w76dui' target=\"_blank\">GCN_2_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/t4w76dui' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/t4w76dui</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_4\\mean\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 528   \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "682       Trainable params\n",
      "0         Non-trainable params\n",
      "682       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d667b6aaf41486e9ed6827fea6d28d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇▇▇▇▇█▇▇████▇▇▇▇█▇█▇██▇█▇██▇██▇▇▇██</td></tr><tr><td>train_auc</td><td>▁▇▇▇▇█▇█▇▇█▇▇▇▇██▇█▇▇██▇████████████▇███</td></tr><tr><td>train_f1</td><td>▁▇▇▇█▇███▇█▇█████▇█████████▇█▇█████▇▇███</td></tr><tr><td>train_loss_epoch</td><td>█▃▃▂▂▁▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▁▁▂▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▅▄▅▄▆▄▅▂▆▅▆▄▇▄▄▁▄▃▃▃▇▄▅▄▃▄▅▇▄▃▃▂▆▃▅▄▄▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▇▆▇▆█▇█▆▇▇█▇▆▇▆▇▇▆▅▇▇▇▇▆▇▇▆▆▇▇▇▆█▇▆▆▇▇</td></tr><tr><td>val_auc</td><td>▁▆▇▇█████▇█████████████▇███████████████▇</td></tr><tr><td>val_f1</td><td>▁▂▇▆▆▆▇▆█▆▇█▇█▅▇▆█▇▆▄▇▇▇▇▆▇▇▅▇█▇▇██▇▇▇▇▆</td></tr><tr><td>val_loss_epoch</td><td>█▄▂▂▂▂▂▂▁▂▁▂▁▁▃▂▁▁▂▂▃▁▂▂▂▂▂▂▃▂▃▂▂▃▂▁▂▂▂▂</td></tr><tr><td>val_loss_step</td><td>█▅▃▃▆▆▅▄▁▃▂▃▂▂▄▅▁▃▄▅▄▂▄▃▃▃▃▄▅▃█▃▅▆▅▂▃▃▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84238</td></tr><tr><td>train_auc</td><td>0.91105</td></tr><tr><td>train_f1</td><td>0.83026</td></tr><tr><td>train_loss_epoch</td><td>0.38212</td></tr><tr><td>train_loss_step</td><td>0.29595</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82033</td></tr><tr><td>val_auc</td><td>0.91064</td></tr><tr><td>val_f1</td><td>0.8296</td></tr><tr><td>val_loss_epoch</td><td>0.39789</td></tr><tr><td>val_loss_step</td><td>0.42327</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/t4w76dui' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/t4w76dui</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_111838-t4w76dui\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a35386d8d89e40a4a3eb0f95be52049f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_113940-fzqkac9b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fzqkac9b' target=\"_blank\">GraphConv_2_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fzqkac9b' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fzqkac9b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_4\\mean\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 992   \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇█▇█████▇██████▇████████████</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇█▇▇█▇█▇████████████████████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▇▆▆▇▆▇▇▇█▇▇▇▇▇█▇██▇▇▇▇▇█▇▇▇▇▇▇▇██▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▂▁▂▂▂▁▂▂▁▁▁▂▁▂▁▂▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▄▄▃▃▃▃▄▂▃▃▁▃▂▂▅▅▃▂▃▄▅▄▅▃▃▆▃▁▂▅▃▁▃▃▂▂▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▅▇▇▆▇▇▇▇▇█▇█▇██▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇</td></tr><tr><td>val_auc</td><td>▁▆▇▇▇▇▇█████████████████████████████████</td></tr><tr><td>val_f1</td><td>▁▅▄▆▆▆▇▇▇▇▇█▆█▇▇▇▇▇▇▇▇█▇▆▇▇▇▇▇▇▇▇▇▆▇█▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▂▂▂▂▁▂▁▃▂▃▂▁▁▂▂▁▁▂▁▂▂▂▁▁▂▂▂▁▁▁▂▂▂▂▂▂▂</td></tr><tr><td>val_loss_step</td><td>█▄▄▅▅▂▄▂▅▂▇▆▆▃▃▃▄▄▃▂▄▂▄▃▃▃▃▄▆▄▂▂▁▃▃▄▄▅▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85124</td></tr><tr><td>train_auc</td><td>0.9149</td></tr><tr><td>train_f1</td><td>0.84483</td></tr><tr><td>train_loss_epoch</td><td>0.36137</td></tr><tr><td>train_loss_step</td><td>0.37779</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.85579</td></tr><tr><td>val_auc</td><td>0.92657</td></tr><tr><td>val_f1</td><td>0.86353</td></tr><tr><td>val_loss_epoch</td><td>0.3619</td></tr><tr><td>val_loss_step</td><td>0.39852</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_2_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fzqkac9b' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fzqkac9b</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_113940-fzqkac9b\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04dc159380f24806b3cde87bb5965848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_120043-x0cq06ci</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/x0cq06ci' target=\"_blank\">GCN_2_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/x0cq06ci' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/x0cq06ci</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_4\\max\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 528   \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "682       Trainable params\n",
      "0         Non-trainable params\n",
      "682       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▆▆▆▇▇▇▇▇▇▇▇▇█▇▇██▇██▇██▇▇██▇▇█████▇██</td></tr><tr><td>train_auc</td><td>▁▁▂▄▅▆▆▇▇▇▇▇▇▇▇██▇▇▇▇█▇▇▇█▇▇▇██▇█▇█▇█▇█▇</td></tr><tr><td>train_f1</td><td>▁▃▄▅▆▅▆▆▇▆▇▆▇▆▇▇▇▇▇█▇██▇█▇▇▇▇▇▇▇████▇▇█▇</td></tr><tr><td>train_loss_epoch</td><td>█▃▃▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▅▄▅▄▅▄▃▃▅▃▅▃▃▃▂▄▄▂▄▂▁▄▃▄▃▄▄▄▂▂▃▃▅▂▃▃▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▁████▇▇▇█▇██▇▇▇▇▇▇▇▇██▇▇██▇███▇██▇▇▅▇█▆</td></tr><tr><td>val_auc</td><td>▁▆▇▇▇██▇▇▇▇████▇▆▆▆▇▆▆▆▆▅▅▅▆▆▇▆▆▆▇▆▆▆▆▆▅</td></tr><tr><td>val_f1</td><td>▁▁███████████████▇▇████████████▇████▆██▆</td></tr><tr><td>val_loss_epoch</td><td>█▇▆▃▃▃▂▂▂▁▂▁▂▃▁▂▁▂▃▂▂▂▁▁▂▂▁▂▁▁▁▂▁▁▁▁▄▂▃▂</td></tr><tr><td>val_loss_step</td><td>▇▇▆▄▅▅▄▄▃▂▃▂▄▇▂▃▁▃▇▄▄▆▄▃▄▄▃▅▃▄▃▄▄▄▃▃█▆█▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.71192</td></tr><tr><td>train_auc</td><td>0.7471</td></tr><tr><td>train_f1</td><td>0.70673</td></tr><tr><td>train_loss_epoch</td><td>0.57204</td></tr><tr><td>train_loss_step</td><td>0.57019</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.63593</td></tr><tr><td>val_auc</td><td>0.76694</td></tr><tr><td>val_f1</td><td>0.60309</td></tr><tr><td>val_loss_epoch</td><td>0.61211</td></tr><tr><td>val_loss_step</td><td>0.61691</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/x0cq06ci' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/x0cq06ci</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_120043-x0cq06ci\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_122122-qci14kt1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qci14kt1' target=\"_blank\">GraphConv_2_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qci14kt1' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qci14kt1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_4\\max\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 992   \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▃▅▅▆▇▇▇▇▇▇▇██▇▇▇▇▇▇██▇██████▇█████████</td></tr><tr><td>train_auc</td><td>▁▂▂▃▃▄▅▅▅▅▅▅▆▇▆▇▇▇▇▇▇▇▇▇▇▇██▇█▇█▇██▇████</td></tr><tr><td>train_f1</td><td>▁▃▄▄▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇█▇██▇█▇█▇█▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▄▄▃▃▃▂▃▃▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▁▂▁▂▂▂▁▂▂▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▆▅▄▄▃▄▄▃▄▃▃▃▃▂▂▁▃▄▄▃▄▃▂▃▁▄▃▂▃▄▂▃▂▄▂▃▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▂▅▆▆▆▇▇▇▇▇▇▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██▇█▇█▇█████</td></tr><tr><td>val_auc</td><td>▁▄▅▅▄▅▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████████</td></tr><tr><td>val_f1</td><td>▁▂▄▄▅▅▅▅▅▅▅▅▄▃▄▃▅▅▄▅▆▆▅▆▆▇▇▇█▇▇▇▇▇▇█▇▇██</td></tr><tr><td>val_loss_epoch</td><td>█▇▆▄▄▄▃▃▃▃▄▃▃▃▃▃▃▃▃▃▂▂▃▂▂▂▂▁▂▁▂▁▁▂▂▂▂▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▇▆▄▅▄▃▂▃▄▆▅▄▄▃▄▄▃▄▂▃▂▃▂▃▃▃▁▄▂▂▁▁▂▃▂▃▂▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8046</td></tr><tr><td>train_auc</td><td>0.84243</td></tr><tr><td>train_f1</td><td>0.79755</td></tr><tr><td>train_loss_epoch</td><td>0.44803</td></tr><tr><td>train_loss_step</td><td>0.5217</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83924</td></tr><tr><td>val_auc</td><td>0.90713</td></tr><tr><td>val_f1</td><td>0.8547</td></tr><tr><td>val_loss_epoch</td><td>0.4482</td></tr><tr><td>val_loss_step</td><td>0.46474</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_2_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qci14kt1' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qci14kt1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_122122-qci14kt1\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_124156-aud3jnud</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/aud3jnud' target=\"_blank\">GCN_2_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/aud3jnud' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/aud3jnud</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_4\\sum\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 528   \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "682       Trainable params\n",
      "0         Non-trainable params\n",
      "682       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▆▆▆▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇███▇▇▇▇█</td></tr><tr><td>train_auc</td><td>▄▂▂▄▄▅▄▅▄▅▅▄▄▃▃▄▃▃▁▃▁▅▅▆▅▇▄▄▇▅▆▆▇▅▆▆▆▇▇█</td></tr><tr><td>train_f1</td><td>▁▃▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇▇▇██▇▇▇███▇▇▇██</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▃▂▃▂▃▃▃▁▃▂▃▃▃▂▂▁▂▂▂▂▃▂▃▂▂▁▃▃▂▂▂▁▃▁▂▂▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▆▆▆▆▆▇▇▆▇▇▇▇▆█▇▇▇▇▇▇█▆▇▇▇▇▇▇▆▇▇▇▇▇▇█▇▇</td></tr><tr><td>val_auc</td><td>▅▁▅▇▇▇▇▇▇█▇▇▇████▇▇█▆███████████████████</td></tr><tr><td>val_f1</td><td>▁▅▅▅▄▃▅▆▆▄▇▇▇▆▄█▆▇▅▆▇▇█▆▆▆▇▆▇▇▇▆█▇▇▇▇█▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▂▂▃▂▂▁▂▁▁▁▁▂▂▁▁▂▂▁▁▁▂▁▁▁▂▁▁▂▁▂▂▃▁▂▁▁▂</td></tr><tr><td>val_loss_step</td><td>█▄▂▂▄▄▃▃▂▂▂▂▂▂▃▃▁▃▃▄▃▂▃▂▂▂▂▃▂▂▄▂▄▃▅▂▄▂▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8353</td></tr><tr><td>train_auc</td><td>0.72844</td></tr><tr><td>train_f1</td><td>0.82308</td></tr><tr><td>train_loss_epoch</td><td>0.40222</td></tr><tr><td>train_loss_step</td><td>0.3278</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83452</td></tr><tr><td>val_auc</td><td>0.89729</td></tr><tr><td>val_f1</td><td>0.84783</td></tr><tr><td>val_loss_epoch</td><td>0.43195</td></tr><tr><td>val_loss_step</td><td>0.47559</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/aud3jnud' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/aud3jnud</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_124156-aud3jnud\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d6a0148567e4f80bad4b44bc95d088c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666883975, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_130305-pezv6p21</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/pezv6p21' target=\"_blank\">GraphConv_2_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/pezv6p21' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/pezv6p21</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_4\\sum\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 992   \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇███▇▇█▇▇█████████</td></tr><tr><td>train_auc</td><td>▃▅▅▆▄▃▄▃▂▂▁▂▃▅▅▄▅▅▆▅▆▇▇▅▅▅▆▇▆▇█▇▇▇▇▄▇▇█▆</td></tr><tr><td>train_f1</td><td>▁▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇█▇██████████</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▂▂▁▁▂▁▂▂▁▁▁▁▂▂▁▁▂▁▂▂▂▂▁▂▁▁▁▂▁▁▁▂▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▄▄▅▆▆▅▆▅▆▅▅▅▇▆▆▇▇▇▇██▇██▇▇▇▇▇▇██▆▇▇▆█▇</td></tr><tr><td>val_auc</td><td>▇▆▆▅▄▄▃▃▁▁▁▇▆▇█▆▆▇▇▇▇███▇██████████▇████</td></tr><tr><td>val_f1</td><td>▁▃▄▄▄▅▆▅▆▅▆▄▄▅▇▆▆▆▆▆▇█▇▆▇█▇▇▇▆▇▆█▇▅▆▆▅█▇</td></tr><tr><td>val_loss_epoch</td><td>█▆▇▇▆▄▄▃▅▃▇▅▄▄▃▃▃▃▂▁▃▂▃▄▂▂▃▂▅▂▁▂▁▃▂▅▄▃▃▃</td></tr><tr><td>val_loss_step</td><td>▅▄▅▅▆▃▄▂▆▂█▆▄▅▄▄▄▃▃▂▅▂▅▅▃▃▄▄▇▄▂▃▁▄▃▆▆▅▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83648</td></tr><tr><td>train_auc</td><td>0.58115</td></tr><tr><td>train_f1</td><td>0.82806</td></tr><tr><td>train_loss_epoch</td><td>0.40423</td></tr><tr><td>train_loss_step</td><td>0.40075</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.85106</td></tr><tr><td>val_auc</td><td>0.91379</td></tr><tr><td>val_f1</td><td>0.86093</td></tr><tr><td>val_loss_epoch</td><td>0.392</td></tr><tr><td>val_loss_step</td><td>0.45153</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_2_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/pezv6p21' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/pezv6p21</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_130305-pezv6p21\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7144ab0bf2494de280d243d91f45febd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666883975, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_132411-8xjwx5ng</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8xjwx5ng' target=\"_blank\">GCN_2_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8xjwx5ng' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8xjwx5ng</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_4\\attention\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 528   \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "699       Trainable params\n",
      "0         Non-trainable params\n",
      "699       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇▇▇██▇███▇███▇█████▇███▇██████▇▇██▇</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇▇██▇█████████████████▇███████████</td></tr><tr><td>train_f1</td><td>▁▆▇▇▇▇▇▇██▇███▇███▇█████▇███▇██████▇▇██▇</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▂▂▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▂▁▂▂▂▁▁▂▁▁▁▂▁▁▂▂▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▆▅▃▂▂▃▂▃▃▃▃▁▃▃▃▂▁▃▇▂▂▃▁▂▂▂▃▃▃▃▂▄▂▃▂▃▂▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▆▇▇▆▆▇▇▇▇▇▇█▇▇▇▇▇▇█▇▇▇▇██████▇▇▇██▇▇██</td></tr><tr><td>val_auc</td><td>▁▅▆▇▇▆▇▇▇▇▇████▇▇█▇█████████████████████</td></tr><tr><td>val_f1</td><td>▂▁▅▆▇▅▄▇▇▇▆▇▅▇▇▇▇▇▇▅█▇▇▇▇▇▇███▆▇▇█▇█▇▇▇█</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▂▃▂▂▂▂▂▂▂▃▂▃▃▂▂▂▂▂▂▂▂▂▁▁▂▂▂▂▃▂▁▂▂▂▂▁▁</td></tr><tr><td>val_loss_step</td><td>█▅▄▄▇▄▃▅▄▃▅▄▆▅█▆▅▂▄▄▃▄▅▃▅▃▂▄▄▅▃▅▅▂▄▆▃▄▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.82408</td></tr><tr><td>train_auc</td><td>0.90192</td></tr><tr><td>train_f1</td><td>0.81445</td></tr><tr><td>train_loss_epoch</td><td>0.39619</td></tr><tr><td>train_loss_step</td><td>0.33794</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83688</td></tr><tr><td>val_auc</td><td>0.92063</td></tr><tr><td>val_f1</td><td>0.85474</td></tr><tr><td>val_loss_epoch</td><td>0.35056</td></tr><tr><td>val_loss_step</td><td>0.31187</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8xjwx5ng' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8xjwx5ng</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_132411-8xjwx5ng\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_134539-q52j929v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/q52j929v' target=\"_blank\">GraphConv_2_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/q52j929v' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/q52j929v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_4\\attention\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 992   \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▇▇▇▇█▇█▇████▇██▇█▇██▇███████████████▇</td></tr><tr><td>train_auc</td><td>▁▅▇▇▇▇▇█████████████████████████████████</td></tr><tr><td>train_f1</td><td>▁▄▆▆▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇█▇▇████▇▇█████████▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▂▂▂▁▁▁▁▁▁▂▁▂</td></tr><tr><td>train_loss_step</td><td>█▆▆▅▅▅▄▃▄▃▂▃▂▃▄▃▄▇▄▄▄▄▄▃▄▃▃▄▃▄▂▂▂▄▃▃▁▃▄▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▆▇█▇▇▇██▇▇▆██▇████████████████▇█▇▇█▇██</td></tr><tr><td>val_auc</td><td>▁▄▆▇▇▇▇█████████████████████████████████</td></tr><tr><td>val_f1</td><td>▁▆▅▆█▅▆▆▇▇▇▆▅█▇▆▇▇███▇█▇█▇██▇███▆▇▆▇▇▆██</td></tr><tr><td>val_loss_epoch</td><td>█▄▄▂▂▂▂▂▂▁▂▂▃▁▁▂▁▁▂▁▂▂▂▁▁▂▁▂▁▂▂▁▂▁▂▃▂▃▂▂</td></tr><tr><td>val_loss_step</td><td>█▆▆▄▅▂▅▄▄▃▅▂▆▂▁▃▂▂▅▃▃▄▄▁▂▃▂▅▂▄▄▁▁▁▄▅▅▅▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83648</td></tr><tr><td>train_auc</td><td>0.91048</td></tr><tr><td>train_f1</td><td>0.8272</td></tr><tr><td>train_loss_epoch</td><td>0.39407</td></tr><tr><td>train_loss_step</td><td>0.50516</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.85816</td></tr><tr><td>val_auc</td><td>0.92633</td></tr><tr><td>val_f1</td><td>0.87603</td></tr><tr><td>val_loss_epoch</td><td>0.35434</td></tr><tr><td>val_loss_step</td><td>0.35264</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_2_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/q52j929v' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/q52j929v</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_134539-q52j929v\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_140745-oh34lm03</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/oh34lm03' target=\"_blank\">GCN_2_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/oh34lm03' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/oh34lm03</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_4\\attention2\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 528   \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "963       Trainable params\n",
      "0         Non-trainable params\n",
      "963       Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇▇▇▇▇▇██▇▇███████████████▇█████████</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇██████████████████████████████████</td></tr><tr><td>train_f1</td><td>▁▇▇▇▇█▇▇█▇▇██▇▇████▇██████████▇█████████</td></tr><tr><td>train_loss_epoch</td><td>█▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▂▁▁▂▂▂▂▂▁▂▁▁▂▂▂▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▆█▄▃▅▁▅▄▃▄▄▂▄▄▃▅▂▃▂▁▂▆▅▂▄▂▃▄▂▃▃▄▄▆▂▂▄▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▇▆▄▇▇▇▇▇▆▆▇▇▇▇▇▇▇▇██▇▇▇▇▇▇▇▇▇███▇▇█▇▇▅</td></tr><tr><td>val_auc</td><td>▁▅▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█████▇██▇██▇▇████▇████▇</td></tr><tr><td>val_f1</td><td>▁▂▇▇▄▇▇▇▇▇▆▆▇▇██▇▇▇███▇▇█▇█▇▇▇███████▇█▅</td></tr><tr><td>val_loss_epoch</td><td>█▅▂▂▄▂▁▃▁▁▂▃▁▂▂▁▁▂▂▁▁▁▂▂▁▂▁▂▂▂▂▁▂▁▁▁▂▂▂▃</td></tr><tr><td>val_loss_step</td><td>█▅▁▃▄▄▂█▂▁▂▇▂▆▃▃▁▅▅▃▁▁▃▄▂▄▂▆▃▃▅▃▆▄▂▃▅▅▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83707</td></tr><tr><td>train_auc</td><td>0.90219</td></tr><tr><td>train_f1</td><td>0.83394</td></tr><tr><td>train_loss_epoch</td><td>0.40349</td></tr><tr><td>train_loss_step</td><td>0.38282</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.79905</td></tr><tr><td>val_auc</td><td>0.90987</td></tr><tr><td>val_f1</td><td>0.79319</td></tr><tr><td>val_loss_epoch</td><td>0.43148</td></tr><tr><td>val_loss_step</td><td>0.39382</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/oh34lm03' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/oh34lm03</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_140745-oh34lm03\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_142940-2pdn8sbp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/2pdn8sbp' target=\"_blank\">GraphConv_2_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/2pdn8sbp' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/2pdn8sbp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_16_onehot_4\\attention2\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 992   \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "1.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.4 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "956f813624c54629a0c6098ffdef8944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇██▇███▇█▇██▇█████████▇█████</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇▇██████████████████████████</td></tr><tr><td>train_f1</td><td>▁▄▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇▇▇██▇▇█▇██▇</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▂▂▃▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▁▁▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▅▅▆▅▄▄▃▃▃▅▂▆▃▄▄▃▂▃▂▄▂▁▄▃▄▄▂▄▃▃▂▂▃▂▃▄▂▂▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▅▇▇▇▇▇▇▇▇▇▇▇▇██▇█▇▇▇███▇▇█▇▇██▇▇████▇█</td></tr><tr><td>val_auc</td><td>▁▅▆▇▇▇▇█████████████████████████████████</td></tr><tr><td>val_f1</td><td>▁▅▄▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇█▇▇▇█▇▆▇▇██▇█</td></tr><tr><td>val_loss_epoch</td><td>█▄▄▂▂▂▂▂▂▁▁▂▂▂▂▂▂▂▂▂▁▁▂▁▁▂▁▁▂▁▁▂▂▂▂▂▂▂▁▂</td></tr><tr><td>val_loss_step</td><td>█▆▆▅▅▄▃▄▅▃▁▂▄▃▆▅▄▅▅▄▃▃▄▂▃▃▂▂▄▃▁▃▃▅▅▄▃▄▃▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85714</td></tr><tr><td>train_auc</td><td>0.91803</td></tr><tr><td>train_f1</td><td>0.84932</td></tr><tr><td>train_loss_epoch</td><td>0.3765</td></tr><tr><td>train_loss_step</td><td>0.5019</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.86052</td></tr><tr><td>val_auc</td><td>0.93166</td></tr><tr><td>val_f1</td><td>0.87033</td></tr><tr><td>val_loss_epoch</td><td>0.37164</td></tr><tr><td>val_loss_step</td><td>0.55632</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_2_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/2pdn8sbp' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/2pdn8sbp</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_142940-2pdn8sbp\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_145046-b9oc9gnn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/b9oc9gnn' target=\"_blank\">GCN_2_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/b9oc9gnn' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/b9oc9gnn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_4\\mean\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 1.6 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇▇█▇▇▇█▇▇▇▇▇██▇█▇█████</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇█▇▇█████▇███▇████████▇█████</td></tr><tr><td>train_f1</td><td>▁▆▇▇▇▇▇▇█▇▇▇▇█▇█▇█▇▇█▇█▇█▇██████▇█▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▂▁▁▂▂▁▂▁▂▂▂▂▁▃▂▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▇█▅▄▆▅▄▆▆▅▄▆▆▇▅▅▅▅▆▃▅▅▄▄▅▄▂▆▆█▆▃▁▄▄▄▃▆▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▄▁▆▆▄▆▅▇▆▄▇▇▇▇▇▆▇▆▆▇▅▆▇██▇▇█▇█▆▅▇▇▇▅▇▇▇▆</td></tr><tr><td>val_auc</td><td>▁▆▇▇▆▇▇▇▇▇▇█▇▇█▇████▇████▇████▇▇█▇█▇▇███</td></tr><tr><td>val_f1</td><td>▆▁▆▆▅▇▄▇▆▅▇▇▇▇▇▇▇▇▇▇▆▇▇██▇▆██▇▆▇▇▇▇▅▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▅▂▂▂▂▃▂▂▄▂▂▂▂▁▂▂▁▁▁▃▂▂▂▂▁▂▁▂▁▃▄▂▂▂▃▂▃▂▁</td></tr><tr><td>val_loss_step</td><td>▇▅▃▃▂▃▃▄▄█▄▄▃▃▂▂▃▂▁▂▅▄▄▃▂▂▃▂▂▁▆█▃▄▄▄▅▇▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84298</td></tr><tr><td>train_auc</td><td>0.91472</td></tr><tr><td>train_f1</td><td>0.83165</td></tr><tr><td>train_loss_epoch</td><td>0.36854</td></tr><tr><td>train_loss_step</td><td>0.18599</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82979</td></tr><tr><td>val_auc</td><td>0.92203</td></tr><tr><td>val_f1</td><td>0.84937</td></tr><tr><td>val_loss_epoch</td><td>0.35613</td></tr><tr><td>val_loss_step</td><td>0.33699</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/b9oc9gnn' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/b9oc9gnn</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_145046-b9oc9gnn\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_151231-dwp07pwi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/dwp07pwi' target=\"_blank\">GraphConv_2_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/dwp07pwi' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/dwp07pwi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_4\\mean\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 3.0 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "3.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 K     Total params\n",
      "0.014     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▆▇▇▇▇▇▇█▇▇▇▇█▇▇▇██████▇███▇████████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇███▇████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▇▇▇▇▇▇█▇▇█▇▇██▇██████▇███▇████████</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂</td></tr><tr><td>train_loss_step</td><td>█▅▆▇▄▅▅▃▅▃▄▃▅▃▃▃▄▁▃▄▆▁▁▁▃▃▂▂▂▄▄▄▃▂▃▃▃▃▄▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▅█▇▇▇▇▆▆█▇▇█▆▇▇█▇▇▇▆▇▇▇▇██▆▇█▆█▇████▇█</td></tr><tr><td>val_auc</td><td>▁▅▆▆▇▇▇▇██████▇█████████████████▇███████</td></tr><tr><td>val_f1</td><td>▁▆▄██▇▇▇▆▇█▇▇█▇▇▇█▇▇▇▇▇▇▇▇██▇▇█▇█▇█▇█▇▇█</td></tr><tr><td>val_loss_epoch</td><td>█▃▄▃▂▂▂▂▃▂▂▂▂▂▂▂▁▁▁▂▂▃▃▂▂▂▁▁▂▂▃▃▂▂▁▂▂▂▃▂</td></tr><tr><td>val_loss_step</td><td>█▄▆▆▅▂▃▅▄▄▄▄▄▄▂▄▁▃▁▅▄▅█▃▅▃▂▂▄▅▇▃▅▄▃▅▄▁▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86482</td></tr><tr><td>train_auc</td><td>0.93368</td></tr><tr><td>train_f1</td><td>0.8596</td></tr><tr><td>train_loss_epoch</td><td>0.33587</td></tr><tr><td>train_loss_step</td><td>0.38653</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.85816</td></tr><tr><td>val_auc</td><td>0.92437</td></tr><tr><td>val_f1</td><td>0.86486</td></tr><tr><td>val_loss_epoch</td><td>0.36756</td></tr><tr><td>val_loss_step</td><td>0.41483</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_2_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/dwp07pwi' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/dwp07pwi</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_151231-dwp07pwi\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_153401-u0u19iv4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/u0u19iv4' target=\"_blank\">GCN_2_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/u0u19iv4' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/u0u19iv4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_4\\max\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 1.6 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▅▆▅▅▆▆▆▅▆▆▆▆▆▆▆▇▇▆▇▆▇▇▇▇▇▇▇▇▇███████</td></tr><tr><td>train_auc</td><td>▁▂▄▅▅▅▅▅▆▆▅▆▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇█▇▇███████</td></tr><tr><td>train_f1</td><td>▁▃▄▅▅▅▄▅▆▆▆▅▆▆▆▆▆▆▇▇▇▆▇▆▇▇▇▇▇▇▇▇▇███████</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▄▃▃▃▃▃▃▃▃▃▃▂▃▂▂▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▂▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▆▆▅▆▆▅▅▇▅▄▄▄▄▅▄▄▄▄▃▅▂▃▃▃▃▂▃▃▅▃▃▁▁▃▃▁▁▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▂▆▆▆▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████▇▇▇█</td></tr><tr><td>val_auc</td><td>▁▂▂▂▃▃▃▃▃▃▃▃▃▃▃▃▄▅▅▅▅▆▆▆▇▇▇▇███▇█████▇██</td></tr><tr><td>val_f1</td><td>▁▂███▇██████▇███████████████████████████</td></tr><tr><td>val_loss_epoch</td><td>█▇▆▆▆▆▅▅▅▅▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▂▁▂▂▁▁▁▂▂▂▁</td></tr><tr><td>val_loss_step</td><td>██▆▆▆▇▆▅▆▆▆▆▅▅▆▄▅▆▄▃▅▃▄▄▄▂▄▃▂▃▂▄▃▂▁▂▅▃▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77037</td></tr><tr><td>train_auc</td><td>0.85197</td></tr><tr><td>train_f1</td><td>0.77579</td></tr><tr><td>train_loss_epoch</td><td>0.47185</td></tr><tr><td>train_loss_step</td><td>0.49968</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.79669</td></tr><tr><td>val_auc</td><td>0.88772</td></tr><tr><td>val_f1</td><td>0.82231</td></tr><tr><td>val_loss_epoch</td><td>0.42978</td></tr><tr><td>val_loss_step</td><td>0.4131</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/u0u19iv4' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/u0u19iv4</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_153401-u0u19iv4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9d5b1f87286489ea667a63bbbedea04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_155623-usx91axw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/usx91axw' target=\"_blank\">GraphConv_2_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/usx91axw' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/usx91axw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_4\\max\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 3.0 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "3.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 K     Total params\n",
      "0.014     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▄▅▆▇▇▇▇▇▇▇▇▇██▇█▇████▇███████▇████████</td></tr><tr><td>train_auc</td><td>▁▂▃▄▅▆▆▆▇▇▇▇▇▇▇▇▇█▇▇████████████████████</td></tr><tr><td>train_f1</td><td>▂▁▄▅▆▇▇▇▇▇▇▇▇▇██▇█▇████▇███████▇████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▃▂▂▂▂▂▂▂▂▂▁▂▁▂▂▂▁▂▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▆▅▄▆▄▃▅▃▅▃▄▃▄▂▄▁▂▃▃▁▇▂▂▂▂▁▂▃▃▃▂▃▂▃▂▂▃▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▃▅▅▅▅▅▅▅▅▅▅▆▆▆▇▆▆▆▆▇▇▆▇▇██▇▇▇▆██▆▇▇▇▇▇</td></tr><tr><td>val_auc</td><td>▁▃▃▅▆▆▆▆▆▆▆▇▇▇▇▇▇█▇▇▇███████▇██████▇████</td></tr><tr><td>val_f1</td><td>▁▃▃▅▅▅▅▅▄▄▅▄▄▆▆▆▇▇▅▆▆▇▇▆▇▇▇█▇█▆▇██▆▇█▆▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▇▆▅▄▃▃▃▄▄▃▃▄▃▂▂▂▁▃▃▂▁▂▂▂▁▂▁▂▁▂▁▂▁▂▂▂▁▁▁</td></tr><tr><td>val_loss_step</td><td>███▆▅▃▄▄▄▆▅▄▇▄▁▃▄▁▂▄▃▃▄▃▃▂▃▂▄▄▇▁▅▃▄▅▅▁▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83353</td></tr><tr><td>train_auc</td><td>0.89688</td></tr><tr><td>train_f1</td><td>0.83094</td></tr><tr><td>train_loss_epoch</td><td>0.41267</td></tr><tr><td>train_loss_step</td><td>0.56252</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82742</td></tr><tr><td>val_auc</td><td>0.90917</td></tr><tr><td>val_f1</td><td>0.84233</td></tr><tr><td>val_loss_epoch</td><td>0.42767</td></tr><tr><td>val_loss_step</td><td>0.52938</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_2_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/usx91axw' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/usx91axw</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_155623-usx91axw\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_161638-x9r17bfo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/x9r17bfo' target=\"_blank\">GCN_2_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/x9r17bfo' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/x9r17bfo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_4\\sum\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 1.6 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55899cfaf09a41b5b35db4b32cc97335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.013 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.080682…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▆▆▆▆▇▇▇▆▇▇▇▇▇█▇█▇▇▇▇▇▇▇█▇▇█▇▇▇▇▇▇████</td></tr><tr><td>train_auc</td><td>▃▁▃▂▁▁▁▂▂▂▃▅▅▆▇▇▇▆▇▇▇▇▇▇▇▅▃▆▇█▇███▇█████</td></tr><tr><td>train_f1</td><td>▁▂▅▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇█▇▇▇█▇▇▇█▇▇█▇▇▇▇▇▇██▇█</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▃▃▂▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▂▂▁▂▂▂▂▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▅▅▆▇▆▆▇█▇▆▇▇▇▅█▆▅▇▅▆▆▇█▇▇▆█▅▆▇▇▆▆▇▆██▆</td></tr><tr><td>val_auc</td><td>▁▄▆▆▇▇▇██▇▇███▇███████▇██▇▇▇█▇██████▇███</td></tr><tr><td>val_f1</td><td>▂▁▄▄▅▅▅▅▆▇▇▄▆▇▆▃█▄▃▇▃▆▆▆█▇▆▆▇▆▅▆▇▄▇▆▆██▇</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▂▂▂▂▂▃▃▂▃▂▂▁▂▁▂▂▂▄▂▃▂▂▁▁▂▂▁▅▃▂▃▃▂▃▃▁▂</td></tr><tr><td>val_loss_step</td><td>█▄▃▃▂▃▃▃▅▆▃▅▂▂▁▃▂▂▂▂▆▃▄▃▂▂▁▁▂▁█▅▂▅▅▃▅▆▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83353</td></tr><tr><td>train_auc</td><td>0.85501</td></tr><tr><td>train_f1</td><td>0.82397</td></tr><tr><td>train_loss_epoch</td><td>0.39797</td></tr><tr><td>train_loss_step</td><td>0.21127</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83688</td></tr><tr><td>val_auc</td><td>0.91197</td></tr><tr><td>val_f1</td><td>0.8535</td></tr><tr><td>val_loss_epoch</td><td>0.39282</td></tr><tr><td>val_loss_step</td><td>0.42364</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/x9r17bfo' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/x9r17bfo</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_161638-x9r17bfo\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_163714-6nvv1tvx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6nvv1tvx' target=\"_blank\">GraphConv_2_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6nvv1tvx' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6nvv1tvx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_4\\sum\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 3.0 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "3.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 K     Total params\n",
      "0.014     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇█▇██▇▇██</td></tr><tr><td>train_auc</td><td>▄▄▃▂▂▁▁▁▂▃▄▄▂▃▃▄▆▆▆▅▄▃▃▄▅▅▅▆▅▅▄▅▄▄▄▄▆▇█▅</td></tr><tr><td>train_f1</td><td>▁▃▄▅▆▅▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇█▇███▇██</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▂▂▂▂▂▂▂▁▂▁▂▂▁▁▂▁▁▂▂▁▁▁▂▁▁▁▁▁▂▂▁▁▁▁▁▂▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▅▄▆▆▆▆▆▆▆▆▇▇▇█▇██▇██▇█▇▇▇▇▇▇█▇▇▇██▇▇▇▇</td></tr><tr><td>val_auc</td><td>▃▂▃▃▃▁▂▃▃▇▇▇▆▅▇▇▇▇▇█▆▆▇▇█▇██████▇▇█▇███▇</td></tr><tr><td>val_f1</td><td>▁▇▅▄▆▆▆▆▆▆▆▆▇▇▇█▇██▇██▇█▇▇▇█▇███▇████▇▆▇</td></tr><tr><td>val_loss_epoch</td><td>█▄▄▄▄▃▃▃▃▃▃▂▃▂▂▂▂▃▂▄▂▂▃▂▂▂▂▂▂▂▄▂▂▂▂▂▂▁▃▂</td></tr><tr><td>val_loss_step</td><td>█▃▅▅▄▃▄▄▃▄▄▃▅▄▂▃▃▄▂▇▃▄▄▂▄▂▂▂▃▃▆▃▄▃▂▄▄▁▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84357</td></tr><tr><td>train_auc</td><td>0.69948</td></tr><tr><td>train_f1</td><td>0.83871</td></tr><tr><td>train_loss_epoch</td><td>0.39092</td></tr><tr><td>train_loss_step</td><td>0.45607</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.84397</td></tr><tr><td>val_auc</td><td>0.90139</td></tr><tr><td>val_f1</td><td>0.85897</td></tr><tr><td>val_loss_epoch</td><td>0.3991</td></tr><tr><td>val_loss_step</td><td>0.5008</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_2_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6nvv1tvx' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6nvv1tvx</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_163714-6nvv1tvx\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "defafe93aad84999ac7d4886df1fde16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333330477276, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_170042-byjmuphb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/byjmuphb' target=\"_blank\">GCN_2_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/byjmuphb' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/byjmuphb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_4\\attention\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 1.6 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "2.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.2 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇██▇▇▇▇███▇█</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇████▇██▇▇█▇███▇█</td></tr><tr><td>train_f1</td><td>▁▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇██▇▇▇▇███▇█</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▂▃▂▂▂▂▂▂▂▂▂▃▂▂▂▂▂▂▂▂▁▂▁▂▃▂▂▂▂▂▂▂▂▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▇▆▄▄▄▆▆▄▃▃▅▅▄▃▄▅▁▃▄▄▃▃▃▅▆▁▂▄▃▄▆▅▂▅▃▄▆▃▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▆▅▇▇▇▇▇█▆▇▇▇▆▇▇▇▇█▆▇█▇▇▇▇██▇██▆█▇▇██▇▇</td></tr><tr><td>val_auc</td><td>▁▅▆▇▇▇▇▇▇▇▇█▇▇▇▇▇▇█▇▇▇▇█▇█▇█████▇███████</td></tr><tr><td>val_f1</td><td>▁▃▇▅▇▇▇▇▇█▆█▇█▇▇█▇██▇▇█▇▇█▇██▇██▆██▇████</td></tr><tr><td>val_loss_epoch</td><td>█▅▂▄▂▃▂▂▂▁▃▂▂▁▃▂▃▂▂▃▃▂▁▂▃▂▁▁▁▂▂▁▃▂▂▂▁▂▂▂</td></tr><tr><td>val_loss_step</td><td>█▆▄▅▄▇▅▄▃▃▆▂▅▁▄▆▇▆▃█▅▆▂▄▅▄▂▂▃▄▅▃▆▄▁▄▃▆▁▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84888</td></tr><tr><td>train_auc</td><td>0.92115</td></tr><tr><td>train_f1</td><td>0.84236</td></tr><tr><td>train_loss_epoch</td><td>0.36034</td></tr><tr><td>train_loss_step</td><td>0.41988</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.84161</td></tr><tr><td>val_auc</td><td>0.92563</td></tr><tr><td>val_f1</td><td>0.85653</td></tr><tr><td>val_loss_epoch</td><td>0.36211</td></tr><tr><td>val_loss_step</td><td>0.43112</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/byjmuphb' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/byjmuphb</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_170042-byjmuphb\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_172355-9brz4bfz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9brz4bfz' target=\"_blank\">GraphConv_2_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9brz4bfz' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9brz4bfz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_4\\attention\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 3.0 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "3.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.6 K     Total params\n",
      "0.014     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "effc5ebf80ef452f9e1bfbf08c9586bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█▇▇████▇██████▇██</td></tr><tr><td>train_auc</td><td>▁▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██▇▇██████████▇██████▇█▇</td></tr><tr><td>train_f1</td><td>▁▅▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█▇▇████▇██████▇██</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▁▁▂▁▂▁▃▁▂</td></tr><tr><td>train_loss_step</td><td>█▅▄▅▄▅▄▅▂▃▃▃▃▄▄▃▂▆▃▄▃▂▁▃▂▄▃▆▂▄▂▃▂▂▃▃▃▃▁▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▅▃▄▆▇▂▆▆▆▇▇▆▄▇▇▇█▇▆█▇█▇█▇▇▇█▇▆▇▇█▆▇▆██</td></tr><tr><td>val_auc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇██▇█████▇█▇██</td></tr><tr><td>val_f1</td><td>▃▄▆▃▄▇▇▁▆▆▇▇▆▇▃▇█▇▇▇▇▇▇█▆█▇█▇█▇▇▆▇█▅█▆▇█</td></tr><tr><td>val_loss_epoch</td><td>█▃▄▄▃▂▃▅▂▃▃▃▃▂▃▂▃▂▃▂▄▃▃▂▂▃▂▃▂▂▁▃▂▂▂▄▂▃▂▁</td></tr><tr><td>val_loss_step</td><td>▇▃▆▅▅▂▆▇▃▇▆▇▄▃▃▃▅▄▆▃▇▅▅▄▂▅▃▆▅▂▂▃▁▄▄█▃▅▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8595</td></tr><tr><td>train_auc</td><td>0.92446</td></tr><tr><td>train_f1</td><td>0.85558</td></tr><tr><td>train_loss_epoch</td><td>0.3543</td></tr><tr><td>train_loss_step</td><td>0.39002</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.86998</td></tr><tr><td>val_auc</td><td>0.93517</td></tr><tr><td>val_f1</td><td>0.88172</td></tr><tr><td>val_loss_epoch</td><td>0.29456</td></tr><tr><td>val_loss_step</td><td>0.13566</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_2_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9brz4bfz' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9brz4bfz</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_172355-9brz4bfz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_174629-zd5zc0hu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zd5zc0hu' target=\"_blank\">GCN_2_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zd5zc0hu' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zd5zc0hu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_4\\attention2\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 1.6 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "3.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.2 K     Total params\n",
      "0.013     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇█▇▇████▇▇▇▇████████</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇▇▇▇██▇▇███▇█▇███▇███████▇████████</td></tr><tr><td>train_f1</td><td>▁▆▆▇▇▇▇▇▇██▇█▇▇█▇▇█▇▇█▇▇█████▇▇▇████████</td></tr><tr><td>train_loss_epoch</td><td>█▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▂▂▁▂▂▁▁▂▁▂▁▁▁▂▁▂▂▁▁▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▃▅▆▄▂▄▄▃▃▅▆▄▄▂▃▂▄▄▅▄▂▄▁▅▁▄▂▄▂▃▆▃▂▂▃▂▃▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▁▇▇▆▇▇█▇█▇██▇▇█▇▇▇█▇██▇▇▇▆▇██▇███▇█▇███</td></tr><tr><td>val_auc</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇▇▇██▇██████▇██</td></tr><tr><td>val_f1</td><td>▂▁▇▇▇▇▇█▇█▇█▇▇▇█▇▇▇██████▇▇█████████▇███</td></tr><tr><td>val_loss_epoch</td><td>█▅▂▂▃▃▂▁▂▁▂▁▂▂▂▁▃▂▂▁▂▁▂▁▁▂▃▁▁▂▂▁▂▁▁▁▃▁▁▂</td></tr><tr><td>val_loss_step</td><td>█▅▆▄▆▇▅▂▅▄▄▃▄▆▅▃▇▄▅▄▇▄▆▁▂▃█▂▂▄▅▄▅▄▁▄▆▂▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85596</td></tr><tr><td>train_auc</td><td>0.92205</td></tr><tr><td>train_f1</td><td>0.85194</td></tr><tr><td>train_loss_epoch</td><td>0.35753</td></tr><tr><td>train_loss_step</td><td>0.39224</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.84397</td></tr><tr><td>val_auc</td><td>0.92628</td></tr><tr><td>val_f1</td><td>0.85268</td></tr><tr><td>val_loss_epoch</td><td>0.35829</td></tr><tr><td>val_loss_step</td><td>0.36431</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zd5zc0hu' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zd5zc0hu</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_174629-zd5zc0hu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_181128-y03t83m5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/y03t83m5' target=\"_blank\">GraphConv_2_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/y03t83m5' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/y03t83m5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_32_onehot_4\\attention2\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 3.0 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "4.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.6 K     Total params\n",
      "0.019     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▅▆▆▆▆▆▆▇▇▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇</td></tr><tr><td>train_auc</td><td>▁▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇█████▇█████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▇▆▇▇▇▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▃▂▃▃▃▃▂▃▂▃▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▁▂▁▂▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▅▅▆▄▄▃▄▄▅▄▂▆▄▄▃▃▅▃▂▃▂▃▄▃▂▄▄▃▁▄▃▂▂▃▁▃▃▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▁▅▆▄▅▆▆▅▆▅▄▅▆▇▇▇▇▇█▆▇▇▇▆▇▆▆▇▇▇▇▆▇▇▇▇▆█</td></tr><tr><td>val_auc</td><td>▁▅▆▇▇▇▇▇▇█▇▇▇▇▇█▇▇██▇▇███▇██████████████</td></tr><tr><td>val_f1</td><td>▃▅▁▆▆▃▅▇▇▇▇▅▄▄▇▇█▇▇▇▇▇▇▇▇▆█▇▇▇▇▇█▆██▇▇▇█</td></tr><tr><td>val_loss_epoch</td><td>█▄▄▄▂▄▃▂▂▃▂▂▃▃▂▁▃▄▃▃▂▂▂▂▂▃▂▁▃▂▁▂▁▂▂▂▁▁▂▁</td></tr><tr><td>val_loss_step</td><td>▆▆▅▇▃▆▅▃▃▄▃▂▃▄▂▁▅█▇▅▂▁▃▂▃▃▃▂▅▃▂▂▁▂▄▃▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8719</td></tr><tr><td>train_auc</td><td>0.94202</td></tr><tr><td>train_f1</td><td>0.86872</td></tr><tr><td>train_loss_epoch</td><td>0.30951</td></tr><tr><td>train_loss_step</td><td>0.39989</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.86525</td></tr><tr><td>val_auc</td><td>0.9288</td></tr><tr><td>val_f1</td><td>0.87582</td></tr><tr><td>val_loss_epoch</td><td>0.3235</td></tr><tr><td>val_loss_step</td><td>0.21918</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_2_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/y03t83m5' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/y03t83m5</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_181128-y03t83m5\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_183209-k545o3mb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/k545o3mb' target=\"_blank\">GCN_2_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/k545o3mb' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/k545o3mb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_4\\mean\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 5.2 K \n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "7.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.3 K     Total params\n",
      "0.029     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef73bcd1fded468fbac4710fd090c769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▇▇▇▇▇█▇▇████▇█▇█▇▇▇██▇█▇█▇███▇██▇██▇███</td></tr><tr><td>train_auc</td><td>▁▇▇▇▇▇█▇▇▇▇██▇██████▇███▇█████▇█████▇███</td></tr><tr><td>train_f1</td><td>▁▇▇▇▇▇█▇▇▇███▇█▇██▇███▇█▇█████▇██▇██▇███</td></tr><tr><td>train_loss_epoch</td><td>█▃▃▂▃▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▁▁▁▂▂▁▂▂▂▂▁▂▂▂▁▂▁▂▁</td></tr><tr><td>train_loss_step</td><td>▆▆▅▅▅▅▄▅█▄▃▅▂▄▃▅▅▂▆▄▄▅▁▅▅▅▆▅▅▄▄▇▄▃▄▃▄▁▃▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▆▄▅▆▅▆▃▇▅▅▇▅▇▆▇▅▃▇▆▇▇▄▇▇▇▇▂█▇▇▅▇▂▄▅▇▆▄</td></tr><tr><td>val_auc</td><td>▁▅▇▇▇▇▇█▇▇█████▇████▇██▇▇████▇▇▇███▆██▇█</td></tr><tr><td>val_f1</td><td>▄▂▇▄▇▇▅▇▂▇▆▄▇▄▇▇█▅▆█▇▇█▄▇▇█▇▁█▇▇▅▇▂▄▇██▄</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▃▁▃▂▂▄▂▂▄▃▁▁▂▂▃▃▂▂▁▂▃▂▁▂▂▄▁▂▂▂▁▅▂▂▂▂▃</td></tr><tr><td>val_loss_step</td><td>▇▅▇▅▃█▅▆▆▃▄▇▆▂▃▄▅▆▃▃▅▃▅▇▃▂▄▄▅▂▃▃▃▃█▁▄▆▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84593</td></tr><tr><td>train_auc</td><td>0.92214</td></tr><tr><td>train_f1</td><td>0.83799</td></tr><tr><td>train_loss_epoch</td><td>0.35382</td></tr><tr><td>train_loss_step</td><td>0.35156</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81797</td></tr><tr><td>val_auc</td><td>0.92115</td></tr><tr><td>val_f1</td><td>0.82051</td></tr><tr><td>val_loss_epoch</td><td>0.3996</td></tr><tr><td>val_loss_step</td><td>0.435</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/k545o3mb' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/k545o3mb</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_183209-k545o3mb\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_185355-zciy35fn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zciy35fn' target=\"_blank\">GraphConv_2_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zciy35fn' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zciy35fn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_4\\mean\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 10.1 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "12.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "12.3 K    Total params\n",
      "0.049     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▆▆▆▇▇▆▇▇▇▇█▇▇▇▇▇▇▇▇▇█▇▇▇█▇▇█▇▇█▇█▇█▇██</td></tr><tr><td>train_auc</td><td>▁▅▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████▇██▇█▇█████████</td></tr><tr><td>train_f1</td><td>▁▅▆▇▇▇▇▇▇▇▇▇█▇▇▇▇▇█▇███▇▇▇██▇██████▇████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▂▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▆▅▄▄▃▅▄▄▃▄▄▁▃▅▂▂▃▁▃▂▂▆▃▂▃▃▃▂▁▂▁▄▃▃▃▄▂▅▇</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▃▅▅▅▆▇▆▆▆▇▇▇▇▇▇▅▇▆▇▆▇▆▆▆█▇▇▇▆▇▇▇█▆▆█▇▇</td></tr><tr><td>val_auc</td><td>▁▄▅▆▆▆▆▆▇▇▇▇▇▆▇▇▇▇▇█▇▇▇█▇██▇▇▇▇▇██▇▇█▇▇█</td></tr><tr><td>val_f1</td><td>▁▅▄▅▅▆▆▇▇▇▇▇▇▇▇▇▇▆▇▇█▇▇▇▇▇█▇▇▇▆▇█▇█▇▇█▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▄▅▃▃▃▄▃▃▃▂▂▃▃▃▄▂▃▂▃▂▃▄▃▂▃▂▂▂▂▄▃▂▂▁▂▂▃▂▁</td></tr><tr><td>val_loss_step</td><td>▇▄▆▃▅▄▆▅▅▅▃▂▄▄▅█▃▅▂▆▄▄█▅▁▅▃▃▂▄▄▃▃▄▂▃▃▆▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87839</td></tr><tr><td>train_auc</td><td>0.94913</td></tr><tr><td>train_f1</td><td>0.87284</td></tr><tr><td>train_loss_epoch</td><td>0.30559</td></tr><tr><td>train_loss_step</td><td>0.5267</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.86525</td></tr><tr><td>val_auc</td><td>0.93477</td></tr><tr><td>val_f1</td><td>0.87305</td></tr><tr><td>val_loss_epoch</td><td>0.30049</td></tr><tr><td>val_loss_step</td><td>0.12482</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_2_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zciy35fn' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zciy35fn</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_185355-zciy35fn\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_191436-4t9y4i65</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4t9y4i65' target=\"_blank\">GCN_2_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4t9y4i65' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4t9y4i65</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_4\\max\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 5.2 K \n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "7.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.3 K     Total params\n",
      "0.029     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇██▇▇▇▇███████████</td></tr><tr><td>train_auc</td><td>▁▄▅▅▅▅▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇█▇▇████████████</td></tr><tr><td>train_f1</td><td>▁▄▅▅▅▅▅▆▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇██▇▇▇████████████</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▄▃▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▄▅▅▅▄▄▆▅▄▃█▅▄▃▃▄▄▄▄▄▂▃▄▃▄▃▃▂▃▃▂▃▂▂▃▁▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▄▆▇▄▆█▆█▇▆▇▇██▇██████▇▇█</td></tr><tr><td>val_auc</td><td>▁▁▁▁▁▁▂▁▁▁▁▂▂▂▂▃▄▅▅▅▆▆▇▇▇▇▇▇▇███████████</td></tr><tr><td>val_f1</td><td>▁▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▅▇▇▅▇█▇██▇█▇██▇██████▇▇█</td></tr><tr><td>val_loss_epoch</td><td>█▆▅▆▅▆▅▅▅▅▅▅▅▆▄▅▆▄▅▇▄▃▄▃▂▅▂▃▃▃▃▂▂▁▂▂▂▃▃▂</td></tr><tr><td>val_loss_step</td><td>█▇▆▆▅▇▇▅▆▅▆▆▆▇▄▅▇▅▆▇▅▃▆▆▂▅▄▅▅▄▄▁▂▂▄▁▂▄▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.80401</td></tr><tr><td>train_auc</td><td>0.88549</td></tr><tr><td>train_f1</td><td>0.79854</td></tr><tr><td>train_loss_epoch</td><td>0.41835</td></tr><tr><td>train_loss_step</td><td>0.33242</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81797</td></tr><tr><td>val_auc</td><td>0.91471</td></tr><tr><td>val_f1</td><td>0.81623</td></tr><tr><td>val_loss_epoch</td><td>0.42959</td></tr><tr><td>val_loss_step</td><td>0.48741</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4t9y4i65' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4t9y4i65</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_191436-4t9y4i65\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_193524-wxu6pxwh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wxu6pxwh' target=\"_blank\">GraphConv_2_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wxu6pxwh' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wxu6pxwh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_4\\max\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 10.1 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "12.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "12.3 K    Total params\n",
      "0.049     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇██▇▇██████████████</td></tr><tr><td>train_auc</td><td>▁▂▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇███▇▇▇██████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇█▇▇████▇▇██████████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▂▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▃▃▃▃▄▄▄▃▂▃▂▃▂▂▂▂▂▃▂▁▂▂▁▂▂▂▂▁▂▃▂▂▂▁▂▁▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▂▄▄▅▅▅▅▆▇▆▆▇▆▇▇▆▇▆█▇█▇▇▆▇▇█▇█▇▇█▇▇▇▇▇▇▆</td></tr><tr><td>val_auc</td><td>▁▃▄▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇██████████████</td></tr><tr><td>val_f1</td><td>▃▁▄▅▄▄▅▅▆▆▆▆▇▇▆▇▆▇▇▇▇▇▇▇▆▇▇███▇▇█▇▇▇▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▇▅▄▅▄▄▄▃▄▃▃▂▂▃▃▂▃▂▂▁▂▂▂▂▂▁▁▂▁▂▁▂▂▁▁▁▂▂▂</td></tr><tr><td>val_loss_step</td><td>█▇▆▄▆▃▄▆▄▅▄▄▅▄▃▅▄▅▃▅▂▄▅▃▂▃▂▂▃▂▄▂▄▅▁▃▃▄▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84829</td></tr><tr><td>train_auc</td><td>0.91648</td></tr><tr><td>train_f1</td><td>0.84185</td></tr><tr><td>train_loss_epoch</td><td>0.35045</td></tr><tr><td>train_loss_step</td><td>0.44302</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81324</td></tr><tr><td>val_auc</td><td>0.92486</td></tr><tr><td>val_f1</td><td>0.8454</td></tr><tr><td>val_loss_epoch</td><td>0.38406</td></tr><tr><td>val_loss_step</td><td>0.21793</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_2_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wxu6pxwh' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wxu6pxwh</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_193524-wxu6pxwh\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_195603-p13d39k3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/p13d39k3' target=\"_blank\">GCN_2_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/p13d39k3' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/p13d39k3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_4\\sum\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 5.2 K \n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "7.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.3 K     Total params\n",
      "0.029     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▆▆▇▇▇▇▇▆▇▇▇▇▇▇▇▇█▇▇▇▇▇▇█▇█▇████▇▇███▇█</td></tr><tr><td>train_auc</td><td>▆▅▅▆▆▅▄▂▃▃▂▅▅▅▃▃▆██▇▆▇▆▇▆▅▅▅▄▅▅▅▁▄▆▂▁▂▂▅</td></tr><tr><td>train_f1</td><td>▁▃▆▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇█▇███▇████▇██▇█▇█</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▂▂▂▂▃▂▁▂▁▂▂▂▂▁▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▁▂▁▂▁▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▂▆▅▆▆▇▆█▅▅▅▆▇▆▆█▇▇▆▇▇▆▇▇█▇▇▇▆▆█▇▄▇▆▅███</td></tr><tr><td>val_auc</td><td>█▇████▇▆▇▄▅███▆▇███████████████▆▂██▆▁▇▅█</td></tr><tr><td>val_f1</td><td>▄▁▅▅▅▅▆▆▇▅▅▄▆▆▆▆█▆▇▇▇▆▇▇▇▇▇▇▇▅▆█▆▃▆▆▇██▇</td></tr><tr><td>val_loss_epoch</td><td>█▅▄▃▂▅▂▆▅▂▃▃▅▁▁▂▃▃▂▂▂▁▃▃▂▁▃▂▂▁▂▂▁▄▃▁▃▃▁▂</td></tr><tr><td>val_loss_step</td><td>▆▅▅▃▂▇▄█▆▂▄▅▇▁▂▂▄▄▂▃▃▂▅▄▂▂▄▃▂▂▂▃▂▄▅▁▃▄▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84002</td></tr><tr><td>train_auc</td><td>0.63848</td></tr><tr><td>train_f1</td><td>0.83199</td></tr><tr><td>train_loss_epoch</td><td>0.38758</td></tr><tr><td>train_loss_step</td><td>0.35619</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.84634</td></tr><tr><td>val_auc</td><td>0.91233</td></tr><tr><td>val_f1</td><td>0.85651</td></tr><tr><td>val_loss_epoch</td><td>0.38381</td></tr><tr><td>val_loss_step</td><td>0.43249</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/p13d39k3' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/p13d39k3</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_195603-p13d39k3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_201816-4mrqj09f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4mrqj09f' target=\"_blank\">GraphConv_2_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4mrqj09f' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4mrqj09f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_4\\sum\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 10.1 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "12.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "12.3 K    Total params\n",
      "0.049     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇████▇██████</td></tr><tr><td>train_auc</td><td>█▆▄▃▃▃▃▄▄▅▅▅▅▄▂▂▂▄▄▅▄▂▁▁▃▄▅▆▃▂▃▂▁▂▂▆▆▇▆▅</td></tr><tr><td>train_f1</td><td>▁▃▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇████▇▇▇▇██▇████▇██████</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▁▂▂▃▃▂▃▄▃▅▅▆▅▆▅▅▅▅▄▆▇▆▆▆▅▇▇▄▆▅▆▄▆▆█▆▇██</td></tr><tr><td>val_auc</td><td>█▇▂▂▁▂▁▂▂▂▅▅▄▂▁▁▁▁▂▂▁▁▁▁▁▂█▃▁▁▁▁▁▁▁███▅▂</td></tr><tr><td>val_f1</td><td>▂▁▃▂▃▄▃▃▄▄▆▅▆▅▆▆▅▆▅▅▆▇▆▇▇▆▆▇▄▆▅▆▅▆▆█▇▇█▇</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▂▃▃▃▃▃▃▂▂▂▂▂▃▂▂▁▂▂▂▂▂▁▃▂▁▁▂▂▂▂▂▂▂▂▂▂▁</td></tr><tr><td>val_loss_step</td><td>▇▃▄▃▆▄▆▅▆▅▃▂▄▄▃█▁▃▂▆▃▃▆▅▂▆▂▂▂▃▂▃▄▄▁▃▃▄▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86246</td></tr><tr><td>train_auc</td><td>0.50879</td></tr><tr><td>train_f1</td><td>0.85644</td></tr><tr><td>train_loss_epoch</td><td>0.35141</td></tr><tr><td>train_loss_step</td><td>0.40989</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.86761</td></tr><tr><td>val_auc</td><td>0.14194</td></tr><tr><td>val_f1</td><td>0.87719</td></tr><tr><td>val_loss_epoch</td><td>0.32954</td></tr><tr><td>val_loss_step</td><td>0.16814</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_2_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4mrqj09f' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4mrqj09f</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_201816-4mrqj09f\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_204204-07nb76u4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/07nb76u4' target=\"_blank\">GCN_2_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/07nb76u4' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/07nb76u4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_4\\attention\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 5.2 K \n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "7.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.4 K     Total params\n",
      "0.030     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▇▇▇▇▇▇▇█▇▇██▇▇▇▇▇▇▇▇█▇███▇█▇▇▇▇█▇███</td></tr><tr><td>train_auc</td><td>▁▆▇▆▇▇▇▇▇▇▇▇▇▇██▇█▇▇▇█▇██▇███▇▇▇▇▇██████</td></tr><tr><td>train_f1</td><td>▁▆▇▇▇▇▇▇▇▇▇█▇▇██▇▇▇▇▇█▇▇█▇███▇█▇▇▇▇█▇███</td></tr><tr><td>train_loss_epoch</td><td>█▃▃▃▃▃▃▂▃▂▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂</td></tr><tr><td>train_loss_step</td><td>█▅▆▄▂▄▄▂▃▃▄▄▅▄▁▄▄▅▄▃▃▂▂▂▃▃▁▄▁▄▁▂▂▆▃▅▄▄▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▇▆▇▇▇▇▇▇▇█▇▇█▇▇███▇██▇▇███████▇█████▇█</td></tr><tr><td>val_auc</td><td>▁▅▆▇▇▇▇▇▇▇▇███▇▇▇███▇██████▇████████████</td></tr><tr><td>val_f1</td><td>▁▇▇▆▇████▇███▇██████████████████████████</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▄▃▂▃▂▃▂▂▂▃▃▂▃▂▂▂▂▂▁▁▂▂▁▂▂▂▂▂▂▂▂▁▂▂▂▂▂</td></tr><tr><td>val_loss_step</td><td>█▄▂▆▇▅▄▃▆▁▄▄█▃▄█▃▄▄▆▂▂▃▇▄▁▆▃▅▂▄▆▅▄▂▄▅▃▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8536</td></tr><tr><td>train_auc</td><td>0.92427</td></tr><tr><td>train_f1</td><td>0.84653</td></tr><tr><td>train_loss_epoch</td><td>0.3486</td></tr><tr><td>train_loss_step</td><td>0.31294</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.85579</td></tr><tr><td>val_auc</td><td>0.92302</td></tr><tr><td>val_f1</td><td>0.86414</td></tr><tr><td>val_loss_epoch</td><td>0.3736</td></tr><tr><td>val_loss_step</td><td>0.45056</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/07nb76u4' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/07nb76u4</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_204204-07nb76u4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_210710-lc12cdyg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/lc12cdyg' target=\"_blank\">GraphConv_2_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/lc12cdyg' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/lc12cdyg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_4\\attention\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 10.1 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "12.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "12.3 K    Total params\n",
      "0.049     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▆▆▆▆▇▇▇▇▆▇▇▇▇▇▇█▇▇▇▇▇▇▇▇████▇█▇▇▇▇▇█▇█</td></tr><tr><td>train_auc</td><td>▁▄▆▆▆▆▇▇▇▇▆▇▇▇▇▇▇█▇█▇▇▇█▇▇█▇██▇█████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▇▇▇▇▆▇▇▇█▇▇█▇█▇▇█▇▇▇██████▇█▇▇▇███</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▄▃▃▃▃▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▁▂▂▂▂▂▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▆▆▆▅▆▅▂▄▄▄▃▆▃▃▃▄▅▃▃▃▃▄▅▄▃▄▁▄▄▂▄▃▃▃▄▃▄▄▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▇▇▆▇▇▇▇█▆▇▇▆▇▇███▇▇▇▆▇▇█▇█▇█▇█▇██▆█▇██</td></tr><tr><td>val_auc</td><td>▁▄▅▅▆▅▆▇▆▇▅▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇██▇█▇▇▇▇█</td></tr><tr><td>val_f1</td><td>▁▆▇▇▇▇▇▇▇█▇▇▇▇▇▇███▇▇▇▆█▇███▇█▇████▇█▇██</td></tr><tr><td>val_loss_epoch</td><td>█▅▃▂▂▂▂▂▃▂▃▃▂▃▂▂▁▁▂▁▂▂▃▃▃▂▃▁▃▂▂▂▁▂▁▃▃▂▂▂</td></tr><tr><td>val_loss_step</td><td>█▆▆▂▂▂▄▅▆▄▆▇▄▃▃▄▄▁▅▃▅▆▄▆▇▃▆▄▇▆▄▇▄▆▃▇█▆▅▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.88371</td></tr><tr><td>train_auc</td><td>0.94477</td></tr><tr><td>train_f1</td><td>0.88053</td></tr><tr><td>train_loss_epoch</td><td>0.30466</td></tr><tr><td>train_loss_step</td><td>0.32379</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.88416</td></tr><tr><td>val_auc</td><td>0.93958</td></tr><tr><td>val_f1</td><td>0.8977</td></tr><tr><td>val_loss_epoch</td><td>0.34331</td></tr><tr><td>val_loss_step</td><td>0.40291</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_2_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/lc12cdyg' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/lc12cdyg</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_210710-lc12cdyg\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_212938-wcuimukd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wcuimukd' target=\"_blank\">GCN_2_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wcuimukd' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wcuimukd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_4\\attention2\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 5.2 K \n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "11.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "11.5 K    Total params\n",
      "0.046     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▇▆▆▇▇▇▇▇▇█▇▇▇█▇▇▇▇▇██▇▇██▇▇█████▇█▇██</td></tr><tr><td>train_auc</td><td>▁▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇██▇▇▇███▇▇██▇▇██████████</td></tr><tr><td>train_f1</td><td>▁▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇██▇▇▇▇██▇▇██▇▇█████▇█▇██</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▄▃▃▃▃▃▂▂▂▂▂▂▁▂▂▂▂▂▂▁▃▂▁▁▂▂▁▂▁▁▁▂▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>███▄▇█▅▃▅▅▅▃▂▇▇▇▅▄▅▄▄▆▆▁▇▄▄▂▄▄▆▅▂▃▃▅▇▅▂▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▇▇▇▇█▇▇▇▇▇▇▇█▇▇▇▇█▇█▇▇█▇▇████▇▇██▇██▇█</td></tr><tr><td>val_auc</td><td>▁▄▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▆▇█▇█████▇▇█</td></tr><tr><td>val_f1</td><td>▁▇▇▇██████████████████████▇█████████████</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▃▂▂▁▂▂▂▂▂▃▂▁▂▂▂▃▂▂▁▃▂▂▂▃▂▃▂▂▂▃▂▁▁▁▂▂▁</td></tr><tr><td>val_loss_step</td><td>▇▄▃▂▅▄▃▂▃▃▆▃▃▂▂▅▃▅█▄▃▁▄▅▄▆▅▅▄▅▆▄▅▅▂▁▃▃▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86187</td></tr><tr><td>train_auc</td><td>0.9333</td></tr><tr><td>train_f1</td><td>0.85573</td></tr><tr><td>train_loss_epoch</td><td>0.3284</td></tr><tr><td>train_loss_step</td><td>0.35336</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.8487</td></tr><tr><td>val_auc</td><td>0.92691</td></tr><tr><td>val_f1</td><td>0.86611</td></tr><tr><td>val_loss_epoch</td><td>0.33439</td></tr><tr><td>val_loss_step</td><td>0.24397</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wcuimukd' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wcuimukd</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_212938-wcuimukd\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_215205-a56np4pe</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/a56np4pe' target=\"_blank\">GraphConv_2_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/a56np4pe' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/a56np4pe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_2_64_onehot_4\\attention2\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 10.1 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "16.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "16.5 K    Total params\n",
      "0.066     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "293aaf29bbd9492d8d9d4007474e4540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▆█▇▇▇▇█▇▇▇▇▇▇▇█▇█▇██████████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇▇██████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇██████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▃▄▃▃▃▂▂▃▂▃▃▂▃▂▂▂▂▂▃▃▂▂▂▂▁▁▂▂▁▁▁▁▁▁▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▅▅▆▅▅▄▄▃▂▄▄▂▄▄▃▂█▁▃▅▃▃▆▆▃▄▄▃▄▆▂▄▃▃▃▃▄▄▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▆▆▆▇▇▇█▆▇▇▇▇▆█▇▇█▇▆▇▇█▇██▆▇▇▇▇█▇▆▇██▇█</td></tr><tr><td>val_auc</td><td>▁▅▇▆▇▇▇█▇▇▇▇▇█▇▇▇█▇▇███▇▇▇▇█████████████</td></tr><tr><td>val_f1</td><td>▁▆▇▇▇▇▇██▇▇▇▇▇▇█▇▇█▇▇███▇██▇█▇▇███▇███▇█</td></tr><tr><td>val_loss_epoch</td><td>█▄▂▃▃▂▁▂▂▂▂▂▂▂▂▂▃▃▁▁▃▂▁▂▂▃▄▂▂▂▂▂▁▂▂▁▂▃▂▂</td></tr><tr><td>val_loss_step</td><td>▇▄▄▄▅▃▁▄▄▄▄▃▃▃▃▃▄▆▁▁▅▅▁▁▂▄█▂▃▂▆▄▃▃▃▂▃▆▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87721</td></tr><tr><td>train_auc</td><td>0.94895</td></tr><tr><td>train_f1</td><td>0.87208</td></tr><tr><td>train_loss_epoch</td><td>0.28417</td></tr><tr><td>train_loss_step</td><td>0.22444</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.86998</td></tr><tr><td>val_auc</td><td>0.9302</td></tr><tr><td>val_f1</td><td>0.88069</td></tr><tr><td>val_loss_epoch</td><td>0.35255</td></tr><tr><td>val_loss_step</td><td>0.30912</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_2_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/a56np4pe' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/a56np4pe</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_215205-a56np4pe\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_221524-jm78jsfx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jm78jsfx' target=\"_blank\">GCN_3_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jm78jsfx' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jm78jsfx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_4\\mean\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 832   \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "986       Trainable params\n",
      "0         Non-trainable params\n",
      "986       Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a1b319303fa453296dda2b3ec4f18fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇▇▇▇▇██▇█▇███▇███████████▇█████████</td></tr><tr><td>train_auc</td><td>▁▇▇▇█▇██████████████████████████████████</td></tr><tr><td>train_f1</td><td>▁▇▇▇▇███████████████████████████████████</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▂▃▂▂▂▂▂▂▂▂▂▂▁▂▂▁▂▂▂▁▁▂▂▁▂▁▂▂▂▂▂▁▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▅▃▃▃▄▃▃▃▃▃▂▅▃▅▅▃▇▂▄▃▂▃▁▅▂▃▁▂▄▂▃▃▂▄▃▃▃▄▆</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▇▇█████████████▇████████████▆████▇██▇██</td></tr><tr><td>val_auc</td><td>▁▅▇▇▇▇▇▇▇█▇██▇▇▇█▇▇███▇██████▇▇█████████</td></tr><tr><td>val_f1</td><td>▁█▇██████████████████████████▇████▇█████</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▂▂▂▂▂▂▂▂▁▂▂▂▂▁▂▂▁▂▁▂▂▂▂▁▂▁▅▁▁▂▂▄▁▁▂▂▂</td></tr><tr><td>val_loss_step</td><td>█▅▆▂▄▃▄▃▂▄▄▃▅▃▂▆▁▄▅▂▄▃▃▅▅▅▃▄▁▇▂▃▂▅▆▁▃▃▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.82999</td></tr><tr><td>train_auc</td><td>0.90207</td></tr><tr><td>train_f1</td><td>0.82482</td></tr><tr><td>train_loss_epoch</td><td>0.41106</td></tr><tr><td>train_loss_step</td><td>0.53938</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83452</td></tr><tr><td>val_auc</td><td>0.91525</td></tr><tr><td>val_f1</td><td>0.84305</td></tr><tr><td>val_loss_epoch</td><td>0.37699</td></tr><tr><td>val_loss_step</td><td>0.36206</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jm78jsfx' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jm78jsfx</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_221524-jm78jsfx\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_223921-1yvjnrxd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1yvjnrxd' target=\"_blank\">GraphConv_3_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1yvjnrxd' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1yvjnrxd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_4\\mean\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 1.6 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▇▇▇▇▇▇▇▇█▇▇█▇▇██████▇█▇███████████████</td></tr><tr><td>train_auc</td><td>▁▅▇▇▇▇▇▇▇▇██▇███████████████████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████▇█▇███████████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▁▂▂▂▂▁▁▂▂▁▂▁▂▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▄▃▅▅▄▅▂▅▃▃▅▃▃▄▂▄▅▃▂▂▁▄▃▃▅▄▂▂▃▄▃▂▃▃▄▃▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▆▇▆▇▇█▇▇▇▇██▇▇▇▇▇▇█▇█▇████▇█▇▇█████▇██</td></tr><tr><td>val_auc</td><td>▁▆▇▇▇███████████████████████████████████</td></tr><tr><td>val_f1</td><td>▁▆▆▇▇█▇██▇██████▇██▇█▇█▇████▇█▇▇█████▇██</td></tr><tr><td>val_loss_epoch</td><td>█▅▄▃▄▃▃▂▂▃▂▂▂▂▂▃▃▂▁▃▂▂▂▃▂▂▂▂▃▂▂▂▂▂▂▁▁▃▂▂</td></tr><tr><td>val_loss_step</td><td>█▅▆▆▆▆▅▃▄▇▅▃▄▅▆█▆▃▃▆▃▅▃▇▂▃▂▄▄▃▄▅▆▃▅▁▂▅▅▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8595</td></tr><tr><td>train_auc</td><td>0.92927</td></tr><tr><td>train_f1</td><td>0.85697</td></tr><tr><td>train_loss_epoch</td><td>0.34868</td></tr><tr><td>train_loss_step</td><td>0.29182</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.85579</td></tr><tr><td>val_auc</td><td>0.93301</td></tr><tr><td>val_f1</td><td>0.86882</td></tr><tr><td>val_loss_epoch</td><td>0.35371</td></tr><tr><td>val_loss_step</td><td>0.46887</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1yvjnrxd' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1yvjnrxd</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_223921-1yvjnrxd\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3606423a0ed4339a0f47f46957ef862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_230334-zpcdozot</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zpcdozot' target=\"_blank\">GCN_3_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zpcdozot' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zpcdozot</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_4\\max\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 832   \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "986       Trainable params\n",
      "0         Non-trainable params\n",
      "986       Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7078992987004d70b79a8264a6d0ed5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▂▃▄▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇▇██████▇▇█▇▇▇</td></tr><tr><td>train_auc</td><td>▂▂▂▂▂▁▂▄▃▁▃▃▄▅▅▄▅▅▄▅▄▅▆▆▆▅▅▆▅▆▆▆▇▆▇▆▇▇██</td></tr><tr><td>train_f1</td><td>▃▁▂▃▄▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇██████▇███▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▅▄▄▃▃▃▃▂▂▃▂▁▂▁▂▂▂▂▂▂▂▁▂▂▁▂▁▂▂▂▂▂▂▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▆▆▆▅▅▅▃▅▄▄▄▇▄▅▄▅▅▄▃▅▄▂▄▄▃▄▁▄▃▃▃▃▄▄▃▄▃▄▇</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_auc</td><td>▄▄▄▃▂▁▁▁▂▁▂█████████████████████████████</td></tr><tr><td>val_f1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_epoch</td><td>█▇▇▆▆▅▅▄▃▅▃▃▅▃▄▅▃▄▄▃▃▃▃▄▆▄▄▃▃▃▂▃▁▁▃▂▃▂▂▄</td></tr><tr><td>val_loss_step</td><td>▆▆▅▅▆▅▆▄▃▅▃▄▆▅▆█▂▅▅▅▅▂▃▄▇▅▃▃▄▃▂▂▁▂▅▂▄▂▂▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.69776</td></tr><tr><td>train_auc</td><td>0.69893</td></tr><tr><td>train_f1</td><td>0.69524</td></tr><tr><td>train_loss_epoch</td><td>0.59745</td></tr><tr><td>train_loss_step</td><td>0.77597</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.45863</td></tr><tr><td>val_auc</td><td>0.78094</td></tr><tr><td>val_f1</td><td>0.0</td></tr><tr><td>val_loss_epoch</td><td>0.65842</td></tr><tr><td>val_loss_step</td><td>0.74185</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zpcdozot' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zpcdozot</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_230334-zpcdozot\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_232611-sjbget0u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/sjbget0u' target=\"_blank\">GraphConv_3_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/sjbget0u' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/sjbget0u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_4\\max\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 1.6 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▃▄▅▅▆▇▇▇▇▇▇▇▇▇█████▇█▇██▇███▇▇████████</td></tr><tr><td>train_auc</td><td>▁▁▂▂▂▃▅▅▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇█▇▇█▇██▇████████</td></tr><tr><td>train_f1</td><td>▁▂▃▄▅▅▇▇▇▇▇▆▇▇▇▇██▇██▇██████████████▇███</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▂▁▁▁▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▅▅▆▅▄▄▄▄▃▄▄▂▃▃▃▂▅▂▂▂▃▄▄▃▅▄▂▃▃▂▃▃▃▄▄▂▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▆▅▅▆▆▇▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇█▇▆███▇██▇█▇▇▆██</td></tr><tr><td>val_auc</td><td>▁▃▃▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████████</td></tr><tr><td>val_f1</td><td>▁▁▄▂▃▃▄▅▃▂▂▃▄▅▆▆▂▅▆▆▅▅▇▅▇▅▂▇▇▇▅▇█▆█▅▄▃█▇</td></tr><tr><td>val_loss_epoch</td><td>██▇▆▆▅▅▄▅▅▅▄▄▃▄▄▄▄▃▂▂▃▂▃▁▃▃▂▃▁▂▃▂▂▂▂▃▃▂▂</td></tr><tr><td>val_loss_step</td><td>██▇▇▇▅▅▄▆▆▇▆▆▅▇▆▆▅▂▃▃▄▃▅▁▃▂▃▄▁▃▆▃▂▄▂▄▃▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.78867</td></tr><tr><td>train_auc</td><td>0.84515</td></tr><tr><td>train_f1</td><td>0.78408</td></tr><tr><td>train_loss_epoch</td><td>0.46526</td></tr><tr><td>train_loss_step</td><td>0.34004</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81797</td></tr><tr><td>val_auc</td><td>0.89533</td></tr><tr><td>val_f1</td><td>0.82851</td></tr><tr><td>val_loss_epoch</td><td>0.49456</td></tr><tr><td>val_loss_step</td><td>0.5118</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/sjbget0u' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/sjbget0u</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_232611-sjbget0u\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "386479f6750241849422ed83390e17ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_234756-sr0uc67l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/sr0uc67l' target=\"_blank\">GCN_3_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/sr0uc67l' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/sr0uc67l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_4\\sum\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 832   \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "986       Trainable params\n",
      "0         Non-trainable params\n",
      "986       Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇██████████▇███████</td></tr><tr><td>train_auc</td><td>▁▂▅▅▅▅▆▅▆▅▄▄▅▅▄▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇████▇▇▇▆█</td></tr><tr><td>train_f1</td><td>▁▂▅▅▆▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇▇██████████████████</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▃▁▂▂▁▃▂▂▁▂▁▁▁▁▁▂▂▂▁▂▁▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▆▆▇▇▇▇▇███▇▇██▇█████▇██▇██████▇██████▇</td></tr><tr><td>val_auc</td><td>▁▇▇█████████████████████████████████████</td></tr><tr><td>val_f1</td><td>▁▇▇▆▇▇██████▇████████████▇██████████████</td></tr><tr><td>val_loss_epoch</td><td>█▅▅▄▄▃▃▂▃▃▂▂▃▃▂▃▂▂▃▂▂▂▃▂▂▃▂▃▁▂▂▂▂▂▂▁▁▁▂▂</td></tr><tr><td>val_loss_step</td><td>█▇▇▄▇▅▄▄▄▅▄▂▆▄▃▇▁▃▆▃▄▃▄▅▅▆▄▅▁▅▂▃▂▆▄▁▂▂▅▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.82231</td></tr><tr><td>train_auc</td><td>0.83117</td></tr><tr><td>train_f1</td><td>0.81813</td></tr><tr><td>train_loss_epoch</td><td>0.43023</td></tr><tr><td>train_loss_step</td><td>0.54339</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82033</td></tr><tr><td>val_auc</td><td>0.91136</td></tr><tr><td>val_f1</td><td>0.81991</td></tr><tr><td>val_loss_epoch</td><td>0.41309</td></tr><tr><td>val_loss_step</td><td>0.37732</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/sr0uc67l' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/sr0uc67l</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_234756-sr0uc67l\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_001012-saka6xvu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/saka6xvu' target=\"_blank\">GraphConv_3_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/saka6xvu' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/saka6xvu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_4\\sum\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 1.6 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▂▄▄▅▅▅▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇███████</td></tr><tr><td>train_auc</td><td>▄▂▃▂▂▁▁▁▂▃▄▄▄▅▄▅▅▅▄▅▅▅▆▆▆▆▆▇▇▇█▇▇▇███▇██</td></tr><tr><td>train_f1</td><td>▁▂▃▄▄▅▅▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇███████</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▂▂▁▂▁▂▁▁▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▄▅▆▆▆▇▇▆▆▇▇▇▇▆▇▇▇▇█▅▇█▇█▇▇█▇▇▇▆████▇██</td></tr><tr><td>val_auc</td><td>▄▂▃▄▃▁▁▄▇▇▇█████████████████████████████</td></tr><tr><td>val_f1</td><td>▁▅▄▅▆▆▆▇▇▇▇▇▇▇▇▆▇█▇▇█▅▇█▇█▇███▇▇▆████▇██</td></tr><tr><td>val_loss_epoch</td><td>█▅▅▅▅▄▄▃▃▄▄▂▃▃▄▄▃▂▂▃▂▄▂▂▁▂▂▂▂▁▂▂▃▁▂▁▁▃▂▃</td></tr><tr><td>val_loss_step</td><td>▅▅▆▆▆▆▅▃▄▇▆▃▅▅▆█▆▃▃▅▂▄▃▄▁▃▃▃▃▂▄▄▄▃▅▁▂▅▅▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85065</td></tr><tr><td>train_auc</td><td>0.76295</td></tr><tr><td>train_f1</td><td>0.84676</td></tr><tr><td>train_loss_epoch</td><td>0.40403</td></tr><tr><td>train_loss_step</td><td>0.39646</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.84634</td></tr><tr><td>val_auc</td><td>0.91773</td></tr><tr><td>val_f1</td><td>0.85261</td></tr><tr><td>val_loss_epoch</td><td>0.45395</td></tr><tr><td>val_loss_step</td><td>0.66616</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/saka6xvu' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/saka6xvu</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_001012-saka6xvu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_003139-6tyr4vr4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6tyr4vr4' target=\"_blank\">GCN_3_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6tyr4vr4' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6tyr4vr4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_4\\attention\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 832   \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "1.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.0 K     Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▇▆▇▇▇▇▇████▇▇███▇▇███████████████████</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇██████████████████████████████████</td></tr><tr><td>train_f1</td><td>▁▇▇▇▇███████████████████████████████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▃▃▄▂▂▂▂▂▁▂▂▂▂▂▂▁▁▂▂▂▁▁▂▁▁▂▁▁▁▁▁▁▂▁▁▂▂▂</td></tr><tr><td>train_loss_step</td><td>▆▅▃▂▅▃▃▄▂▂▃▃▂▃▄▂▂▁▅▂▂▂▄▂▂▂▃█▂▂▂▂▁▂▂▂▃▂▁▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▆▇▇█▇█▇███▇███▇██▇██████▇█████████████</td></tr><tr><td>val_auc</td><td>▁▅▇▇▇█▇████████████▇████████████████████</td></tr><tr><td>val_f1</td><td>▁▆▆▇▇██████████████▇████████████████████</td></tr><tr><td>val_loss_epoch</td><td>█▅▅▃▃▂▂▃▂▂▂▂▃▂▂▂▂▁▂▄▂▁▁▁▂▁▃▂▂▁▁▂▂▂▃▁▂▂▂▂</td></tr><tr><td>val_loss_step</td><td>█▆▇▆▄▄▃▆▃▄▄▄▆▄▅▄▄▃▅▄▄▄▃▃▃▁▅▃▄▂▃▄▅▄▅▃▄▅▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83943</td></tr><tr><td>train_auc</td><td>0.90861</td></tr><tr><td>train_f1</td><td>0.83354</td></tr><tr><td>train_loss_epoch</td><td>0.40824</td></tr><tr><td>train_loss_step</td><td>0.5157</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82506</td></tr><tr><td>val_auc</td><td>0.91618</td></tr><tr><td>val_f1</td><td>0.84647</td></tr><tr><td>val_loss_epoch</td><td>0.38053</td></tr><tr><td>val_loss_step</td><td>0.40811</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6tyr4vr4' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6tyr4vr4</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_003139-6tyr4vr4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_005603-42s3y7w1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/42s3y7w1' target=\"_blank\">GraphConv_3_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/42s3y7w1' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/42s3y7w1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_4\\attention\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 1.6 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "1.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▇▇▇▇▇▇▇▇▇▇▇█▇▇██▇████████▇██████▇████</td></tr><tr><td>train_auc</td><td>▁▄▆▇▇▇▇▇▇██▇████████████████████████████</td></tr><tr><td>train_f1</td><td>▁▄▆▆▆▆▇▇▇▇▇▇▇▇█▇▇██▇██▇█▇███▇███▇██▇████</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▃▃▃▃▂▃▂▂▃▂▂▂▂▂▁▂▂▂▁▂▂▁▁▁▂▂▁▁▁▂▁▁▂▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▅▆▅▄▃▄▅▃▄▄▃▂▃▃▅▄▅▃▄▂▃▄▃▃▄▄▃▂▃▃▄▂▂▄▄▁▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▆▆▇█▇▆▇▇███▇▇█▇▇▇█▇██▇▇████▇██▇███████</td></tr><tr><td>val_auc</td><td>▁▃▅▆▇▇▇▇▇▇▇▇▇▇▇██▇▇█████████████████████</td></tr><tr><td>val_f1</td><td>▁▅▇▇▇█▇▇████████▇█▇█▇██▇▇███████▇███████</td></tr><tr><td>val_loss_epoch</td><td>█▆▄▄▂▂▃▄▂▂▂▁▂▂▂▂▂▂▃▁▂▁▁▂▃▁▁▂▂▃▁▁▂▁▁▃▁▁▂▁</td></tr><tr><td>val_loss_step</td><td>█▆▄▅▄▄▃▆▂▃▃▂▃▃▄▆▄▃▃▃▂▂▃▃▆▄▂▄▄▅▄▂▂▂▁▆▂▂▅▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85419</td></tr><tr><td>train_auc</td><td>0.91902</td></tr><tr><td>train_f1</td><td>0.84893</td></tr><tr><td>train_loss_epoch</td><td>0.36924</td></tr><tr><td>train_loss_step</td><td>0.36255</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.85579</td></tr><tr><td>val_auc</td><td>0.92574</td></tr><tr><td>val_f1</td><td>0.86475</td></tr><tr><td>val_loss_epoch</td><td>0.34785</td></tr><tr><td>val_loss_step</td><td>0.34729</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/42s3y7w1' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/42s3y7w1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_005603-42s3y7w1\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ead263e59c9545bfa379270830bae15a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_011841-v61stdor</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/v61stdor' target=\"_blank\">GCN_3_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/v61stdor' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/v61stdor</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_4\\attention2\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 832   \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇▇█▇███████████████████████████████</td></tr><tr><td>train_auc</td><td>▁▇▇▇▇▇██████████████████████████████████</td></tr><tr><td>train_f1</td><td>▁▇▇█████████████████████████████████████</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▂▃▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▁▂▁▁▂▁▁▁▂▁▁▁▂▂▁▁▂▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▆▅▄▄▅▄▅▄▃▄▄▅▅▄▅▄▅▄▄▄▄▁▃▄▃▃▂▄▄▄▄▅▄▄▄▅▄▄▆</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▅▇▇█▇█▇██▇██████████████▇▇▇█▇███████▇█</td></tr><tr><td>val_auc</td><td>▁▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇██████▇▇█▇▇▇▇█▇█▇▇██████</td></tr><tr><td>val_f1</td><td>▁▇▆█▇█▇█████████████████████████████████</td></tr><tr><td>val_loss_epoch</td><td>█▄▅▂▃▂▃▂▃▂▂▃▂▃▂▁▂▂▂▂▂▂▁▂▂▂▂▃▃▂▃▂▂▂▂▂▂▂▄▂</td></tr><tr><td>val_loss_step</td><td>█▅▆▄▆▅▅▆▆▆▃▄▄▇▃▂▄▄▃▅▅▅▁▄▆▄▄▅▅▅▅▆▆▄▆▅▄▄█▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84298</td></tr><tr><td>train_auc</td><td>0.90549</td></tr><tr><td>train_f1</td><td>0.8327</td></tr><tr><td>train_loss_epoch</td><td>0.40513</td></tr><tr><td>train_loss_step</td><td>0.53402</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82742</td></tr><tr><td>val_auc</td><td>0.91541</td></tr><tr><td>val_f1</td><td>0.8476</td></tr><tr><td>val_loss_epoch</td><td>0.38111</td></tr><tr><td>val_loss_step</td><td>0.39528</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/v61stdor' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/v61stdor</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_011841-v61stdor\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_014124-riqq9qzg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/riqq9qzg' target=\"_blank\">GraphConv_3_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/riqq9qzg' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/riqq9qzg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_16_onehot_4\\attention2\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 1.6 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▇▇▇▇▇▇▇▇▇▇▇████▇██▇██▇▇███████▇██████</td></tr><tr><td>train_auc</td><td>▁▅▇▇▇▇▇▇██▇█▇███████████████████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▇▇▇▇▇▇▆▇▇▇█▇█▇▇██▇▇▇▇▇▇██████▇██████</td></tr><tr><td>train_loss_epoch</td><td>█▅▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▂▂▁▁▁▁▂▁▂▂▂▂▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▅▄▄▄▅▄▂▃▃▂▂▃▃▄▃▂▃▃▂▃▂▂▂▅▃▅▂▂▃▄▄▃▃▂▂▃▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▆▇▇▇██▇▇▇▇▇▇████▇▇██▇█▇██▇▇▇█▇███▇▇█▇▇</td></tr><tr><td>val_auc</td><td>▁▄▆▇▇▇▇▇████████████████████████████████</td></tr><tr><td>val_f1</td><td>▁▆▆▇▇▇███▇▇█▇▇██████████████████████▇█▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▅▃▂▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂▁▂▂▁▃▁▂▃▂▁▁▂▁▂▂▂▃▁▃▂</td></tr><tr><td>val_loss_step</td><td>█▆▄▃▄▄▃▅▃▅▇▄▃▃▄▄▃▂▃▃▁▅▅▃▇▁▃▆▃▁▁▅▂▅▅▆▇▂▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.866</td></tr><tr><td>train_auc</td><td>0.92758</td></tr><tr><td>train_f1</td><td>0.86317</td></tr><tr><td>train_loss_epoch</td><td>0.34423</td></tr><tr><td>train_loss_step</td><td>0.24494</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.84634</td></tr><tr><td>val_auc</td><td>0.92793</td></tr><tr><td>val_f1</td><td>0.85057</td></tr><tr><td>val_loss_epoch</td><td>0.36012</td></tr><tr><td>val_loss_step</td><td>0.34509</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/riqq9qzg' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/riqq9qzg</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_014124-riqq9qzg\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_020400-rrii28v0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/rrii28v0' target=\"_blank\">GCN_3_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/rrii28v0' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/rrii28v0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_4\\mean\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 2.7 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "3.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.2 K     Total params\n",
      "0.013     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇██▇█▇▇█████▇██▇███</td></tr><tr><td>train_auc</td><td>▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████▇██████████████████</td></tr><tr><td>train_f1</td><td>▁▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇██▇▇██</td></tr><tr><td>train_loss_epoch</td><td>█▃▃▂▂▃▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▂▂▂▂▁▂▁▁▂▁▁▂▂▁▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>▇█▄▄▄▅▄▄▅▃▅▆▅▃▅▄▃▃▄▄▄▇▅▂▃▄▂▁▃▅▄▅▅▄▃▃▄▃▆▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▇▆▆▇▇▇▇████▇████▇▇▇▇█▇▇█▇██▇███████▇██</td></tr><tr><td>val_auc</td><td>▁▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█▇████▇█▇█</td></tr><tr><td>val_f1</td><td>▁▃▇▆▆▇▇█▇████▇███████▇██▇████▇███████▇██</td></tr><tr><td>val_loss_epoch</td><td>█▆▃▄▃▃▃▂▃▁▂▂▃▃▂▂▂▃▃▂▂▃▂▁▃▁▁▁▁▂▂▃▁▂▂▂▂▂▁▁</td></tr><tr><td>val_loss_step</td><td>█▇▅▆▃▅▅▄▅▂▅▄▇▄▃▅▆▇█▄▃▅▄▂▅▂▁▄▃▄▆▆▂▄▅▃▂▃▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8595</td></tr><tr><td>train_auc</td><td>0.92608</td></tr><tr><td>train_f1</td><td>0.85714</td></tr><tr><td>train_loss_epoch</td><td>0.34727</td></tr><tr><td>train_loss_step</td><td>0.23646</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.84161</td></tr><tr><td>val_auc</td><td>0.92477</td></tr><tr><td>val_f1</td><td>0.84598</td></tr><tr><td>val_loss_epoch</td><td>0.34949</td></tr><tr><td>val_loss_step</td><td>0.2411</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/rrii28v0' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/rrii28v0</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_020400-rrii28v0\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_022631-8794hbl8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8794hbl8' target=\"_blank\">GraphConv_3_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8794hbl8' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8794hbl8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_4\\mean\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 5.2 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "5.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.7 K     Total params\n",
      "0.023     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▇▇▇▇▇▇▇▇▇▇██▇▇▇█▇███▇▇██▇█████████▇██</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇▇▇█▇▇▇▇█████▇████▇███████████████</td></tr><tr><td>train_f1</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇█▇█▇▇███████████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▃▃▂▃▂▂▃▂▃▂▂▂▂▂▂▂▂▂▁▂▂▁▁▂▁▁▂▂▁▁▁▂▂▂▁▂</td></tr><tr><td>train_loss_step</td><td>▆▄▃▄▃▃▃▂▃▃▃▂█▃▂▂▁▄▂▂▂▂▁▂▂▃▂▃▂▂▃▂▂▂▃▃▂▂▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▆▇▇█▇▇▇█▇▇█▇▇▇▇██▇██▇▇███▇▇▆▇██▇█▆▆██▇</td></tr><tr><td>val_auc</td><td>▁▅▇▇▇▇█████▇████████████▇██▇██▇█████▇▇██</td></tr><tr><td>val_f1</td><td>▁▄▄▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▆▆▇█▇█▄▆▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▆▃▃▂▂▂▂▂▁▂▂▂▂▁▃▁▂▃▁▁▃▂▂▂▁▂▃▃▄▂▂▂▃▃▄▅▄▂▃</td></tr><tr><td>val_loss_step</td><td>▆▆▄▄▄▂▃▃▂▃▃▄▃▄▁▂▁▄▆▂▃▆▄▄▃▂▃▅▇▆▂▄▃▃▆▇█▅▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8778</td></tr><tr><td>train_auc</td><td>0.94005</td></tr><tr><td>train_f1</td><td>0.87355</td></tr><tr><td>train_loss_epoch</td><td>0.3235</td></tr><tr><td>train_loss_step</td><td>0.35766</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.84397</td></tr><tr><td>val_auc</td><td>0.92322</td></tr><tr><td>val_f1</td><td>0.86585</td></tr><tr><td>val_loss_epoch</td><td>0.38477</td></tr><tr><td>val_loss_step</td><td>0.40485</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8794hbl8' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8794hbl8</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_022631-8794hbl8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_024819-fup4p1ah</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fup4p1ah' target=\"_blank\">GCN_3_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fup4p1ah' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fup4p1ah</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_4\\max\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 2.7 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "3.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.2 K     Total params\n",
      "0.013     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▃▅▅▅▆▆▅▆▅▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇███████</td></tr><tr><td>train_auc</td><td>▄▅▄▄▂▂▁▁▁▁▁▂▂▂▂▃▃▄▄▄▄▅▆▅▅▅▆▆▆▆▆▇▇▇▇▇██▇█</td></tr><tr><td>train_f1</td><td>▁▂▂▄▄▅▅▅▅▆▅▆▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇█▇█▇███████</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▆▇▆▅▄▆▅▅▅▄▅▄▄▃▃▇▂▃▄▆▃▂▂▄▃▃▃▃▃▄▃▂▂▃▃▂▄▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▁▇▆▆▆▆▆▆▆▆▆▆▆▆▆▅▆▇▇▆▇▆▇█▇▆▇▆▇▇▇███▇█▇▇▇</td></tr><tr><td>val_auc</td><td>▄▂▂▁▁▁▁▁▁▁▁▁▁▁▂▁▂▂▂▄▄███████████████████</td></tr><tr><td>val_f1</td><td>▄▄▇▆▆▆▆▆▆▆▆▅▅▆▆▆▁▆▆▇▄▇▃▇██▇█▇▆▇▇█████▇█▇</td></tr><tr><td>val_loss_epoch</td><td>██▇▆▆▆▆▆▅▅▅▅▅▄▅▄▅▄▄▃▄▃▄▃▃▂▃▂▂▂▂▂▂▁▁▁▁▁▁▂</td></tr><tr><td>val_loss_step</td><td>██▇▆▅▆▇▆▆▅▆▆▅▄▅▅▅▃▆▄▄▅▆▅▄▂▄▄▄▃▅▄▃▂▄▃▁▂▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77863</td></tr><tr><td>train_auc</td><td>0.71146</td></tr><tr><td>train_f1</td><td>0.7816</td></tr><tr><td>train_loss_epoch</td><td>0.45707</td></tr><tr><td>train_loss_step</td><td>0.36953</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.76359</td></tr><tr><td>val_auc</td><td>0.86287</td></tr><tr><td>val_f1</td><td>0.80392</td></tr><tr><td>val_loss_epoch</td><td>0.47139</td></tr><tr><td>val_loss_step</td><td>0.48888</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fup4p1ah' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fup4p1ah</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_024819-fup4p1ah\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_031045-fh5l3vuo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fh5l3vuo' target=\"_blank\">GraphConv_3_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fh5l3vuo' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fh5l3vuo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_4\\max\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 5.2 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "5.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.7 K     Total params\n",
      "0.023     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▄▅▅▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇█▇██████</td></tr><tr><td>train_auc</td><td>▁▁▂▂▂▃▄▄▅▅▅▆▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██████▇█████</td></tr><tr><td>train_f1</td><td>▁▂▄▅▅▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇████████</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▃▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▁▁▁▂▂▁▁▂▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▅▅▆▅▄▄▄▄▄▄▄▄▄▃▄▄▄▂▃▄▂▃▃▄▃▂▂▃▃▃▂▂▄▃▃▃▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▅▆▇▇▇▇█▇▇███▇█████▇████▇█▇███▇██▇███▇█</td></tr><tr><td>val_auc</td><td>▁▃▁▃▆▆▇▇▇█▇▇▇██████▇█████▇█▇██▇█████████</td></tr><tr><td>val_f1</td><td>▁▆▆▇▇▇█▇█▇▇██▇▇█████▇████▇█▇███▇████████</td></tr><tr><td>val_loss_epoch</td><td>█▇▆▅▅▅▃▄▃▄▄▃▃▃▃▃▂▃▃▂▃▃▂▂▂▃▂▂▁▁▃▂▁▁▂▂▂▁▂▂</td></tr><tr><td>val_loss_step</td><td>█▇▆▆▇▆▄▆▃▅▇▄▅▄▅▄▂▅▅▄▄▄▅▄▂▄▄▃▂▁▄▃▁▂▄▅▅▃▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83589</td></tr><tr><td>train_auc</td><td>0.88387</td></tr><tr><td>train_f1</td><td>0.83192</td></tr><tr><td>train_loss_epoch</td><td>0.38394</td></tr><tr><td>train_loss_step</td><td>0.244</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81324</td></tr><tr><td>val_auc</td><td>0.90289</td></tr><tr><td>val_f1</td><td>0.84168</td></tr><tr><td>val_loss_epoch</td><td>0.42882</td></tr><tr><td>val_loss_step</td><td>0.50667</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fh5l3vuo' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fh5l3vuo</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_031045-fh5l3vuo\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_033246-qyfbos39</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qyfbos39' target=\"_blank\">GCN_3_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qyfbos39' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qyfbos39</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_4\\sum\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 2.7 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "3.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.2 K     Total params\n",
      "0.013     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▇▇▆▇▇▇▆▇▇▇▇▇▇▇▇█▇████▇█▇███▇█████████</td></tr><tr><td>train_auc</td><td>▄▂▂▄▅▅▅▆▆▅▄▃▃▅▇▇██▇▇▆▅▆▇▇█▆▄▄▆██▅▄▂▃▃▃▃▁</td></tr><tr><td>train_f1</td><td>▁▅▅▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇███▇▇▇▇██▇█████▇███</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▃▃▃▃▃▃▃▂▃▃▂▂▃▂▂▂▂▃▃▄▃▂▂▂▂▁▂▃▃▃▂▃▂▂▃▂▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▇▇▇▇█▇▇▇█▇█▇██▇█▇█▇█▇█▇█▇█████▇██▇████</td></tr><tr><td>val_auc</td><td>▇▃▆███████▇▇▇████████████████████▅▆▃█▁▂▁</td></tr><tr><td>val_f1</td><td>▁▇▇▇█████▇█▇█▇██▇█▇█████▇██████████▇████</td></tr><tr><td>val_loss_epoch</td><td>█▂▂▂▁▂▂▁▁▂▁▂▂▂▁▁▂▂▂▁▁▁▁▁▂▁▁▁▂▁▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▃▂▃▂▃▂▂▂▁▃▃▄▂▂▂▅▄▅▂▂▂▂▂▃▁▁▂▂▃▃▂▁▂▂▂▁▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83884</td></tr><tr><td>train_auc</td><td>0.41191</td></tr><tr><td>train_f1</td><td>0.83584</td></tr><tr><td>train_loss_epoch</td><td>0.38457</td></tr><tr><td>train_loss_step</td><td>0.32788</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83452</td></tr><tr><td>val_auc</td><td>0.11169</td></tr><tr><td>val_f1</td><td>0.83721</td></tr><tr><td>val_loss_epoch</td><td>0.37179</td></tr><tr><td>val_loss_step</td><td>0.24975</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qyfbos39' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qyfbos39</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_033246-qyfbos39\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_035454-cpxyrjpy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/cpxyrjpy' target=\"_blank\">GraphConv_3_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/cpxyrjpy' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/cpxyrjpy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_4\\sum\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 5.2 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "5.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.7 K     Total params\n",
      "0.023     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▃▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇█▇████▇███</td></tr><tr><td>train_auc</td><td>▅▅▄▃▁▁▂▁▁▂▃▄▄▄▄▄▂▂▃▅▄▅▆▆▆▅▄▄▃▄▃▅▆▇▆▆██▇▆</td></tr><tr><td>train_f1</td><td>▁▃▃▅▆▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇████▇███</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇██▇▇▇▇▇█▇▇▇▇███▇██████</td></tr><tr><td>val_auc</td><td>▄▆▃▃▂▂▂▂▁▁▂▄▆▆▄▃▂▁▇▇▆▇███▇▆▂▆▆▆█▇███████</td></tr><tr><td>val_f1</td><td>▁▃▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇██▇▇▇▇▇▇▇▇▇▇█▇█▇█▇███▇</td></tr><tr><td>val_loss_epoch</td><td>█▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▅▃▃▃▂▃▃▂▂▂▂▂▂▁▁▁▂▃▁▂▃▂▂▁▂▂▂▃▁▂▂▂▁▃▂▃▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85183</td></tr><tr><td>train_auc</td><td>0.59174</td></tr><tr><td>train_f1</td><td>0.84361</td></tr><tr><td>train_loss_epoch</td><td>0.37546</td></tr><tr><td>train_loss_step</td><td>0.47206</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83452</td></tr><tr><td>val_auc</td><td>0.8809</td></tr><tr><td>val_f1</td><td>0.8583</td></tr><tr><td>val_loss_epoch</td><td>0.45675</td></tr><tr><td>val_loss_step</td><td>0.61854</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/cpxyrjpy' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/cpxyrjpy</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_035454-cpxyrjpy\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_041702-qwrzusar</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qwrzusar' target=\"_blank\">GCN_3_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qwrzusar' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qwrzusar</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_4\\attention\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 2.7 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "3.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.3 K     Total params\n",
      "0.013     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▇▇▇▇▇▆▇▇█▇▇▇▇█▇▇██▇██████▇██▇▇▇▇▇█▇█▇</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇▇▇▇▇██▇▇██▇██████████████▇███████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▇▇▇▇▆▇▇▇▇▇▇▇█▇▇▇▇▇▇█▇█▇▇▇█▇▇▇▇▇▇█▇█▇</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▂▂▂▂▃▂▂▁▂▃▂▂▁▂▂▁▂▂▁▁▁▁▁▁▁▁▁▂▂▂▁▂▁▁▂▂</td></tr><tr><td>train_loss_step</td><td>█▅▃▂▅▃▄▄▃▃▅▄▆▄▂▅▄▂▅▃▃▃▃▂▃▁▅▅▂▁▃▁▃▄▂▄▂▄▃▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▇▅▇▇▇█▇██████▇█████████▇▇▇█████▇▇▇████</td></tr><tr><td>val_auc</td><td>▁▅▇▇█▇██████████▇██▇▇█▇█████▇▇██████████</td></tr><tr><td>val_f1</td><td>▁▆▇▅▇▇▇███████████████████▇▇█████▇▇█████</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▅▃▃▃▂▃▃▂▁▂▂▂▃▂▁▂▂▂▂▁▂▁▃▂▃▂▂▂▃▂▄▄▂▂▁▃▂</td></tr><tr><td>val_loss_step</td><td>▇▄▄▃▅▂▅▃▅▆▂▃▃▄▄▆▄▃▄▅▆▇▂▃▁█▂▄▃▅▅▆▅█▆▂▅▁▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83412</td></tr><tr><td>train_auc</td><td>0.90893</td></tr><tr><td>train_f1</td><td>0.82514</td></tr><tr><td>train_loss_epoch</td><td>0.38325</td></tr><tr><td>train_loss_step</td><td>0.4205</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83688</td></tr><tr><td>val_auc</td><td>0.92014</td></tr><tr><td>val_f1</td><td>0.84768</td></tr><tr><td>val_loss_epoch</td><td>0.38061</td></tr><tr><td>val_loss_step</td><td>0.43345</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qwrzusar' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qwrzusar</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_041702-qwrzusar\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_043845-nfefqonh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/nfefqonh' target=\"_blank\">GraphConv_3_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/nfefqonh' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/nfefqonh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_4\\attention\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 5.2 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "5.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.7 K     Total params\n",
      "0.023     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "248587224f14494bad751b9320eaa290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇██▇█▇████▇█████████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▇▇▇▇▇▇██▇▇█▇▇██▇██████████▇█████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▇▇▇▇▇▇█▇▇▇▇▇▇█▇▇▇██▇█▇████▇███████▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▄▃▃▃▃▃▃▃▂▂▂▂▂▃▂▁▃▂▁▂▂▁▂▂▂▂▁▂▂▂▁▂▂▂▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▆▆▅▄▅▄▄▄▅▅▄▆▄▄▃▄▃▄▄▃▃▆▃▄▄▃▅▃▄▃▄▅▅▃▄▅▄▄▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▇▇████▇▆██▇████▆▇▆█▇██▇█▇▇██████▇██▇▇██</td></tr><tr><td>val_auc</td><td>▁▅▆▇▇▇▇█▇▇███████▇████▇███▇█▇▇████▇██▇█▇</td></tr><tr><td>val_f1</td><td>▁▆▇▇▇▇█▅▄▇█▆▇█▇▇▄▆▃█▆█▇▆▇▆▅▇▇▇█▇▇▆██▅▄▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▂▂▃▂▂▃▂▂▃▂▁▂▂▃▂▄▁▃▂▂▁▂▂▃▂▁▂▂▂▁▃▂▂▄▄▂▃</td></tr><tr><td>val_loss_step</td><td>▇▃▃▄▃▆▄▃▂▅▃▅▅▂▄▄▅▃▃▃▅▃▃▂▃▅▃▄▁▄▅▄▃▇▃▂█▃▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87249</td></tr><tr><td>train_auc</td><td>0.94334</td></tr><tr><td>train_f1</td><td>0.8665</td></tr><tr><td>train_loss_epoch</td><td>0.29916</td></tr><tr><td>train_loss_step</td><td>0.09453</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.84397</td></tr><tr><td>val_auc</td><td>0.91915</td></tr><tr><td>val_f1</td><td>0.84579</td></tr><tr><td>val_loss_epoch</td><td>0.42422</td></tr><tr><td>val_loss_step</td><td>0.39548</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/nfefqonh' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/nfefqonh</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_043845-nfefqonh\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_050025-ve9kfomk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ve9kfomk' target=\"_blank\">GCN_3_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ve9kfomk' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ve9kfomk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_4\\attention2\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 2.7 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "4.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.3 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇██▇▇▇████▇████▇█▇██▇██████</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇█▇█▇███▇█████▇██████</td></tr><tr><td>train_f1</td><td>▁▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇████▇▇▇█▇▇█▇▇█▇█▇██▇█</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▂▂▂▂▂▃▂▂▂▂▂▁▂▁▂▂▁▂▂▂▁▂▂▁▂▂▁▂▁▂▁▂▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>▇▄▄▅▄▃▄▃▄▄▅▅█▄▃▃▄▂▃▃▃▃▄▄▁▄▅▁▃▃▂▃▃▃▃▃▃▂▃▆</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▆█▇▆█▅█▇█▇▇█████▇███████▇███████▇██▆█▇</td></tr><tr><td>val_auc</td><td>▁▆▇▇▇▆▇▇▇▇▇▇▇█▇▇▇█▇██▇█▇█▇███████▇██▇█▇█</td></tr><tr><td>val_f1</td><td>▁▅▇█▇▆█▅█▇█▇▇█████▇███████▇███████▇██▇█▇</td></tr><tr><td>val_loss_epoch</td><td>█▅▄▂▃▆▁█▁▃▂▃▄▂▂▂▃▃▃▂▃▂▃▂▁▁▃▁▃▁▃▃▂▂▅▃▂▄▁▄</td></tr><tr><td>val_loss_step</td><td>▆▅▅▄▄▇▁▇▂▃▃▄▅▁▃▃▆▅▃▂▆▄▅▅▃▂▅▁▆▁▅█▃▃▆▃▂▂▁▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85301</td></tr><tr><td>train_auc</td><td>0.92345</td></tr><tr><td>train_f1</td><td>0.84752</td></tr><tr><td>train_loss_epoch</td><td>0.36128</td></tr><tr><td>train_loss_step</td><td>0.49818</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81797</td></tr><tr><td>val_auc</td><td>0.9225</td></tr><tr><td>val_f1</td><td>0.81081</td></tr><tr><td>val_loss_epoch</td><td>0.44643</td></tr><tr><td>val_loss_step</td><td>0.53188</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ve9kfomk' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ve9kfomk</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_050025-ve9kfomk\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef35cf29c54540fa8063e5a8f3cb44b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666495924, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_052151-e26dqtta</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/e26dqtta' target=\"_blank\">GraphConv_3_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/e26dqtta' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/e26dqtta</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_32_onehot_4\\attention2\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 5.2 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "6.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.8 K     Total params\n",
      "0.027     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fda0eaceb8704bcbae1ff1d7ff70edf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇█▇████████████████████████</td></tr><tr><td>train_auc</td><td>▁▆▆▇▇▇▇▇▇▇█▇█▇▇█████████████████████████</td></tr><tr><td>train_f1</td><td>▁▆▆▇▇▇▇▇▇▇▇▇█▇████▇█████████████████████</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▂▁▁▁▂▁▂▂▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▇▃▆▄▃▂▅▄▃▅▄▃▂▅▂▄▄▂▂▃▁▂▃▂▃▃▂▂▂▃▂▄▂▃▂▃▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▇▇▇▇▇▇█▇▇▇▇▇█▇█▇▇▇▇▇▇▇█▇██▇█▇▇▇█▆█▇██▇█</td></tr><tr><td>val_auc</td><td>▁▆▇▇████████████████████▇███████████████</td></tr><tr><td>val_f1</td><td>▁▆▇▇▇▇▇█▇▇▇▇▇█▇█▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇█▇▆▇▇█▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▂▂▁▂▂▂▂▂▁▁▂▂▂▂▂▄▁▂▁▂▂▂▃▃▃▁▂▂▂▃▃▃▁▁▂▃▂</td></tr><tr><td>val_loss_step</td><td>█▄▂▄▅▂▅▄▄▄▃▁▃▅▄▆▄▄▇▂▄▃▅▄▂▅▅▆▃▄▃▂█▃█▃▂▅▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86954</td></tr><tr><td>train_auc</td><td>0.93809</td></tr><tr><td>train_f1</td><td>0.86614</td></tr><tr><td>train_loss_epoch</td><td>0.31707</td></tr><tr><td>train_loss_step</td><td>0.24843</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.84634</td></tr><tr><td>val_auc</td><td>0.92153</td></tr><tr><td>val_f1</td><td>0.85714</td></tr><tr><td>val_loss_epoch</td><td>0.39165</td></tr><tr><td>val_loss_step</td><td>0.51404</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/e26dqtta' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/e26dqtta</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_052151-e26dqtta\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_054246-zi0znzn2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zi0znzn2' target=\"_blank\">GCN_3_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zi0znzn2' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zi0znzn2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_4\\mean\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 9.5 K \n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "11.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "11.6 K    Total params\n",
      "0.046     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▇▆▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇█▇▇▇▇▇▇▇▇█▇▇▇▇█▇█▇█▇▇</td></tr><tr><td>train_auc</td><td>▁▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇████████▇█▇██████▇▇</td></tr><tr><td>train_f1</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇▇▇██▇▇▇▇█▇█▇█▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▃▃▃▃▃▃▂▂▃▂▃▃▂▂▂▃▂▁▁▂▂▂▂▁▂▂▂▂▂▁▂▁▂▁▃▂</td></tr><tr><td>train_loss_step</td><td>█▇▇▇▆▄▅▅▅▄▃▇▇▃▆▃▄▅▄▅▆▂▁▅▆▅▆▂▄▅▅▄▄▄██▄▅▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▂▄▇▇█▇██▇▇██▇█▇▇█████▆▇████████▇▇██████</td></tr><tr><td>val_auc</td><td>▁▄▆▆▇▇▇▇▆▇▆▇▇▇▇▇██▇█▆▇▇▇▇█▇███████▆▇█▇██</td></tr><tr><td>val_f1</td><td>▁▂▅▇█████▇▇████▇██████▇█████████▇▇██████</td></tr><tr><td>val_loss_epoch</td><td>█▆▄▂▂▂▂▁▁▂▂▁▁▂▁▂▂▂▂▁▁▁▃▂▁▁▁▁▁▁▁▂▂▂▂▁▁▁▁▂</td></tr><tr><td>val_loss_step</td><td>█▇▄▃▂▂▂▂▂▃▃▂▂▂▂▃▂▄▃▁▂▁▄▃▂▁▁▂▁▃▁▃▃▃▃▃▂▂▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85537</td></tr><tr><td>train_auc</td><td>0.92194</td></tr><tr><td>train_f1</td><td>0.85015</td></tr><tr><td>train_loss_epoch</td><td>0.35583</td></tr><tr><td>train_loss_step</td><td>0.28795</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82742</td></tr><tr><td>val_auc</td><td>0.92273</td></tr><tr><td>val_f1</td><td>0.81975</td></tr><tr><td>val_loss_epoch</td><td>0.45714</td></tr><tr><td>val_loss_step</td><td>0.63568</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zi0znzn2' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zi0znzn2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_054246-zi0znzn2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_060435-bq0i7pq8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/bq0i7pq8' target=\"_blank\">GraphConv_3_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/bq0i7pq8' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/bq0i7pq8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_4\\mean\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 18.5 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "20.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.6 K    Total params\n",
      "0.083     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▇▆▆▇▇▇▇▇▇▇█▇▇▇▇▇▇█▇▇█▇▇███▇█▇█████▇█</td></tr><tr><td>train_auc</td><td>▁▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇████████████████████</td></tr><tr><td>train_f1</td><td>▁▆▆▆▇▆▆▇▇▇▇▇▇▇█▇▇▇▇▇██▇▇█▇▇███▇███████▇█</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▃▃▄▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▂▁▁▁▁▁▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▆▆▅▄▄▄▃▃▄▅▅▂▅▄▅▃▄▂▃▄▅▂▄▃▃▄▄▃▃▄▆▃▄▃▂▃▅▄▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▅▆▆▇▇▇▆▆█▅▅▇▆▅▆▆▇▇▇▄▇▅▅▆▇▇█▅▇▇▇▇▅▇█▅▅▇</td></tr><tr><td>val_auc</td><td>▁▅▇▇▇▇▇▇▇██▇█▇▇█████▇███▇▇▇███▇█████████</td></tr><tr><td>val_f1</td><td>▁▃▄▅▅▇▇▆▆▆▇▅▆▆▆▅▆▆▆▇▇▅▆▆▆▄▇▆█▅▅▆▇▇▂▇█▆▆▆</td></tr><tr><td>val_loss_epoch</td><td>█▃▅▃▁▃▂▂▂▂▂▄▃▃▃▃▃▄▃▂▂▅▁▄▄▃▅▃▁▄▄▂▃▃▄▂▂▄▃▃</td></tr><tr><td>val_loss_step</td><td>▆▃█▅▁▅▂▃▃▄▄▅▃▃▄▅▄▆▅▃▃▃▁▅▅▄█▃▁▄▅▃▄▃▄▄▄▂▂▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.89315</td></tr><tr><td>train_auc</td><td>0.95592</td></tr><tr><td>train_f1</td><td>0.88943</td></tr><tr><td>train_loss_epoch</td><td>0.26935</td></tr><tr><td>train_loss_step</td><td>0.1662</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.85106</td></tr><tr><td>val_auc</td><td>0.92696</td></tr><tr><td>val_f1</td><td>0.86031</td></tr><tr><td>val_loss_epoch</td><td>0.38914</td></tr><tr><td>val_loss_step</td><td>0.45953</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/bq0i7pq8' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/bq0i7pq8</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_060435-bq0i7pq8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_062520-5jya37xo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5jya37xo' target=\"_blank\">GCN_3_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5jya37xo' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5jya37xo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_4\\max\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 9.5 K \n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "11.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "11.6 K    Total params\n",
      "0.046     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇██████████</td></tr><tr><td>train_auc</td><td>▁▁▃▃▃▃▃▅▅▅▅▅▆▆▇▇▇▇▇▇▇██▇█▇███▇██████████</td></tr><tr><td>train_f1</td><td>▁▃▄▅▄▅▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇██████████</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▄▄▄▃▄▄▃▄▃▄▄▃▃▂▂▃▂▃▃▃▁▂▂▂▂▂▂▂▂▂▂▃▂▂▂▂▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▆▆▆▆▆▆▆▆▆▆▃▅▇▆▇▇▇▇▆▇██▇▇██▇▇██████████</td></tr><tr><td>val_auc</td><td>▁▁▄▄▄▄▄▄▄▅▅▆▅▆▇▇▇▇▇▇▇▇██▇█████████████▇█</td></tr><tr><td>val_f1</td><td>▁▇▇▇▇▇▇▇▇▇▇▇▄▆█▇▇█▇█▇▇██▇███████████████</td></tr><tr><td>val_loss_epoch</td><td>█▇▆▆▅▆▅▅▅▆▅▅▆▅▃▄▄▃▃▂▄▃▂▂▂▂▂▂▁▃▁▂▃▁▂▁▁▁▂▂</td></tr><tr><td>val_loss_step</td><td>█▇▆▆▅▇▄▆▅▅▆▅▆▅▄▃▆▄▄▄▆▄▅▂▁▂▄▄▂▄▁▅▅▃▄▃▁▂▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.81287</td></tr><tr><td>train_auc</td><td>0.87829</td></tr><tr><td>train_f1</td><td>0.81097</td></tr><tr><td>train_loss_epoch</td><td>0.41969</td></tr><tr><td>train_loss_step</td><td>0.39624</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81324</td></tr><tr><td>val_auc</td><td>0.90168</td></tr><tr><td>val_f1</td><td>0.82561</td></tr><tr><td>val_loss_epoch</td><td>0.41675</td></tr><tr><td>val_loss_step</td><td>0.42194</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5jya37xo' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5jya37xo</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_062520-5jya37xo\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_064557-53qge996</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/53qge996' target=\"_blank\">GraphConv_3_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/53qge996' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/53qge996</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_4\\max\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 18.5 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "20.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.6 K    Total params\n",
      "0.083     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇████▇██▇████████</td></tr><tr><td>train_auc</td><td>▁▃▅▅▆▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇██▇████▇██████▇█</td></tr><tr><td>train_f1</td><td>▁▄▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇███████▇████████</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▁▁▁▁▁▂▁▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▆▅▅▄▅▄▃▃▄▄▃▃▃▅▂▂▃▂▃▃▃▃▁▂▄▁▃▂▁▂▂▂▁▂▂▂▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▆▆▄▆▆▇▇▇▆▇█▇▇█▇▇█▇█▇█▇▇█▇▇█▇█▇▇▇██▇▆▇█</td></tr><tr><td>val_auc</td><td>▁▃▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇█▇█▇██▇▇█▇▇█</td></tr><tr><td>val_f1</td><td>▁▄▆▇▄▆▇▇▇▇▇▇█▇▇████▇████████████▇████▇▇█</td></tr><tr><td>val_loss_epoch</td><td>█▆▅▄▅▄▄▄▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▁▂▂▁</td></tr><tr><td>val_loss_step</td><td>█▇▆▅▅▆▄▅▄▄▆▄▄▄▃▄▄▄▄▅▄▃▄▃▄▄▃▃▁▃▅▂▆▃▃▄▁▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86068</td></tr><tr><td>train_auc</td><td>0.91653</td></tr><tr><td>train_f1</td><td>0.85766</td></tr><tr><td>train_loss_epoch</td><td>0.34303</td></tr><tr><td>train_loss_step</td><td>0.34501</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83924</td></tr><tr><td>val_auc</td><td>0.92234</td></tr><tr><td>val_f1</td><td>0.85774</td></tr><tr><td>val_loss_epoch</td><td>0.35266</td></tr><tr><td>val_loss_step</td><td>0.29086</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/53qge996' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/53qge996</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_064557-53qge996\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "842c88411d57436183350a679ec7c761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_070630-a8xrkpu7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/a8xrkpu7' target=\"_blank\">GCN_3_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/a8xrkpu7' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/a8xrkpu7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_4\\sum\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 9.5 K \n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "11.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "11.6 K    Total params\n",
      "0.046     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▆▆▇▆▇▆▆▇▇▇▇▇▇▆▇▇▇▇▇███▇█▇▇▇▇█████████▇</td></tr><tr><td>train_auc</td><td>▆▅▄▃▃▄▄▄▃▂▂▂▂▁▁▁▁▂▂▂▃▃▂▂▃▃▁▃▅▄▄▅▄▅▇████▇</td></tr><tr><td>train_f1</td><td>▁▄▆▆▇▆▇▆▆▇▇▇▇▇▇▆▇▇▇▇▇███▇█▇█▇▇████████▇▆</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▂▁▁▂▂▁▁▁▂▁▁▁▁▂▁▁▁▁▁▁▂▁▂▁▁▁▂▁▁▁▂▂▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▁▅▇█▆▇▆▇▆▆▆▇▇▇▇▇█▇█▇▇▇▇▆▇▇▇█▆▆▇▅▇▇▇▄▇▇▆</td></tr><tr><td>val_auc</td><td>▆▆▃▂▃▅▇▂▂▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▂▁▁▄▇▁█▇▇███████</td></tr><tr><td>val_f1</td><td>▁▁▆██▇▇▇▇▆▇▇▇▇█▇▇█▇██▇▇▇▇█▇██▇▇█▆▇█▇▅▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▁▁▂▁▁▁▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▂▁▁▁▂▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▃▂▁▁▂▁▂▃▂▂▂▂▁▂▃▂▂▂▁▂▂▂▂▂▁▁▂▁▃▁▂▂▂▂▂▂▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.81169</td></tr><tr><td>train_auc</td><td>0.72076</td></tr><tr><td>train_f1</td><td>0.79746</td></tr><tr><td>train_loss_epoch</td><td>0.41709</td></tr><tr><td>train_loss_step</td><td>0.3253</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.73286</td></tr><tr><td>val_auc</td><td>0.92237</td></tr><tr><td>val_f1</td><td>0.68698</td></tr><tr><td>val_loss_epoch</td><td>0.59278</td></tr><tr><td>val_loss_step</td><td>0.6755</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/a8xrkpu7' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/a8xrkpu7</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_070630-a8xrkpu7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_072705-fyzf2exs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fyzf2exs' target=\"_blank\">GraphConv_3_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fyzf2exs' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fyzf2exs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_4\\sum\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 18.5 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "20.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.6 K    Total params\n",
      "0.083     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34443b213d2347a5937269a665fa3fea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇███████████</td></tr><tr><td>train_auc</td><td>▆▄▄▄▄▃▃▂▃▂▂▁▁▂▃▄▅▄▄▅▆▇▇▆▇███▇▇▅▆▆▆▆▆▅▄▆▆</td></tr><tr><td>train_f1</td><td>▁▃▅▅▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇██████████</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▂▂▂▁▂▁▂▂▁▂▁▂▁▂▁▁▁▂▁▂▁▁▂▁▁▁▁▂▁▂▁▁▁▂▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▇▇▇▇▇▇▇▇██▇█▇█▇██▇█▇▇▇████▇███▇▇███▇██</td></tr><tr><td>val_auc</td><td>▅▅▅▅▅▂▄▃▃▂▁▁▁▁▅▇█▃▇▇███▇████████████▇███</td></tr><tr><td>val_f1</td><td>▁▄▆▇▇▇▇▆▇▇▇█▇▇▇▇▇██▇▇▇▇▇▇▇█▇▇▇█▇▇▇█▇█▇█▇</td></tr><tr><td>val_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▃▂▂▁▂▁▂▁▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▂▂▂▁▂▂▁▂▂▂▂▂▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87013</td></tr><tr><td>train_auc</td><td>0.66775</td></tr><tr><td>train_f1</td><td>0.86453</td></tr><tr><td>train_loss_epoch</td><td>0.31796</td></tr><tr><td>train_loss_step</td><td>0.15801</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.85816</td></tr><tr><td>val_auc</td><td>0.86519</td></tr><tr><td>val_f1</td><td>0.869</td></tr><tr><td>val_loss_epoch</td><td>0.44838</td></tr><tr><td>val_loss_step</td><td>0.51217</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fyzf2exs' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fyzf2exs</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_072705-fyzf2exs\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "930ffb22088c431fb2c836fa9edc3e50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_074720-0f7kncyw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0f7kncyw' target=\"_blank\">GCN_3_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0f7kncyw' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0f7kncyw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_4\\attention\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 9.5 K \n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "11.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "11.7 K    Total params\n",
      "0.047     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▇▇▆▇▇▆▇▇▇▆▇▇▇███▇▇▇▇▇▇▇▇█▇██▇█▇█▇███</td></tr><tr><td>train_auc</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▆█▇████▇▇▇█████████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▇▇▆▇▇▆▇▆▇▆▇▇▇███▇▇▇▇█▇▇▇█▇████▇█▇███</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▃▃▃▂▂▃▂▂▂▃▂▂▂▁▁▁▂▂▂▂▁▁▁▂▁▁▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▄▄▃▅▆▄▂▄▃▃▄▄▄▄▅▃▃▃▄▄▃▄▄▄▅▆▃▂▄▃▃▄▁▃▃▂▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▂▆▆███▇█████▆████▅▇▆██████████████▇████</td></tr><tr><td>val_auc</td><td>▁▅▆▆▇▇▇▇▇▇█▇█▇▇▇███▇▇█▇▇██▇▇█▇▇█▇██▇████</td></tr><tr><td>val_f1</td><td>▁▂▇▇███▇█████▇████▆▇▇██████████████▇████</td></tr><tr><td>val_loss_epoch</td><td>▆█▄▄▂▂▂▃▁▂▂▁▂▃▁▂▂▂▅▂▄▁▂▂▂▂▂▁▁▂▂▁▁▂▁▃▂▂▁▁</td></tr><tr><td>val_loss_step</td><td>▇█▇▆▆▅▄▅▂▄▄▂▅▂▂▃▂▅▅▃▄▃▅▂▄▂▇▂▂▆▃▂▂▅▂▄▅▅▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85773</td></tr><tr><td>train_auc</td><td>0.93036</td></tr><tr><td>train_f1</td><td>0.85491</td></tr><tr><td>train_loss_epoch</td><td>0.34193</td></tr><tr><td>train_loss_step</td><td>0.32405</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.84397</td></tr><tr><td>val_auc</td><td>0.92552</td></tr><tr><td>val_f1</td><td>0.86192</td></tr><tr><td>val_loss_epoch</td><td>0.3314</td></tr><tr><td>val_loss_step</td><td>0.23077</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0f7kncyw' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0f7kncyw</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_074720-0f7kncyw\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_080754-63gb3894</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/63gb3894' target=\"_blank\">GraphConv_3_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/63gb3894' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/63gb3894</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_4\\attention\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 18.5 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "20.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.7 K    Total params\n",
      "0.083     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03918a2899cb4a2cb61265f498318dee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▇▆▆▆▇▇▇▇▇▇▇█▇████▇██▇█▇████████████</td></tr><tr><td>train_auc</td><td>▁▄▆▆▇▇▇▆▇▇▇▇▇█▇▇██████▇█████████████████</td></tr><tr><td>train_f1</td><td>▁▄▅▅▆▇▆▆▆▇▇▇▇█▇▇█▇████▇██▇█▇████████████</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▅▃▃▃▄▃▂▂▂▂▂▃▂▂▂▁▂▁▁▃▂▁▂▁▂▂▁▁▁▁▁▁▁▂▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▆▅▇▄▃▄▆▃▃▄▃▂▃▃▄▄▂▂▃▃▂▄▃▃▂▂▄▃▂▄▄▂▁▃▃▂▂▄▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▃▁▅▆▇▆▃▇▇▄▇▇█▇▇█▇▇▇█▇▇▆▇█▇█▇▆████▇▅▇█▅▇▆</td></tr><tr><td>val_auc</td><td>▁▅▆▇▇▇▇▇▇▇██████▇█████▇█████████████▇█▇█</td></tr><tr><td>val_f1</td><td>▄▁▆▇▇▇▃▇▇▄▇█████▇▇██▇▇▆██▇█▇▇█████▅▇█▆█▆</td></tr><tr><td>val_loss_epoch</td><td>█▇▇▃▃▃▅▃▃▄▂▁▂▃▃▁▃▃▃▂▂▂▃▃▂▂▂▂▃▂▂▃▃▃▄▃▂▄▂▃</td></tr><tr><td>val_loss_step</td><td>▆▆█▄▅▃▆▅▄▄▄▁▂▄▅▁▄▇▃▂▂▂▃▆▃▃▅▁▅▃▄▅▄▄▂▄▁▃▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87485</td></tr><tr><td>train_auc</td><td>0.94623</td></tr><tr><td>train_f1</td><td>0.86865</td></tr><tr><td>train_loss_epoch</td><td>0.30747</td></tr><tr><td>train_loss_step</td><td>0.40032</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82979</td></tr><tr><td>val_auc</td><td>0.92806</td></tr><tr><td>val_f1</td><td>0.83256</td></tr><tr><td>val_loss_epoch</td><td>0.38239</td></tr><tr><td>val_loss_step</td><td>0.27584</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/63gb3894' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/63gb3894</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_080754-63gb3894\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_082843-vhqxx2tc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/vhqxx2tc' target=\"_blank\">GCN_3_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/vhqxx2tc' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/vhqxx2tc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_4\\attention2\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 9.5 K \n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "15.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.8 K    Total params\n",
      "0.063     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d845da95e3424451a42d34a136010b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▆▆▆▆▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇██▇█▇▇█████▇█▇█</td></tr><tr><td>train_auc</td><td>▁▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇███▇████████▇███</td></tr><tr><td>train_f1</td><td>▁▆▆▆▇▆▇▆▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇██▇█▇▇████▇▇███</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▄▃▃▃▄▂▂▂▃▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▂▁▂▂▁▁▂▁▂▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▆▇█▃▆█▂▄▄▄█▄▄▃▅▄▄▄▂▆▁▄▄▃▄▁▅▃▄▆▄▂▃▂▁▂▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▂▅▇▆▇▇▇█▇▇███▇▇██▇▇███████▇██▇█▇█▇██▇██</td></tr><tr><td>val_auc</td><td>▁▅▆▇▇▇▇▇▇▇▆▇▇▇▇▇▆▇▇▆▇▇▇▇▇▇▆▆█▇▆▇█▇▇▇█▇█▇</td></tr><tr><td>val_f1</td><td>▁▃▆█▇██▇██▇████▇███████████▇████▇█▇█████</td></tr><tr><td>val_loss_epoch</td><td>█▆▃▂▃▁▂▂▁▂▂▁▁▁▂▂▁▁▂▂▂▁▁▂▁▁▁▂▁▁▂▁▂▂▂▁▁▂▁▁</td></tr><tr><td>val_loss_step</td><td>█▆▄▃▃▂▃▃▂▂▂▂▄▂▃▃▁▃▂▃▄▂▃▂▂▁▃▃▂▃▄▂▃▃▃▃▁▃▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86541</td></tr><tr><td>train_auc</td><td>0.93123</td></tr><tr><td>train_f1</td><td>0.8566</td></tr><tr><td>train_loss_epoch</td><td>0.33438</td></tr><tr><td>train_loss_step</td><td>0.27708</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.84161</td></tr><tr><td>val_auc</td><td>0.92077</td></tr><tr><td>val_f1</td><td>0.85714</td></tr><tr><td>val_loss_epoch</td><td>0.38458</td></tr><tr><td>val_loss_step</td><td>0.49272</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/vhqxx2tc' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/vhqxx2tc</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_082843-vhqxx2tc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_085105-stj4p803</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/stj4p803' target=\"_blank\">GraphConv_3_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/stj4p803' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/stj4p803</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_3_64_onehot_4\\attention2\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 18.5 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "24.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.8 K    Total params\n",
      "0.099     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇███▇█▇█████▇██</td></tr><tr><td>train_auc</td><td>▁▅▅▆▇▇▇▇▇▇▇▇▇▇▇█▇██▇▇▇▇████████▇█████▇██</td></tr><tr><td>train_f1</td><td>▁▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇█▇███▇█▇█████▇██</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▃▃▃▃▃▂▂▂▂▃▂▂▂▂▂▁▂▂▂▂▂▂▂▂▁▁▂▁▂▂▁▁▁▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▆█▄▃▅▄▄▄▄▁▅▄▃▄▄▅▃▄▃▄▂▅▂▂▂▂▁▁▂▂▂▃▅▅▃▃▂▄▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▆▇▇▇▇▇▇▇▇▇▇▇█▆▆▇▆▇▇▇▇▇▇▆█▅▇█▇▅▇▆▆▇▆▇▇▆</td></tr><tr><td>val_auc</td><td>▁▅▆▆▇▇▇██▇█▇▇██▇▇██████▇▇▇█▇▇▇▇▇▇▇▇▇▆▇▇▇</td></tr><tr><td>val_f1</td><td>▁▂▆▆▇▅▆▇█▆▆▇▆▆▇▇▆▆▆▇▇▇▇▇▇▆█▅▇█▇▅▇▆▆▇▅▇▆▆</td></tr><tr><td>val_loss_epoch</td><td>█▄▂▂▂▂▁▂▁▁▂▁▂▁▂▁▅▂▃▂▁▂▂▂▂▄▁▄▂▂▄▄▂▅▃▅▃▁▁▄</td></tr><tr><td>val_loss_step</td><td>▇▅▄▄▅▄▃▃▄▂▆▂▄▄▅▁▆▅▅▅▃▃▄▃▄▅▃▅▂▅▅▄▄▇▄█▃▂▁▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.89374</td></tr><tr><td>train_auc</td><td>0.95861</td></tr><tr><td>train_f1</td><td>0.88778</td></tr><tr><td>train_loss_epoch</td><td>0.26078</td></tr><tr><td>train_loss_step</td><td>0.18888</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.8227</td></tr><tr><td>val_auc</td><td>0.92241</td></tr><tr><td>val_f1</td><td>0.85207</td></tr><tr><td>val_loss_epoch</td><td>0.44802</td></tr><tr><td>val_loss_step</td><td>0.42863</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_3_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/stj4p803' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/stj4p803</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_085105-stj4p803\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_091507-mcptop39</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/mcptop39' target=\"_blank\">GCN_4_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/mcptop39' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/mcptop39</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_4\\mean\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 1.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5b8236a02bb463f8d16d89fe3c27438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇▇█▇█████▇▇████████████████████████</td></tr><tr><td>train_auc</td><td>▁▇▇▇▇███████████████████████████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█▇▇▇▇█▇█▇██▇█▇███▇▇██</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>▅▃▂▂▂▃▃▂▂▂▂▂▂▁▂▂▂█▂▂▂▂▃▂▃▂▂▂▂▂▂▂▂▃▃▂▃▁▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▇▇▇▆█▇▇▇█▆█▇█▇▇▇█▇█▇▇▇█▇▇███▇█▇██▇▇▆▇▇█</td></tr><tr><td>val_auc</td><td>▁▅▆▇▇▇█▇████▇█▇▇█████▇████████████▇██▇▇▇</td></tr><tr><td>val_f1</td><td>▁▇▇█▆██▇▇█▇█▇█▇█▇█▇█▇▇██▇▇███▇████▇▇▇█▇█</td></tr><tr><td>val_loss_epoch</td><td>█▄▄▂▅▂▃▃▄▂▄▃▃▂▃▃▄▃▄▁▄▃▂▃▄▅▂▃▂▄▁▃▂▃▄▃▅▃▅▃</td></tr><tr><td>val_loss_step</td><td>█▆▇▂▇▃▆▄▇▅▆▅▄▄▅▄▆▄▇▂▆▄▄▅▆▇▅▆▃▄▁▅▄▆▇▄▆▅▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84061</td></tr><tr><td>train_auc</td><td>0.90539</td></tr><tr><td>train_f1</td><td>0.83456</td></tr><tr><td>train_loss_epoch</td><td>0.38882</td></tr><tr><td>train_loss_step</td><td>0.30883</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82506</td></tr><tr><td>val_auc</td><td>0.9028</td></tr><tr><td>val_f1</td><td>0.82464</td></tr><tr><td>val_loss_epoch</td><td>0.44245</td></tr><tr><td>val_loss_step</td><td>0.49553</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/mcptop39' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/mcptop39</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_091507-mcptop39\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_093901-2zl0y14p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/2zl0y14p' target=\"_blank\">GraphConv_4_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/2zl0y14p' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/2zl0y14p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_4\\mean\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 2.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.3 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇█▇█████████████████</td></tr><tr><td>train_auc</td><td>▁▅▆▇▇▇▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>train_f1</td><td>▁▄▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇▇█▇██▇▇▇██▇██▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▃▁▂▁▁▂▁▁▂▂▁▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▆▃▂▅▃▃▂▃▅▃▅▃▄▃▄▂▂▂▃▃▂▄▂▄▃▇▄▅▃▃▄▁▃▂▃▃▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▆▇▇▇▇████▇█▇█▇█▇▇█▇▇▇▇▇███▇█████████▇█</td></tr><tr><td>val_auc</td><td>▁▆▇▇████████████████████████████████████</td></tr><tr><td>val_f1</td><td>▁▁▄▆▆▇▇██▇▇▇█▇█▇▇▇▇█▇▇▇▇▇▇▇█▆███▇██▇█▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▅▄▃▃▂▂▂▂▂▃▃▁▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▂▁▁▂▂▂▂▁▂▂</td></tr><tr><td>val_loss_step</td><td>█▆▅▄▆▃▃▃▃▅█▇▂▄▅▄▃▅▅▄▃▇▃▃▂▅▂▄▁▂▅▂▂▄▄▃▄▂▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85124</td></tr><tr><td>train_auc</td><td>0.91862</td></tr><tr><td>train_f1</td><td>0.84982</td></tr><tr><td>train_loss_epoch</td><td>0.36596</td></tr><tr><td>train_loss_step</td><td>0.26485</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.85343</td></tr><tr><td>val_auc</td><td>0.93</td></tr><tr><td>val_f1</td><td>0.85973</td></tr><tr><td>val_loss_epoch</td><td>0.36438</td></tr><tr><td>val_loss_step</td><td>0.41751</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/2zl0y14p' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/2zl0y14p</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_093901-2zl0y14p\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_100236-xz6a5wc5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/xz6a5wc5' target=\"_blank\">GCN_4_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/xz6a5wc5' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/xz6a5wc5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_4\\max\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 1.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▂▁▂▂▂▅▅▅▆▆▆▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇█████▇▇███▇███</td></tr><tr><td>train_auc</td><td>▁▁▂▂▂▄▅▆▆▆▆▇▇▇▇▇▇█▇▇███████████▇████████</td></tr><tr><td>train_f1</td><td>▅▃▄▁▃▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▆▇▇▇▇███▇▇███▇███</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▆▆▆▅▅▄▅▄▃▄▃▃▃▄▃▃▄▂▄▃▄▃▃▁▂▂▂▁▂▂▂▄▃▄▄▂▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▃▃▃▁▁▁▁███▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_auc</td><td>▅▁▁▃▆▇██████████▇▇▇███▇███▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>val_f1</td><td>███▁▁▁▁███▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_epoch</td><td>█████▇▆▄▄▄▅▆▆▅▃▅▅▄▃▃▄▂▃▄▃▂▁▂▂▇▃▄▁▃▃▁▄▂▅▂</td></tr><tr><td>val_loss_step</td><td>▆▆▆▆▆▅▄▄▅▄▅▇▆▅▃▅▅▅▂▃▄▁▃▇▅▄▂▅▂█▇▇▂▅▅▁▃▄█▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.71665</td></tr><tr><td>train_auc</td><td>0.76942</td></tr><tr><td>train_f1</td><td>0.73034</td></tr><tr><td>train_loss_epoch</td><td>0.56626</td></tr><tr><td>train_loss_step</td><td>0.55519</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.45863</td></tr><tr><td>val_auc</td><td>0.77351</td></tr><tr><td>val_f1</td><td>0.0</td></tr><tr><td>val_loss_epoch</td><td>0.63652</td></tr><tr><td>val_loss_step</td><td>0.64499</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/xz6a5wc5' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/xz6a5wc5</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_100236-xz6a5wc5\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_102607-pafz7c87</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/pafz7c87' target=\"_blank\">GraphConv_4_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/pafz7c87' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/pafz7c87</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_4\\max\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 2.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.3 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▂▄▄▄▅▅▅▆▆▇▇▇▇▇▇▇▇▇▇█▇█▇███████████████</td></tr><tr><td>train_auc</td><td>▁▁▁▂▂▁▃▁▃▂▃▄▄▅▅▆▆▅▆▅▅▆▆▇▇▇▇▇▇▇█▇█▇█▇████</td></tr><tr><td>train_f1</td><td>▁▂▂▄▅▅▆▅▅▆▇▆▇▇▇█▇▇▇▇▇█▇█▇███████████████</td></tr><tr><td>train_loss_epoch</td><td>█▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▄▃▃▄▄▃▂▃▄▃▃▃▂▂▂▁▁▃▃▂▂▃▁▂▂▄▂▂▂▂▃▂▂▂▂▂▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▁▂▄▄▅▅▆▆▆▇▇▇▇███▇▇▇██▇▇▆▇▇▇▇▆▆▆▇▆▆▆▇▆▆▆</td></tr><tr><td>val_auc</td><td>▁▁▂▄▅▂▆▃▆▇▇▇▇▇▇▇▇▇▇██▇▇████▇████████████</td></tr><tr><td>val_f1</td><td>▁▁▂▃▄▄▄▅▆▆▆▆▇▇▇▇█▆▇▇██▇▇▆▆▇▇▇▆▆▆▇▆▆▆█▆▆▆</td></tr><tr><td>val_loss_epoch</td><td>██▇▆▆▆▄▅▅▄▅▅▅▄▄▄▄▄▃▃▃▃▄▃▃▂▂▂▂▃▂▂▂▂▂▃▁▃▂▂</td></tr><tr><td>val_loss_step</td><td>██▇▆▇▅▄▅▄▅▇▇▄▅▅▃▄▅▃▂▂▄▄▄▁▁▂▂▁▁▃▂▂▃▄▂▃▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.7863</td></tr><tr><td>train_auc</td><td>0.83985</td></tr><tr><td>train_f1</td><td>0.78756</td></tr><tr><td>train_loss_epoch</td><td>0.47008</td></tr><tr><td>train_loss_step</td><td>0.40112</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.75177</td></tr><tr><td>val_auc</td><td>0.91217</td></tr><tr><td>val_f1</td><td>0.80874</td></tr><tr><td>val_loss_epoch</td><td>0.4861</td></tr><tr><td>val_loss_step</td><td>0.5018</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/pafz7c87' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/pafz7c87</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_102607-pafz7c87\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_104945-kn8ll575</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kn8ll575' target=\"_blank\">GCN_4_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kn8ll575' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kn8ll575</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_4\\sum\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 1.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▆▆▇▇▇▇▇▇▇▇▇▇▇██▇▇██▇██▇▇█████████████</td></tr><tr><td>train_auc</td><td>▃▅▆▅▄▄▄▆▆▇▆▅▆▅▄▄▅▅▇▅▅▁▃▆██▇▇▇▄▄█████▇███</td></tr><tr><td>train_f1</td><td>▁▃▅▅▆▆▆▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇██▇▇▇████████████</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▆▂▂▂▂▃▂▃▂▂▂▂▁▂▂▂▂▃▂▃▂▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▆▇▅▇▆▆▇▇▆▇█▆██▇▇▇█▇▇██▇█▇█▇▇█▇▇▇▇▆█▇▇█</td></tr><tr><td>val_auc</td><td>▆▇▇▇▇▇███████▇██████▆▁██████████████████</td></tr><tr><td>val_f1</td><td>▁▄▇▇▆▇▇▇▇█▇██▇██▇█▇█▇▇████▇██▇█▇▇▇▇▇██▇█</td></tr><tr><td>val_loss_epoch</td><td>█▆▄▂▄▂▄▃▃▂▃▂▂▃▁▂▃▂▃▁▂▃▂▁▂▂▃▂▂▂▁▂▂▃▃▃▂▃▃▂</td></tr><tr><td>val_loss_step</td><td>█▆▆▂▅▂▄▂▆▄▃▄▄▄▂▂▄▃▄▂▄▄▃▂▄▃▄▄▃▃▁▃▃▅▆▄▄▆▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8353</td></tr><tr><td>train_auc</td><td>0.66222</td></tr><tr><td>train_f1</td><td>0.8281</td></tr><tr><td>train_loss_epoch</td><td>0.4083</td></tr><tr><td>train_loss_step</td><td>0.31168</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83452</td></tr><tr><td>val_auc</td><td>0.91523</td></tr><tr><td>val_f1</td><td>0.83491</td></tr><tr><td>val_loss_epoch</td><td>0.41058</td></tr><tr><td>val_loss_step</td><td>0.46195</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kn8ll575' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kn8ll575</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_104945-kn8ll575\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_111355-8btbj6dh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8btbj6dh' target=\"_blank\">GraphConv_4_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8btbj6dh' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8btbj6dh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_4\\sum\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 2.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.3 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▂▃▄▄▅▅▆▆▆▆▆▇▆▇▇▇▇▇▇█▇▇▇██▇███▇█▇████▇█</td></tr><tr><td>train_auc</td><td>█▇▆▅▄▅▄▄▅▄▅▅▄▄▄▃▃▂▃▂▁▂▂▂▂▁▂▁▂▁▂▂▁▂▃▃▃▄▃▂</td></tr><tr><td>train_f1</td><td>▁▂▂▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇█▇▇███▇███▇▇▇██████</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▄▅▆▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████</td></tr><tr><td>val_auc</td><td>▇██▄▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_f1</td><td>▁▃▄▄▅▆▆▇▆▅▆▅▅▄▆▆▇▇▅▇▆▇▇▇▇▇▇█▇██▇█▇▇▇▇█▇█</td></tr><tr><td>val_loss_epoch</td><td>█▅▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▂▁▂▂▂▂▁▁▁▂</td></tr><tr><td>val_loss_step</td><td>█▆▅▄▅▄▄▄▃▅▅▅▃▃▄▄▃▄▄▂▃▄▄▂▂▄▂▄▁▁▃▂▃▃▅▃▃▁▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.81169</td></tr><tr><td>train_auc</td><td>0.34203</td></tr><tr><td>train_f1</td><td>0.81001</td></tr><tr><td>train_loss_epoch</td><td>0.43153</td></tr><tr><td>train_loss_step</td><td>0.33132</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.85106</td></tr><tr><td>val_auc</td><td>0.09312</td></tr><tr><td>val_f1</td><td>0.86214</td></tr><tr><td>val_loss_epoch</td><td>0.41395</td></tr><tr><td>val_loss_step</td><td>0.5015</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8btbj6dh' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8btbj6dh</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_111355-8btbj6dh\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_113653-vdnwgbfk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/vdnwgbfk' target=\"_blank\">GCN_4_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/vdnwgbfk' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/vdnwgbfk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_4\\attention\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 1.1 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▆▇▇█▇▇▇▇▇▇█▇▇███▇██████████▇▇█████████</td></tr><tr><td>train_auc</td><td>▁▄▆▇▇▇▇██████▇██████████████████████████</td></tr><tr><td>train_f1</td><td>▁▁▄▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇█▇███▇▇████▇▇▇██</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▃▃▂▂▂▂▂▂▂▂▃▂▂▂▂▂▂▁▂▁▁▁▂▁▁▁▂▂▁▁▁▁▂▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▇▆▄▄▃▁▄▄▃▃▂▃▄▃▃▂▄▃▂▃▄▅▂▂▂▁▂▃▂▂▂▃▃▃▂▂▃▂▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▆▆▆▆▇█▇▇▇▇▇▇█▇██▇▇█▇██▇██▇▇▇█▇█▇█▅██▇█</td></tr><tr><td>val_auc</td><td>▁▄▆▇▇▇██▇▇██████████████████████████████</td></tr><tr><td>val_f1</td><td>▁▄▇▇▇▇██▇▇███▇█████▇████▇██▇▇▇█▇█▇█▆████</td></tr><tr><td>val_loss_epoch</td><td>█▇▄▄▄▄▂▁▄▂▃▂▂▃▁▂▂▁▂▃▂▂▂▁▃▂▁▄▃▃▁▂▂▄▁▇▁▁▂▁</td></tr><tr><td>val_loss_step</td><td>▇▅▅▄▄▅▃▂▅▂▅▃▁▃▁▂▅▂▂▃▄▂▄▃▃▅▂▄▅▂▁▂▄▃▃█▃▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83766</td></tr><tr><td>train_auc</td><td>0.90106</td></tr><tr><td>train_f1</td><td>0.82993</td></tr><tr><td>train_loss_epoch</td><td>0.41374</td></tr><tr><td>train_loss_step</td><td>0.54662</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81797</td></tr><tr><td>val_auc</td><td>0.91136</td></tr><tr><td>val_f1</td><td>0.82135</td></tr><tr><td>val_loss_epoch</td><td>0.38521</td></tr><tr><td>val_loss_step</td><td>0.30128</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/vdnwgbfk' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/vdnwgbfk</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_113653-vdnwgbfk\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63af3a27385f45a0bce083b54539d41a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_120006-la4opld4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/la4opld4' target=\"_blank\">GraphConv_4_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/la4opld4' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/la4opld4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_4\\attention\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 2.1 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "2.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.3 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▅▆▆▇▇▇▇▇▇▇▇█▇█▇▇█▇████▇█████████████▇█</td></tr><tr><td>train_auc</td><td>▁▂▅▆▆▇▇▇▇▇▇▇███████▇████▇███████████████</td></tr><tr><td>train_f1</td><td>▃▁▅▆▆▇▇▇▇▆▇▇▇█▇█▇▇█▇████▇█████████████▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▁▁▁▁▂▂▁▁▁▁▁▂▂</td></tr><tr><td>train_loss_step</td><td>█▇▆▅▄▄▄▅▂▄▃▃▁▄▃▃▃▄▃▃▄▂▁▄▃▃▃▁▄▂▁▂▃▄▃▂▃▄▂▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▂▅▅▆▇▇▇▇▇▇███▇▇▇█▇▇█▇█▇██▇█▇▇█▇████▇███</td></tr><tr><td>val_auc</td><td>▁▅▅▆▇▇▇▇████████████████████████████████</td></tr><tr><td>val_f1</td><td>▅▁▆▆▇▇▇▇████████▇█▇████▇██▇██▇██████▇███</td></tr><tr><td>val_loss_epoch</td><td>██▅▅▄▃▃▃▂▃▂▂▂▁▂▂▂▁▃▂▂▂▂▂▂▂▂▁▂▃▂▂▂▂▁▁▁▂▁▂</td></tr><tr><td>val_loss_step</td><td>█▇▄▇▄▃▆▃▃▅▃▆▅▂▅▄▄▂▆▃▄▃▅▄▄▄▃▃▃▆▃▄▃▄▃▄▁▅▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84475</td></tr><tr><td>train_auc</td><td>0.91251</td></tr><tr><td>train_f1</td><td>0.83835</td></tr><tr><td>train_loss_epoch</td><td>0.39259</td></tr><tr><td>train_loss_step</td><td>0.52767</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.8487</td></tr><tr><td>val_auc</td><td>0.92615</td></tr><tr><td>val_f1</td><td>0.85455</td></tr><tr><td>val_loss_epoch</td><td>0.36378</td></tr><tr><td>val_loss_step</td><td>0.37408</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/la4opld4' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/la4opld4</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_120006-la4opld4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_122225-6nljykre</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6nljykre' target=\"_blank\">GCN_4_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6nljykre' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6nljykre</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_4\\attention2\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 1.1 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "1.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇▇▇▇██▇█▇██████████████████████████</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇▇▇▇█▇█▇▇█████████████████████████</td></tr><tr><td>train_f1</td><td>▁▄▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇█▇▇▇▇███████████▇███</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▃▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▁▁▁▁▁▂▁▁▁▁▂▁▁▂▁▁▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▅▅▄▄▂▄▂▃▄▄▄▄▃▄▄▄▄▄▃▃▄▁▄▆▄▃▃▄▄▃▂▂▄▃▃▃▃▄▆</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▇▅▇▇▆█▄██▇███▇█▇███▇▇█▇▇█▇▇▇▇█▇▇█▇███▇█</td></tr><tr><td>val_auc</td><td>▁▅▆▇▇▇▇▇██▇▇███▇███▇▇█▇██▇██▇██▇████▇███</td></tr><tr><td>val_f1</td><td>▁▇▆██▇█▅██████▇█████████▇████▇█▇██▇███▇█</td></tr><tr><td>val_loss_epoch</td><td>█▃▆▃▃▅▂█▁▁▃▂▂▂▃▂▃▂▂▂▂▂▁▃▃▂▃▂▂▄▂▅▃▂▅▂▂▁▄▂</td></tr><tr><td>val_loss_step</td><td>█▅▆▄▃▆▅▅▁▂▅▃▅▅▅▅▅▄▃▄▅▁▃▄▂▂▄▃▂▆▄█▅▄▆▃▃▁▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83766</td></tr><tr><td>train_auc</td><td>0.89926</td></tr><tr><td>train_f1</td><td>0.83404</td></tr><tr><td>train_loss_epoch</td><td>0.40556</td></tr><tr><td>train_loss_step</td><td>0.53616</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82506</td></tr><tr><td>val_auc</td><td>0.91197</td></tr><tr><td>val_f1</td><td>0.82629</td></tr><tr><td>val_loss_epoch</td><td>0.42152</td></tr><tr><td>val_loss_step</td><td>0.48324</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6nljykre' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6nljykre</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_122225-6nljykre\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_124439-yff1zuzq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yff1zuzq' target=\"_blank\">GraphConv_4_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yff1zuzq' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yff1zuzq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_16_onehot_4\\attention2\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 2.1 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "2.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eb0b38f5f654e1e88d7c0f0b996450f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▇▇▇▇▇▇█▇▇▇█████▇█████████████████████</td></tr><tr><td>train_auc</td><td>▁▅▇▇▇▇▇█▇██▇████████████████████████████</td></tr><tr><td>train_f1</td><td>▁▄▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇████▇▇█▇█▇▇███▇▇▇██</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▂▂▁▁▁▁▂▁▁▂▁▂▂▁▁▁▂▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>▇▅▅▄▃▃▃▂▅▂▄▄▅▃▃▃▃▁▂▂▃▁▂▃▃▂▃▄▄▃▁▂▃▄▃▂▄▃▃█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇█████▇▇█▇▆▇██▇▇▇█▇█▆▆▇▇</td></tr><tr><td>val_auc</td><td>▁▆▇▇▇███████████████████████████████████</td></tr><tr><td>val_f1</td><td>▁▃▆▅▇▇▆▇▇▇█▇▇▇▇▇▇▇██▇█▇▇█▇▇██▇▇▇▇▇▇▇▅▇▆▇</td></tr><tr><td>val_loss_epoch</td><td>█▅▂▃▂▂▂▂▂▂▁▂▂▂▂▁▂▂▁▂▂▂▂▂▃▃▁▁▁▃▂▁▂▂▁▂▃▂▃▂</td></tr><tr><td>val_loss_step</td><td>█▆▃▅▃▅▄▄▅▄▂▅▄▃▃▂▇▄▃▆▄▄▅▆▆▇▁▂▃▆▃▂▄▃▃▅▄▁▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85124</td></tr><tr><td>train_auc</td><td>0.91983</td></tr><tr><td>train_f1</td><td>0.84597</td></tr><tr><td>train_loss_epoch</td><td>0.38424</td></tr><tr><td>train_loss_step</td><td>0.74084</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.84397</td></tr><tr><td>val_auc</td><td>0.92176</td></tr><tr><td>val_f1</td><td>0.86307</td></tr><tr><td>val_loss_epoch</td><td>0.38214</td></tr><tr><td>val_loss_step</td><td>0.42517</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yff1zuzq' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yff1zuzq</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_124439-yff1zuzq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_130556-bnp1bdla</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/bnp1bdla' target=\"_blank\">GCN_4_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/bnp1bdla' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/bnp1bdla</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_4\\mean\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 3.8 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb3d0489a84c4c96b2a122db690c6781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇▇▇█▇▇▇█▇▇▇▇▇▇▇▇█▇█▇▇█████▇███▇█▇██</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇▇█▇▇▇█▇██▇██▇██▇█████████████████</td></tr><tr><td>train_f1</td><td>▁▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇█▇█▇▇█████▇███▇█▇██</td></tr><tr><td>train_loss_epoch</td><td>█▃▃▂▃▂▂▂▂▃▂▂▂▂▂▂▂▂▁▂▂▁▂▂▁▂▁▁▁▂▁▂▁▁▁▂▁▂▂▂</td></tr><tr><td>train_loss_step</td><td>█▅▄▄█▂▅▄▃▄▆▅▄▆▃▄▅▇▅▃▃▃▅▃▃▃▃▁▃▄▄▁▅▅▂▃▄▄▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▅▁▄▆▆▆▇▇▇▇▆▆█▇▇▆▇█▇▇▇▇█▇▆▇▆▆█▇▇▇▇██▅▇▆▆▇</td></tr><tr><td>val_auc</td><td>▁▅▇▇▇▇▇▇▇▇██▇▇██▇█▇██▇█████▇█▇█▇▇▇██▇▇▇▇</td></tr><tr><td>val_f1</td><td>▅▁▄▆▆▆█▇▇▇▆▆██▇▆▇██▇▇██▇▆█▆▆██▇▇███▅█▆▆█</td></tr><tr><td>val_loss_epoch</td><td>▇█▆▄▂▄▂▂▃▂▅▄▂▂▂▃▁▁▁▃▄▂▁▁▄▂▄▄▂▁▂▂▁▂▂▅▂▃▄▂</td></tr><tr><td>val_loss_step</td><td>▆▆█▅▂▄▃▃▃▃▅▅▅▂▂▄▂▃▂▅▇▄▃▂▆▅▅▅▄▁▄▄▃▃▄▃▄▄▅▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84829</td></tr><tr><td>train_auc</td><td>0.9174</td></tr><tr><td>train_f1</td><td>0.84434</td></tr><tr><td>train_loss_epoch</td><td>0.3676</td></tr><tr><td>train_loss_step</td><td>0.3274</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82742</td></tr><tr><td>val_auc</td><td>0.91185</td></tr><tr><td>val_f1</td><td>0.84886</td></tr><tr><td>val_loss_epoch</td><td>0.37907</td></tr><tr><td>val_loss_step</td><td>0.34908</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/bnp1bdla' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/bnp1bdla</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_130556-bnp1bdla\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_132645-bd6uxhwk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/bd6uxhwk' target=\"_blank\">GraphConv_4_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/bd6uxhwk' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/bd6uxhwk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_4\\mean\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 7.3 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "7.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.9 K     Total params\n",
      "0.031     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇█▇▇█████▇█▇████</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇▇▇▇▇▇█▇██████████████████████████</td></tr><tr><td>train_f1</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇██▇█▇▇███████████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▁▂▁▁▁▁▁▂▁▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▄▃▄▃▄▄▃▃▃▃▃▄▂▅▂▄▅▃▄▅▃▂▃▂▃▄▄▂▃▂▃▄▄▃▃▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▆▇▇▇▇█▇█▇█▇██▇█▇▇▇▇███▇▇▄▇▇▇▇█▇▇▇▇▇▇█▇</td></tr><tr><td>val_auc</td><td>▁▆▇█▇█████████████████████████████▇█▇██▇</td></tr><tr><td>val_f1</td><td>▂▆▇▆██▇███▇▇▇█▇▇█▇▇▇▇█▇█▇▇▁▇▇▇█▇▇▇▇▇▇▆█▇</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▂▂▂▁▁▂▂▂▁▂▂▂▂▂▂▁▂▃▂▂▂▂▂▆▂▃▃▂▂▂▂▂▁▂▃▂▂</td></tr><tr><td>val_loss_step</td><td>▇▄▃▄▄▅▃▃▃▄▅▂▅▃▄▄▅▃▂▄▇▃▄▄▃▃█▄▇▅▁▅▄▄▂▃▄▅▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87072</td></tr><tr><td>train_auc</td><td>0.93975</td></tr><tr><td>train_f1</td><td>0.86799</td></tr><tr><td>train_loss_epoch</td><td>0.30945</td></tr><tr><td>train_loss_step</td><td>0.21029</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.84397</td></tr><tr><td>val_auc</td><td>0.91413</td></tr><tr><td>val_f1</td><td>0.85333</td></tr><tr><td>val_loss_epoch</td><td>0.39306</td></tr><tr><td>val_loss_step</td><td>0.41687</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/bd6uxhwk' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/bd6uxhwk</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_132645-bd6uxhwk\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_134758-zw25eq08</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zw25eq08' target=\"_blank\">GCN_4_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zw25eq08' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zw25eq08</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_4\\max\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 3.8 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▁▂▄▅▄▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇███▇██████████</td></tr><tr><td>train_auc</td><td>▁▁▁▂▂▃▄▄▄▃▄▃▃▄▄▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇█▇███</td></tr><tr><td>train_f1</td><td>▂▃▁▃▄▃▃▅▅▅▅▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇█▇▇▇████████▇█</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▆▆▆▅▅▅▅▅▅▅▂▆▅▄▄▅▅▄▄▅▃▃▄▂▃▁▂▂▄▃▃▄▃▄▅▃▃▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▁▃▆▆▆▆▆▆▆▅▆▆▆▆▆▆▇▄▇▆▆▇▆▇▇▆▇▇█▇█▆██▆▇▆█▇</td></tr><tr><td>val_auc</td><td>▁▂▃▆▅▆▆▅▅▅▅▅▆▆▆▇▇▇▆▇▇▇████▇▇█████████▇▇▇</td></tr><tr><td>val_f1</td><td>▅▅▅▆▆▆▆▆▇▆▆▆▇▇▆▆▇▇▁▇▇▅▇▅▇▇▅█▆█▆█▅▇▇▅▅▅█▇</td></tr><tr><td>val_loss_epoch</td><td>████▇▆▆▆▅▆▆▅▅▄▅▅▄▅▅▅▄▄▃▃▂▂▃▂▂▁▁▁▂▂▁▂▂▂▁▂</td></tr><tr><td>val_loss_step</td><td>████▇▆▇▆▆▅▆▇▆▄▄▆▄▅▄▆▅▆▄▄▃▅▄▃▄▂▂▃▁▄▂▁▄▃▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77155</td></tr><tr><td>train_auc</td><td>0.81704</td></tr><tr><td>train_f1</td><td>0.77141</td></tr><tr><td>train_loss_epoch</td><td>0.48217</td></tr><tr><td>train_loss_step</td><td>0.50801</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.77069</td></tr><tr><td>val_auc</td><td>0.87104</td></tr><tr><td>val_f1</td><td>0.77701</td></tr><tr><td>val_loss_epoch</td><td>0.47134</td></tr><tr><td>val_loss_step</td><td>0.53851</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zw25eq08' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zw25eq08</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_134758-zw25eq08\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_141039-txbbh8ox</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/txbbh8ox' target=\"_blank\">GraphConv_4_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/txbbh8ox' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/txbbh8ox</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_4\\max\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 7.3 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "7.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.9 K     Total params\n",
      "0.031     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▃▄▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇███▇▇██████▇▇██▇██▇██</td></tr><tr><td>train_auc</td><td>▃▃▄▄▃▂▁▁▂▂▂▁▁▃▃▃▄▄▄▅▃▄▄▆▄▅▅▅▆▅▅▅▇▇▇▇▇▆▇█</td></tr><tr><td>train_f1</td><td>▂▁▃▅▆▆▇▇▇▇▇▇▇▇▇▇█▇████▇██████████████▇██</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▄▄▄▃▃▃▃▂▃▃▂▃▃▃▂▃▂▂▂▃▂▁▃▂▂▂▂▂▃▁▂▂▂▂▃▁▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▂▄▆▆▇▇▇▇▆▇▇▇▆████▇▇███▇███▇▇▇███▇▇▇▇█▇▇</td></tr><tr><td>val_auc</td><td>▆▅▇▇▆▄▃▂▃▁▂▂▃▅▇▇▇████▇██████████████████</td></tr><tr><td>val_f1</td><td>▁▃▆▇▇███▇▇█▇█▆████▇▇██████████████████▇█</td></tr><tr><td>val_loss_epoch</td><td>█▇▆▆▅▅▄▄▄▄▄▄▄▄▃▂▃▂▃▃▃▃▃▃▂▂▃▂▂▂▂▂▁▂▂▁▁▁▃▂</td></tr><tr><td>val_loss_step</td><td>█▇▆▆▅▆▄▄▆▄▄▅▆▄▄▃▅▃▂▅▄▃▄▃▃▂▄▂▆▄▄▃▃▃▂▃▁▃▆▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.82704</td></tr><tr><td>train_auc</td><td>0.78656</td></tr><tr><td>train_f1</td><td>0.8208</td></tr><tr><td>train_loss_epoch</td><td>0.42218</td></tr><tr><td>train_loss_step</td><td>0.3305</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80851</td></tr><tr><td>val_auc</td><td>0.89202</td></tr><tr><td>val_f1</td><td>0.8357</td></tr><tr><td>val_loss_epoch</td><td>0.46925</td></tr><tr><td>val_loss_step</td><td>0.50524</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/txbbh8ox' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/txbbh8ox</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_141039-txbbh8ox\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_143311-p99o5dz7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/p99o5dz7' target=\"_blank\">GCN_4_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/p99o5dz7' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/p99o5dz7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_4\\sum\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 3.8 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da11fa2f53cb42d78df83bab8b090b3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇██▇█▇███▇███████████</td></tr><tr><td>train_auc</td><td>▄▄▂▂▁▁▂▃▃▂▃▂▃▂▃▃▃▅▅▅▇▇▆▆▅▆▆▅▇▆▆▄▅▇▆▅▆▇██</td></tr><tr><td>train_f1</td><td>▁▄▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇██▇█▇███████████████</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▃▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▂▂▂▁▂▂▁▁▂▂▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▇▅▇▆▆▇▆▇█▆▇▇▆▆▅▇▅▇▇▆██▆▇█▇▆▆▇▇███▇▆▇▆▅▇</td></tr><tr><td>val_auc</td><td>▇▇▂▁▁▁▂▄▆▁▃▄▆▁▇█████████████████████████</td></tr><tr><td>val_f1</td><td>▁▇▅█▇▇▇▆▇█▇▇▇▆▆▆▇▆▇▇▆██▆▇█▇▇▆▇████▇▆▇▆▅▇</td></tr><tr><td>val_loss_epoch</td><td>█▄▆▃▃▃▃▃▂▂▄▃▃▃▅▄▂▄▃▂▄▃▁▃▃▂▂▄▃▂▂▁▂▁▄▃▃▃▇▂</td></tr><tr><td>val_loss_step</td><td>▅▆█▅▂▄▄▃▃▃▄▅▆▄▅▃▃▅▃▄▇▅▃▂▅▆▃▄▄▁▄▄▅▃▆▂▃▄█▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83353</td></tr><tr><td>train_auc</td><td>0.86304</td></tr><tr><td>train_f1</td><td>0.83012</td></tr><tr><td>train_loss_epoch</td><td>0.3801</td></tr><tr><td>train_loss_step</td><td>0.33932</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81087</td></tr><tr><td>val_auc</td><td>0.91395</td></tr><tr><td>val_f1</td><td>0.81043</td></tr><tr><td>val_loss_epoch</td><td>0.43652</td></tr><tr><td>val_loss_step</td><td>0.45355</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/p99o5dz7' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/p99o5dz7</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_143311-p99o5dz7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fecd551b4c74bf890b67bb7fe0aabfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_145514-2cqifybv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/2cqifybv' target=\"_blank\">GraphConv_4_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/2cqifybv' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/2cqifybv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_4\\sum\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 7.3 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "7.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.9 K     Total params\n",
      "0.031     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇█▇▇▇█▇███▇▇▇███████████</td></tr><tr><td>train_auc</td><td>▅▅▃▃▃▃▂▁▁▃▄▆▅▄▅▃▃▃▃▄▄▆▅▆▆▅▄▁▂▄▅▆▃▄▅▃▄▅▃█</td></tr><tr><td>train_f1</td><td>▁▂▃▅▅▆▆▆▇▆▇▇▇▇▇▇▇█████▇███▇▇████████████</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▂▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▆▆▆▆▆▇▇▇▇█▇▇▇█▇██▇█▇███████▇██████████</td></tr><tr><td>val_auc</td><td>▆▅▃▃▃▂▂▁▂▂█▇▇▇▇▆▄▂▅▅█▇████▆▁▂▆██▂▅▆▅▁█▅█</td></tr><tr><td>val_f1</td><td>▁▅▆▅▅▆▆▇▇▇▇▇▇▇▇█▇██▇█▇▇███▇▇█▇██▇██████▇</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▃▂▃▂▂▃▂▃▁▂▂▂▂▂▂▁▂▃▂▂▁▁▁▁▂▁▂▁▂▁▂▁▂▁▁▁▂</td></tr><tr><td>val_loss_step</td><td>█▄▃▄▄▅▄▂▃▄▆▂▅▃▄▃▃▃▂▃▇▃▄▃▂▃▃▅▄▄▁▄▃▂▁▃▃▃▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84652</td></tr><tr><td>train_auc</td><td>0.68093</td></tr><tr><td>train_f1</td><td>0.84281</td></tr><tr><td>train_loss_epoch</td><td>0.3756</td></tr><tr><td>train_loss_step</td><td>0.25477</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83452</td></tr><tr><td>val_auc</td><td>0.88257</td></tr><tr><td>val_f1</td><td>0.85537</td></tr><tr><td>val_loss_epoch</td><td>0.46599</td></tr><tr><td>val_loss_step</td><td>0.44742</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/2cqifybv' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/2cqifybv</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_145514-2cqifybv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_152256-94ocsuok</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/94ocsuok' target=\"_blank\">GCN_4_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/94ocsuok' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/94ocsuok</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_4\\attention\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 3.8 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.018     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac0299abf3847b3911333c0d4a05281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▇▆▇▇▇▇▇▇▇▇██▇█████████████████▇████████</td></tr><tr><td>train_auc</td><td>▁▇▇▇▇▇█▇█▇▇██▇█████████████████▇████████</td></tr><tr><td>train_f1</td><td>▁▆▆▇▇▇▇▇▇▇▇██▇▇█▇██████████████▇████████</td></tr><tr><td>train_loss_epoch</td><td>█▃▃▃▃▃▂▂▂▃▂▂▁▂▂▁▂▁▂▂▂▂▂▁▁▁▂▂▂▁▁▂▁▁▁▁▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▅▅▆▅▄▃▄▃▂▃▃▃▄▅▂▃▂▂▄▂▄▅▂▃▃▄▃▁▃▃▁▁▃▁▃▂▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▄▅▂▆▇▄▇▇▇▃▇█▁▇▇▃▇▇▇▅▇▇▇▇▁▇▅▅▇▇▅█▆▇▃▇▆█▂▂</td></tr><tr><td>val_auc</td><td>▁▅▆▇▇▇▇▇▇▇▇█▇▇▇█▇▇██▇▇▇▇█▇▇▇▇▇▇▇▇█▇█▇█▇█</td></tr><tr><td>val_f1</td><td>▆▆▃▆▇▅▇▇▇▃▇█▁▇▇▃▇▇▇▅▇▇▇▇▁▇▅▆▇▇▆█▆▇▃▇▆█▃▂</td></tr><tr><td>val_loss_epoch</td><td>█▄▅▃▃▄▂▃▂▄▂▁▆▂▂▄▃▂▂▃▂▂▂▂▇▁▄▃▁▃▄▂▂▂▆▂▃▂▅▅</td></tr><tr><td>val_loss_step</td><td>█▅▅▅█▅▅▆▄▄▄▃▅▃▆▄█▃▅▄▄▃▄▆▇▁▅▄▃▇▆▅▃▂▇▄▆▄▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84061</td></tr><tr><td>train_auc</td><td>0.91591</td></tr><tr><td>train_f1</td><td>0.83656</td></tr><tr><td>train_loss_epoch</td><td>0.37211</td></tr><tr><td>train_loss_step</td><td>0.36579</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.74232</td></tr><tr><td>val_auc</td><td>0.92448</td></tr><tr><td>val_f1</td><td>0.69468</td></tr><tr><td>val_loss_epoch</td><td>0.51708</td></tr><tr><td>val_loss_step</td><td>0.50724</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/94ocsuok' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/94ocsuok</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_152256-94ocsuok\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_154547-z2gmi0jp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/z2gmi0jp' target=\"_blank\">GraphConv_4_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/z2gmi0jp' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/z2gmi0jp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_4\\attention\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 7.3 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "7.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.9 K     Total params\n",
      "0.032     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "181bcfa0e866410884b80f606c70f4bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████▇█▇███████████</td></tr><tr><td>train_auc</td><td>▁▄▆▇▇▇▇▇▇▇▇█████████████████████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▇▇▇▇▇▇▇▇▇████████████████▇███████████</td></tr><tr><td>train_loss_epoch</td><td>█▇▅▄▃▃▃▃▂▃▃▂▂▂▂▂▂▃▂▂▂▂▂▂▁▂▂▂▂▁▂▁▁▂▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>▇▆▅▄▂▃▂▃▃▃▃▄▅▃▃▃▂█▂▁▃▂▅▁▂▂▁▂▁▂▃▃▁▃▄▁▃▁▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▆▇▇▇▇███▇███▇████████████████▇█████▇██</td></tr><tr><td>val_auc</td><td>▁▅▆▇▇▇█▇██████████████▇█████████████████</td></tr><tr><td>val_f1</td><td>▁▇▇███████████▇█████████████████████████</td></tr><tr><td>val_loss_epoch</td><td>█▅▄▂▃▁▂▂▂▂▂▁▁▁▃▁▂▂▂▂▂▁▂▂▂▂▂▂▂▃▁▃▃▁▂▁▂▃▃▂</td></tr><tr><td>val_loss_step</td><td>█▆▇▃▄▁▄▄▂▃▅▂▃▂▄▂▆▃▃▃▄▂▂▃▃▄▅▅▃▇▂▆▇▁▄▁▄▅▅▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8719</td></tr><tr><td>train_auc</td><td>0.93285</td></tr><tr><td>train_f1</td><td>0.86695</td></tr><tr><td>train_loss_epoch</td><td>0.33599</td></tr><tr><td>train_loss_step</td><td>0.35549</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.85816</td></tr><tr><td>val_auc</td><td>0.91982</td></tr><tr><td>val_f1</td><td>0.87395</td></tr><tr><td>val_loss_epoch</td><td>0.36312</td></tr><tr><td>val_loss_step</td><td>0.32703</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/z2gmi0jp' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/z2gmi0jp</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_154547-z2gmi0jp\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_160724-u0suxar5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/u0suxar5' target=\"_blank\">GCN_4_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/u0suxar5' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/u0suxar5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_4\\attention2\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 3.8 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "5.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.4 K     Total params\n",
      "0.022     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▇▆▇▇▇▇▇▇▇▇███▇▇█▇▇███▇██████████▇█▇██</td></tr><tr><td>train_auc</td><td>▁▆▇▇▆▇▇▇▇▇▇▇█████▇██████▇███████████████</td></tr><tr><td>train_f1</td><td>▁▆▆▇▆▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇███▇████████▇███▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▄▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▁▂▂▁▂▁▂▂▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>▇▅▄▄▅▅▅▃▄▅▄▆▃▃▅▄▆▅▃▃▄▅█▃▃▅▄▄▃▃▄▅▅▄▃▅▄▂▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▄▂▃▅▆▄▅▆▇█▁▇▄▆█▇▃▇▅▂▇▆▇▃▆▇▇▄█▇▆█▇▇▆▄█▆▇▇</td></tr><tr><td>val_auc</td><td>▁▅▆▆▇▇█▇▇██▇▇██▇██▇█▆▇██▇▆▇█▆█▇██▇▇███▇▇</td></tr><tr><td>val_f1</td><td>▅▂▃▅▆▄▅▇▇█▁█▅▇█▇▄▇▆▃█▇▇▄▆▇█▅█▇▇█▇▇▇▄█▆██</td></tr><tr><td>val_loss_epoch</td><td>▆▆▇▅▄▅▄▂▂▁█▁▅▃▂▃▆▂▄▆▁▃▂▇▃▃▁▅▂▂▃▂▂▂▂▅▁▂▂▂</td></tr><tr><td>val_loss_step</td><td>▇▅▆▆▇▇▅▁▄▃▇▃█▅▄▅▇▃▆▃▂▃▃█▃▄▂▄▅▄▅▅▅▄▅▃▁▁▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86009</td></tr><tr><td>train_auc</td><td>0.92731</td></tr><tr><td>train_f1</td><td>0.85047</td></tr><tr><td>train_loss_epoch</td><td>0.33689</td></tr><tr><td>train_loss_step</td><td>0.1826</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82742</td></tr><tr><td>val_auc</td><td>0.90769</td></tr><tr><td>val_f1</td><td>0.83521</td></tr><tr><td>val_loss_epoch</td><td>0.39861</td></tr><tr><td>val_loss_step</td><td>0.4044</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/u0suxar5' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/u0suxar5</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_160724-u0suxar5\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_163120-5bp3395n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5bp3395n' target=\"_blank\">GraphConv_4_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5bp3395n' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5bp3395n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_32_onehot_4\\attention2\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 7.3 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "8.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.9 K     Total params\n",
      "0.036     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▇▇▇▇▇▇▇▇▇▇█▇█▇███▇▇████▇████████████▇</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇▇▇▇▇▇██▇███████████▇█████████████</td></tr><tr><td>train_f1</td><td>▁▆▇▇▇▇▇█▇▇██▇█████████████▇█████████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▂▁▂▁▁▁▁▁▁▂▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▆▄▄▄▃▄▃▃▄▃▅▄▃▄▄▃▅▂▄▄▁▃▃▄▄▃▃▄▄▄▄▃▄▃▃▅▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▇█▇▇████▇▇█▇▇██▇▇███▇▇▇█▇█████▆▇▇▇▇████</td></tr><tr><td>val_auc</td><td>▁▆▇▇███████████▇████████▇██████▇████████</td></tr><tr><td>val_f1</td><td>▁▆▇▆▅▇█▇█▇▇█▇▆█▇▆▆█▇█▇▇▄▇▇█▇▇█▇▅▇▅▇▆██▇█</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▂▃▃▂▂▂▂▂▃▃▂▂▂▂▃▃▁▃▂▄▄▂▂▃▄▂▂▂▃▃▃▃▂▂▃▃▁</td></tr><tr><td>val_loss_step</td><td>█▂▄▄▆▇▅▃▄▄▃▇▇▅▆▄▄▅▇▂▅▃▅▄▃▂▇█▅▂▄▄▇▄▃▃▂▇▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85419</td></tr><tr><td>train_auc</td><td>0.93002</td></tr><tr><td>train_f1</td><td>0.84874</td></tr><tr><td>train_loss_epoch</td><td>0.32789</td></tr><tr><td>train_loss_step</td><td>0.28364</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.8487</td></tr><tr><td>val_auc</td><td>0.92155</td></tr><tr><td>val_f1</td><td>0.86266</td></tr><tr><td>val_loss_epoch</td><td>0.33001</td></tr><tr><td>val_loss_step</td><td>0.1448</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5bp3395n' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5bp3395n</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_163120-5bp3395n\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_165426-xq2w4zd7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/xq2w4zd7' target=\"_blank\">GCN_4_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/xq2w4zd7' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/xq2w4zd7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_4\\mean\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 13.8 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.9 K    Total params\n",
      "0.064     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇█▇▇█▇██▇█████</td></tr><tr><td>train_auc</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇████▇██▇█████</td></tr><tr><td>train_f1</td><td>▁▆▆▆▇▇▇▇▇▇▇█▇▇█▇████▇▇█▇▇█▇██▇█▇██▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▃▂▃▃▂▂▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▂▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>▇▃▅▅▅▃▃▅▃▄▄▅▂▄▄▃▄▄▅▆▄▂▂▆▃▄▄█▄▅▃▆▄▄▄▄▄▃▅▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▂▆▇▇▇▇▇▇██▇█▇▇▇▇▇▇█▇█▇████▇▄▆████▇▇█▇▇█</td></tr><tr><td>val_auc</td><td>▁▄▇▆▇▇▇▇▇▇▆█▇▇▇▇▆▇█▇█▇██▇▆█▆▇▇▆▇██▇███▇█</td></tr><tr><td>val_f1</td><td>▁▂▇▇▇▇▇████▇█▇████▇█▇█▇█████▅▇████▇▇█▇██</td></tr><tr><td>val_loss_epoch</td><td>██▃▃▂▂▃▂▂▂▂▃▁▂▁▁▁▁▂▁▂▁▂▁▁▁▂▂▅▃▂▁▁▁▂▃▁▃▁▁</td></tr><tr><td>val_loss_step</td><td>█▅▄▄▃▂▄▃▃▂▄▄▃▂▁▃▂▁▃▂▁▂▄▁▄▃▃▅▅▅▂▂▃▂▁▅▄▂▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86305</td></tr><tr><td>train_auc</td><td>0.93547</td></tr><tr><td>train_f1</td><td>0.855</td></tr><tr><td>train_loss_epoch</td><td>0.32265</td></tr><tr><td>train_loss_step</td><td>0.204</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82742</td></tr><tr><td>val_auc</td><td>0.92313</td></tr><tr><td>val_f1</td><td>0.8266</td></tr><tr><td>val_loss_epoch</td><td>0.39701</td></tr><tr><td>val_loss_step</td><td>0.34216</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/xq2w4zd7' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/xq2w4zd7</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_165426-xq2w4zd7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_171641-t6e3gnun</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/t6e3gnun' target=\"_blank\">GraphConv_4_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/t6e3gnun' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/t6e3gnun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_4\\mean\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 26.9 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "29.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "29.0 K    Total params\n",
      "0.116     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇█▇▇██▇██████▇█▇█</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇████████████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇█▇▇██▇██████▇█▇█</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▃▃▃▂▃▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▁▂▁▁▂▂▂▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▅▆▄▃▃▃▅▃▅▅▄▇▃▃▃▄▃▃▂▄▄▃▃▄▃▃▁▃▅▃▃▂▂▄▃▄▃▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▆▇▇▇▆▇▇▇▇█▇▇▇▆▇▇█▇▇▇███▇▇▇█▇▇▆▇▅▇▇▇▇▇▇</td></tr><tr><td>val_auc</td><td>▁▆▇███████▇█▇███▇██▇████████████████████</td></tr><tr><td>val_f1</td><td>▁▅▆▇▇▇▆▇▇▇▆▇▇▇▅▅▆▇█▅▇▇▇▇█▇▅▆█▇▇▅▇▂▆▇▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▂▂▂▄▂▁▁▂▂▁▃▃▁▂▂▁▂▂▂▁▂▃▁▃▂▂▄▂▃▁▅▂▂▃▂▃▃</td></tr><tr><td>val_loss_step</td><td>█▆▃▅▅▄█▄▄▄▆▅▂▆▅▂▄▄▃▄▄▄▃▄▇▁▄▄▄█▄▅▁▅▃▅▄▃▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.89197</td></tr><tr><td>train_auc</td><td>0.95603</td></tr><tr><td>train_f1</td><td>0.88794</td></tr><tr><td>train_loss_epoch</td><td>0.26076</td></tr><tr><td>train_loss_step</td><td>0.13091</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.84397</td></tr><tr><td>val_auc</td><td>0.92237</td></tr><tr><td>val_f1</td><td>0.86076</td></tr><tr><td>val_loss_epoch</td><td>0.4042</td></tr><tr><td>val_loss_step</td><td>0.47069</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/t6e3gnun' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/t6e3gnun</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_171641-t6e3gnun\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_173929-fpczmx9z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fpczmx9z' target=\"_blank\">GCN_4_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fpczmx9z' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fpczmx9z</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_4\\max\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 13.8 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.9 K    Total params\n",
      "0.064     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbd3d549132b4ec18166a441af8093be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██▇▇█▇█▇██▇█▇▇██</td></tr><tr><td>train_auc</td><td>▁▁▁▂▂▁▂▂▂▂▃▅▆▅▆▇▇▇▇▇▇▆▇▇▇▇██▇▇█▇████████</td></tr><tr><td>train_f1</td><td>▁▂▄▄▅▅▅▅▅▆▆▇▆▇▇▇▇▇▇▇▇▆▇▇██▇▇█▇█▇██▇█▇▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▂▂▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▄▄▅▄▄▄▄▄▄▃▅▃▃▃▄▄▃▃▂▃▃▄▃▃▂▅▂▂▁▁▂▂▂▂▂▂▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▆▆▆▆▆▆▁▁▃▄▆▇▅▇▆▄▇█▇▆███▇▇▇▇▇█▇█▇██████</td></tr><tr><td>val_auc</td><td>▁▃▃▃▃▄▄▄▂▆▆▆▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇██▇████▇██▇</td></tr><tr><td>val_f1</td><td>▁▇▇▇▇▇▇▇▁▂▄▅▇█▆▇▇▅▇█▇▆██████▇▇█▇█▇██████</td></tr><tr><td>val_loss_epoch</td><td>█▇▆▆▅▅▆▅▇▇▇▇▄▂▅▃▅█▄▂▃▄▃▂▃▃▂▃▂▃▁▃▁▂▂▁▂▁▂▂</td></tr><tr><td>val_loss_step</td><td>▇▆▆▆▅▅▆▅▇▆█▆▄▃▅▃▅█▅▂▁▅▄▂▆▄▃▅▁▄▃▆▂▂▃▂▂▃▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.82704</td></tr><tr><td>train_auc</td><td>0.86027</td></tr><tr><td>train_f1</td><td>0.82339</td></tr><tr><td>train_loss_epoch</td><td>0.40888</td></tr><tr><td>train_loss_step</td><td>0.37099</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81324</td></tr><tr><td>val_auc</td><td>0.87739</td></tr><tr><td>val_f1</td><td>0.84168</td></tr><tr><td>val_loss_epoch</td><td>0.41766</td></tr><tr><td>val_loss_step</td><td>0.37857</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fpczmx9z' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fpczmx9z</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_173929-fpczmx9z\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_180551-e3v7lgn0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/e3v7lgn0' target=\"_blank\">GraphConv_4_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/e3v7lgn0' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/e3v7lgn0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_4\\max\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 26.9 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "29.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "29.0 K    Total params\n",
      "0.116     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▅▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇█▇████████</td></tr><tr><td>train_auc</td><td>▁▂▂▄▄▄▄▃▅▅▅▅▆▆▆▅▆▇▇▇▇▇▇█▇▇▇▇▇▇▇▇█████▇██</td></tr><tr><td>train_f1</td><td>▁▃▄▅▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇█▇█▇████████</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▂▂▂▂▁▁▁▂▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▇█▄▄▄▅▃▅▄▄▅▅▃▃▂▄▁▂▄▅▂▃▃▂▂▂▂▃▄▂▂▃▂▃▃▃▂▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▆▇▇▇▇▇█▇████▇█▇█▇████▇█▇▇▇▇█▇▇▇▇██▇███</td></tr><tr><td>val_auc</td><td>▁▄▆▇▆▇▇▇▇▇▇▇██▇▇██▇████▇█▇▇█▇█████████▇█</td></tr><tr><td>val_f1</td><td>▁▄▅▅▆▇▇▇▇▇▇▆▇▇▅▇▇▇▆▇█▇▇▇▇▇▅▇▇▇▇▇▇▆██▇▇█▇</td></tr><tr><td>val_loss_epoch</td><td>█▇▅▅▄▃▄▃▃▃▃▃▂▃▃▂▂▂▂▂▂▂▂▂▂▂▄▁▂▂▂▂▁▃▁▁▁▁▂▂</td></tr><tr><td>val_loss_step</td><td>█▇▅▆▅▄▆▃▄▆▅▅▂▄▄▃▁▃▂▃▂▂▃▄▃▁▅▂▃▅▂▄▁▅▁▁▂▁▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85596</td></tr><tr><td>train_auc</td><td>0.90238</td></tr><tr><td>train_f1</td><td>0.85372</td></tr><tr><td>train_loss_epoch</td><td>0.3464</td></tr><tr><td>train_loss_step</td><td>0.36524</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83215</td></tr><tr><td>val_auc</td><td>0.91253</td></tr><tr><td>val_f1</td><td>0.85772</td></tr><tr><td>val_loss_epoch</td><td>0.37863</td></tr><tr><td>val_loss_step</td><td>0.37849</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/e3v7lgn0' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/e3v7lgn0</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_180551-e3v7lgn0\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_182851-1gnp02e9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1gnp02e9' target=\"_blank\">GCN_4_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1gnp02e9' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1gnp02e9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_4\\sum\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 13.8 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.9 K    Total params\n",
      "0.064     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████▇▇████▇██▇█████</td></tr><tr><td>train_auc</td><td>▅▃▁▁▂▂▃▂▃▃▂▂▂▃▃▃▁▁▃▅▅▆▇▇▅▆▇█▇▆▅▄▄▄▂▂▅▆▇▇</td></tr><tr><td>train_f1</td><td>▁▄▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇█▇▇████▇▇████▇██▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▂▂▁▃▁▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▂▅▄▅▅▅▇▅▅▅▅▄▆██▆▆▆█▇▅█▆▇▇▆▅▄▇█▇▇▇▆▆▆▄▆▅</td></tr><tr><td>val_auc</td><td>▆▁▁▁▁▁▃▁▂▁▁▁▁▃▃▁▁▁▂██████████▇▇▇▇▂▁▁████</td></tr><tr><td>val_f1</td><td>▁▂▆▅▆▆▆▇▆▆▆▆▅▇██▆▇▇█▇▆█▆▇▇▆▆▅▇██▇▇▆▇▇▅▇▅</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▃▂▂▂▂▃▃▂▂▃▂▁▁▂▂▂▁▂▄▂▃▁▂▂▃▃▂▁▁▁▂▂▂▂▃▁▂</td></tr><tr><td>val_loss_step</td><td>█▃▃▄▃▂▃▂▄▄▄▃▄▂▁▁▂▃▃▁▁▅▄▂▂▃▃▅▄▄▂▂▂▃▁▅▅▄▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8412</td></tr><tr><td>train_auc</td><td>0.76427</td></tr><tr><td>train_f1</td><td>0.83385</td></tr><tr><td>train_loss_epoch</td><td>0.38205</td></tr><tr><td>train_loss_step</td><td>0.3405</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.63593</td></tr><tr><td>val_auc</td><td>0.90827</td></tr><tr><td>val_f1</td><td>0.50323</td></tr><tr><td>val_loss_epoch</td><td>0.63268</td></tr><tr><td>val_loss_step</td><td>0.60874</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1gnp02e9' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1gnp02e9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_182851-1gnp02e9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_185058-z1y1qf5l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/z1y1qf5l' target=\"_blank\">GraphConv_4_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/z1y1qf5l' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/z1y1qf5l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_4\\sum\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 26.9 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "29.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "29.0 K    Total params\n",
      "0.116     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07e18c2635df4b1bad4a605b9a16d185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇█████▇██</td></tr><tr><td>train_auc</td><td>▁▂▃▄▅▅▅▄▅▄▄▅▅▆▇▇▆▇▆▆▇▇▇▇▇▇▇███▇▆▇▇▇▇▇▆▆█</td></tr><tr><td>train_f1</td><td>▁▃▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇██▇▇█▇█████▇██</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▆▆▆▆▆▇▆▆▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████</td></tr><tr><td>val_auc</td><td>▁▄▇▇▇▇▇▇▇▇▇██████████▇██████████████████</td></tr><tr><td>val_f1</td><td>▁▄▅▅▆▆▆▆▆▆▇▆▇▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▂▂▁▂▁▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▄▂▃▂▂▃▂▂▃▃▃▁▂▂▁▂▁▁▂▂▂▁▂▂▁▂▂▂▃▂▁▁▁▁▂▁▂▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86836</td></tr><tr><td>train_auc</td><td>0.88128</td></tr><tr><td>train_f1</td><td>0.86243</td></tr><tr><td>train_loss_epoch</td><td>0.34026</td></tr><tr><td>train_loss_step</td><td>0.22752</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.87943</td></tr><tr><td>val_auc</td><td>0.91408</td></tr><tr><td>val_f1</td><td>0.89079</td></tr><tr><td>val_loss_epoch</td><td>0.38568</td></tr><tr><td>val_loss_step</td><td>0.38499</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/z1y1qf5l' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/z1y1qf5l</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_185058-z1y1qf5l\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_191242-vwv17pl2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/vwv17pl2' target=\"_blank\">GCN_4_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/vwv17pl2' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/vwv17pl2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_4\\attention\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 13.8 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "16.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "16.0 K    Total params\n",
      "0.064     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▆▇▇▇▇▇▆▆▇▇▇▆▇▆▇▇▇▇▇▇▇▇▇█▇▇█▇▇▇▇▇█▇▇█</td></tr><tr><td>train_auc</td><td>▁▆▆▇▆▇▇▇▇▇▇▇▇▇█▇█▇▇▇▇▇████▇██▇██████████</td></tr><tr><td>train_f1</td><td>▁▅▅▆▆▇▇▇▇▇▆▆▆▇▇▆▇▆▇▇▇▇▇▇▇▇▇█▇▇█▇▇▇▇▇█▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▃▃▂▃▂▂▂▂▂▂▂▂▃▂▃▂▂▂▂▂▂▂▂▂▁▂▂▁▂▁▂▁▂▂▁▂▁</td></tr><tr><td>train_loss_step</td><td>▇▅▆▃▆▄▅▂▄▃▃▄█▄▃▄▃█▅▂▂▄▇▃▄▃█▁▃▄▃▃▁▄▃▂▃▃▅▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▁▇▄▇█▇██▆█▇▇█▆▇▆█▇▇███▇▇▇▇▇▇▇▆▆▇▆██▆██▇</td></tr><tr><td>val_auc</td><td>▁▅▆▇▇▇▇▇███▇██▇██▇█▇▆▇▇▇▇▇█▇████▇▇█▇▇▇▇▇</td></tr><tr><td>val_f1</td><td>▁▁▇▅▇█▇██▇█▇▇█▇█▇█▇▇███▇▇██▇▇█▇▆█▆██▇██▇</td></tr><tr><td>val_loss_epoch</td><td>▄█▂▃▂▁▂▁▁▂▁▂▂▁▃▁▂▁▂▂▁▁▁▂▂▂▁▂▂▂▃▃▁▃▁▁▂▁▂▂</td></tr><tr><td>val_loss_step</td><td>▄█▃▃▂▂▂▁▃▂▂▂▂▃▅▂▃▂▂▂▂▂▂▄▃▂▂▂▂▃▃▃▂▃▁▁▂▁▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86954</td></tr><tr><td>train_auc</td><td>0.9342</td></tr><tr><td>train_f1</td><td>0.86516</td></tr><tr><td>train_loss_epoch</td><td>0.32543</td></tr><tr><td>train_loss_step</td><td>0.29881</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.79905</td></tr><tr><td>val_auc</td><td>0.91757</td></tr><tr><td>val_f1</td><td>0.78803</td></tr><tr><td>val_loss_epoch</td><td>0.47683</td></tr><tr><td>val_loss_step</td><td>0.50147</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/vwv17pl2' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/vwv17pl2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_191242-vwv17pl2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_193503-ud0j6paj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ud0j6paj' target=\"_blank\">GraphConv_4_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ud0j6paj' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ud0j6paj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_4\\attention\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 26.9 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "29.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "29.1 K    Total params\n",
      "0.116     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52cdbb1aa49345499cf8870b525b7b6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████▇██</td></tr><tr><td>train_auc</td><td>▁▄▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████▇██▇█████████████</td></tr><tr><td>train_f1</td><td>▁▄▅▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████▇██</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▄▃▄▃▃▃▃▂▃▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▃▂▂▁▁▁▁▁▂▂▁</td></tr><tr><td>train_loss_step</td><td>██▅▄▃▄▂▃▂▃▁▃▆▁▂▄▂▃▂▃▃▂▂▄▂▃▃▄▅▂▃▃▂▂▁▄▂▁▂▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▅▃▆▆▆▇▇█▇▇▇▇▇▆▇▇█▇▇▅▇▃▅▆▇▇█▇▇█▇███▄▇█▇</td></tr><tr><td>val_auc</td><td>▁▅▆▇▇▇▇████████████████████▇█▇█████▇█▇█▇</td></tr><tr><td>val_f1</td><td>▁▂▅▂▇▆▅█▆▇▇▇▇▆▇▅▇▇█▇▆▄▇▁▄▆▇▇█▇█▇▇▇██▅▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▅▄▅▂▂▃▂▂▂▂▂▂▂▂▂▁▂▂▂▃▃▁▅▄▃▂▂▂▂▂▂▁▂▂▃█▃▂▄</td></tr><tr><td>val_loss_step</td><td>█▅▆▆▄▄▇▅▄▄▄▄▄▃▄▃▃▄▄▄█▄▃▅▆▆▄▅▄▃▄▃▁▃▅▆▅▅▄▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8961</td></tr><tr><td>train_auc</td><td>0.95869</td></tr><tr><td>train_f1</td><td>0.89149</td></tr><tr><td>train_loss_epoch</td><td>0.27197</td></tr><tr><td>train_loss_step</td><td>0.45764</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.85343</td></tr><tr><td>val_auc</td><td>0.91908</td></tr><tr><td>val_f1</td><td>0.8692</td></tr><tr><td>val_loss_epoch</td><td>0.45017</td></tr><tr><td>val_loss_step</td><td>0.59896</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ud0j6paj' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ud0j6paj</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_193503-ud0j6paj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_195749-d6fef9tf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/d6fef9tf' target=\"_blank\">GCN_4_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/d6fef9tf' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/d6fef9tf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_4\\attention2\\GraphLevelGCN exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 13.8 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "20.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.1 K    Total params\n",
      "0.080     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49c512e95b5249fdad78fda86f4d63f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▇▆▇▇▇▇▇▇▇▇▇█▇█▇█▇▇▇██▇▇████████▇██▇█</td></tr><tr><td>train_auc</td><td>▁▆▆▆▇▇▇▇▇▇▇▇▇▇▇███▇█▇▇▇██▇▇████████▇████</td></tr><tr><td>train_f1</td><td>▁▆▆▇▇▆▇▇▇▇▇▇▇▇▇███▇█▇▇▇██▇▇████████▇██▇█</td></tr><tr><td>train_loss_epoch</td><td>█▃▄▃▂▃▂▂▃▂▂▂▂▂▂▂▁▁▂▁▂▂▂▁▂▂▂▂▂▁▂▁▁▂▁▂▂▂▁▁</td></tr><tr><td>train_loss_step</td><td>▇▅▅▆▄█▆▅▅▂▄▃▃▅▇▃▂▁▃▄▃▅▁▃▅▂▂▇▆▅▃▅▂▃▃▃▅▃▄▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▅▅▇▇▇██▇██▇██▇▇▇█▆██▆▅███▇██▇▇██▇▇████</td></tr><tr><td>val_auc</td><td>▁▄▆▇▇▆▇▇▆▆▆▆▇▇▇▆▇█▇▇█▇█▇▇▇▇▇▇▇▅▇▇▆▇███▇▇</td></tr><tr><td>val_f1</td><td>▁▄▆▆▇▇▇██▇██▇███▇▇█▇██▇▆███████▇████████</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▃▂▂▂▁▁▂▁▁▂▁▂▂▂▂▁▃▁▁▂▄▁▁▁▁▂▁▁▂▁▁▂▁▂▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▅▅▅▂▃▃▂▁▄▃▁▃▁▃▂▂▂▂▅▂▂▃▇▁▂▁▂▄▁▂▃▂▂▃▂▃▃▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85832</td></tr><tr><td>train_auc</td><td>0.93052</td></tr><tr><td>train_f1</td><td>0.85056</td></tr><tr><td>train_loss_epoch</td><td>0.33215</td></tr><tr><td>train_loss_step</td><td>0.22202</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83452</td></tr><tr><td>val_auc</td><td>0.91825</td></tr><tr><td>val_f1</td><td>0.84716</td></tr><tr><td>val_loss_epoch</td><td>0.36878</td></tr><tr><td>val_loss_step</td><td>0.37621</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/d6fef9tf' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/d6fef9tf</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_195749-d6fef9tf\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_202039-e9topdls</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/e9topdls' target=\"_blank\">GraphConv_4_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/e9topdls' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/e9topdls</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\13PPI\\Graph_GNNs_Kfold\\GIN_4_64_onehot_4\\attention2\\GraphLevelGraphConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 26.9 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "33.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "33.2 K    Total params\n",
      "0.133     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd85df26203a4833bb33617c9284e0b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██████▇█████████▇█▇</td></tr><tr><td>train_auc</td><td>▁▅▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇█▇█▇████████████████▇██</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██████▇█████████▇█▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▃▃▃▃▃▂▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂▂▁▁▁▁▁▁▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▇▆▇▆▅▅▅▄▆▃▅▄▅▄▄▄█▄▃▅▅▃▃▄▅▄▁▄▃▄▄▄▃▄▅▃▄▅▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▅▆▆▆▇▇▇█▇▆▇▇▆▇▇▇█▇▇▇▆▇▇▆▇▇▇██▆▆▆▇▇▅▆▇▅</td></tr><tr><td>val_auc</td><td>▁▆▇▇▇▇█████████▇▇██▇██▇█▇▇█████▇████▇██▇</td></tr><tr><td>val_f1</td><td>▁▄▆▆▆▆▇▇▇█▇▇▇▇▆▇▆█▇▇▆▇▅▇▇▆▇▇▇██▆▆▆▆█▆▅▇▃</td></tr><tr><td>val_loss_epoch</td><td>█▄▄▂▂▃▃▂▃▁▂▃▃▃▄▂▂▁▂▂▂▃▂▂▃▃▂▃█▃▁▇▅▆▅▄█▂▂▄</td></tr><tr><td>val_loss_step</td><td>▄▃▃▂▂▃▄▃▃▁▂▃▃▃▃▂▂▁▂▃▂▃▂▃▃▂▂▃█▄▂▆▄▄▄▅▃▂▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87131</td></tr><tr><td>train_auc</td><td>0.94691</td></tr><tr><td>train_f1</td><td>0.86724</td></tr><tr><td>train_loss_epoch</td><td>0.28751</td></tr><tr><td>train_loss_step</td><td>0.17835</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.8227</td></tr><tr><td>val_auc</td><td>0.91203</td></tr><tr><td>val_f1</td><td>0.82916</td></tr><tr><td>val_loss_epoch</td><td>0.41064</td></tr><tr><td>val_loss_step</td><td>0.42043</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_4_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/e9topdls' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/e9topdls</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_202039-e9topdls\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k_folds = 5\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_ids, valid_ids) in enumerate(kfold.split(dataset_filtered)):\n",
    "    train_subset = dataset_filtered.index_select(train_ids.tolist())\n",
    "    val_subset = dataset_filtered.index_select(valid_ids.tolist())\n",
    "    for NUM_LAYERS, HIDDEN_CHANNELS, pool, model in list(itertools.product(*[num_layers, hiddens, pools, models])):\n",
    "            # Path to the folder where the pretrained models are saved\n",
    "        CHECKPOINT_PATH = checkpoint_folder / f'GIN_{NUM_LAYERS}_{HIDDEN_CHANNELS}_onehot_{fold}' / pool\n",
    "        CHECKPOINT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Skip already trained kfold and pool\n",
    "        checkpoint = CHECKPOINT_PATH / f\"GraphLevel{model}\" / f\"GraphLevel{model}.ckpt\" \n",
    "        if checkpoint.exists():\n",
    "            print(checkpoint)\n",
    "            continue\n",
    "\n",
    "        # Run training\n",
    "        run = wandb.init(project=project_name, name=f'{model}_{NUM_LAYERS}_{HIDDEN_CHANNELS}_onehot_{fold}', \n",
    "                        group=f'{model}_{pool}', \n",
    "                        # mode=\"disabled\"\n",
    "                        )\n",
    "        PPIGraph.train_graph_classifier_kfold(model, \n",
    "                                                train_subset, \n",
    "                                                val_subset, \n",
    "                                                dataset, \n",
    "                                                CHECKPOINT_PATH, \n",
    "                                                AVAIL_GPUS, \n",
    "                                                in_channels=13,\n",
    "                                                hidden_channels=HIDDEN_CHANNELS, \n",
    "                                                out_channels = HIDDEN_CHANNELS,\n",
    "                                                num_layers=NUM_LAYERS, \n",
    "                                                epochs=epochs,\n",
    "                                                embedding=False,\n",
    "                                                batch_size=128, \n",
    "                                                graph_pooling=pool)\n",
    "        run.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
