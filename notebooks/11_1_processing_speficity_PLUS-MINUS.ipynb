{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\h5py\\__init__.py:36: UserWarning: h5py is running against HDF5 1.14.3 when it was built against 1.14.2, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.io\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import trange, tqdm, tqdm_notebook\n",
    "from joblib import Parallel, delayed\n",
    "import re\n",
    "import h5py\n",
    "import tifffile as tiff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = (Path().cwd().parents[0] / 'data').absolute()\n",
    "data_processed = data_dir / 'processed'\n",
    "data_raw = r'Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\Specificity experiments\\PLUS-MINUS specificity'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    " \n",
    "os.environ['JDK_HOME'] = \"C:\\Program Files\\Java\\jdk-17\"\n",
    "os.environ['JAVA_HOME'] = \"C:\\Program Files\\Java\\jdk-17\"\n",
    "\n",
    "os.environ['PATH'] += ';C:\\\\Program Files\\\\Java\\\\jdk-17\\\\jre\\\\bin\\\\server\\\\;C:\\\\Program Files\\\\Java\\\\jdk-17\\\\bin\\\\;C:\\\\Program Files\\\\Java\\\\jdk-17\\\\bin\\\\jar.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers_map = {\n",
    "    'cycle1': {\n",
    "        1: 'DNA', \n",
    "        4: 'PLUS Perk',\n",
    "    },\n",
    "    'cycle2': {\n",
    "        1: 'DNA', \n",
    "        4: 'MINUS Yap',\n",
    "    },\n",
    "    'cycle3': {\n",
    "        1: 'DNA', \n",
    "        4: 'Cyclin E/CDK2',\n",
    "    },\n",
    "    'cycle4': {\n",
    "        1: 'DNA',\n",
    "        2: 'Concanavalin A',\n",
    "        3: 'Phalloidin',  \n",
    "        4: 'WGA',\n",
    "    },\n",
    "}\n",
    "\n",
    "def get_info(data_raw, marker_dict):\n",
    "    conditions = []\n",
    "    fovs = []\n",
    "    cycles = []\n",
    "    channels = []\n",
    "    markers = []\n",
    "    paths = [] \n",
    "    \n",
    "    # Loop through image folder\n",
    "    for (dirpath, dirnames, filenames) in os.walk(data_raw):\n",
    "        if 'after nuclease' in dirpath or 'Test' in dirpath or 'dont use' in dirpath:\n",
    "            continue\n",
    "        \n",
    "            \n",
    "        for name in sorted(filenames):\n",
    "            if \"tif\" in name and \"sti\" in name \\\n",
    "            and 'overlay' not in name \\\n",
    "            and 'Composite' not in name:\n",
    "                # Get information from image name\n",
    "                condition = 'Control'\n",
    "                                \n",
    "                d_split = dirpath.split('\\\\')\n",
    "                n_split = name.split('_')\n",
    "                ch = int(n_split[-1][-5])\n",
    "\n",
    "                cycle = d_split[-1].split('_')[3][-1]\n",
    "                cycle = 'cycle'+cycle\n",
    "                try: marker = marker_dict[cycle][ch] \n",
    "                except: continue\n",
    "        \n",
    "                conditions.append(condition)\n",
    "                fovs.append(d_split[-1].split('_')[-1])\n",
    "                cycles.append(cycle)\n",
    "                channels.append(ch)\n",
    "                markers.append(marker)\n",
    "                paths.append(os.path.join(dirpath, name))\n",
    "                \n",
    "    info = {\n",
    "            \"Condition\": conditions,\n",
    "            \"FOV\": fovs,\n",
    "            \"Cycle\": cycles,\n",
    "            \"Channels\": channels,\n",
    "            \"Markers\": markers,\n",
    "            \"Path\": paths\n",
    "        }\n",
    "\n",
    "    df = pd.DataFrame(info)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created df\n"
     ]
    }
   ],
   "source": [
    "df_meta_path = data_dir / 'specificity_PlusMinus' / 'metadata' / 'info.csv'\n",
    "df_meta_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_exist = df_meta_path.is_file()\n",
    "\n",
    "if not df_exist:\n",
    "    print('Created df')\n",
    "    df = get_info(data_raw, markers_map)\n",
    "    df.to_csv(df_meta_path, index=False)\n",
    "else:\n",
    "    print('Loaded df')\n",
    "    df = pd.read_csv(df_meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Condition</th>\n",
       "      <th>FOV</th>\n",
       "      <th>Cycle</th>\n",
       "      <th>Channels</th>\n",
       "      <th>Markers</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Control</td>\n",
       "      <td>FW1</td>\n",
       "      <td>cycle1</td>\n",
       "      <td>1</td>\n",
       "      <td>DNA</td>\n",
       "      <td>y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Control</td>\n",
       "      <td>FW1</td>\n",
       "      <td>cycle1</td>\n",
       "      <td>4</td>\n",
       "      <td>PLUS Perk</td>\n",
       "      <td>y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Control</td>\n",
       "      <td>FW1</td>\n",
       "      <td>cycle2</td>\n",
       "      <td>1</td>\n",
       "      <td>DNA</td>\n",
       "      <td>y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Control</td>\n",
       "      <td>FW1</td>\n",
       "      <td>cycle2</td>\n",
       "      <td>4</td>\n",
       "      <td>MINUS Yap</td>\n",
       "      <td>y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Control</td>\n",
       "      <td>FW1</td>\n",
       "      <td>cycle3</td>\n",
       "      <td>1</td>\n",
       "      <td>DNA</td>\n",
       "      <td>y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Control</td>\n",
       "      <td>FW1</td>\n",
       "      <td>cycle3</td>\n",
       "      <td>4</td>\n",
       "      <td>Cyclin E/CDK2</td>\n",
       "      <td>y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Control</td>\n",
       "      <td>FW1</td>\n",
       "      <td>cycle4</td>\n",
       "      <td>1</td>\n",
       "      <td>DNA</td>\n",
       "      <td>y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Control</td>\n",
       "      <td>FW1</td>\n",
       "      <td>cycle4</td>\n",
       "      <td>2</td>\n",
       "      <td>Concanavalin A</td>\n",
       "      <td>y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Control</td>\n",
       "      <td>FW1</td>\n",
       "      <td>cycle4</td>\n",
       "      <td>3</td>\n",
       "      <td>Phalloidin</td>\n",
       "      <td>y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Control</td>\n",
       "      <td>FW1</td>\n",
       "      <td>cycle4</td>\n",
       "      <td>4</td>\n",
       "      <td>WGA</td>\n",
       "      <td>y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Condition  FOV   Cycle  Channels         Markers  \\\n",
       "0   Control  FW1  cycle1         1             DNA   \n",
       "1   Control  FW1  cycle1         4       PLUS Perk   \n",
       "2   Control  FW1  cycle2         1             DNA   \n",
       "3   Control  FW1  cycle2         4       MINUS Yap   \n",
       "4   Control  FW1  cycle3         1             DNA   \n",
       "5   Control  FW1  cycle3         4   Cyclin E/CDK2   \n",
       "6   Control  FW1  cycle4         1             DNA   \n",
       "7   Control  FW1  cycle4         2  Concanavalin A   \n",
       "8   Control  FW1  cycle4         3      Phalloidin   \n",
       "9   Control  FW1  cycle4         4             WGA   \n",
       "\n",
       "                                                Path  \n",
       "0  y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...  \n",
       "1  y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...  \n",
       "2  y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...  \n",
       "3  y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...  \n",
       "4  y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...  \n",
       "5  y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...  \n",
       "6  y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...  \n",
       "7  y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...  \n",
       "8  y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...  \n",
       "9  y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Registration ImageJ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile as tf\n",
    "from PIL import Image\n",
    "import PIL.Image\n",
    "PIL.Image.MAX_IMAGE_PIXELS = 933120000\n",
    "import shutil\n",
    "from datetime import date, datetime\n",
    "import skimage.io \n",
    "from skimage import util\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure, util\n",
    "\n",
    "def contrast_str(img, n_min=0.1, n_max=100):\n",
    "    p2, p98 = np.percentile(img, (n_min, n_max))\n",
    "    img_rescale = exposure.rescale_intensity(img, in_range=(p2, p98))\n",
    "    img_rescale = util.img_as_ubyte(img_rescale)\n",
    "    return img_rescale\n",
    "\n",
    "def make_imgs_same_dim(imgs):\n",
    "    # Get max dimensions\n",
    "    shapes = np.array([img.shape[1:] for img in imgs])\n",
    "    min_x, min_y = shapes.min(axis=0)\n",
    "    imgs_cropped = [img[:, :min_x, :min_y] for img in imgs]\n",
    "    # imgs_cropped[0] = contrast_str(imgs_cropped[0])\n",
    "    return imgs_cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thu71\\AppData\\Local\\Temp\\ipykernel_2820\\171642068.py:9: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for cycle, df_cycle in df_group.groupby(['Cycle']):\n"
     ]
    }
   ],
   "source": [
    "regSavePath = data_dir /'specificity_PlusMinus'  /'imgs' / 'registered_imagej'\n",
    "regSavePath.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "chs = [1, 2, 3, 4]\n",
    "group = df.groupby(['Condition', 'FOV'])\n",
    "for name, df_group in group:\n",
    "    path = df_group.iloc[0].Path\n",
    "    \n",
    "    for cycle, df_cycle in df_group.groupby(['Cycle']):\n",
    "        cycle = cycle[-1]\n",
    "        channel = df_cycle.Channels.tolist()\n",
    "        imgs = [cv2.imread(f, cv2.IMREAD_GRAYSCALE) for f in df_cycle.Path.tolist()]\n",
    "        \n",
    "        for ch in chs: \n",
    "            # Save path per Channel\n",
    "            folderPath = os.path.join(regSavePath, '_'.join(name), 'Original', 'CH' + str(ch)) # 1 index\n",
    "            if not os.path.exists(folderPath):\n",
    "                os.makedirs(folderPath, exist_ok = True)\n",
    "            \n",
    "            fileOut = 'CH' + str(ch) + '_Cycle' + str(cycle).zfill(2) + '.tif'\n",
    "            fileOut = os.path.join(folderPath, fileOut)\n",
    "            if os.path.exists(fileOut):\n",
    "                continue\n",
    "\n",
    "            if ch in channel:\n",
    "                if ch == 1:\n",
    "                    img = contrast_str(imgs[list(channel).index(ch)], n_min=0.1, n_max=99.9)\n",
    "                else:\n",
    "                    img = imgs[list(channel).index(ch)]\n",
    "                tf.imwrite(fileOut, img, photometric = 'minisblack', bigtiff = True)\n",
    "\n",
    "            else:\n",
    "                emptyImage = np.zeros(imgs[0].shape, np.uint8)\n",
    "                # print('Dont exist create empty image', cycle, ch)\n",
    "                tf.imwrite(fileOut, emptyImage, photometric = 'minisblack', bigtiff = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runMacro(\"y:/coskun-lab/Thomas/23_PLA_revision/data/specificity_PlusMinus/imgs/registered_imagej/Control_FW1/Original/CH1/18Dec2023_register_transforms.ijm\");\n"
     ]
    }
   ],
   "source": [
    "group = df.groupby(['Condition', 'FOV'])\n",
    "chs = [1, 2, 3, 4]\n",
    "\n",
    "for name, channels in group:\n",
    "    name = '_'.join(name)\n",
    "    '''\n",
    "    run(\"Register Virtual Stack Slices\", \"source=[Y:/coskun-lab/Nicky/07 Temp/register large stitch] output=[Y:/coskun-lab/Nicky/07 Temp/register output] feature=Rigid registration=[Rigid                -- translate + rotate                  ] advanced shrinkage save save_dir=[Y:/coskun-lab/Nicky/07 Temp/register output] initial_gaussian_blur=1.60 steps_per_scale_octave=3 minimum_image_size=64 maximum_image_size=1024 feature_descriptor_size=8 feature_descriptor_orientation_bins=8 closest/next_closest_ratio=0.92 maximal_alignment_error=25 inlier_ratio=0.05 feature_extraction_model=Rigid registration_model=[Rigid                -- translate + rotate                  ] interpolate\");\n",
    "    run(\"Transform Virtual Stack Slices\", \"source = [Y:/coskun-lab/Nicky/07 Temp/other channels/original] output = [Y:/coskun-lab/Nicky/07 Temp/other channels/original] transforms = [Y:/coskun-lab/Nicky/07 Temp/register output] interpolate\");\n",
    "    '''\n",
    "    # folder to save registered images separated by channel to apply transforms\n",
    "    # create all folder\n",
    "    for ii, ch in enumerate(chs): # all channels\n",
    "        os.makedirs(os.path.join(regSavePath, name, 'Original', 'CH' + str(ch)), exist_ok = True)\n",
    "        os.makedirs(os.path.join(regSavePath, name, 'Registered', 'CH' + str(ch)), exist_ok = True)\n",
    "    \n",
    "    os.chdir(os.path.join(regSavePath, name, 'Original', 'CH1'))\n",
    "    now = datetime.now() # current date and time\n",
    "    date_time = now.strftime(\"%d%b%Y\")\n",
    "    macro = open(date_time + '_register_transforms.ijm', 'w')\n",
    "    \n",
    "    # register cycles on CH1\n",
    "    macro.write('run(\"Register Virtual Stack Slices\", \"source=[')\n",
    "    # original files\n",
    "    macro.write(os.path.join(regSavePath, name, 'Original', 'CH1').replace('\\\\', '/'))\n",
    "    macro.write('] output=[')\n",
    "    # registered output files\n",
    "    macro.write(os.path.join(regSavePath, name, 'Registered', 'CH1').replace('\\\\', '/'))\n",
    "    \n",
    "    # Rigid registration: translation + rotation\n",
    "    macro.write('] feature=Rigid registration=[Rigid                -- translate + rotate                  ] advanced shrinkage save save_dir=[')\n",
    "    # folder to save recorded transformations \n",
    "    macro.write('] initial_gaussian_blur=1.60 steps_per_scale_octave=3 minimum_image_size=64 maximum_image_size=1024 feature_descriptor_size=8 feature_descriptor_orientation_bins=8 closest/next_closest_ratio=0.92 maximal_alignment_error=25 inlier_ratio=0.05 feature_extraction_model=Rigid registration_model=[Rigid                -- translate + rotate                  ] interpolate\"); \\n')\n",
    "    \n",
    "    # # bigwrap registration\n",
    "    # macro.write('] feature=Similarity registration=[Elastic              -- bUnwarpJ splines                    ] advanced shrinkage save save_dir=[')\n",
    "    # # folder to save recorded transformations \n",
    "    # macro.write('] initial_gaussian_blur=1.60 steps_per_scale_octave=3 minimum_image_size=64 maximum_image_size=1024 feature_descriptor_size=8 feature_descriptor_orientation_bins=8 closest/next_closest_ratio=0.92 maximal_alignment_error=25 inlier_ratio=0.05 feature_extraction_model=Similarity registration_model=[[Elastic              -- bUnwarpJ splines                    ] interpolate registration=Mono image_subsample_factor=0 initial_deformation=[Very Coarse] final_deformation=Fine divergence_weight=0.1 curl_weight=0.1 landmark_weight=1 image_weight=0 consistency_weight=0 stop_threshold=0.01 shear=0.95 scale=0.95 isotropy=1\"); \\n')\n",
    "    \n",
    "    # Or use similarity: translation + rotation + isotropic scale\n",
    "    # macro.write('] feature=Similarity registration=[Similarity           -- translate + rotate + isotropic scale] advanced shrinkage save save_dir=[')\n",
    "    # # folder to save recorded transformations \n",
    "    # macro.write('] initial_gaussian_blur=1.60 steps_per_scale_octave=3 minimum_image_size=64 maximum_image_size=1024 feature_descriptor_size=25 feature_descriptor_orientation_bins=8 closest/next_closest_ratio=0.92 maximal_alignment_error=50 inlier_ratio=0.05 feature_extraction_model=Similarity registration_model=[Similarity           -- translate + rotate + isotropic scale] interpolate\"); \\n')\n",
    "    \n",
    "    macro.write('run(\"Close All\"); \\n\\n')\n",
    "    \n",
    "    # now apply transform to other channels\n",
    "    for ii, ch in enumerate([1,2,3,4]): # each other channel\n",
    "        \n",
    "        macro.write('run(\"Transform Virtual Stack Slices\", \"source=[')\n",
    "        # unregsitered folder\n",
    "        macro.write(os.path.join(regSavePath, name, 'Original', 'CH' + str(ch)).replace('\\\\', '/'))\n",
    "        macro.write('] output=[')\n",
    "        # registered folder\n",
    "        macro.write(os.path.join(regSavePath, name, 'Registered', 'CH' + str(ch)).replace('\\\\', '/'))\n",
    "        macro.write('] transforms=[')\n",
    "        macro.write(os.path.join(regSavePath, name, 'Original', 'CH1').replace('\\\\', '/')) # stored in original registration folder\n",
    "        macro.write('] interpolate\"); \\n')\n",
    "        macro.write('run(\"Close All\"); \\n\\n')\n",
    "    \n",
    "    macro.close()\n",
    "    \n",
    "    # print command to run macro\n",
    "    print('runMacro(\"' + os.path.join(regSavePath, name, 'Original', 'CH1', macro.name).replace('\\\\', '/') + '\");')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine all registered images into single folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "regSavePath = data_dir / 'specificity_PlusMinus' /'imgs' / 'registered_imagej'\n",
    "\n",
    "regSaveFinalPath = data_dir / 'specificity_PlusMinus' / 'imgs' / 'registered_imagej_final'\n",
    "regSaveFinalPath.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "regSaveCropPath = data_dir / 'specificity_PlusMinus' / 'imgs' /  'registered_crop'\n",
    "regSaveCropPath.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = df.groupby(['Condition', 'FOV'])\n",
    "\n",
    "for name, channels in group:\n",
    "    name = '_'.join(name)\n",
    "    for ii, cycle in enumerate(tqdm(channels['Cycle'].unique())): # each cycle\n",
    "    \n",
    "        dfCycle = channels.loc[channels['Cycle'] == cycle]\n",
    "        dfCycle.reset_index(drop = True, inplace = True) # index is channel - 1\n",
    "        cycle = cycle[5:]\n",
    "        for jj, ch in enumerate(dfCycle.Channels): # each channel\n",
    "            \n",
    "            # find registered file\n",
    "            tifPath = os.path.join(regSavePath, name, 'Registered', 'CH' + str(ch), 'CH' + str(ch)+ '_Cycle' + str(cycle).zfill(2) + '.tif')\n",
    "\n",
    "            # File out\n",
    "            fileOut = 'Cycle' + str(cycle).zfill(2) + \\\n",
    "            '_' + 'CH' + str(ch) + '.tif'\n",
    "            folder = regSaveFinalPath / name\n",
    "            folder.mkdir(parents=True, exist_ok=True)\n",
    "            fileOut = os.path.join(regSaveFinalPath, name, fileOut)\n",
    "            # print(tifPath)\n",
    "            # Copy\n",
    "            if os.path.exists(tifPath):\n",
    "                shutil.copyfile(tifPath, fileOut)\n",
    "            else:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Cropped image to smallest bounding box of non black region\n",
    "\n",
    "# Get channel list\n",
    "group = df.groupby(['Condition', 'FOV'])\n",
    "\n",
    "for name, df_group in group:\n",
    "    channels = df_group.Channels.tolist()\n",
    "    break\n",
    "\n",
    "# Crop\n",
    "for dir in os.listdir(regSaveFinalPath):\n",
    "\n",
    "    # Read imgs\n",
    "    imgs = []\n",
    "    paths = []\n",
    "    for file in os.listdir(regSaveFinalPath / dir):\n",
    "        if 'tif' in file:\n",
    "            path = regSaveFinalPath / dir/ file\n",
    "            imgs.append(tiff.imread(path))\n",
    "            paths.append(file)\n",
    "\n",
    "    # Get bboxs\n",
    "    bboxs = []\n",
    "    for i, img in enumerate(imgs):\n",
    "        if channels[i] != 1:\n",
    "            continue\n",
    "        bbox = skimage.measure.regionprops((img>0).astype(np.uint8))[0]['bbox']\n",
    "        bboxs.append(np.array(bbox))\n",
    "    bboxs = np.stack(bboxs)\n",
    "\n",
    "    bbox_final = [np.max(bboxs[:,0]),\n",
    "                np.max(bboxs[:,1]),\n",
    "                np.min(bboxs[:,2]),\n",
    "                np.min(bboxs[:,3])]\n",
    "\n",
    "    min_row, min_col, max_row, max_col = bbox_final\n",
    "\n",
    "    # Save cropped images\n",
    "    save_dir = regSaveCropPath / dir\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for i, img in enumerate(imgs):\n",
    "        save_path = save_dir / paths[i]\n",
    "        tiff.imwrite(save_path, img[min_row:max_row, min_col:max_col], bigtiff = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import util\n",
    "import h5py\n",
    "\n",
    "def get_info(data_raw, marker_dict):\n",
    "    conditions = []\n",
    "    fovs = []\n",
    "    cycles = []\n",
    "    channels = []\n",
    "    markers = []\n",
    "    paths = [] \n",
    "\n",
    "    # Loop through image folder\n",
    "    for (dirpath, dirnames, filenames) in os.walk(data_raw):\n",
    "        for name in sorted(filenames):\n",
    "            if \"tif\" in name:\n",
    "                # Get information from image name\n",
    "                n_split = name.split('_')\n",
    "                                \n",
    "                cond=dirpath.split('\\\\')[-1].split('_')[0]\n",
    "                fov=dirpath.split('\\\\')[-1].split('_')[1]\n",
    "                cycle='cycle'+str(int(n_split[0][-2:]))\n",
    "                ch = int(n_split[1][2])\n",
    "                try:\n",
    "                    marker = marker_dict[cycle][ch]\n",
    "                except:\n",
    "                    continue \n",
    "                    \n",
    "                conditions.append(cond)\n",
    "                fovs.append(fov)\n",
    "                cycles.append(cycle)\n",
    "                channels.append(ch)\n",
    "                markers.append(marker)\n",
    "                paths.append(os.path.join(dirpath, name))\n",
    "                \n",
    "    info = {\n",
    "            \"Condition\": conditions,\n",
    "            \"FOV\": fovs,\n",
    "            \"Cycle\": cycles,\n",
    "            \"Channels\": channels,\n",
    "            \"Markers\": markers,\n",
    "            \"Path\": paths\n",
    "        }\n",
    "\n",
    "    df = pd.DataFrame(info)\n",
    "    return df\n",
    "\n",
    "def save_hdf5(\n",
    "    path: str, name: str, data: np.ndarray, attr_dict=None, mode: str = \"a\"\n",
    ") -> None:\n",
    "    # Read h5 file\n",
    "    hf = h5py.File(path, mode)\n",
    "    # Create z_stack_dataset\n",
    "    if hf.get(name) is None:\n",
    "        data_shape = data.shape\n",
    "        data_type = data.dtype\n",
    "        max_shape = (data_shape[0],) + data_shape[1:]\n",
    "        dset = hf.create_dataset(\n",
    "            name,\n",
    "            shape=data_shape,\n",
    "            maxshape=max_shape,\n",
    "            chunks=True,\n",
    "            dtype=data_type,\n",
    "            compression=\"gzip\",\n",
    "        )\n",
    "        dset[:] = data\n",
    "        if attr_dict is not None:\n",
    "            for attr_key, attr_val in attr_dict.items():\n",
    "                dset.attrs[attr_key] = attr_val\n",
    "    else:\n",
    "        print(f\"Dataset {name} exists\")\n",
    "\n",
    "    hf.close()\n",
    "\n",
    "def read_img(path):\n",
    "    return skimage.io.imread(path, as_gray=True)\n",
    "\n",
    "def joblib_loop(task, pics):\n",
    "    return Parallel(n_jobs=20)(delayed(task)(i) for i in pics)\n",
    "\n",
    "def read_img(path):\n",
    "    return skimage.io.imread(path, as_gray=True)\n",
    "\n",
    "def get_min(imgs):\n",
    "    shapes = np.array([np.array(img.shape) for img in imgs])\n",
    "    return np.min(shapes, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder is already there\n",
      "Loaded df\n"
     ]
    }
   ],
   "source": [
    "data_raw = data_dir /'specificity_PlusMinus' / 'imgs' /  'registered_crop'\n",
    "df_meta_path = data_dir /  'specificity_PlusMinus'/ 'metadata' / 'info_sti.csv'\n",
    "\n",
    "try:\n",
    "    df_meta_path.parent.mkdir(parents=True, exist_ok=False)\n",
    "except FileExistsError:\n",
    "    print(\"Folder is already there\")\n",
    "\n",
    "df_exist = df_meta_path.is_file()\n",
    "\n",
    "if not df_exist:\n",
    "    print('Created df')\n",
    "    df = get_info(data_raw, markers_map)\n",
    "    df.to_csv(df_meta_path, index=False)\n",
    "else:\n",
    "    print('Loaded df')\n",
    "    df = pd.read_csv(df_meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Condition</th>\n",
       "      <th>FOV</th>\n",
       "      <th>Cycle</th>\n",
       "      <th>Channels</th>\n",
       "      <th>Markers</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Control</td>\n",
       "      <td>FW1</td>\n",
       "      <td>cycle1</td>\n",
       "      <td>1</td>\n",
       "      <td>DNA</td>\n",
       "      <td>y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Control</td>\n",
       "      <td>FW1</td>\n",
       "      <td>cycle1</td>\n",
       "      <td>4</td>\n",
       "      <td>PLUS Perk</td>\n",
       "      <td>y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Control</td>\n",
       "      <td>FW1</td>\n",
       "      <td>cycle2</td>\n",
       "      <td>1</td>\n",
       "      <td>DNA</td>\n",
       "      <td>y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Control</td>\n",
       "      <td>FW1</td>\n",
       "      <td>cycle2</td>\n",
       "      <td>4</td>\n",
       "      <td>MINUS Yap</td>\n",
       "      <td>y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Control</td>\n",
       "      <td>FW1</td>\n",
       "      <td>cycle3</td>\n",
       "      <td>1</td>\n",
       "      <td>DNA</td>\n",
       "      <td>y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Control</td>\n",
       "      <td>FW1</td>\n",
       "      <td>cycle3</td>\n",
       "      <td>4</td>\n",
       "      <td>Cyclin E/CDK2</td>\n",
       "      <td>y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Control</td>\n",
       "      <td>FW1</td>\n",
       "      <td>cycle4</td>\n",
       "      <td>1</td>\n",
       "      <td>DNA</td>\n",
       "      <td>y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Control</td>\n",
       "      <td>FW1</td>\n",
       "      <td>cycle4</td>\n",
       "      <td>2</td>\n",
       "      <td>Concanavalin A</td>\n",
       "      <td>y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Control</td>\n",
       "      <td>FW1</td>\n",
       "      <td>cycle4</td>\n",
       "      <td>3</td>\n",
       "      <td>Phalloidin</td>\n",
       "      <td>y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Control</td>\n",
       "      <td>FW1</td>\n",
       "      <td>cycle4</td>\n",
       "      <td>4</td>\n",
       "      <td>WGA</td>\n",
       "      <td>y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Condition  FOV   Cycle  Channels         Markers  \\\n",
       "0   Control  FW1  cycle1         1             DNA   \n",
       "1   Control  FW1  cycle1         4       PLUS Perk   \n",
       "2   Control  FW1  cycle2         1             DNA   \n",
       "3   Control  FW1  cycle2         4       MINUS Yap   \n",
       "4   Control  FW1  cycle3         1             DNA   \n",
       "5   Control  FW1  cycle3         4   Cyclin E/CDK2   \n",
       "6   Control  FW1  cycle4         1             DNA   \n",
       "7   Control  FW1  cycle4         2  Concanavalin A   \n",
       "8   Control  FW1  cycle4         3      Phalloidin   \n",
       "9   Control  FW1  cycle4         4             WGA   \n",
       "\n",
       "                                                Path  \n",
       "0  y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...  \n",
       "1  y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...  \n",
       "2  y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...  \n",
       "3  y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...  \n",
       "4  y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...  \n",
       "5  y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...  \n",
       "6  y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...  \n",
       "7  y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...  \n",
       "8  y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...  \n",
       "9  y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder is already there\n",
      "Created df\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e7c462b04049139195d0dd0e524056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_imgs_path = data_dir / 'specificity_PlusMinus' / 'metadata' / 'imgs_reg.csv'\n",
    "temp_path =data_dir / 'specificity_PlusMinus' / 'hdf5' / 'registered'\n",
    "try:\n",
    "    temp_path.mkdir(parents=True, exist_ok=False)\n",
    "except FileExistsError:\n",
    "    print(\"Folder is already there\")\n",
    "\n",
    "df_exist = df_imgs_path.is_file()\n",
    "\n",
    "if not df_exist:\n",
    "    print('Created df')\n",
    "    group = df.groupby(['Condition','FOV'])\n",
    "    rows = []\n",
    "\n",
    "    for name, df_group in tqdm(group, total=len(group)):\n",
    "        file_name = '_'.join(np.array(name).astype(str)) + '.hdf5'\n",
    "        file_path = temp_path / file_name\n",
    "        rows.append(list(name)+[file_path])\n",
    "        \n",
    "        # if file_path.exists():\n",
    "        #     continue\n",
    "        \n",
    "        channels = df_group.Channels.to_list()\n",
    "        cycles = df_group.Cycle.to_list()\n",
    "        markers = df_group.Markers.to_list()\n",
    "        paths = df_group.Path.to_numpy()\n",
    "            \n",
    "        imgs = joblib_loop(read_img, paths)\n",
    "        min_shape = get_min(imgs)\n",
    "        imgs_cropped = np.array([img[:min_shape[0], :min_shape[1]] for img in imgs])\n",
    "        info = {\"Cycle\": cycles, \"Channel\": channels, \"Marker\": markers}\n",
    "\n",
    "        imgs_cropped = util.img_as_ubyte(imgs_cropped)\n",
    "        \n",
    "        # hdf5 as Channel -> Z mapping\n",
    "        save_hdf5(file_path, 'imgs', imgs_cropped, info)\n",
    "    df_imgs = pd.DataFrame(rows, columns=['Condition', 'FOV', 'Path'])        \n",
    "    df_imgs.to_csv(df_imgs_path, index=False)\n",
    "else:\n",
    "    print('Loaded df')\n",
    "    df_imgs = pd.read_csv(df_imgs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari \n",
    "from skimage import exposure, util\n",
    "\n",
    "def contrast_str(img, n_min=0.1, n_max=99.9):\n",
    "    p2, p98 = np.percentile(img, (n_min, n_max))\n",
    "    img_rescale = exposure.rescale_intensity(img, in_range=(p2, p98))\n",
    "    img_rescale = util.img_as_ubyte(img_rescale)\n",
    "    return img_rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imgs_path = data_dir / 'specificity_PlusMinus' /'metadata' / 'imgs_reg.csv'\n",
    "df_imgs = pd.read_csv(df_imgs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyto_markers = ['Phalloidin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save combined images\n",
    "for row in df_imgs.itertuples():\n",
    "    # Read image\n",
    "    path = row.Path\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        imgs = f['imgs'][:]\n",
    "        markers = f['imgs'].attrs['Marker']\n",
    "\n",
    "    napari.view_image(imgs, name=markers, channel_axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_seg_path = data_dir /  'specificity_PlusMinus' / 'imgs' / 'segmentation'\n",
    "whole_seg_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save combined images\n",
    "for row in df_imgs.itertuples():\n",
    "    # Read image\n",
    "    path = row.Path\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        imgs = f['imgs'][:]\n",
    "        markers = f['imgs'].attrs['Marker']\n",
    "\n",
    "    # Get dapi and cyto imgaes\n",
    "    indices = np.isin(markers, cyto_markers)\n",
    "    img_dapi = imgs[4]\n",
    "    imgs_cyto = imgs[indices,:]\n",
    "    \n",
    "    # Contrast streching and combine to rgb image\n",
    "    img_dapi = contrast_str(img_dapi, n_max=99.9)\n",
    "    imgs_cyto_scaled = [contrast_str(imgs_cyto[0], n_max=99.9)]\n",
    "    img_cyto = np.max(np.array(imgs_cyto_scaled), axis=0)\n",
    "    img_rgb = np.stack([np.zeros(img_dapi.shape),img_cyto, img_dapi], axis=0).astype(np.uint8)\n",
    "    \n",
    "    # Crop and save\n",
    "    file_name = f'{\"_\".join(row[1:3])}.tif'\n",
    "    file_path = whole_seg_path / file_name\n",
    "    tiff.imwrite(file_path, img_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PLA2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
