{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test torch geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import networkx as nx \n",
    "import pickle \n",
    "import torch_geometric \n",
    "\n",
    "data_dir = r'Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\graphs\\raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thu71\\Anaconda3\\envs\\snowflake\\lib\\site-packages\\torch_geometric\\utils\\convert.py:192: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:204.)\n",
      "  data[key] = torch.tensor(value)\n"
     ]
    }
   ],
   "source": [
    "for f in os.listdir(data_dir):\n",
    "    with open(os.path.join(data_dir, f), 'rb') as file:\n",
    "        G = pickle.load(file)\n",
    "    data = torch_geometric.utils.from_networkx(G)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 986, 6128],\n",
       "        [ 990, 6148],\n",
       "        [ 962, 6122],\n",
       "        [1040, 6213],\n",
       "        [ 958, 6092],\n",
       "        [ 974, 6074],\n",
       "        [1042, 6129],\n",
       "        [1041, 6194],\n",
       "        [ 957, 6124],\n",
       "        [ 997, 6070],\n",
       "        [ 996, 6184],\n",
       "        [1034, 6172],\n",
       "        [ 958, 6062],\n",
       "        [1024, 6152],\n",
       "        [1046, 6191],\n",
       "        [1001, 6046],\n",
       "        [ 996, 6186],\n",
       "        [ 984, 6052],\n",
       "        [1014, 6172],\n",
       "        [ 975, 6059],\n",
       "        [1038, 6201],\n",
       "        [1079, 6175],\n",
       "        [1053, 6164],\n",
       "        [1093, 6188],\n",
       "        [1020, 6069],\n",
       "        [1053, 6204],\n",
       "        [1028, 6159],\n",
       "        [1035, 6102],\n",
       "        [ 996, 6177],\n",
       "        [1048, 6121],\n",
       "        [1103, 6159],\n",
       "        [1053, 6193],\n",
       "        [1027, 6046],\n",
       "        [ 975, 6100],\n",
       "        [1066, 6153],\n",
       "        [ 966, 6141],\n",
       "        [1000, 6043],\n",
       "        [1093, 6155],\n",
       "        [1032, 6213],\n",
       "        [ 957, 6072],\n",
       "        [1004, 6110],\n",
       "        [1085, 6178],\n",
       "        [ 982, 6143],\n",
       "        [ 972, 6042],\n",
       "        [1001, 6135],\n",
       "        [1008, 6137],\n",
       "        [1103, 6181],\n",
       "        [ 985, 6080],\n",
       "        [1048, 6155],\n",
       "        [ 982, 6039],\n",
       "        [1054, 6099],\n",
       "        [ 967, 6085],\n",
       "        [1092, 6142],\n",
       "        [1075, 6192],\n",
       "        [ 945, 6108],\n",
       "        [1050, 6131],\n",
       "        [1018, 6143],\n",
       "        [ 982, 6041],\n",
       "        [ 996, 6185],\n",
       "        [1010, 6120],\n",
       "        [1040, 6095],\n",
       "        [1032, 6103],\n",
       "        [ 997, 6071],\n",
       "        [1056, 6077],\n",
       "        [ 972, 6102],\n",
       "        [1008, 6078],\n",
       "        [ 964, 6138],\n",
       "        [1023, 6107],\n",
       "        [1089, 6187],\n",
       "        [1017, 6048],\n",
       "        [1075, 6155],\n",
       "        [1013, 6172],\n",
       "        [1022, 6078],\n",
       "        [1079, 6160],\n",
       "        [ 999, 6095],\n",
       "        [1030, 6121],\n",
       "        [1078, 6134],\n",
       "        [ 990, 6072],\n",
       "        [ 973, 6164],\n",
       "        [1103, 6160],\n",
       "        [1027, 6047],\n",
       "        [ 983, 6143],\n",
       "        [1077, 6116],\n",
       "        [1021, 6105],\n",
       "        [ 982, 6040],\n",
       "        [1075, 6168],\n",
       "        [1012, 6078],\n",
       "        [ 965, 6140],\n",
       "        [1054, 6098],\n",
       "        [ 962, 6140],\n",
       "        [ 945, 6109],\n",
       "        [ 994, 6122],\n",
       "        [ 999, 6107],\n",
       "        [1004, 6111],\n",
       "        [1049, 6132],\n",
       "        [ 997, 6156],\n",
       "        [ 993, 6168],\n",
       "        [1020, 6149],\n",
       "        [1047, 6155],\n",
       "        [ 967, 6057],\n",
       "        [1054, 6083],\n",
       "        [1023, 6099],\n",
       "        [1006, 6204],\n",
       "        [ 999, 6101],\n",
       "        [1015, 6132],\n",
       "        [1109, 6159],\n",
       "        [1053, 6161],\n",
       "        [1022, 6107],\n",
       "        [1030, 6122],\n",
       "        [1078, 6160],\n",
       "        [1090, 6176],\n",
       "        [1090, 6174],\n",
       "        [1074, 6164],\n",
       "        [1027, 6155],\n",
       "        [1025, 6157],\n",
       "        [ 974, 6163],\n",
       "        [ 969, 6064],\n",
       "        [ 952, 6059],\n",
       "        [1004, 6125],\n",
       "        [1104, 6150],\n",
       "        [ 971, 6109],\n",
       "        [ 972, 6152],\n",
       "        [1042, 6179],\n",
       "        [ 978, 6118],\n",
       "        [1009, 6173],\n",
       "        [1011, 6063],\n",
       "        [ 986, 6058],\n",
       "        [ 980, 6120],\n",
       "        [ 988, 6103],\n",
       "        [1055, 6138],\n",
       "        [1028, 6165],\n",
       "        [1005, 6130],\n",
       "        [1011, 6162],\n",
       "        [ 968, 6136],\n",
       "        [ 991, 6076],\n",
       "        [1030, 6166],\n",
       "        [ 953, 6101],\n",
       "        [1098, 6166],\n",
       "        [ 938, 6096],\n",
       "        [1046, 6102],\n",
       "        [ 978, 6119],\n",
       "        [1009, 6174],\n",
       "        [1081, 6117],\n",
       "        [1046, 6080],\n",
       "        [1072, 6127],\n",
       "        [1029, 6165],\n",
       "        [1054, 6138],\n",
       "        [1035, 6094],\n",
       "        [ 976, 6153],\n",
       "        [1045, 6103],\n",
       "        [1031, 6137],\n",
       "        [1015, 6053],\n",
       "        [1010, 6041],\n",
       "        [1028, 6109],\n",
       "        [1019, 6090],\n",
       "        [ 985, 6053],\n",
       "        [ 972, 6074],\n",
       "        [1041, 6072],\n",
       "        [ 986, 6145],\n",
       "        [1090, 6193],\n",
       "        [1055, 6077],\n",
       "        [1053, 6163],\n",
       "        [ 959, 6063],\n",
       "        [1024, 6156],\n",
       "        [1079, 6113],\n",
       "        [1061, 6140],\n",
       "        [1015, 6174],\n",
       "        [1055, 6081],\n",
       "        [1095, 6181],\n",
       "        [ 979, 6072],\n",
       "        [ 992, 6053],\n",
       "        [1054, 6115],\n",
       "        [1018, 6123],\n",
       "        [ 968, 6072],\n",
       "        [1056, 6182],\n",
       "        [1050, 6185],\n",
       "        [ 968, 6070],\n",
       "        [1055, 6076],\n",
       "        [1013, 6156],\n",
       "        [ 962, 6121],\n",
       "        [ 976, 6072],\n",
       "        [1050, 6188],\n",
       "        [1036, 6157],\n",
       "        [1086, 6168],\n",
       "        [1082, 6118],\n",
       "        [1090, 6162],\n",
       "        [1078, 6113],\n",
       "        [1070, 6194],\n",
       "        [1009, 6158],\n",
       "        [1046, 6126],\n",
       "        [ 996, 6187],\n",
       "        [1090, 6165],\n",
       "        [1089, 6178],\n",
       "        [ 937, 6105],\n",
       "        [1030, 6190],\n",
       "        [1003, 6110],\n",
       "        [ 968, 6071],\n",
       "        [ 972, 6146],\n",
       "        [ 942, 6102],\n",
       "        [1009, 6153],\n",
       "        [1048, 6162],\n",
       "        [ 941, 6077],\n",
       "        [ 962, 6133],\n",
       "        [1029, 6161],\n",
       "        [1070, 6137],\n",
       "        [ 979, 6138],\n",
       "        [ 959, 6058],\n",
       "        [1029, 6158],\n",
       "        [ 990, 6134],\n",
       "        [ 986, 6175],\n",
       "        [ 997, 6188],\n",
       "        [1047, 6126],\n",
       "        [1006, 6143],\n",
       "        [ 968, 6125],\n",
       "        [1041, 6105],\n",
       "        [1038, 6115],\n",
       "        [1023, 6147],\n",
       "        [1017, 6160],\n",
       "        [1057, 6183],\n",
       "        [1068, 6189],\n",
       "        [1007, 6150],\n",
       "        [1075, 6111],\n",
       "        [1090, 6149],\n",
       "        [1073, 6193],\n",
       "        [ 989, 6125],\n",
       "        [1030, 6125],\n",
       "        [1026, 6145],\n",
       "        [1004, 6121],\n",
       "        [1056, 6147],\n",
       "        [1042, 6108],\n",
       "        [1036, 6108],\n",
       "        [ 966, 6106],\n",
       "        [1039, 6151],\n",
       "        [ 953, 6109],\n",
       "        [1017, 6079],\n",
       "        [1031, 6122],\n",
       "        [ 969, 6073],\n",
       "        [1013, 6071],\n",
       "        [1028, 6069],\n",
       "        [1015, 6054],\n",
       "        [1004, 6071],\n",
       "        [1046, 6081],\n",
       "        [1081, 6118],\n",
       "        [1081, 6162],\n",
       "        [1076, 6118],\n",
       "        [1005, 6049],\n",
       "        [1028, 6125],\n",
       "        [ 992, 6125],\n",
       "        [ 982, 6134],\n",
       "        [ 996, 6057],\n",
       "        [1046, 6155]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.io\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import re\n",
    "import h5py\n",
    "import napari\n",
    "import tifffile as tiff\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.utils\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_dir = (Path().cwd().parents[0]).absolute()\n",
    "\n",
    "module_path = str(p_dir / \"src\")\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = (Path().cwd().parents[0] / 'data').absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning.pytorch as pl\n",
    "import PPIGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Define condition mapping\n",
    "condition_mapping = {'HCC827Ctrl': 0, 'HCC827Osim': 1}\n",
    "\n",
    "# Load graph dataset and process if neede\n",
    "graph_path = data_dir / '9PPI' / 'graphs' \n",
    "\n",
    "dataset = PPIGraph.GraphDataset(graph_path, 'raw', 'pt', condition_mapping=condition_mapping, n_c=2)\n",
    "train_set, val_set, test_set = PPIGraph.train_test_val_split(dataset)\n",
    "\n",
    "# Create Dataloader\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: GraphDataset(1491):\n",
      "======================\n",
      "Number of graphs: 1491\n",
      "Number of features: 9\n",
      "Number of classes: 2\n",
      "Train set: 716, test set: 596, val set: 179\n",
      "Step 1:\n",
      "=======\n",
      "Number of graphs in the current batch: 32\n",
      "DataBatch(edge_index=[2, 45964], pos=[7834, 2], labels=[7834, 9], nuclei=[7834], weight=[45964], condition=[32], fov=[32], id=[32], train_mask=[7834], test_mask=[7834], edge_attr=[45964, 2], x=[7834, 9], y=[32], edge_weight=[45964], name=[32], batch=[7834], ptr=[33])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print some information on the dataset\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('======================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "print(f'Train set: {len(train_set)}, test set: {len(test_set)}, val set: {len(val_set)}')\n",
    "for step, data in enumerate(train_loader):\n",
    "\n",
    "    print(f'Step {step + 1}:')\n",
    "    print('=======')\n",
    "    print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "    print(data)\n",
    "    print()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-fold on filter dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from lightning.pytorch.accelerators import find_usable_cuda_devices\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from torch.utils.data import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out by maximum number of counts per cell\n",
    "min_count = 100\n",
    "max_count = 400\n",
    "\n",
    "graph_path = data_dir / '9PPI' / 'graphs' \n",
    "dataset = PPIGraph.GraphDataset(graph_path, 'raw', 'pt', condition_mapping=condition_mapping, n_c=2)\n",
    "\n",
    "# Create Dataloader\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Get Indices\n",
    "indices = []\n",
    "for step, data in enumerate(loader):\n",
    "    if len(data.x) <= min_count:\n",
    "        continue \n",
    "    \n",
    "    if (data.x.sum(axis=0) >= max_count).any():\n",
    "        continue\n",
    "    indices.append(step)\n",
    "    \n",
    "# Get subset dataset\n",
    "dataset_filtered = dataset.index_select(indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1368"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = '9PPI_v3'\n",
    "condition = 'Kfold'\n",
    "checkpoint_folder = (Path().cwd().parents[0]).absolute() / 'data' / '9PPI' /\"saved_models\" / dataset_name / f\"Graph_GNNs_{condition}\" \n",
    "project_name = f'PLA_10152023_{dataset_name}_{condition}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "AVAIL_GPUS = [1]\n",
    "\n",
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "NUM_LAYERS = 2\n",
    "HIDDEN_CHANNELS = 16\n",
    "pools = ['mean', 'max', 'sum', 'attention', 'attention2']\n",
    "num_layers = [2,3,4]\n",
    "hiddens = [16, 32, 64]\n",
    "\n",
    "\n",
    "epochs = 80\n",
    "model = 'GAT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_16_onehot_0\\mean\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_16_onehot_0\\max\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_16_onehot_0\\sum\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_16_onehot_0\\attention\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_16_onehot_0\\attention2\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_32_onehot_0\\mean\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_32_onehot_0\\max\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_32_onehot_0\\sum\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_32_onehot_0\\attention\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_32_onehot_0\\attention2\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_64_onehot_0\\mean\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_64_onehot_0\\max\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_64_onehot_0\\sum\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_64_onehot_0\\attention\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_64_onehot_0\\attention2\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_16_onehot_0\\mean\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_16_onehot_0\\max\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_16_onehot_0\\sum\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_16_onehot_0\\attention\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_16_onehot_0\\attention2\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_32_onehot_0\\mean\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_32_onehot_0\\max\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_32_onehot_0\\sum\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_32_onehot_0\\attention\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_32_onehot_0\\attention2\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_64_onehot_0\\mean\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_64_onehot_0\\max\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_64_onehot_0\\sum\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_64_onehot_0\\attention\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_64_onehot_0\\attention2\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_16_onehot_0\\mean\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_16_onehot_0\\max\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_16_onehot_0\\sum\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_16_onehot_0\\attention\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_16_onehot_0\\attention2\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_32_onehot_0\\mean\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_32_onehot_0\\max\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_32_onehot_0\\sum\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_32_onehot_0\\attention\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_32_onehot_0\\attention2\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_64_onehot_0\\mean\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_64_onehot_0\\max\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_64_onehot_0\\sum\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_64_onehot_0\\attention\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_64_onehot_0\\attention2\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_16_onehot_1\\mean\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_16_onehot_1\\max\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_16_onehot_1\\sum\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_16_onehot_1\\attention\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_16_onehot_1\\attention2\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_32_onehot_1\\mean\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_32_onehot_1\\max\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_32_onehot_1\\sum\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_32_onehot_1\\attention\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_32_onehot_1\\attention2\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_64_onehot_1\\mean\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_64_onehot_1\\max\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_64_onehot_1\\sum\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_64_onehot_1\\attention\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_64_onehot_1\\attention2\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_16_onehot_1\\mean\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_16_onehot_1\\max\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_16_onehot_1\\sum\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_16_onehot_1\\attention\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_16_onehot_1\\attention2\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_32_onehot_1\\mean\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_32_onehot_1\\max\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_32_onehot_1\\sum\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_32_onehot_1\\attention\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_32_onehot_1\\attention2\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_64_onehot_1\\mean\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_64_onehot_1\\max\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_64_onehot_1\\sum\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_64_onehot_1\\attention\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_64_onehot_1\\attention2\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_16_onehot_1\\mean\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_16_onehot_1\\max\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_16_onehot_1\\sum\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_16_onehot_1\\attention\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_16_onehot_1\\attention2\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_32_onehot_1\\mean\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_32_onehot_1\\max\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_32_onehot_1\\sum\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_32_onehot_1\\attention\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_32_onehot_1\\attention2\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_64_onehot_1\\mean\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_64_onehot_1\\max\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_64_onehot_1\\sum\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_64_onehot_1\\attention\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_64_onehot_1\\attention2\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_16_onehot_2\\mean\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_16_onehot_2\\max\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_16_onehot_2\\sum\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_16_onehot_2\\attention\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_16_onehot_2\\attention2\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_32_onehot_2\\mean\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_32_onehot_2\\max\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_32_onehot_2\\sum\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_32_onehot_2\\attention\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_32_onehot_2\\attention2\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_64_onehot_2\\mean\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_64_onehot_2\\max\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_64_onehot_2\\sum\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_64_onehot_2\\attention\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_64_onehot_2\\attention2\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_16_onehot_2\\mean\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_16_onehot_2\\max\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_16_onehot_2\\sum\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_16_onehot_2\\attention\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_16_onehot_2\\attention2\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_32_onehot_2\\mean\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_32_onehot_2\\max\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_32_onehot_2\\sum\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_32_onehot_2\\attention\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_32_onehot_2\\attention2\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_64_onehot_2\\mean\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_64_onehot_2\\max\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_64_onehot_2\\sum\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_64_onehot_2\\attention\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_64_onehot_2\\attention2\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_16_onehot_2\\mean\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_16_onehot_2\\max\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_16_onehot_2\\sum\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_16_onehot_2\\attention\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_16_onehot_2\\attention2\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_32_onehot_2\\mean\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_32_onehot_2\\max\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_32_onehot_2\\sum\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_32_onehot_2\\attention\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_32_onehot_2\\attention2\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_64_onehot_2\\mean\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_64_onehot_2\\max\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_64_onehot_2\\sum\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_64_onehot_2\\attention\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_64_onehot_2\\attention2\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_16_onehot_3\\mean\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_16_onehot_3\\max\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_16_onehot_3\\sum\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_16_onehot_3\\attention\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_16_onehot_3\\attention2\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_32_onehot_3\\mean\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_32_onehot_3\\max\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_32_onehot_3\\sum\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_32_onehot_3\\attention\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_32_onehot_3\\attention2\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_64_onehot_3\\mean\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_64_onehot_3\\max\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_64_onehot_3\\sum\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_64_onehot_3\\attention\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_64_onehot_3\\attention2\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_16_onehot_3\\mean\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_16_onehot_3\\max\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_16_onehot_3\\sum\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_16_onehot_3\\attention\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_16_onehot_3\\attention2\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_32_onehot_3\\mean\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_32_onehot_3\\max\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_32_onehot_3\\sum\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_32_onehot_3\\attention\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_32_onehot_3\\attention2\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_64_onehot_3\\mean\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_64_onehot_3\\max\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_64_onehot_3\\sum\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_64_onehot_3\\attention\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_64_onehot_3\\attention2\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_16_onehot_3\\mean\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_16_onehot_3\\max\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_16_onehot_3\\sum\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_16_onehot_3\\attention\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_16_onehot_3\\attention2\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_32_onehot_3\\mean\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_32_onehot_3\\max\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_32_onehot_3\\sum\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_32_onehot_3\\attention\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_32_onehot_3\\attention2\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_64_onehot_3\\mean\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_64_onehot_3\\max\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_64_onehot_3\\sum\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_64_onehot_3\\attention\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_4_64_onehot_3\\attention2\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_16_onehot_4\\mean\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_16_onehot_4\\max\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_16_onehot_4\\sum\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_16_onehot_4\\attention\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_16_onehot_4\\attention2\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_32_onehot_4\\mean\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_32_onehot_4\\max\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_32_onehot_4\\sum\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_32_onehot_4\\attention\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_32_onehot_4\\attention2\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_64_onehot_4\\mean\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_64_onehot_4\\max\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_64_onehot_4\\sum\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_64_onehot_4\\attention\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_2_64_onehot_4\\attention2\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_16_onehot_4\\mean\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_16_onehot_4\\max\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_16_onehot_4\\sum\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_16_onehot_4\\attention\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_16_onehot_4\\attention2\\GraphLevelGAT\\GraphLevelGAT.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GAT_3_32_onehot_4\\mean\\GraphLevelGAT\\GraphLevelGAT.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mthoomas\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e88e856fcb404a449573c8254503b546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666495924, max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231219_093524-70ar3cur</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/70ar3cur' target=\"_blank\">GAT_3_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/70ar3cur' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/70ar3cur</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\Anaconda3\\envs\\snowflake\\lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GAT              | 20.8 K\n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "21.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "21.4 K    Total params\n",
      "0.086     Total estimated model params size (MB)\n",
      "C:\\Users\\thu71\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:478: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\thu71\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\thu71\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightning\\pytorch\\utilities\\data.py:77: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "C:\\Users\\thu71\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\thu71\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:280: PossibleUserWarning: The number of training batches (9) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e252015077294c8e8522739268fff066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>lr-Adam</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_auc</td><td></td></tr><tr><td>train_f1</td><td></td></tr><tr><td>train_loss_epoch</td><td></td></tr><tr><td>train_loss_step</td><td></td></tr><tr><td>trainer/global_step</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_auc</td><td></td></tr><tr><td>val_f1</td><td></td></tr><tr><td>val_loss_epoch</td><td></td></tr><tr><td>val_loss_step</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.73425</td></tr><tr><td>train_auc</td><td>0.77469</td></tr><tr><td>train_f1</td><td>0.62644</td></tr><tr><td>train_loss_epoch</td><td>0.54705</td></tr><tr><td>train_loss_step</td><td>0.55704</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.65201</td></tr><tr><td>val_auc</td><td>0.77026</td></tr><tr><td>val_f1</td><td>0.68013</td></tr><tr><td>val_loss_epoch</td><td>0.64219</td></tr><tr><td>val_loss_step</td><td>0.64657</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GAT_3_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/70ar3cur' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/70ar3cur</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231219_093524-70ar3cur\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7730e3fc47e3455c8025a45419be3687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.0171999999981684, max=1.0))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231219_095850-awbkzc66</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/awbkzc66' target=\"_blank\">GAT_3_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/awbkzc66' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/awbkzc66</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GAT              | 20.8 K\n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "21.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "21.4 K    Total params\n",
      "0.086     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c414f0aa7924e548d2eb0e41b281c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>lr-Adam</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_auc</td><td></td></tr><tr><td>train_f1</td><td></td></tr><tr><td>train_loss_epoch</td><td></td></tr><tr><td>train_loss_step</td><td></td></tr><tr><td>trainer/global_step</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_auc</td><td></td></tr><tr><td>val_f1</td><td></td></tr><tr><td>val_loss_epoch</td><td></td></tr><tr><td>val_loss_step</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.71416</td></tr><tr><td>train_auc</td><td>0.3413</td></tr><tr><td>train_f1</td><td>0.61876</td></tr><tr><td>train_loss_epoch</td><td>0.57332</td></tr><tr><td>train_loss_step</td><td>0.48656</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.69231</td></tr><tr><td>val_auc</td><td>0.22266</td></tr><tr><td>val_f1</td><td>0.54839</td></tr><tr><td>val_loss_epoch</td><td>0.67375</td></tr><tr><td>val_loss_step</td><td>0.79005</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GAT_3_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/awbkzc66' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/awbkzc66</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231219_095850-awbkzc66\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9da0b9d0d7a7434b909fcb637ade8d93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666495924, max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231219_102221-o71vr9q4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/o71vr9q4' target=\"_blank\">GAT_3_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/o71vr9q4' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/o71vr9q4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\Anaconda3\\envs\\snowflake\\lib\\site-packages\\torch_geometric\\deprecation.py:12: UserWarning: 'nn.glob.GlobalAttention' is deprecated, use 'nn.aggr.AttentionalAggregation' instead\n",
      "  warnings.warn(out)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GAT              | 20.8 K\n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "21.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "21.4 K    Total params\n",
      "0.086     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5b25e5599ff448896e682411986ed50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>lr-Adam</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_auc</td><td></td></tr><tr><td>train_f1</td><td></td></tr><tr><td>train_loss_epoch</td><td></td></tr><tr><td>train_loss_step</td><td></td></tr><tr><td>trainer/global_step</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_auc</td><td></td></tr><tr><td>val_f1</td><td></td></tr><tr><td>val_loss_epoch</td><td></td></tr><tr><td>val_loss_step</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.76256</td></tr><tr><td>train_auc</td><td>0.79977</td></tr><tr><td>train_f1</td><td>0.69194</td></tr><tr><td>train_loss_epoch</td><td>0.53964</td></tr><tr><td>train_loss_step</td><td>0.5943</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.64103</td></tr><tr><td>val_auc</td><td>0.76427</td></tr><tr><td>val_f1</td><td>0.34667</td></tr><tr><td>val_loss_epoch</td><td>0.65981</td></tr><tr><td>val_loss_step</td><td>0.59428</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GAT_3_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/o71vr9q4' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/o71vr9q4</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231219_102221-o71vr9q4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dd1aba74e9742fea25fab9fb172b4e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231219_104442-4hzpgs7v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/4hzpgs7v' target=\"_blank\">GAT_3_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/4hzpgs7v' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/4hzpgs7v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GAT              | 20.8 K\n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "22.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "22.5 K    Total params\n",
      "0.090     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64bb266fbf544ca5b8149d9cc007465f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>lr-Adam</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_auc</td><td></td></tr><tr><td>train_f1</td><td></td></tr><tr><td>train_loss_epoch</td><td></td></tr><tr><td>train_loss_step</td><td></td></tr><tr><td>trainer/global_step</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_auc</td><td></td></tr><tr><td>val_f1</td><td></td></tr><tr><td>val_loss_epoch</td><td></td></tr><tr><td>val_loss_step</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.7653</td></tr><tr><td>train_auc</td><td>0.80923</td></tr><tr><td>train_f1</td><td>0.68697</td></tr><tr><td>train_loss_epoch</td><td>0.53365</td></tr><tr><td>train_loss_step</td><td>0.63121</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.69597</td></tr><tr><td>val_auc</td><td>0.76541</td></tr><tr><td>val_f1</td><td>0.56085</td></tr><tr><td>val_loss_epoch</td><td>0.54184</td></tr><tr><td>val_loss_step</td><td>0.37715</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GAT_3_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/4hzpgs7v' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/4hzpgs7v</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231219_104442-4hzpgs7v\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb509a4efd36468ca9ed64c6610ce24d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666883975, max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231219_110726-j1h9emwb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/j1h9emwb' target=\"_blank\">GAT_3_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/j1h9emwb' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/j1h9emwb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GAT              | 78.5 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "80.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "80.7 K    Total params\n",
      "0.323     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "121fbfa219de4fe88f1b997a92dc89da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>lr-Adam</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_auc</td><td></td></tr><tr><td>train_f1</td><td></td></tr><tr><td>train_loss_epoch</td><td></td></tr><tr><td>train_loss_step</td><td></td></tr><tr><td>trainer/global_step</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_auc</td><td></td></tr><tr><td>val_f1</td><td></td></tr><tr><td>val_loss_epoch</td><td></td></tr><tr><td>val_loss_step</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.75434</td></tr><tr><td>train_auc</td><td>0.8138</td></tr><tr><td>train_f1</td><td>0.64744</td></tr><tr><td>train_loss_epoch</td><td>0.51917</td></tr><tr><td>train_loss_step</td><td>0.49548</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.69963</td></tr><tr><td>val_auc</td><td>0.739</td></tr><tr><td>val_f1</td><td>0.58163</td></tr><tr><td>val_loss_epoch</td><td>0.61975</td></tr><tr><td>val_loss_step</td><td>0.66054</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GAT_3_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/j1h9emwb' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/j1h9emwb</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231219_110726-j1h9emwb\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b6e6cb891384842911eb712f0aa3549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231219_113053-eer29qhc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/eer29qhc' target=\"_blank\">GAT_3_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/eer29qhc' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/eer29qhc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GAT              | 78.5 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "80.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "80.7 K    Total params\n",
      "0.323     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0588ed06ba6470993ce0727c23cd52c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>lr-Adam</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_auc</td><td></td></tr><tr><td>train_f1</td><td></td></tr><tr><td>train_loss_epoch</td><td></td></tr><tr><td>train_loss_step</td><td></td></tr><tr><td>trainer/global_step</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_auc</td><td></td></tr><tr><td>val_f1</td><td></td></tr><tr><td>val_loss_epoch</td><td></td></tr><tr><td>val_loss_step</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.73699</td></tr><tr><td>train_auc</td><td>0.79315</td></tr><tr><td>train_f1</td><td>0.64792</td></tr><tr><td>train_loss_epoch</td><td>0.53686</td></tr><tr><td>train_loss_step</td><td>0.54803</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.68864</td></tr><tr><td>val_auc</td><td>0.77936</td></tr><tr><td>val_f1</td><td>0.69965</td></tr><tr><td>val_loss_epoch</td><td>0.62318</td></tr><tr><td>val_loss_step</td><td>0.65254</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GAT_3_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/eer29qhc' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/eer29qhc</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231219_113053-eer29qhc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e4d7864b89b4a33acbe6f613da23564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333330477276, max=1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231219_115529-kycklvg4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/kycklvg4' target=\"_blank\">GAT_3_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/kycklvg4' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/kycklvg4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GAT              | 78.5 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "80.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "80.7 K    Total params\n",
      "0.323     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cba0d310a4046958651745a51575aed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>lr-Adam</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_auc</td><td></td></tr><tr><td>train_f1</td><td></td></tr><tr><td>train_loss_epoch</td><td></td></tr><tr><td>train_loss_step</td><td></td></tr><tr><td>trainer/global_step</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_auc</td><td></td></tr><tr><td>val_f1</td><td></td></tr><tr><td>val_loss_epoch</td><td></td></tr><tr><td>val_loss_step</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.72694</td></tr><tr><td>train_auc</td><td>0.42443</td></tr><tr><td>train_f1</td><td>0.65984</td></tr><tr><td>train_loss_epoch</td><td>0.56561</td></tr><tr><td>train_loss_step</td><td>0.52088</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.72527</td></tr><tr><td>val_auc</td><td>0.2909</td></tr><tr><td>val_f1</td><td>0.69636</td></tr><tr><td>val_loss_epoch</td><td>0.5926</td></tr><tr><td>val_loss_step</td><td>0.5896</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GAT_3_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/kycklvg4' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/kycklvg4</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231219_115529-kycklvg4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eca83643d284ce6b1088896b2a773f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231219_121941-qfo799q9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qfo799q9' target=\"_blank\">GAT_3_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qfo799q9' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qfo799q9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GAT              | 78.5 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "80.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "80.7 K    Total params\n",
      "0.323     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1903218aaf044b2eaf0808aef61477f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>lr-Adam</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_auc</td><td></td></tr><tr><td>train_f1</td><td></td></tr><tr><td>train_loss_epoch</td><td></td></tr><tr><td>train_loss_step</td><td></td></tr><tr><td>trainer/global_step</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_auc</td><td></td></tr><tr><td>val_f1</td><td></td></tr><tr><td>val_loss_epoch</td><td></td></tr><tr><td>val_loss_step</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.75525</td></tr><tr><td>train_auc</td><td>0.80698</td></tr><tr><td>train_f1</td><td>0.67237</td></tr><tr><td>train_loss_epoch</td><td>0.53214</td></tr><tr><td>train_loss_step</td><td>0.51688</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.68498</td></tr><tr><td>val_auc</td><td>0.7598</td></tr><tr><td>val_f1</td><td>0.51685</td></tr><tr><td>val_loss_epoch</td><td>0.60422</td></tr><tr><td>val_loss_step</td><td>0.54941</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GAT_3_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qfo799q9' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qfo799q9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231219_121941-qfo799q9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8061c3a60ba3411f8b4b93fa42ad14f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333330477276, max=1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231219_124426-yar3rkyv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/yar3rkyv' target=\"_blank\">GAT_3_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/yar3rkyv' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/yar3rkyv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GAT              | 78.5 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "84.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "84.9 K    Total params\n",
      "0.339     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acb002f5de31457792a7d487e47a8423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>lr-Adam</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_auc</td><td></td></tr><tr><td>train_f1</td><td></td></tr><tr><td>train_loss_epoch</td><td></td></tr><tr><td>train_loss_step</td><td></td></tr><tr><td>trainer/global_step</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_auc</td><td></td></tr><tr><td>val_f1</td><td></td></tr><tr><td>val_loss_epoch</td><td></td></tr><tr><td>val_loss_step</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.74977</td></tr><tr><td>train_auc</td><td>0.80698</td></tr><tr><td>train_f1</td><td>0.65835</td></tr><tr><td>train_loss_epoch</td><td>0.53344</td></tr><tr><td>train_loss_step</td><td>0.63061</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.65568</td></tr><tr><td>val_auc</td><td>0.74423</td></tr><tr><td>val_f1</td><td>0.44706</td></tr><tr><td>val_loss_epoch</td><td>0.61681</td></tr><tr><td>val_loss_step</td><td>0.46774</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GAT_3_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/yar3rkyv' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/yar3rkyv</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231219_124426-yar3rkyv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "886928cf32b8411fa61e47445f802e91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231219_131002-ko5gnuf9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ko5gnuf9' target=\"_blank\">GAT_4_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ko5gnuf9' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ko5gnuf9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GAT              | 6.4 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "6.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.6 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ef5995e7674750a7541e21dcc56114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>lr-Adam</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_auc</td><td></td></tr><tr><td>train_f1</td><td></td></tr><tr><td>train_loss_epoch</td><td></td></tr><tr><td>train_loss_step</td><td></td></tr><tr><td>trainer/global_step</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_auc</td><td></td></tr><tr><td>val_f1</td><td></td></tr><tr><td>val_loss_epoch</td><td></td></tr><tr><td>val_loss_step</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.74886</td></tr><tr><td>train_auc</td><td>0.80182</td></tr><tr><td>train_f1</td><td>0.66747</td></tr><tr><td>train_loss_epoch</td><td>0.54993</td></tr><tr><td>train_loss_step</td><td>0.57143</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.62637</td></tr><tr><td>val_auc</td><td>0.77925</td></tr><tr><td>val_f1</td><td>0.66447</td></tr><tr><td>val_loss_epoch</td><td>0.63988</td></tr><tr><td>val_loss_step</td><td>0.6145</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GAT_4_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ko5gnuf9' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ko5gnuf9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231219_131002-ko5gnuf9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b30c7ccc2c646478b28023be1c2df96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666883975, max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231219_133436-qb98myhe</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qb98myhe' target=\"_blank\">GAT_4_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qb98myhe' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qb98myhe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GAT              | 6.4 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "6.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.6 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "426a191a0c6847a1b2aa21681aa6a5aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>lr-Adam</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_auc</td><td></td></tr><tr><td>train_f1</td><td></td></tr><tr><td>train_loss_epoch</td><td></td></tr><tr><td>train_loss_step</td><td></td></tr><tr><td>trainer/global_step</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_auc</td><td></td></tr><tr><td>val_f1</td><td></td></tr><tr><td>val_loss_epoch</td><td></td></tr><tr><td>val_loss_step</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.71416</td></tr><tr><td>train_auc</td><td>0.7497</td></tr><tr><td>train_f1</td><td>0.6043</td></tr><tr><td>train_loss_epoch</td><td>0.5829</td></tr><tr><td>train_loss_step</td><td>0.55907</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.60073</td></tr><tr><td>val_auc</td><td>0.74668</td></tr><tr><td>val_f1</td><td>0.64952</td></tr><tr><td>val_loss_epoch</td><td>0.65016</td></tr><tr><td>val_loss_step</td><td>0.64513</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GAT_4_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qb98myhe' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qb98myhe</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231219_133436-qb98myhe\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b837c7f0db92446491ec51afea45d964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231219_140118-azxdkznp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/azxdkznp' target=\"_blank\">GAT_4_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/azxdkznp' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/azxdkznp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GAT              | 6.4 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "6.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.6 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07de31859dfd4a868e422c8b4a250ba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>lr-Adam</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_auc</td><td></td></tr><tr><td>train_f1</td><td></td></tr><tr><td>train_loss_epoch</td><td></td></tr><tr><td>train_loss_step</td><td></td></tr><tr><td>trainer/global_step</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_auc</td><td></td></tr><tr><td>val_f1</td><td></td></tr><tr><td>val_loss_epoch</td><td></td></tr><tr><td>val_loss_step</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.72055</td></tr><tr><td>train_auc</td><td>0.61005</td></tr><tr><td>train_f1</td><td>0.62774</td></tr><tr><td>train_loss_epoch</td><td>0.59716</td></tr><tr><td>train_loss_step</td><td>0.63539</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.7033</td></tr><tr><td>val_auc</td><td>0.7573</td></tr><tr><td>val_f1</td><td>0.65236</td></tr><tr><td>val_loss_epoch</td><td>0.57601</td></tr><tr><td>val_loss_step</td><td>0.49717</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GAT_4_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/azxdkznp' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/azxdkznp</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231219_140118-azxdkznp\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f77f9086af84a0fbd543aebc3e15ebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666883975, max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231219_142721-4umv1m9d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/4umv1m9d' target=\"_blank\">GAT_4_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/4umv1m9d' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/4umv1m9d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GAT              | 6.4 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "6.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.6 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a7b4247e8ab4ff99ae86733aa6cd94b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>lr-Adam</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_auc</td><td></td></tr><tr><td>train_f1</td><td></td></tr><tr><td>train_loss_epoch</td><td></td></tr><tr><td>train_loss_step</td><td></td></tr><tr><td>trainer/global_step</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_auc</td><td></td></tr><tr><td>val_f1</td><td></td></tr><tr><td>val_loss_epoch</td><td></td></tr><tr><td>val_loss_step</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.73881</td></tr><tr><td>train_auc</td><td>0.81083</td></tr><tr><td>train_f1</td><td>0.61456</td></tr><tr><td>train_loss_epoch</td><td>0.53053</td></tr><tr><td>train_loss_step</td><td>0.46198</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.72894</td></tr><tr><td>val_auc</td><td>0.7841</td></tr><tr><td>val_f1</td><td>0.704</td></tr><tr><td>val_loss_epoch</td><td>0.5569</td></tr><tr><td>val_loss_step</td><td>0.55482</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GAT_4_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/4umv1m9d' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/4umv1m9d</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231219_142721-4umv1m9d\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4eec76a31cc4eacb73a59b68184cdb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231219_145223-fba7okgk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/fba7okgk' target=\"_blank\">GAT_4_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/fba7okgk' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/fba7okgk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GAT              | 6.4 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "6.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.9 K     Total params\n",
      "0.028     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "760b0b3774e04ac599af2a1eddff1c47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>lr-Adam</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_auc</td><td></td></tr><tr><td>train_f1</td><td></td></tr><tr><td>train_loss_epoch</td><td></td></tr><tr><td>train_loss_step</td><td></td></tr><tr><td>trainer/global_step</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_auc</td><td></td></tr><tr><td>val_f1</td><td></td></tr><tr><td>val_loss_epoch</td><td></td></tr><tr><td>val_loss_step</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.7516</td></tr><tr><td>train_auc</td><td>0.79931</td></tr><tr><td>train_f1</td><td>0.64948</td></tr><tr><td>train_loss_epoch</td><td>0.54233</td></tr><tr><td>train_loss_step</td><td>0.61318</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.69597</td></tr><tr><td>val_auc</td><td>0.76536</td></tr><tr><td>val_f1</td><td>0.68679</td></tr><tr><td>val_loss_epoch</td><td>0.63586</td></tr><tr><td>val_loss_step</td><td>0.71378</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GAT_4_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/fba7okgk' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/fba7okgk</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231219_145223-fba7okgk\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f557b13fe644cf9d8e8245b934a44e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231219_151653-iwnfu703</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/iwnfu703' target=\"_blank\">GAT_4_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/iwnfu703' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/iwnfu703</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GAT              | 23.1 K\n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "23.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "23.7 K    Total params\n",
      "0.095     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22a289398d324de095f2c32e21dc2e64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>lr-Adam</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_auc</td><td></td></tr><tr><td>train_f1</td><td></td></tr><tr><td>train_loss_epoch</td><td></td></tr><tr><td>train_loss_step</td><td></td></tr><tr><td>trainer/global_step</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_auc</td><td></td></tr><tr><td>val_f1</td><td></td></tr><tr><td>val_loss_epoch</td><td></td></tr><tr><td>val_loss_step</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.75799</td></tr><tr><td>train_auc</td><td>0.80482</td></tr><tr><td>train_f1</td><td>0.66583</td></tr><tr><td>train_loss_epoch</td><td>0.52755</td></tr><tr><td>train_loss_step</td><td>0.45226</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.72161</td></tr><tr><td>val_auc</td><td>0.78017</td></tr><tr><td>val_f1</td><td>0.67521</td></tr><tr><td>val_loss_epoch</td><td>0.564</td></tr><tr><td>val_loss_step</td><td>0.57937</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GAT_4_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/iwnfu703' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/iwnfu703</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231219_151653-iwnfu703\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b24ea62d2909420ab80475598ff100b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231219_154015-gckc4okw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/gckc4okw' target=\"_blank\">GAT_4_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/gckc4okw' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/gckc4okw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GAT              | 23.1 K\n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "23.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "23.7 K    Total params\n",
      "0.095     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f043ee5e5d7401795ec4fd28c8be6ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>lr-Adam</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_auc</td><td></td></tr><tr><td>train_f1</td><td></td></tr><tr><td>train_loss_epoch</td><td></td></tr><tr><td>train_loss_step</td><td></td></tr><tr><td>trainer/global_step</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_auc</td><td></td></tr><tr><td>val_f1</td><td></td></tr><tr><td>val_loss_epoch</td><td></td></tr><tr><td>val_loss_step</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.7379</td></tr><tr><td>train_auc</td><td>0.79669</td></tr><tr><td>train_f1</td><td>0.64348</td></tr><tr><td>train_loss_epoch</td><td>0.53085</td></tr><tr><td>train_loss_step</td><td>0.43972</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.7033</td></tr><tr><td>val_auc</td><td>0.78666</td></tr><tr><td>val_f1</td><td>0.67729</td></tr><tr><td>val_loss_epoch</td><td>0.61555</td></tr><tr><td>val_loss_step</td><td>0.64756</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GAT_4_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/gckc4okw' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/gckc4okw</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231219_154015-gckc4okw\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "556e17e251464b80bc5b9f15f6fbf826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666495924, max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231219_160054-aio1bmsu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/aio1bmsu' target=\"_blank\">GAT_4_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/aio1bmsu' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/aio1bmsu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GAT              | 23.1 K\n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "23.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "23.7 K    Total params\n",
      "0.095     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e04642a1e9624f4c904db3e0310163f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>lr-Adam</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_auc</td><td></td></tr><tr><td>train_f1</td><td></td></tr><tr><td>train_loss_epoch</td><td></td></tr><tr><td>train_loss_step</td><td></td></tr><tr><td>trainer/global_step</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_auc</td><td></td></tr><tr><td>val_f1</td><td></td></tr><tr><td>val_loss_epoch</td><td></td></tr><tr><td>val_loss_step</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.72055</td></tr><tr><td>train_auc</td><td>0.47758</td></tr><tr><td>train_f1</td><td>0.63658</td></tr><tr><td>train_loss_epoch</td><td>0.5857</td></tr><tr><td>train_loss_step</td><td>0.63361</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.70696</td></tr><tr><td>val_auc</td><td>0.23001</td></tr><tr><td>val_f1</td><td>0.59184</td></tr><tr><td>val_loss_epoch</td><td>0.60305</td></tr><tr><td>val_loss_step</td><td>0.50092</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GAT_4_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/aio1bmsu' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/aio1bmsu</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231219_160054-aio1bmsu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c7e6491d7764698854d46af28f3638d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231219_162107-tqn4pvac</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/tqn4pvac' target=\"_blank\">GAT_4_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/tqn4pvac' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/tqn4pvac</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GAT              | 23.1 K\n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "23.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "23.7 K    Total params\n",
      "0.095     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1cd5f5733514abda4df2aea260131d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>lr-Adam</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_auc</td><td></td></tr><tr><td>train_f1</td><td></td></tr><tr><td>train_loss_epoch</td><td></td></tr><tr><td>train_loss_step</td><td></td></tr><tr><td>trainer/global_step</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_auc</td><td></td></tr><tr><td>val_f1</td><td></td></tr><tr><td>val_loss_epoch</td><td></td></tr><tr><td>val_loss_step</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.75616</td></tr><tr><td>train_auc</td><td>0.80838</td></tr><tr><td>train_f1</td><td>0.68917</td></tr><tr><td>train_loss_epoch</td><td>0.53</td></tr><tr><td>train_loss_step</td><td>0.52617</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.71429</td></tr><tr><td>val_auc</td><td>0.78208</td></tr><tr><td>val_f1</td><td>0.60606</td></tr><tr><td>val_loss_epoch</td><td>0.63573</td></tr><tr><td>val_loss_step</td><td>0.75514</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GAT_4_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/tqn4pvac' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/tqn4pvac</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231219_162107-tqn4pvac\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9133980064124b5eb4a54dd211d755a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231219_164133-y5oy77v2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/y5oy77v2' target=\"_blank\">GAT_4_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/y5oy77v2' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/y5oy77v2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GAT              | 23.1 K\n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "24.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.8 K    Total params\n",
      "0.099     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "121626c5f36c4ced8e8f96f2168e7553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>lr-Adam</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_auc</td><td></td></tr><tr><td>train_f1</td><td></td></tr><tr><td>train_loss_epoch</td><td></td></tr><tr><td>train_loss_step</td><td></td></tr><tr><td>trainer/global_step</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_auc</td><td></td></tr><tr><td>val_f1</td><td></td></tr><tr><td>val_loss_epoch</td><td></td></tr><tr><td>val_loss_step</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.75434</td></tr><tr><td>train_auc</td><td>0.81096</td></tr><tr><td>train_f1</td><td>0.65906</td></tr><tr><td>train_loss_epoch</td><td>0.5283</td></tr><tr><td>train_loss_step</td><td>0.57679</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.69963</td></tr><tr><td>val_auc</td><td>0.77249</td></tr><tr><td>val_f1</td><td>0.64035</td></tr><tr><td>val_loss_epoch</td><td>0.55345</td></tr><tr><td>val_loss_step</td><td>0.51726</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GAT_4_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/y5oy77v2' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/y5oy77v2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231219_164133-y5oy77v2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0567ad49d4c24490940c861fb886f141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333330477276, max=1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231219_170003-dhssw5do</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/dhssw5do' target=\"_blank\">GAT_4_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/dhssw5do' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/dhssw5do</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GAT              | 87.2 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "89.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "89.4 K    Total params\n",
      "0.358     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe81b1e4d3144bb18e795ef6eb9a89ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>lr-Adam</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_auc</td><td></td></tr><tr><td>train_f1</td><td></td></tr><tr><td>train_loss_epoch</td><td></td></tr><tr><td>train_loss_step</td><td></td></tr><tr><td>trainer/global_step</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_auc</td><td></td></tr><tr><td>val_f1</td><td></td></tr><tr><td>val_loss_epoch</td><td></td></tr><tr><td>val_loss_step</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77169</td></tr><tr><td>train_auc</td><td>0.8273</td></tr><tr><td>train_f1</td><td>0.69586</td></tr><tr><td>train_loss_epoch</td><td>0.50491</td></tr><tr><td>train_loss_step</td><td>0.60597</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.65934</td></tr><tr><td>val_auc</td><td>0.72702</td></tr><tr><td>val_f1</td><td>0.52792</td></tr><tr><td>val_loss_epoch</td><td>0.58981</td></tr><tr><td>val_loss_step</td><td>0.50337</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GAT_4_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/dhssw5do' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/dhssw5do</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231219_170003-dhssw5do\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b77e6b0e11c148ae93f530ca53f93483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231219_171743-3s1tzf9l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/3s1tzf9l' target=\"_blank\">GAT_4_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/3s1tzf9l' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/3s1tzf9l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GAT              | 87.2 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "89.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "89.4 K    Total params\n",
      "0.358     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cc2f6417e664a93b361bee16953632d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>lr-Adam</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_auc</td><td></td></tr><tr><td>train_f1</td><td></td></tr><tr><td>train_loss_epoch</td><td></td></tr><tr><td>train_loss_step</td><td></td></tr><tr><td>trainer/global_step</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_auc</td><td></td></tr><tr><td>val_f1</td><td></td></tr><tr><td>val_loss_epoch</td><td></td></tr><tr><td>val_loss_step</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.7653</td></tr><tr><td>train_auc</td><td>0.82075</td></tr><tr><td>train_f1</td><td>0.69148</td></tr><tr><td>train_loss_epoch</td><td>0.52339</td></tr><tr><td>train_loss_step</td><td>0.64804</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.67766</td></tr><tr><td>val_auc</td><td>0.79297</td></tr><tr><td>val_f1</td><td>0.69863</td></tr><tr><td>val_loss_epoch</td><td>0.57881</td></tr><tr><td>val_loss_step</td><td>0.55711</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GAT_4_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/3s1tzf9l' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/3s1tzf9l</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231219_171743-3s1tzf9l\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce4e7f4ce6e947bfa7ccfcf93956979a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231219_173509-jtfobnb4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/jtfobnb4' target=\"_blank\">GAT_4_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/jtfobnb4' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/jtfobnb4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GAT              | 87.2 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "89.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "89.4 K    Total params\n",
      "0.358     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2bc03ca49354d7ea64d90985f5fe088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>lr-Adam</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_auc</td><td></td></tr><tr><td>train_f1</td><td></td></tr><tr><td>train_loss_epoch</td><td></td></tr><tr><td>train_loss_step</td><td></td></tr><tr><td>trainer/global_step</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_auc</td><td></td></tr><tr><td>val_f1</td><td></td></tr><tr><td>val_loss_epoch</td><td></td></tr><tr><td>val_loss_step</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.72968</td></tr><tr><td>train_auc</td><td>0.59355</td></tr><tr><td>train_f1</td><td>0.65176</td></tr><tr><td>train_loss_epoch</td><td>0.5467</td></tr><tr><td>train_loss_step</td><td>0.64297</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.73626</td></tr><tr><td>val_auc</td><td>0.76623</td></tr><tr><td>val_f1</td><td>0.70248</td></tr><tr><td>val_loss_epoch</td><td>0.60036</td></tr><tr><td>val_loss_step</td><td>0.61157</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GAT_4_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/jtfobnb4' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/jtfobnb4</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231219_173509-jtfobnb4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eea31bf702f437e8869365987b23b59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231219_175331-7ixqwkk6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/7ixqwkk6' target=\"_blank\">GAT_4_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/7ixqwkk6' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/7ixqwkk6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GAT              | 87.2 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "89.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "89.4 K    Total params\n",
      "0.358     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adfd63394a2b4bf59fe576e144a29e6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>lr-Adam</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_auc</td><td></td></tr><tr><td>train_f1</td><td></td></tr><tr><td>train_loss_epoch</td><td></td></tr><tr><td>train_loss_step</td><td></td></tr><tr><td>trainer/global_step</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_auc</td><td></td></tr><tr><td>val_f1</td><td></td></tr><tr><td>val_loss_epoch</td><td></td></tr><tr><td>val_loss_step</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.7589</td></tr><tr><td>train_auc</td><td>0.80782</td></tr><tr><td>train_f1</td><td>0.68116</td></tr><tr><td>train_loss_epoch</td><td>0.52168</td></tr><tr><td>train_loss_step</td><td>0.53153</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.68132</td></tr><tr><td>val_auc</td><td>0.73758</td></tr><tr><td>val_f1</td><td>0.56281</td></tr><tr><td>val_loss_epoch</td><td>0.66901</td></tr><tr><td>val_loss_step</td><td>0.74489</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GAT_4_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/7ixqwkk6' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/7ixqwkk6</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231219_175331-7ixqwkk6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84d6d09aeb074cba95293ed4694eb8ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231219_181316-l0u84c9f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/l0u84c9f' target=\"_blank\">GAT_4_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/l0u84c9f' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/l0u84c9f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GAT              | 87.2 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "93.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "93.6 K    Total params\n",
      "0.374     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "353f14ff612b4e3abbad0bec42faec43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>lr-Adam</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_auc</td><td></td></tr><tr><td>train_f1</td><td></td></tr><tr><td>train_loss_epoch</td><td></td></tr><tr><td>train_loss_step</td><td></td></tr><tr><td>trainer/global_step</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_auc</td><td></td></tr><tr><td>val_f1</td><td></td></tr><tr><td>val_loss_epoch</td><td></td></tr><tr><td>val_loss_step</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.76256</td></tr><tr><td>train_auc</td><td>0.81166</td></tr><tr><td>train_f1</td><td>0.67901</td></tr><tr><td>train_loss_epoch</td><td>0.52213</td></tr><tr><td>train_loss_step</td><td>0.53576</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.69231</td></tr><tr><td>val_auc</td><td>0.7561</td></tr><tr><td>val_f1</td><td>0.56701</td></tr><tr><td>val_loss_epoch</td><td>0.5869</td></tr><tr><td>val_loss_step</td><td>0.55083</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GAT_4_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/l0u84c9f' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/l0u84c9f</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231219_181316-l0u84c9f\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k_folds = 5\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_ids, valid_ids) in enumerate(kfold.split(dataset_filtered)):\n",
    "    train_subset = dataset_filtered.index_select(train_ids.tolist())\n",
    "    val_subset = dataset_filtered.index_select(valid_ids.tolist())\n",
    "    for NUM_LAYERS, HIDDEN_CHANNELS, pool, in list(itertools.product(*[num_layers, hiddens, pools])):\n",
    "            # Path to the folder where the pretrained models are saved\n",
    "        CHECKPOINT_PATH = checkpoint_folder / f'GAT_{NUM_LAYERS}_{HIDDEN_CHANNELS}_onehot_{fold}' / pool\n",
    "        CHECKPOINT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Skip already trained kfold and pool\n",
    "        checkpoint = CHECKPOINT_PATH / f\"GraphLevel{model}\" / f\"GraphLevel{model}.ckpt\" \n",
    "        if checkpoint.exists():\n",
    "            print(checkpoint)\n",
    "            continue\n",
    "\n",
    "        # Run training\n",
    "        run = wandb.init(project=project_name, name=f'{model}_{NUM_LAYERS}_{HIDDEN_CHANNELS}_onehot_{fold}', \n",
    "                        group=f'{model}_{pool}', \n",
    "                        # mode=\"disabled\"\n",
    "                        )\n",
    "        PPIGraph.train_graph_classifier_kfold(model, \n",
    "                                                train_subset, \n",
    "                                                val_subset, \n",
    "                                                dataset, \n",
    "                                                CHECKPOINT_PATH, \n",
    "                                                AVAIL_GPUS, \n",
    "                                                in_channels=9,\n",
    "                                                hidden_channels=HIDDEN_CHANNELS, \n",
    "                                                out_channels = HIDDEN_CHANNELS,\n",
    "                                                num_layers=NUM_LAYERS, \n",
    "                                                epochs=epochs,\n",
    "                                                embedding=False,\n",
    "                                                batch_size=128,\n",
    "                                                graph_pooling=pool)\n",
    "        run.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snowflake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
