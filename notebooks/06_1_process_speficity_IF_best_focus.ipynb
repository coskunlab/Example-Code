{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.io\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import trange, tqdm, tqdm_notebook\n",
    "from joblib import Parallel, delayed\n",
    "import re\n",
    "import h5py\n",
    "import tifffile as tiff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = (Path().cwd().parents[0] / 'data').absolute()\n",
    "data_processed = data_dir / 'processed'\n",
    "data_raw = r'Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\Specificity experiments\\Bim IF comparison'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    " \n",
    "os.environ['JDK_HOME'] = \"C:\\Program Files\\Java\\jdk-17\"\n",
    "os.environ['JAVA_HOME'] = \"C:\\Program Files\\Java\\jdk-17\"\n",
    "\n",
    "os.environ['PATH'] += ';C:\\\\Program Files\\\\Java\\\\jdk-17\\\\jre\\\\bin\\\\server\\\\;C:\\\\Program Files\\\\Java\\\\jdk-17\\\\bin\\\\;C:\\\\Program Files\\\\Java\\\\jdk-17\\\\bin\\\\jar.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Get info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers_map = {\n",
    "    'cycle1': {\n",
    "        1: 'DNA', \n",
    "        3: 'Bim',\n",
    "    },\n",
    "    'cycle2': {\n",
    "        1: 'DNA', \n",
    "        2: 'Concanavalin A',\n",
    "        3: 'Phalloidin',\n",
    "        4: 'WGA',\n",
    "    },\n",
    "}\n",
    "\n",
    "def get_info(data_raw, marker_dict):\n",
    "    conditions = []\n",
    "    fovs = []\n",
    "    cycles = []\n",
    "    channels = []\n",
    "    markers = []\n",
    "    rois = []\n",
    "    z_stacks = []\n",
    "    paths = [] \n",
    "    \n",
    "    # Loop through image folder\n",
    "    for (dirpath, dirnames, filenames) in os.walk(data_raw):\n",
    "        if 'after nuclease' in dirpath or 'Test' in dirpath or 'wrong' in dirpath:\n",
    "            continue\n",
    "        \n",
    "            \n",
    "        for name in sorted(filenames):\n",
    "            if \"tif\" in name and \"sti\" not in name \\\n",
    "            and 'over' not in name.lower() \\\n",
    "            and 'comp' not in name.lower():\n",
    "                # Get information from image name\n",
    "                c = filenames[-1][-1] \n",
    "                \n",
    "                if c  == '6':\n",
    "                    condition = 'KO'\n",
    "                elif c == '8':\n",
    "                    condition = 'Control'\n",
    "                \n",
    "                d_split = dirpath.split('\\\\')\n",
    "                well = d_split[-2].split('_')[1].split(' ')[0]\n",
    "                n_split = name.split('_')\n",
    "                roi = int(n_split[2])\n",
    "                z = int(n_split[3][1:])\n",
    "                ch = int(n_split[4][2])\n",
    "                \n",
    "                if 'Seg' in dirpath:\n",
    "                    cycle = 'cycle2'\n",
    "                else:\n",
    "                    cycle = 'cycle1'\n",
    "                try: marker = marker_dict[cycle][ch] \n",
    "                except: continue\n",
    "                \n",
    "                conditions.append(condition)\n",
    "                cycles.append(cycle)\n",
    "                channels.append(ch)\n",
    "                markers.append(marker)\n",
    "                rois.append(roi)\n",
    "                z_stacks.append(z)\n",
    "                paths.append(os.path.join(dirpath, name))\n",
    "                \n",
    "    info = {\n",
    "            \"Condition\": conditions,\n",
    "            'FOV': conditions, \n",
    "            \"Cycle\": cycles,\n",
    "            \"Channels\": channels,\n",
    "            \"Markers\": markers,\n",
    "            \"ROI\": rois,\n",
    "            \"Z\": z_stacks,\n",
    "            \"Path\": paths\n",
    "        }\n",
    "\n",
    "    df = pd.DataFrame(info)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created df\n"
     ]
    }
   ],
   "source": [
    "df_meta_path = data_dir / 'specificity_IF_best' / 'metadata' / 'info.csv'\n",
    "df_meta_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "df_exist = df_meta_path.is_file()\n",
    "\n",
    "if not df_exist:\n",
    "    print('Created df')\n",
    "    df = get_info(data_raw, markers_map)\n",
    "    df.to_csv(df_meta_path, index=False)\n",
    "else:\n",
    "    print('Loaded df')\n",
    "    df = pd.read_csv(df_meta_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Save HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from natsort import natsorted, natsort_keygen\n",
    "\n",
    "def save_hdf5(\n",
    "    path: str, name: str, data: np.ndarray, attr_dict=None, mode: str = \"a\"\n",
    ") -> None:\n",
    "    # Read h5 file\n",
    "    hf = h5py.File(path, mode)\n",
    "    # Create z_stack_dataset\n",
    "    if hf.get(name) is None:\n",
    "        data_shape = data.shape\n",
    "        data_type = data.dtype\n",
    "        max_shape = (data_shape[0],) + data_shape[1:]\n",
    "        dset = hf.create_dataset(\n",
    "            name,\n",
    "            shape=data_shape,\n",
    "            maxshape=max_shape,\n",
    "            chunks=True,\n",
    "            dtype=data_type,\n",
    "            compression=\"gzip\",\n",
    "        )\n",
    "        dset[:] = data\n",
    "        if attr_dict is not None:\n",
    "            for attr_key, attr_val in attr_dict.items():\n",
    "                dset.attrs[attr_key] = attr_val\n",
    "    else:\n",
    "        print(f\"Dataset {name} exists\")\n",
    "\n",
    "    hf.close()\n",
    "\n",
    "def read_img(path):\n",
    "    return skimage.io.imread(path, as_gray=True)\n",
    "\n",
    "def joblib_loop(task, pics):\n",
    "    return Parallel(n_jobs=20)(delayed(task)(i) for i in pics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created df\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfe71dae3e9f4722a03c9ae93578aca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_imgs_path = data_dir / 'specificity_IF_best' / 'metadata' / 'imgs.csv'\n",
    "df_imgs_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "temp_path = data_dir  /'specificity_IF_best' /  'hdf5' / 'raw'\n",
    "temp_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_exist = df_imgs_path.is_file()\n",
    "\n",
    "if not df_exist:\n",
    "    print('Created df')\n",
    "    \n",
    "    group = df.groupby(['Condition','FOV', 'ROI'])\n",
    "    rows = []\n",
    "    \n",
    "    for name, df_group in tqdm(group, total=len(group)):\n",
    "        df_group = df_group.sort_values( # Sort by cycle and channels\n",
    "            by=[\"Cycle\", \"Channels\", 'Z'],\n",
    "            key=natsort_keygen()\n",
    "        )\n",
    "        file_name = '_'.join(np.array(name).astype(str)) + '.hdf5'\n",
    "        file_path = temp_path / file_name\n",
    "        rows.append(list(name)+[file_path])\n",
    "        \n",
    "        group_channel = df_group.groupby(['Cycle', 'Channels'])\n",
    "        for n, df_channel in group_channel:\n",
    "            try:\n",
    "                if test_data_exist(file_path, '_'.join(np.array(n).astype(str))):\n",
    "                    continue\n",
    "            except:pass\n",
    "            \n",
    "            marker = df_channel.iloc[0].Markers\n",
    "            paths = df_channel.Path.to_numpy()\n",
    "\n",
    "            imgs = joblib_loop(read_img, paths)\n",
    "            imgs = np.array(imgs)\n",
    "            info = {\"Cycle\": n[0], \"Channel\": n[1], \"Marker\": marker, \"Z\": df_channel.Z.to_numpy()}\n",
    "            \n",
    "            # hdf5 as Channel -> Z mapping\n",
    "            save_hdf5(file_path, '_'.join(np.array(n).astype(str)), imgs, info)\n",
    "    df_imgs = pd.DataFrame(rows, columns=['Condition','FOV', 'ROI', 'Path'])        \n",
    "    df_imgs.to_csv(df_imgs_path, index=False)\n",
    "else:\n",
    "    print('Loaded df')\n",
    "    df_imgs = pd.read_csv(df_imgs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Condition</th>\n",
       "      <th>FOV</th>\n",
       "      <th>ROI</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Control</td>\n",
       "      <td>Control</td>\n",
       "      <td>1</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Control</td>\n",
       "      <td>Control</td>\n",
       "      <td>2</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Control</td>\n",
       "      <td>Control</td>\n",
       "      <td>3</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Control</td>\n",
       "      <td>Control</td>\n",
       "      <td>4</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Control</td>\n",
       "      <td>Control</td>\n",
       "      <td>5</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Control</td>\n",
       "      <td>Control</td>\n",
       "      <td>6</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Control</td>\n",
       "      <td>Control</td>\n",
       "      <td>7</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Control</td>\n",
       "      <td>Control</td>\n",
       "      <td>8</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Control</td>\n",
       "      <td>Control</td>\n",
       "      <td>9</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KO</td>\n",
       "      <td>KO</td>\n",
       "      <td>1</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KO</td>\n",
       "      <td>KO</td>\n",
       "      <td>2</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KO</td>\n",
       "      <td>KO</td>\n",
       "      <td>3</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KO</td>\n",
       "      <td>KO</td>\n",
       "      <td>4</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KO</td>\n",
       "      <td>KO</td>\n",
       "      <td>5</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KO</td>\n",
       "      <td>KO</td>\n",
       "      <td>6</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>KO</td>\n",
       "      <td>KO</td>\n",
       "      <td>7</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>KO</td>\n",
       "      <td>KO</td>\n",
       "      <td>8</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>KO</td>\n",
       "      <td>KO</td>\n",
       "      <td>9</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Condition      FOV  ROI                                               Path\n",
       "0    Control  Control    1  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...\n",
       "1    Control  Control    2  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...\n",
       "2    Control  Control    3  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...\n",
       "3    Control  Control    4  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...\n",
       "4    Control  Control    5  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...\n",
       "5    Control  Control    6  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...\n",
       "6    Control  Control    7  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...\n",
       "7    Control  Control    8  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...\n",
       "8    Control  Control    9  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...\n",
       "9         KO       KO    1  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...\n",
       "10        KO       KO    2  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...\n",
       "11        KO       KO    3  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...\n",
       "12        KO       KO    4  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...\n",
       "13        KO       KO    5  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...\n",
       "14        KO       KO    6  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...\n",
       "15        KO       KO    7  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...\n",
       "16        KO       KO    8  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...\n",
       "17        KO       KO    9  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec..."
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Calculate best focus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import cv2 \n",
    "import scipy \n",
    "\n",
    "# compute laplacian for each z plane in parallel\n",
    "def computeLapVar(plane):\n",
    "    \n",
    "    var = cv2.Laplacian(plane, cv2.CV_64F, ksize = 31)\n",
    "    var = np.var(var)\n",
    "    \n",
    "    return var\n",
    "\n",
    "# find focus plane via Laplacian variance\n",
    "def findFocusLapVar(subStack):\n",
    "    \n",
    "    lapVar = Parallel(n_jobs = -1, prefer = 'threads', verbose = 0)(delayed(computeLapVar)(subStack[ii, :, :]) for ii in range(subStack.shape[0]))\n",
    "    idxFocus = np.argmax(lapVar)\n",
    "\n",
    "    xRange = np.arange(0, len(lapVar))\n",
    "    \n",
    "    # compute steepest gradient in variance to find focus plane\n",
    "    grad = np.gradient(lapVar)\n",
    "    grad = np.square(grad)\n",
    "    \n",
    "    # extract peaks of gradient\n",
    "    thresh = np.percentile(grad, 50)\n",
    "    # peaks with min horizontal distance\n",
    "    peaks, props = scipy.signal.find_peaks(x = grad, height = thresh, distance = 1)\n",
    "    heights = props['peak_heights']\n",
    "    \n",
    "    # idxFocus = np.argmax(grad) + 2\n",
    "    if len(peaks) == 0:\n",
    "        idxFocus = len(lapVar) // 2 # middle\n",
    "        \n",
    "    else:\n",
    "        idxFocus = peaks[0] # tallest peak\n",
    "        \n",
    "    if idxFocus > len(lapVar) - 2: # exceeds length, out of bounds\n",
    "        idxFocus = len(lapVar) - 2\n",
    "        \n",
    "    return idxFocus, peaks, lapVar\n",
    "\n",
    "# register cycles across Z by matching focus planes\n",
    "def registerAlongZ(fixed, moving): # each ZYX\n",
    "     \n",
    "    # match moving to fixed\n",
    "    focusFixed, peaksFixed = findFocusLapVar(fixed) # focus plane of fixed\n",
    "    focusMoving, peaksMoving = findFocusLapVar(moving) # focus plane of moving\n",
    "    \n",
    "    # if multiple peaks found, choose closest to middle \n",
    "    if len(peaksFixed) > 1:\n",
    "        # print('Multiple fixed peaks found...')\n",
    "        middle = fixed.shape[0] // 2\n",
    "        diff = np.abs(peaksFixed - middle)\n",
    "        closest = np.argmin(diff)\n",
    "        focusFixed = peaksFixed[closest]\n",
    "        \n",
    "    if len(peaksMoving) > 1:\n",
    "        # print('Multiple moving peaks found...')\n",
    "        middle = moving.shape[0] // 2\n",
    "        diff = np.abs(peaksMoving - middle)\n",
    "        closest = np.argmin(diff)\n",
    "        focusMoving = peaksMoving[closest]\n",
    "    \n",
    "    # print('Fixed focus plane is', focusFixed + 1, '/', fixed.shape[0])\n",
    "    # print('Moving focus plane is', focusMoving + 1, '/', moving.shape[0])\n",
    "    shift = focusFixed - focusMoving # z shift applied to moving to match fixed\n",
    "    \n",
    "    return shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row = df_imgs.iloc[1]\n",
    "# path = row.Path\n",
    "# print(row)\n",
    "# with h5py.File(path, \"r\") as f:\n",
    "#     for k in tqdm(f.keys(), total=len(f.keys()), leave=False):\n",
    "#         imgs = f[k][:]\n",
    "#         break\n",
    "\n",
    "# plt.imshow(imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imgs_path = data_dir / 'specificity_IF_best' / 'metadata' / 'imgs.csv'\n",
    "df_imgs = pd.read_csv(df_imgs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56c7f7edc47f4beba9dc281b1f3af96b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import defaultdict \n",
    "\n",
    "best_focus = defaultdict(list)\n",
    "row = df_imgs.iloc[1]\n",
    "path = row.Path\n",
    "\n",
    "with h5py.File(path, \"r\") as f:\n",
    "    for k in tqdm(f.keys(), total=len(f.keys()), leave=False):\n",
    "        cycle = k.split('_')[0]\n",
    "        channel = f[k].attrs['Channel']\n",
    "\n",
    "        if channel == 1:\n",
    "            imgs = f[k][:]\n",
    "\n",
    "            z, p, lapVar = findFocusLapVar(imgs)\n",
    "            \n",
    "            best_focus[cycle] = np.argmax(lapVar)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle \n",
    "# with open(f'{row.Condition}.pkl', 'wb') as f:\n",
    "#     pickle.dump(best_focus,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Save Tifffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile as tiff\n",
    "from skimage import exposure, util\n",
    "import pickle \n",
    "\n",
    "save_path = data_dir / 'specificity_IF_best' / 'imgs' / 'raw_norm'\n",
    "\n",
    "def contrast_str(img, n_min=0.01, n_max=100):\n",
    "    p2, p98 = np.percentile(img, (n_min, n_max))\n",
    "    img_rescale = exposure.rescale_intensity(img, in_range=(p2, p98))\n",
    "    return img_rescale\n",
    "\n",
    "def make_imgs_same_dim(imgs):\n",
    "    # Get max dimensions\n",
    "    shapes = np.array([img.shape[1:] for img in imgs])\n",
    "    min_x, min_y = shapes.min(axis=0)\n",
    "    imgs_cropped = [img[:, :min_x, :min_y] for img in imgs]\n",
    "    for i, img in enumerate(imgs_cropped):\n",
    "        imgs_cropped[i][0,...] = contrast_str(imgs_cropped[i][0,...])\n",
    "    return imgs_cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Control_Control.pkl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73a6b495166d45e89588fd69b251a3c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KO_KO.pkl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1f17d9efcfd414cbcb827dac3eaa2f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_path.mkdir(parents=True, exist_ok=True)\n",
    "n = 1\n",
    "group = df_imgs.groupby(['Condition','FOV'])\n",
    "for name, df_group in group:\n",
    "    print('_'.join(name)+'.pkl')\n",
    "    with open(f'{row.Condition}.pkl', 'rb') as f:\n",
    "        best_focus = pickle.load(f)\n",
    "        \n",
    "    for i, row in tqdm(enumerate(df_group.itertuples()), total=len(df_group)):\n",
    "        path = row.Path\n",
    "\n",
    "        # Read images\n",
    "        cycles = []\n",
    "        imgs_all = []\n",
    "        channels = []\n",
    "        with h5py.File(path, \"r\") as f:\n",
    "            for k in tqdm(f.keys(), total=len(f.keys()), leave=False):\n",
    "                cycle = k.split('_')[0]\n",
    "                channel = f[k].attrs['Channel']\n",
    "\n",
    "                imgs = f[k][:]\n",
    "                cycles.append(cycle)\n",
    "                channels.append(channel)\n",
    "                imgs_all.append(imgs)\n",
    "                       \n",
    "        cycles = np.array(cycles)\n",
    "        channels = np.array(channels)\n",
    "\n",
    "        # Register by z focus\n",
    "        imgs_matched_z = [] \n",
    "        for i, img in enumerate(imgs_all):\n",
    "            best = best_focus[cycles[i]]\n",
    "            imgs_matched_z.append(img[best-n:best+n])\n",
    "\n",
    "        # Get imgs_stacked\n",
    "        imgs_stacked = np.stack(imgs_matched_z)\n",
    "        for cycle in np.unique(cycles):\n",
    "            indices = np.where(cycles == cycle)[0]\n",
    "            imgs = imgs_stacked[indices,...]\n",
    "            for z in range(imgs.shape[1]):\n",
    "                 # Create temp path\n",
    "                name = [row[1], row[2], z]\n",
    "                temp_path =  save_path / '_'.join(np.array(name).astype(str))\n",
    "                temp_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                file_name = '_'.join(np.array([\"{:03d}\".format(row[3]), cycle]).astype(str)) + '.tif'\n",
    "                file_path = temp_path / file_name\n",
    "\n",
    "                # if os.path.exists(file_path):\n",
    "                #     continue\n",
    "                \n",
    "                # Write image\n",
    "                tiff.imwrite(file_path, imgs[:,z,...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ashlar import fileseries, thumbnail,reg\n",
    "import matplotlib.pyplot as plt\n",
    "from ashlar.scripts.ashlar import process_axis_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "066454edf07c4f14ac72518eaa6c8122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    assembling thumbnail 9/9\n",
      "    assembling thumbnail 9/9\n",
      "    estimated cycle offset [y x] = [15. 17.]\n",
      "    assembling thumbnail 9/9\n",
      "    assembling thumbnail 9/9\n",
      "    estimated cycle offset [y x] = [15. 17.]\n",
      "    assembling thumbnail 9/9\n",
      "    assembling thumbnail 9/9\n",
      "    estimated cycle offset [y x] = [12. 16.]\n",
      "    assembling thumbnail 9/9\n",
      "    assembling thumbnail 9/9\n",
      "    estimated cycle offset [y x] = [12. 16.]\n",
      "    assembling thumbnail 9/9\n",
      "    assembling thumbnail 9/9\n",
      "    estimated cycle offset [y x] = [-1. 25.]\n",
      "    assembling thumbnail 9/9\n",
      "    assembling thumbnail 9/9\n",
      "    estimated cycle offset [y x] = [-1. 25.]\n",
      "    assembling thumbnail 9/9\n",
      "    assembling thumbnail 9/9\n",
      "    estimated cycle offset [y x] = [-2. 24.]\n",
      "    assembling thumbnail 9/9\n",
      "    assembling thumbnail 9/9\n",
      "    estimated cycle offset [y x] = [-2. 24.]\n"
     ]
    }
   ],
   "source": [
    "# Loop all images\n",
    "thumb_dir = data_dir / 'specificity_IF_best' / 'thumbnails'\n",
    "imgs_dir = data_dir / 'specificity_IF_best'/ 'imgs' / 'raw_norm'\n",
    "save_dir = data_dir / 'specificity_IF_best'/ 'imgs' / 'registered_norm'\n",
    "\n",
    "save_dir .mkdir(parents=True, exist_ok=True)\n",
    "imgs_dir_list = os.listdir(imgs_dir)\n",
    "thumb_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for dir_path in tqdm(imgs_dir_list):\n",
    "        \n",
    "    # Create reader for each cycle\n",
    "    readers = []\n",
    "    for i in range(1, 3):\n",
    "        reader = fileseries.FileSeriesReader(\n",
    "            str(imgs_dir / dir_path),\n",
    "            pattern='{series}_cycle'+f'{i}.tif',\n",
    "            overlap=0.29,\n",
    "            width=3,\n",
    "            height=3,\n",
    "            layout='snake',\n",
    "            direction='horizontal',\n",
    "            pixel_size=0.18872, \n",
    "        )\n",
    "        readers.append(reader)\n",
    "    reader_1 = readers[0]\n",
    "    \n",
    "    # Run stitching\n",
    "    aligner0 = reg.EdgeAligner(reader_1, channel=0, filter_sigma=2, verbose=False,)\n",
    "    aligner0.run()\n",
    "    \n",
    "    # Generate merge image for 1 cycle\n",
    "    # Parramter\n",
    "    mosaic_args = {}\n",
    "    mosaic_args['verbose'] = False\n",
    "\n",
    "    mosaic = reg.Mosaic(\n",
    "            aligner0,aligner0.mosaic_shape,**mosaic_args\n",
    "        )\n",
    "    writer_class = reg.TiffListWriter\n",
    "    writer = writer_class(\n",
    "            [mosaic], str(save_dir / (dir_path + '_cycle1_ch{channel}.ome.tif'))\n",
    "    )\n",
    "    writer.run()\n",
    "    \n",
    "    # Loop through rest of cycles\n",
    "    aligners = list()\n",
    "    aligners.append(aligner0)\n",
    "\n",
    "    for j in range(1, len(readers)):\n",
    "        aligners.append(\n",
    "            reg.LayerAligner(readers[j], aligners[0], channel=0, filter_sigma=2, verbose=False)\n",
    "        )\n",
    "        aligners[j].run()\n",
    "        mosaic = reg.Mosaic(\n",
    "            aligners[j], aligners[0].mosaic_shape,**mosaic_args\n",
    "        )\n",
    "        writer = writer_class(\n",
    "                [mosaic], str(save_dir / (dir_path +'_cycle'+str(j+1)+'_ch{channel}.ome.tif'))\n",
    "        )\n",
    "        writer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(data_raw, marker_dict):\n",
    "    conditions = []\n",
    "    fovs = []\n",
    "    Zs = []\n",
    "    cycles = []\n",
    "    channels = []\n",
    "    markers = []\n",
    "    paths = [] \n",
    "\n",
    "    # Loop through image folder\n",
    "    for (dirpath, dirnames, filenames) in os.walk(data_raw):\n",
    "        for name in sorted(filenames):\n",
    "            if \"tif\" in name:\n",
    "                # Get information from image name\n",
    "                n_split = name.split('_')\n",
    "                                \n",
    "                cond=n_split[0]\n",
    "                fov=n_split[1]\n",
    "                z=n_split[2]\n",
    "                cycle=n_split[3]\n",
    "                ch = n_split[4][:3]\n",
    "                try:\n",
    "                    marker = marker_dict[cycle][ch]\n",
    "                except:\n",
    "                    continue \n",
    "                    \n",
    "                conditions.append(cond)\n",
    "                fovs.append(fov)\n",
    "                Zs.append(z)\n",
    "                cycles.append(cycle)\n",
    "                channels.append(ch)\n",
    "                markers.append(marker)\n",
    "                paths.append(os.path.join(dirpath, name))\n",
    "                \n",
    "    info = {\n",
    "            \"Condition\": conditions,\n",
    "            \"FOV\": fovs,\n",
    "            \"Z\": Zs,\n",
    "            \"Cycle\": cycles,\n",
    "            \"Channels\": channels,\n",
    "            \"Markers\": markers,\n",
    "            \"Path\": paths\n",
    "        }\n",
    "\n",
    "    df = pd.DataFrame(info)\n",
    "    return df\n",
    "\n",
    "def joblib_loop(task, pics):\n",
    "    return Parallel(n_jobs=20)(delayed(task)(i) for i in pics)\n",
    "\n",
    "def read_img(path):\n",
    "    return skimage.io.imread(path, as_gray=True)\n",
    "\n",
    "def get_min(imgs):\n",
    "    shapes = np.array([np.array(img.shape) for img in imgs])\n",
    "    return np.min(shapes, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "markers_map_new = defaultdict(dict)\n",
    "for k,v in markers_map.items():\n",
    "    for i, (ch,marker) in enumerate(v.items()):\n",
    "        markers_map_new[k][f'ch{i}'] = marker\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder is already there\n",
      "Loaded df\n"
     ]
    }
   ],
   "source": [
    "data_raw = data_dir  / 'specificity_IF_best' /'imgs' / 'registered_norm'\n",
    "df_meta_path = data_dir / 'specificity_IF_best'  / 'metadata' / 'info_sti.csv'\n",
    "\n",
    "try:\n",
    "    df_meta_path.parent.mkdir(parents=True, exist_ok=False)\n",
    "except FileExistsError:\n",
    "    print(\"Folder is already there\")\n",
    "\n",
    "df_exist = df_meta_path.is_file()\n",
    "\n",
    "if not df_exist:\n",
    "    print('Created df')\n",
    "    df = get_info(data_raw, markers_map_new)\n",
    "    df.to_csv(df_meta_path, index=False)\n",
    "else:\n",
    "    print('Loaded df')\n",
    "    df = pd.read_csv(df_meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natsort import natsorted, natsort_keygen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ae980e98d8431bb1153d2bab26c371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the min dimension accross all z stacks \n",
    "group = df.groupby(['Condition','FOV'])\n",
    "min_dim = {}\n",
    "\n",
    "for name, df_group in tqdm(group, total=len(group)):\n",
    "\n",
    "    df_group = df_group.sort_values( # Sort by cycle and channels\n",
    "        by=[\"Cycle\", \"Channels\", 'Z'],\n",
    "        key=natsort_keygen()\n",
    "    )\n",
    "    df_group = df_group[(df_group.Cycle == 'cycle1') & (df_group.Channels == 'ch1')]\n",
    "\n",
    "    channels = df_group.Channels.to_list()\n",
    "    cycles = df_group.Cycle.to_list()\n",
    "    markers = df_group.Markers.to_list()\n",
    "    paths = df_group.Path.to_numpy()\n",
    "\n",
    "    imgs = joblib_loop(read_img, paths)\n",
    "    min_dim['_'.join(name)] = get_min(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Control_Control': array([3473, 4623]), 'KO_KO': array([3470, 4647])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder is already there\n",
      "Created df\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef786a0c0d3149938987e779e5b5d5c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_imgs_path = data_dir /'specificity_IF_best'/'metadata' / 'imgs_reg.csv'\n",
    "\n",
    "temp_path =data_dir / 'specificity_IF_best'/ 'hdf5' / 'registered'\n",
    "try:\n",
    "    temp_path.mkdir(parents=True, exist_ok=False)\n",
    "except FileExistsError:\n",
    "    print(\"Folder is already there\")\n",
    "\n",
    "df_exist = df_imgs_path.is_file()\n",
    "\n",
    "if not df_exist:\n",
    "    print('Created df')\n",
    "    group = df.groupby(['Condition','FOV', 'Z'])\n",
    "    rows = []\n",
    "\n",
    "    for name, df_group in tqdm(group, total=len(group)):\n",
    "        file_name = '_'.join(np.array(name).astype(str)) + '.hdf5'\n",
    "        file_path = temp_path / file_name\n",
    "        rows.append(list(name)+[file_path])\n",
    "        \n",
    "        df_group = df_group.sort_values( # Sort by cycle and channels\n",
    "            by=[\"Cycle\", \"Channels\", 'Z'],\n",
    "            key=natsort_keygen()\n",
    "        )\n",
    "        \n",
    "        if file_path.exists():\n",
    "            continue\n",
    "        \n",
    "        channels = df_group.Channels.to_list()\n",
    "        cycles = df_group.Cycle.to_list()\n",
    "        markers = df_group.Markers.to_list()\n",
    "        paths = df_group.Path.to_numpy()\n",
    "            \n",
    "        imgs = joblib_loop(read_img, paths)\n",
    "        min_shape = min_dim['_'.join(name[:2])]\n",
    "        imgs_cropped = np.array([img[:min_shape[0], :min_shape[1]] for img in imgs])\n",
    "        info = {\"Cycle\": cycles, \"Channel\": channels, \"Marker\": markers}\n",
    "            \n",
    "            # hdf5 as Channel -> Z mapping\n",
    "        save_hdf5(file_path, 'imgs', imgs_cropped, info)\n",
    "    df_imgs = pd.DataFrame(rows, columns=['Condition', 'FOV', 'Z', 'Path'])        \n",
    "    df_imgs.to_csv(df_imgs_path, index=False)\n",
    "else:\n",
    "    print('Loaded df')\n",
    "    df_imgs = pd.read_csv(df_imgs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.exposure import match_histograms, rescale_intensity\n",
    "import cv2\n",
    "from skimage import img_as_ubyte\n",
    "import tensorflow as tf \n",
    "from skimage import exposure, util, filters, restoration\n",
    "\n",
    "def random_crop(image, NEW_IMG_HEIGHT, NEW_IMG_WIDTH):\n",
    "    cropped_image = tf.image.random_crop(\n",
    "      image, size=[3, NEW_IMG_HEIGHT, NEW_IMG_WIDTH])\n",
    "\n",
    "    return cropped_image\n",
    "\n",
    "def make_color_overlay(input_data):\n",
    "    \"\"\"Create a color overlay from 2 channel image data\n",
    "    \n",
    "    Args:\n",
    "        input_data: stack of input images\n",
    "    \n",
    "    Returns:\n",
    "        numpy.array: color-adjusted stack of overlays in RGB mode\n",
    "    \"\"\"\n",
    "    RGB_data = np.zeros(input_data.shape[:3] + (3, ), dtype='float32')\n",
    "    \n",
    "    # rescale channels to aid plotting\n",
    "    for img in range(input_data.shape[0]):\n",
    "        for channel in range(input_data.shape[-1]):\n",
    "            # get histogram for non-zero pixels\n",
    "            percentiles = np.percentile(input_data[img, :, :, channel][input_data[img, :, :, channel] > 0],\n",
    "                                            [0, 100])\n",
    "            rescaled_intensity = rescale_intensity(input_data[img, :, :, channel],\n",
    "                                                       in_range=(percentiles[0], percentiles[1]),\n",
    "                                                       out_range='float32')\n",
    "            RGB_data[img, :, :, channel + 1] = rescaled_intensity\n",
    "        \n",
    "    # create a blank array for red channel\n",
    "    return RGB_data\n",
    "\n",
    "def contrast_str(img, n_min=10, n_max=100):\n",
    "    p2, p98 = np.percentile(img, (n_min, n_max))\n",
    "    img_rescale = rescale_intensity(img, in_range=(p2, p98))\n",
    "    img_rescale = util.img_as_ubyte(img_rescale)\n",
    "    return img_rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imgs_path = data_dir /  'specificity_IF_best'  /'metadata' / 'imgs_reg.csv'\n",
    "df_imgs = pd.read_csv(df_imgs_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Condition</th>\n",
       "      <th>FOV</th>\n",
       "      <th>Z</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Control</td>\n",
       "      <td>Control</td>\n",
       "      <td>0</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Control</td>\n",
       "      <td>Control</td>\n",
       "      <td>1</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Control</td>\n",
       "      <td>Control</td>\n",
       "      <td>2</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Control</td>\n",
       "      <td>Control</td>\n",
       "      <td>3</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KO</td>\n",
       "      <td>KO</td>\n",
       "      <td>0</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KO</td>\n",
       "      <td>KO</td>\n",
       "      <td>1</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KO</td>\n",
       "      <td>KO</td>\n",
       "      <td>2</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KO</td>\n",
       "      <td>KO</td>\n",
       "      <td>3</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Condition      FOV  Z                                               Path\n",
       "0   Control  Control  0  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...\n",
       "1   Control  Control  1  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...\n",
       "2   Control  Control  2  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...\n",
       "3   Control  Control  3  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...\n",
       "4        KO       KO  0  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...\n",
       "5        KO       KO  1  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...\n",
       "6        KO       KO  2  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...\n",
       "7        KO       KO  3  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45decd82cd8e435aa55b3cc83381eac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for row in tqdm(df_imgs.itertuples(), total=len(df_imgs)):\n",
    "    path = row.Path\n",
    "    \n",
    "    # Read images\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        \n",
    "        markers = f['imgs'].attrs['Marker']\n",
    "        imgs = f['imgs'][:]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint16')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Viewer(axes=Axes(visible=False, labels=True, colored=True, dashed=False, arrows=True), camera=Camera(center=(0.0, 1736.0, 2311.0), zoom=0.36189173625107973, angles=(0.0, 0.0, 90.0), perspective=0.0, interactive=True), cursor=Cursor(position=(1.0, 1.0), scaled=True, size=1, style=<CursorStyle.STANDARD: 'standard'>), dims=Dims(ndim=2, ndisplay=2, last_used=0, range=((0.0, 3473.0, 1.0), (0.0, 4623.0, 1.0)), current_step=(1736, 2311), order=(0, 1), axis_labels=('0', '1')), grid=GridCanvas(stride=1, shape=(-1, -1), enabled=False), layers=[<Image layer 'DNA' at 0x1d71fa89bd0>, <Image layer 'Bim' at 0x1d71e1f30a0>, <Image layer 'DNA [1]' at 0x1d72131d870>, <Image layer 'Concanavalin A' at 0x1d7213d8220>, <Image layer 'Phalloidin' at 0x1d725d49bd0>, <Image layer 'WGA' at 0x1d725df02b0>], scale_bar=ScaleBar(visible=False, colored=False, color=array([1., 0., 1., 1.], dtype=float32), ticks=True, position=<Position.BOTTOM_RIGHT: 'bottom_right'>, font_size=10.0, box=False, box_color=array([0. , 0. , 0. , 0.6], dtype=float32), unit=None), text_overlay=TextOverlay(visible=False, color=array([0.5, 0.5, 0.5, 1. ], dtype=float32), font_size=10.0, position=<TextOverlayPosition.TOP_LEFT: 'top_left'>, text=''), overlays=Overlays(interaction_box=InteractionBox(points=None, show=False, show_handle=False, show_vertices=False, selection_box_drag=None, selection_box_final=None, transform_start=<napari.utils.transforms.transforms.Affine object at 0x000001D77E588760>, transform_drag=<napari.utils.transforms.transforms.Affine object at 0x000001D77E588640>, transform_final=<napari.utils.transforms.transforms.Affine object at 0x000001D77E588670>, transform=<napari.utils.transforms.transforms.Affine object at 0x000001D77E588580>, allow_new_selection=True, selected_vertex=None)), help='', status='Ready', tooltip=Tooltip(visible=False, text=''), theme='dark', title='napari', mouse_over_canvas=False, mouse_move_callbacks=[<function InteractionBoxMouseBindings.initialize_mouse_events.<locals>.mouse_move at 0x000001D71EA2F010>], mouse_drag_callbacks=[<function InteractionBoxMouseBindings.initialize_mouse_events.<locals>.mouse_drag at 0x000001D71E364550>], mouse_double_click_callbacks=[], mouse_wheel_callbacks=[<function dims_scroll at 0x000001D771BF1EA0>], _persisted_mouse_event={}, _mouse_drag_gen={}, _mouse_wheel_gen={}, keymap={'Shift': <function InteractionBoxMouseBindings.initialize_key_events.<locals>.hold_to_lock_aspect_ratio at 0x000001D71E364040>, 'Control-Shift-R': <function InteractionBoxMouseBindings._reset_active_layer_affine at 0x000001D71EA744C0>, 'Control-Shift-A': <function InteractionBoxMouseBindings._transform_active_layer at 0x000001D71EA74430>})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import napari \n",
    "\n",
    "napari.view_image(np.stack(imgs), name=markers, channel_axis=0, contrast_limits=[0,2**16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imgs.sort_values('Z', inplace=True)\n",
    "df_imgs[['FOV', 'Z']] = df_imgs[['FOV', 'Z']].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define markers to use for cytosolic segmentation\n",
    "cyto_markers = ['Phalloidin']\n",
    "\n",
    "# Define folder and create if don't exsit\n",
    "whole_seg_path = data_dir /  'specificity_IF_best'  / 'imgs' / 'segmentation'\n",
    "whole_seg_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save combined images\n",
    "for row in df_imgs.itertuples():\n",
    "    # Read image\n",
    "    path = row.Path\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        imgs = f['imgs'][:]\n",
    "        markers = f['imgs'].attrs['Marker']\n",
    "\n",
    "    # Get dapi and cyto imgaes\n",
    "    indices = np.isin(markers, cyto_markers)\n",
    "    img_dapi =  imgs[-4]\n",
    "    imgs_cyto = imgs[indices,:]\n",
    "    \n",
    "    # Contrast streching and combine to rgb image\n",
    "    img_dapi = contrast_str(img_dapi, n_max=99.9)\n",
    "        \n",
    "    imgs_cyto_scaled = []\n",
    "    for img in imgs_cyto:\n",
    "        imgs_cyto_scaled = [contrast_str(img, n_max=99.9)]\n",
    "    img_cyto = np.max(np.array(imgs_cyto_scaled), axis=0)\n",
    "    img_rgb = np.stack([np.zeros(img_dapi.shape),img_cyto, img_dapi], axis=0).astype(np.uint8)\n",
    "    \n",
    "    # Crop and save\n",
    "    file_name = f'{\"_\".join(row[1:4])}.tif'\n",
    "    file_path = whole_seg_path / file_name\n",
    "    tiff.imwrite(file_path, img_rgb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Viewer(axes=Axes(visible=False, labels=True, colored=True, dashed=False, arrows=True), camera=Camera(center=(0.0, 1734.5, 2323.0), zoom=0.15194524495677234, angles=(0.0, 0.0, 90.0), perspective=0.0, interactive=True), cursor=Cursor(position=(3.0, 1.0, 0.0), scaled=True, size=1, style=<CursorStyle.STANDARD: 'standard'>), dims=Dims(ndim=3, ndisplay=2, last_used=0, range=((0.0, 6.0, 1.0), (0.0, 3470.0, 1.0), (0.0, 4647.0, 1.0)), current_step=(3, 1735, 2323), order=(0, 1, 2), axis_labels=('0', '1', '2')), grid=GridCanvas(stride=1, shape=(-1, -1), enabled=False), layers=[<Image layer 'imgs' at 0x1d703c13c10>], scale_bar=ScaleBar(visible=False, colored=False, color=array([1., 0., 1., 1.], dtype=float32), ticks=True, position=<Position.BOTTOM_RIGHT: 'bottom_right'>, font_size=10.0, box=False, box_color=array([0. , 0. , 0. , 0.6], dtype=float32), unit=None), text_overlay=TextOverlay(visible=False, color=array([0.5, 0.5, 0.5, 1. ], dtype=float32), font_size=10.0, position=<TextOverlayPosition.TOP_LEFT: 'top_left'>, text=''), overlays=Overlays(interaction_box=InteractionBox(points=None, show=False, show_handle=False, show_vertices=False, selection_box_drag=None, selection_box_final=None, transform_start=<napari.utils.transforms.transforms.Affine object at 0x000001D7213A9570>, transform_drag=<napari.utils.transforms.transforms.Affine object at 0x000001D7213A9420>, transform_final=<napari.utils.transforms.transforms.Affine object at 0x000001D7213A9180>, transform=<napari.utils.transforms.transforms.Affine object at 0x000001D7213A9060>, allow_new_selection=True, selected_vertex=None)), help='', status='Ready', tooltip=Tooltip(visible=False, text=''), theme='dark', title='napari', mouse_over_canvas=False, mouse_move_callbacks=[<function InteractionBoxMouseBindings.initialize_mouse_events.<locals>.mouse_move at 0x000001D71F041B40>], mouse_drag_callbacks=[<function InteractionBoxMouseBindings.initialize_mouse_events.<locals>.mouse_drag at 0x000001D71F041AB0>], mouse_double_click_callbacks=[], mouse_wheel_callbacks=[<function dims_scroll at 0x000001D771BF1EA0>], _persisted_mouse_event={}, _mouse_drag_gen={}, _mouse_wheel_gen={}, keymap={'Shift': <function InteractionBoxMouseBindings.initialize_key_events.<locals>.hold_to_lock_aspect_ratio at 0x000001D71F041990>, 'Control-Shift-R': <function InteractionBoxMouseBindings._reset_active_layer_affine at 0x000001D71F040790>, 'Control-Shift-A': <function InteractionBoxMouseBindings._transform_active_layer at 0x000001D71F040D30>})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "napari.view_image(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PLA2]",
   "language": "python",
   "name": "conda-env-PLA2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
