{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.io\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import trange, tqdm, tqdm_notebook\n",
    "from joblib import Parallel, delayed\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = (Path().cwd().parents[0] / 'data').absolute()\n",
    "data_raw = r'Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\PLA\\HCC827-derived OCT mouse'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Get info\n",
    "\n",
    "Here we look at stitched images in all z stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers_map = {\n",
    "    'cycle1': {\n",
    "        1: 'Hoeschst', \n",
    "        4: 'TEAD1 & YAP1'\n",
    "    },\n",
    "    'cycle2': {\n",
    "        1: 'Hoeschst', \n",
    "        4: 'CylinE & CDK2'\n",
    "    },\n",
    "    'cycle3': {\n",
    "        1: 'Hoeschst', \n",
    "        4: 'P-ERK & c-MYC'\n",
    "    },\n",
    "    'cycle4': {\n",
    "        1: 'Hoeschst', \n",
    "        4: 'p-AKT & mTOR'\n",
    "    },\n",
    "    'cycle5': {\n",
    "        1: 'Hoeschst', \n",
    "        4: 'Mcl-1 & BAK'\n",
    "    },\n",
    "    'cycle6': {\n",
    "        1: 'Hoeschst',\n",
    "        2: 'p-EGFR',\n",
    "        3: 'Tom20',\n",
    "        4: 'Ki67'\n",
    "    },\n",
    "    'cycle7': {\n",
    "        1: 'Hoeschst',\n",
    "        2: 'Pan-cytokeratin',\n",
    "        3: 'Golph4',\n",
    "        4: 'Bim'\n",
    "    },\n",
    "    'cycle8': {\n",
    "        1: 'Hoeschst',\n",
    "        2: 'Concanavalin A',\n",
    "        3: 'Phalloidin',\n",
    "        4: 'WGA'\n",
    "    },\n",
    "    'cycle9': {\n",
    "        1: 'Hoeschst',\n",
    "        2: 'NBD-C6'\n",
    "    },\n",
    "}\n",
    "\n",
    "def get_info(data_raw, marker_dict = markers_map):\n",
    "    timepoints = []\n",
    "    resolutions = []\n",
    "    fovs = []\n",
    "    cycles = []\n",
    "    afs = []\n",
    "    channels = []\n",
    "    markers = []\n",
    "    rois = []\n",
    "    z_stacks = []\n",
    "    paths = [] \n",
    "    \n",
    "    # Loop through image folder\n",
    "    for (dirpath, dirnames, filenames) in os.walk(data_raw):\n",
    "        for name in sorted(filenames):\n",
    "            if \"tif\" in name and \"stitched\" not in name \\\n",
    "            and 'Overlay' not in name \\\n",
    "            and 'Composite' not in name \\\n",
    "            and 'defocused' not in dirpath:\n",
    "                # Get information from image name\n",
    "                d_split = dirpath.split('\\\\')\n",
    "                n_split = name.split('_')\n",
    "                                \n",
    "                time = d_split[-1].split('_')[0]\n",
    "                fov = d_split[-1].split('_')[-1]\n",
    "                \n",
    "                try:\n",
    "                    if 'FW' not in fov:\n",
    "                        res = '20X'\n",
    "                        fov = ''\n",
    "                        ch = int(n_split[2][2])\n",
    "                        roi = int(n_split[1])\n",
    "                        z = 1\n",
    "                    else:\n",
    "                        res = '40X'\n",
    "                        ch = int(n_split[3][2])\n",
    "                        roi = int(n_split[1])\n",
    "                        z = int(n_split[2][1:])\n",
    "\n",
    "                    cycle = d_split[-1].split('_')[1]\n",
    "                    if 'Af' in cycle:\n",
    "                        after_bleach = True\n",
    "                        cycle = cycle[2:]\n",
    "                    else:\n",
    "                        after_bleach = False\n",
    "                    marker = marker_dict[cycle][ch]\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "                timepoints.append(time)\n",
    "                resolutions.append(res)\n",
    "                fovs.append(fov)\n",
    "                cycles.append(cycle)\n",
    "                afs.append(after_bleach)\n",
    "                channels.append(ch)\n",
    "                markers.append(marker)\n",
    "                rois.append(roi)\n",
    "                z_stacks.append(z)\n",
    "                paths.append(os.path.join(dirpath, name))\n",
    "                \n",
    "    info = {\n",
    "            \"Timepoint\": timepoints,\n",
    "            \"Resolution\": resolutions,\n",
    "            \"FOV\": fovs,\n",
    "            \"Cycle\": cycles,\n",
    "            \"AfBleach\": afs,\n",
    "            \"Channels\": channels,\n",
    "            \"Markers\": markers,\n",
    "            \"ROI\": rois,\n",
    "            \"Z\": z_stacks,\n",
    "            \"Path\": paths\n",
    "        }\n",
    "\n",
    "    df = pd.DataFrame(info)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder is already there\n",
      "Loaded df\n"
     ]
    }
   ],
   "source": [
    "df_meta_path = data_dir / 'OCT mouse' / 'ROI' / 'metadata' / 'info.csv'\n",
    "\n",
    "try:\n",
    "    df_meta_path.parent.mkdir(parents=True, exist_ok=False)\n",
    "except FileExistsError:\n",
    "    print(\"Folder is already there\")\n",
    "\n",
    "df_exist = df_meta_path.is_file()\n",
    "\n",
    "if not df_exist:\n",
    "    print('Created df')\n",
    "    df = get_info(data_raw)\n",
    "    df.to_csv(df_meta_path, index=False)\n",
    "else:\n",
    "    print('Loaded df')\n",
    "    df = pd.read_csv(df_meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timepoint</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>FOV</th>\n",
       "      <th>Cycle</th>\n",
       "      <th>AfBleach</th>\n",
       "      <th>Channels</th>\n",
       "      <th>Markers</th>\n",
       "      <th>ROI</th>\n",
       "      <th>Z</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1M</td>\n",
       "      <td>20X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cycle1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>Hoeschst</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1M</td>\n",
       "      <td>20X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cycle1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>TEAD1 &amp; YAP1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1M</td>\n",
       "      <td>20X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cycle1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>Hoeschst</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1M</td>\n",
       "      <td>20X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cycle1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>TEAD1 &amp; YAP1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1M</td>\n",
       "      <td>20X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cycle1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>Hoeschst</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347915</th>\n",
       "      <td>1W</td>\n",
       "      <td>40X</td>\n",
       "      <td>FW3</td>\n",
       "      <td>cycle9</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>NBD-C6</td>\n",
       "      <td>40</td>\n",
       "      <td>24</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347916</th>\n",
       "      <td>1W</td>\n",
       "      <td>40X</td>\n",
       "      <td>FW3</td>\n",
       "      <td>cycle9</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Hoeschst</td>\n",
       "      <td>40</td>\n",
       "      <td>25</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347917</th>\n",
       "      <td>1W</td>\n",
       "      <td>40X</td>\n",
       "      <td>FW3</td>\n",
       "      <td>cycle9</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>NBD-C6</td>\n",
       "      <td>40</td>\n",
       "      <td>25</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347918</th>\n",
       "      <td>1W</td>\n",
       "      <td>40X</td>\n",
       "      <td>FW3</td>\n",
       "      <td>cycle9</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Hoeschst</td>\n",
       "      <td>40</td>\n",
       "      <td>26</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347919</th>\n",
       "      <td>1W</td>\n",
       "      <td>40X</td>\n",
       "      <td>FW3</td>\n",
       "      <td>cycle9</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>NBD-C6</td>\n",
       "      <td>40</td>\n",
       "      <td>26</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>347920 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Timepoint Resolution  FOV   Cycle  AfBleach  Channels       Markers  \\\n",
       "0             1M        20X  NaN  cycle1      True         1      Hoeschst   \n",
       "1             1M        20X  NaN  cycle1      True         4  TEAD1 & YAP1   \n",
       "2             1M        20X  NaN  cycle1      True         1      Hoeschst   \n",
       "3             1M        20X  NaN  cycle1      True         4  TEAD1 & YAP1   \n",
       "4             1M        20X  NaN  cycle1      True         1      Hoeschst   \n",
       "...          ...        ...  ...     ...       ...       ...           ...   \n",
       "347915        1W        40X  FW3  cycle9     False         2        NBD-C6   \n",
       "347916        1W        40X  FW3  cycle9     False         1      Hoeschst   \n",
       "347917        1W        40X  FW3  cycle9     False         2        NBD-C6   \n",
       "347918        1W        40X  FW3  cycle9     False         1      Hoeschst   \n",
       "347919        1W        40X  FW3  cycle9     False         2        NBD-C6   \n",
       "\n",
       "        ROI   Z                                               Path  \n",
       "0         1   1  Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  \n",
       "1         1   1  Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  \n",
       "2         2   1  Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  \n",
       "3         2   1  Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  \n",
       "4         3   1  Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  \n",
       "...     ...  ..                                                ...  \n",
       "347915   40  24  Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  \n",
       "347916   40  25  Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  \n",
       "347917   40  25  Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  \n",
       "347918   40  26  Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  \n",
       "347919   40  26  Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  \n",
       "\n",
       "[347920 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert data to hdf5 \n",
    "\n",
    "Convert stitch data to hdf5 format.\n",
    "\n",
    "For each file we are organized into the format of: File with keys cycles\n",
    "\n",
    "Attributes are Channels and Markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import multiprocessing\n",
    "import functools \n",
    "\n",
    "def save_hdf5(\n",
    "    path: str, name: str, data: np.ndarray, attr_dict=None, mode: str = \"a\"\n",
    ") -> None:\n",
    "    # Read h5 file\n",
    "    hf = h5py.File(path, mode)\n",
    "    # Create z_stack_dataset\n",
    "    if hf.get(name) is None:\n",
    "        data_shape = data.shape\n",
    "        data_type = data.dtype\n",
    "        chunk_shape = (1,) + data_shape[1:]\n",
    "        max_shape = (data_shape[0],) + data_shape[1:]\n",
    "        dset = hf.create_dataset(\n",
    "            name,\n",
    "            shape=data_shape,\n",
    "            maxshape=max_shape,\n",
    "            chunks=chunk_shape,\n",
    "            dtype=data_type,\n",
    "            compression=\"gzip\",\n",
    "        )\n",
    "        dset[:] = data\n",
    "        if attr_dict is not None:\n",
    "            for attr_key, attr_val in attr_dict.items():\n",
    "                dset.attrs[attr_key] = attr_val\n",
    "    else:\n",
    "        print(f\"Dataset {name} exists\")\n",
    "\n",
    "    hf.close()\n",
    "\n",
    "def read_img(path):\n",
    "    return skimage.io.imread(path)\n",
    "\n",
    "def joblib_loop(task, pics):\n",
    "    return Parallel(n_jobs=multiprocessing.cpu_count())(delayed(task)(i) for i in pics)\n",
    "\n",
    "def save_imgs(df_channel, n, file_path):\n",
    "    marker = df_channel.iloc[0].Markers\n",
    "    paths = df_channel.Path.to_numpy()\n",
    "\n",
    "    imgs = joblib_loop(read_img, paths)\n",
    "    imgs = np.array(imgs)\n",
    "    info = {\"Cycle\": n[0], \"Channel\": n[1], \"Marker\": marker, \"Z\": df_channel.Z.to_numpy()}\n",
    "\n",
    "    # hdf5 as Channel -> Z mapping\n",
    "    save_hdf5(file_path, '_'.join(np.array(n).astype(str)), imgs, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder is already there\n",
      "Folder is already there\n",
      "Created df\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "095dc4b56f4e4a0e9a613f0fbe98b2b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/306 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1M', '40X', 'FW1', False, 1)\n",
      "('1M', '40X', 'FW1', False, 2)\n",
      "('1M', '40X', 'FW1', False, 3)\n",
      "('1M', '40X', 'FW1', False, 4)\n",
      "('1M', '40X', 'FW1', False, 5)\n",
      "('1M', '40X', 'FW1', False, 6)\n",
      "('1M', '40X', 'FW1', False, 7)\n",
      "('1M', '40X', 'FW1', False, 8)\n",
      "('1M', '40X', 'FW1', False, 9)\n",
      "('1M', '40X', 'FW1', False, 10)\n",
      "('1M', '40X', 'FW1', False, 11)\n",
      "('1M', '40X', 'FW1', False, 12)\n",
      "('1M', '40X', 'FW1', False, 13)\n",
      "('1M', '40X', 'FW1', False, 14)\n",
      "('1M', '40X', 'FW1', False, 15)\n",
      "('1M', '40X', 'FW1', False, 16)\n",
      "('1M', '40X', 'FW1', False, 17)\n",
      "('1M', '40X', 'FW1', False, 18)\n",
      "('1M', '40X', 'FW1', False, 19)\n",
      "('1M', '40X', 'FW1', False, 20)\n",
      "('1M', '40X', 'FW1', False, 21)\n",
      "('1M', '40X', 'FW1', False, 22)\n",
      "('1M', '40X', 'FW1', False, 23)\n",
      "('1M', '40X', 'FW1', False, 24)\n",
      "('1M', '40X', 'FW1', False, 25)\n",
      "('1M', '40X', 'FW1', False, 26)\n",
      "('1M', '40X', 'FW1', False, 27)\n",
      "('1M', '40X', 'FW1', False, 28)\n",
      "('1M', '40X', 'FW1', False, 29)\n",
      "('1M', '40X', 'FW1', False, 30)\n",
      "('1M', '40X', 'FW1', False, 31)\n",
      "('1M', '40X', 'FW1', False, 32)\n",
      "('1M', '40X', 'FW1', False, 33)\n",
      "('1M', '40X', 'FW1', False, 34)\n",
      "('1M', '40X', 'FW1', False, 35)\n",
      "('1M', '40X', 'FW1', False, 36)\n",
      "('1M', '40X', 'FW1', False, 37)\n",
      "('1M', '40X', 'FW1', False, 38)\n",
      "('1M', '40X', 'FW1', False, 39)\n",
      "('1M', '40X', 'FW1', False, 40)\n",
      "('1M', '40X', 'FW1', False, 41)\n",
      "('1M', '40X', 'FW1', False, 42)\n",
      "('1M', '40X', 'FW1', False, 43)\n",
      "('1M', '40X', 'FW1', False, 44)\n",
      "('1M', '40X', 'FW1', False, 45)\n",
      "('1M', '40X', 'FW1', False, 46)\n",
      "('1M', '40X', 'FW1', False, 47)\n",
      "('1M', '40X', 'FW1', False, 48)\n",
      "('1M', '40X', 'FW1', False, 49)\n",
      "('1M', '40X', 'FW1', False, 50)\n",
      "('1M', '40X', 'FW1', False, 51)\n",
      "('1M', '40X', 'FW1', False, 52)\n",
      "('1M', '40X', 'FW1', False, 53)\n",
      "('1M', '40X', 'FW1', False, 54)\n",
      "('1M', '40X', 'FW1', False, 55)\n",
      "('1M', '40X', 'FW1', False, 56)\n",
      "('1M', '40X', 'FW1', False, 57)\n",
      "('1M', '40X', 'FW1', False, 58)\n",
      "('1M', '40X', 'FW1', False, 59)\n",
      "('1M', '40X', 'FW1', False, 60)\n",
      "('1M', '40X', 'FW1', False, 61)\n",
      "('1M', '40X', 'FW1', False, 62)\n",
      "('1M', '40X', 'FW1', False, 63)\n",
      "('1M', '40X', 'FW1', False, 64)\n",
      "('1M', '40X', 'FW1', False, 65)\n",
      "('1M', '40X', 'FW1', False, 66)\n",
      "('1M', '40X', 'FW1', False, 67)\n",
      "('1M', '40X', 'FW1', False, 68)\n",
      "('1M', '40X', 'FW1', False, 69)\n",
      "('1M', '40X', 'FW1', False, 70)\n",
      "('1M', '40X', 'FW1', False, 71)\n",
      "('1M', '40X', 'FW1', False, 72)\n",
      "('1M', '40X', 'FW1', False, 73)\n",
      "('1M', '40X', 'FW1', False, 74)\n",
      "('1M', '40X', 'FW1', False, 75)\n",
      "('1M', '40X', 'FW1', False, 76)\n",
      "('1M', '40X', 'FW1', False, 77)\n",
      "('1M', '40X', 'FW2', False, 1)\n",
      "('1M', '40X', 'FW2', False, 2)\n",
      "('1M', '40X', 'FW2', False, 3)\n",
      "('1M', '40X', 'FW2', False, 4)\n",
      "('1M', '40X', 'FW2', False, 5)\n",
      "('1M', '40X', 'FW2', False, 6)\n",
      "('1M', '40X', 'FW2', False, 7)\n",
      "('1M', '40X', 'FW2', False, 8)\n",
      "('1M', '40X', 'FW2', False, 9)\n",
      "('1M', '40X', 'FW2', False, 10)\n",
      "('1M', '40X', 'FW2', False, 11)\n",
      "('1M', '40X', 'FW2', False, 12)\n",
      "('1M', '40X', 'FW2', False, 13)\n",
      "('1M', '40X', 'FW2', False, 14)\n",
      "('1M', '40X', 'FW2', False, 15)\n",
      "('1M', '40X', 'FW2', False, 16)\n",
      "('1M', '40X', 'FW2', False, 17)\n",
      "('1M', '40X', 'FW2', False, 18)\n",
      "('1M', '40X', 'FW2', False, 19)\n",
      "('1M', '40X', 'FW2', False, 20)\n",
      "('1M', '40X', 'FW2', False, 21)\n",
      "('1M', '40X', 'FW2', False, 22)\n",
      "('1M', '40X', 'FW2', False, 23)\n",
      "('1M', '40X', 'FW2', False, 24)\n",
      "('1M', '40X', 'FW2', False, 25)\n",
      "('1M', '40X', 'FW2', False, 26)\n",
      "('1M', '40X', 'FW2', False, 27)\n",
      "('1M', '40X', 'FW2', False, 28)\n",
      "('1M', '40X', 'FW2', False, 29)\n",
      "('1M', '40X', 'FW2', False, 30)\n",
      "('1M', '40X', 'FW2', False, 31)\n",
      "('1M', '40X', 'FW2', False, 32)\n",
      "('1M', '40X', 'FW2', False, 33)\n",
      "('1M', '40X', 'FW2', False, 34)\n",
      "('1M', '40X', 'FW2', False, 35)\n",
      "('1M', '40X', 'FW2', False, 36)\n",
      "('1M', '40X', 'FW2', False, 37)\n",
      "('1M', '40X', 'FW2', False, 38)\n",
      "('1M', '40X', 'FW2', False, 39)\n",
      "('1M', '40X', 'FW2', False, 40)\n",
      "('1M', '40X', 'FW2', False, 41)\n",
      "('1M', '40X', 'FW2', False, 42)\n",
      "('1M', '40X', 'FW2', False, 43)\n",
      "('1M', '40X', 'FW2', False, 44)\n",
      "('1M', '40X', 'FW2', False, 45)\n",
      "('1M', '40X', 'FW2', False, 46)\n",
      "('1M', '40X', 'FW2', False, 47)\n",
      "('1M', '40X', 'FW2', False, 48)\n",
      "('1M', '40X', 'FW2', False, 49)\n",
      "('1M', '40X', 'FW2', False, 50)\n",
      "('1M', '40X', 'FW2', False, 51)\n",
      "('1M', '40X', 'FW2', False, 52)\n",
      "('1M', '40X', 'FW2', False, 53)\n",
      "('1M', '40X', 'FW2', False, 54)\n",
      "('1M', '40X', 'FW2', False, 55)\n",
      "('1M', '40X', 'FW2', False, 56)\n",
      "('1W', '40X', 'FW1', False, 1)\n",
      "('1W', '40X', 'FW1', False, 2)\n",
      "('1W', '40X', 'FW1', False, 3)\n",
      "('1W', '40X', 'FW1', False, 4)\n",
      "('1W', '40X', 'FW1', False, 5)\n",
      "('1W', '40X', 'FW1', False, 6)\n",
      "('1W', '40X', 'FW1', False, 7)\n",
      "('1W', '40X', 'FW1', False, 8)\n",
      "('1W', '40X', 'FW1', False, 9)\n",
      "('1W', '40X', 'FW1', False, 10)\n",
      "('1W', '40X', 'FW1', False, 11)\n",
      "('1W', '40X', 'FW1', False, 12)\n",
      "('1W', '40X', 'FW1', False, 13)\n",
      "('1W', '40X', 'FW1', False, 14)\n",
      "('1W', '40X', 'FW1', False, 15)\n",
      "('1W', '40X', 'FW1', False, 16)\n",
      "('1W', '40X', 'FW1', False, 17)\n",
      "('1W', '40X', 'FW1', False, 18)\n",
      "('1W', '40X', 'FW1', False, 19)\n",
      "('1W', '40X', 'FW1', False, 20)\n",
      "('1W', '40X', 'FW1', False, 21)\n",
      "('1W', '40X', 'FW1', False, 22)\n",
      "('1W', '40X', 'FW1', False, 23)\n",
      "('1W', '40X', 'FW1', False, 24)\n",
      "('1W', '40X', 'FW1', False, 25)\n",
      "('1W', '40X', 'FW1', False, 26)\n",
      "('1W', '40X', 'FW1', False, 27)\n",
      "('1W', '40X', 'FW1', False, 28)\n",
      "('1W', '40X', 'FW1', False, 29)\n",
      "('1W', '40X', 'FW1', False, 30)\n",
      "('1W', '40X', 'FW1', False, 31)\n",
      "('1W', '40X', 'FW1', False, 32)\n",
      "('1W', '40X', 'FW1', False, 33)\n",
      "('1W', '40X', 'FW1', False, 34)\n",
      "('1W', '40X', 'FW1', False, 35)\n",
      "('1W', '40X', 'FW1', False, 36)\n",
      "('1W', '40X', 'FW1', False, 37)\n",
      "('1W', '40X', 'FW1', False, 38)\n",
      "('1W', '40X', 'FW1', False, 39)\n",
      "('1W', '40X', 'FW1', False, 40)\n",
      "('1W', '40X', 'FW1', False, 41)\n",
      "('1W', '40X', 'FW1', False, 42)\n",
      "('1W', '40X', 'FW1', False, 43)\n",
      "('1W', '40X', 'FW1', False, 44)\n",
      "('1W', '40X', 'FW1', False, 45)\n",
      "('1W', '40X', 'FW1', False, 46)\n",
      "('1W', '40X', 'FW1', False, 47)\n",
      "('1W', '40X', 'FW1', False, 48)\n",
      "('1W', '40X', 'FW1', False, 49)\n",
      "('1W', '40X', 'FW1', False, 50)\n",
      "('1W', '40X', 'FW1', False, 51)\n",
      "('1W', '40X', 'FW1', False, 52)\n",
      "('1W', '40X', 'FW1', False, 53)\n",
      "('1W', '40X', 'FW1', False, 54)\n",
      "('1W', '40X', 'FW1', False, 55)\n",
      "('1W', '40X', 'FW1', False, 56)\n",
      "('1W', '40X', 'FW1', False, 57)\n",
      "('1W', '40X', 'FW1', False, 58)\n",
      "('1W', '40X', 'FW1', False, 59)\n",
      "('1W', '40X', 'FW1', False, 60)\n",
      "('1W', '40X', 'FW1', False, 61)\n",
      "('1W', '40X', 'FW1', False, 62)\n",
      "('1W', '40X', 'FW1', False, 63)\n",
      "('1W', '40X', 'FW1', False, 64)\n",
      "('1W', '40X', 'FW1', False, 65)\n",
      "('1W', '40X', 'FW1', False, 66)\n",
      "('1W', '40X', 'FW1', False, 67)\n",
      "('1W', '40X', 'FW1', False, 68)\n",
      "('1W', '40X', 'FW1', False, 69)\n",
      "('1W', '40X', 'FW1', False, 70)\n",
      "('1W', '40X', 'FW1', False, 71)\n",
      "('1W', '40X', 'FW1', False, 72)\n",
      "('1W', '40X', 'FW2', False, 1)\n",
      "('1W', '40X', 'FW2', False, 2)\n",
      "('1W', '40X', 'FW2', False, 3)\n",
      "('1W', '40X', 'FW2', False, 4)\n",
      "('1W', '40X', 'FW2', False, 5)\n",
      "('1W', '40X', 'FW2', False, 6)\n",
      "('1W', '40X', 'FW2', False, 7)\n",
      "('1W', '40X', 'FW2', False, 8)\n",
      "('1W', '40X', 'FW2', False, 9)\n",
      "('1W', '40X', 'FW2', False, 10)\n",
      "('1W', '40X', 'FW2', False, 11)\n",
      "('1W', '40X', 'FW2', False, 12)\n",
      "('1W', '40X', 'FW2', False, 13)\n",
      "('1W', '40X', 'FW2', False, 14)\n",
      "('1W', '40X', 'FW2', False, 15)\n",
      "('1W', '40X', 'FW2', False, 16)\n",
      "('1W', '40X', 'FW2', False, 17)\n",
      "('1W', '40X', 'FW2', False, 18)\n",
      "('1W', '40X', 'FW2', False, 19)\n",
      "('1W', '40X', 'FW2', False, 20)\n",
      "('1W', '40X', 'FW2', False, 21)\n",
      "('1W', '40X', 'FW2', False, 22)\n",
      "('1W', '40X', 'FW2', False, 23)\n",
      "('1W', '40X', 'FW2', False, 24)\n",
      "('1W', '40X', 'FW2', False, 25)\n",
      "('1W', '40X', 'FW2', False, 26)\n",
      "('1W', '40X', 'FW2', False, 27)\n",
      "('1W', '40X', 'FW2', False, 28)\n",
      "('1W', '40X', 'FW2', False, 29)\n",
      "('1W', '40X', 'FW2', False, 30)\n",
      "('1W', '40X', 'FW2', False, 31)\n",
      "('1W', '40X', 'FW2', False, 32)\n",
      "('1W', '40X', 'FW2', False, 33)\n",
      "('1W', '40X', 'FW2', False, 34)\n",
      "('1W', '40X', 'FW2', False, 35)\n",
      "('1W', '40X', 'FW2', False, 36)\n",
      "('1W', '40X', 'FW2', False, 37)\n",
      "('1W', '40X', 'FW2', False, 38)\n",
      "('1W', '40X', 'FW2', False, 39)\n",
      "('1W', '40X', 'FW2', False, 40)\n",
      "('1W', '40X', 'FW2', False, 41)\n",
      "('1W', '40X', 'FW2', False, 42)\n",
      "('1W', '40X', 'FW2', False, 43)\n",
      "('1W', '40X', 'FW2', False, 44)\n",
      "('1W', '40X', 'FW2', False, 45)\n",
      "('1W', '40X', 'FW2', False, 46)\n",
      "('1W', '40X', 'FW2', False, 47)\n",
      "('1W', '40X', 'FW2', False, 48)\n",
      "('1W', '40X', 'FW2', False, 49)\n",
      "('1W', '40X', 'FW2', False, 50)\n",
      "('1W', '40X', 'FW2', False, 51)\n",
      "('1W', '40X', 'FW2', False, 52)\n",
      "('1W', '40X', 'FW2', False, 53)\n",
      "('1W', '40X', 'FW2', False, 54)\n",
      "('1W', '40X', 'FW2', False, 55)\n",
      "('1W', '40X', 'FW2', False, 56)\n",
      "('1W', '40X', 'FW3', False, 1)\n",
      "('1W', '40X', 'FW3', False, 2)\n",
      "('1W', '40X', 'FW3', False, 3)\n",
      "('1W', '40X', 'FW3', False, 4)\n",
      "('1W', '40X', 'FW3', False, 5)\n",
      "('1W', '40X', 'FW3', False, 6)\n",
      "('1W', '40X', 'FW3', False, 7)\n",
      "('1W', '40X', 'FW3', False, 8)\n",
      "('1W', '40X', 'FW3', False, 9)\n",
      "('1W', '40X', 'FW3', False, 10)\n",
      "('1W', '40X', 'FW3', False, 11)\n",
      "('1W', '40X', 'FW3', False, 12)\n",
      "('1W', '40X', 'FW3', False, 13)\n",
      "('1W', '40X', 'FW3', False, 14)\n",
      "('1W', '40X', 'FW3', False, 15)\n",
      "('1W', '40X', 'FW3', False, 16)\n",
      "('1W', '40X', 'FW3', False, 17)\n",
      "('1W', '40X', 'FW3', False, 18)\n",
      "('1W', '40X', 'FW3', False, 19)\n",
      "('1W', '40X', 'FW3', False, 20)\n",
      "('1W', '40X', 'FW3', False, 21)\n",
      "('1W', '40X', 'FW3', False, 22)\n",
      "('1W', '40X', 'FW3', False, 23)\n",
      "('1W', '40X', 'FW3', False, 24)\n",
      "('1W', '40X', 'FW3', False, 25)\n",
      "('1W', '40X', 'FW3', False, 26)\n",
      "('1W', '40X', 'FW3', False, 27)\n"
     ]
    }
   ],
   "source": [
    "df_imgs_path = data_dir / 'OCT mouse' / 'ROI' / 'metadata' / 'imgs.csv'\n",
    "\n",
    "try:\n",
    "    df_imgs_path.parent.mkdir(parents=True, exist_ok=False)\n",
    "except FileExistsError:\n",
    "    print(\"Folder is already there\")\n",
    "    \n",
    "temp_path = data_dir / 'OCT mouse' / 'ROI' / 'hdf5' / 'raw'\n",
    "try:\n",
    "    temp_path.mkdir(parents=True, exist_ok=False)\n",
    "except FileExistsError:\n",
    "    print(\"Folder is already there\")\n",
    "\n",
    "df_exist = df_imgs_path.is_file()\n",
    "\n",
    "if not df_exist:\n",
    "    print('Created df')\n",
    "    df_z = df[df.Resolution == '40X']\n",
    "    df_z = df_z[df_z.AfBleach == False]\n",
    "    group = df_z.groupby(['Timepoint', 'Resolution', 'FOV', 'AfBleach', 'ROI']) \n",
    "    rows = []\n",
    "\n",
    "    for name, df_group in tqdm(group, total=len(group)):\n",
    "        print(name)\n",
    "        file_name = '_'.join(np.array(name).astype(str)) + '.hdf5'\n",
    "        file_path = temp_path / file_name\n",
    "        rows.append(list(name)+[file_path])\n",
    "\n",
    "        group_channel = df_group.groupby(['Cycle', 'Channels'])\n",
    "        for n, df_channel in group_channel:\n",
    "            marker = df_channel.iloc[0].Markers\n",
    "            paths = df_channel.Path.to_numpy()\n",
    "\n",
    "            imgs = joblib_loop(read_img, paths)\n",
    "            imgs = np.array(imgs)\n",
    "            info = {\"Cycle\": n[0], \"Channel\": n[1], \"Marker\": marker, \"Z\": df_channel.Z.to_numpy()}\n",
    "            \n",
    "            # hdf5 as Channel -> Z mapping\n",
    "            save_hdf5(file_path, '_'.join(np.array(n).astype(str)), imgs, info)\n",
    "    df_imgs = pd.DataFrame(rows, columns=['Timepoint', 'Resolution', 'FOV', 'AfBleach', 'ROI', 'Path'])        \n",
    "    df_imgs.to_csv(df_imgs_path, index=False)\n",
    "else:\n",
    "    print('Loaded df')\n",
    "    df_imgs = pd.read_csv(df_imgs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Get best focus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_blur_fft(image, size=60):\n",
    "    # grab the dimensions of the image and use the dimensions to\n",
    "    # derive the center (x, y)-coordinates\n",
    "    (h, w) = image.shape\n",
    "    (cX, cY) = (int(w / 2.0), int(h / 2.0))\n",
    "    \n",
    "    # compute the FFT to find the frequency transform, then shift\n",
    "    # the zero frequency component (i.e., DC component located at\n",
    "    # the top-left corner) to the center where it will be more\n",
    "    # easy to analyze\n",
    "    fft = np.fft.fft2(image)\n",
    "    fftShift = np.fft.fftshift(fft)\n",
    "    \n",
    "    # zero-out the center of the FFT shift (i.e., remove low\n",
    "    # frequencies), apply the inverse shift such that the DC\n",
    "    # component once again becomes the top-left, and then apply\n",
    "    # the inverse FFT\n",
    "    fftShift[cY - size:cY + size, cX - size:cX + size] = 0\n",
    "    fftShift = np.fft.ifftshift(fftShift)\n",
    "    recon = np.fft.ifft2(fftShift)\n",
    "    \n",
    "    magnitude = 20 * np.log(np.abs(recon))\n",
    "    mean = np.mean(magnitude)\n",
    "    \n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Timepoint', 'Resolution', 'FOV', 'AfBleach', 'ROI', 'Path'], dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imgs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder is already there\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff88edb72f23464f914ee9d93886be11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/306 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "csv_blur = data_dir / 'OCT mouse' / 'ROI'/ 'metadata' / \"blur.csv\"\n",
    "\n",
    "try:\n",
    "    csv_blur.parent.mkdir(parents=True, exist_ok=False)\n",
    "except FileExistsError:\n",
    "    print(\"Folder is already there\")\n",
    "\n",
    "k = '1'    \n",
    "\n",
    "if not csv_blur.is_file():\n",
    "    max_blur_values = []\n",
    "    for row in tqdm(df_imgs.itertuples(), total=len(df_imgs)):\n",
    "        path = row.Path\n",
    "        \n",
    "        with h5py.File(path, \"r\") as f:\n",
    "            for k in f.keys():\n",
    "                if f[k].attrs['Channel'] == 1:\n",
    "                    cycle = k.split('_')[0]\n",
    "                    channel = f[k].attrs['Channel']\n",
    "                    imgs = f[k]\n",
    "                    blur_scores = joblib_loop(detect_blur_fft, imgs)\n",
    "                    blur_max = np.argmax(blur_scores)\n",
    "                    values = list(row[1:])\n",
    "                    values.append(cycle)\n",
    "                    values.append(blur_max)\n",
    "                    max_blur_values.append(values)\n",
    "    df_blur_max = pd.DataFrame(max_blur_values, columns=['Timepoint', 'Resolution', 'FOV', 'AfBleach', 'ROI', 'Path', 'Cycle', 'Z_stack_focus'])\n",
    "    df_blur_max.to_csv(csv_blur, index=False)\n",
    "else:\n",
    "    df_blur_max = pd.read_csv(csv_blur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timepoint</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>FOV</th>\n",
       "      <th>AfBleach</th>\n",
       "      <th>ROI</th>\n",
       "      <th>Path</th>\n",
       "      <th>Cycle</th>\n",
       "      <th>Z_stack_focus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1M</td>\n",
       "      <td>40X</td>\n",
       "      <td>FW1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\15_PLA\\data\\OCT mouse\\ROI...</td>\n",
       "      <td>cycle1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1M</td>\n",
       "      <td>40X</td>\n",
       "      <td>FW1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\15_PLA\\data\\OCT mouse\\ROI...</td>\n",
       "      <td>cycle2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1M</td>\n",
       "      <td>40X</td>\n",
       "      <td>FW1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\15_PLA\\data\\OCT mouse\\ROI...</td>\n",
       "      <td>cycle3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1M</td>\n",
       "      <td>40X</td>\n",
       "      <td>FW1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\15_PLA\\data\\OCT mouse\\ROI...</td>\n",
       "      <td>cycle4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1M</td>\n",
       "      <td>40X</td>\n",
       "      <td>FW1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\15_PLA\\data\\OCT mouse\\ROI...</td>\n",
       "      <td>cycle5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2650</th>\n",
       "      <td>1W</td>\n",
       "      <td>40X</td>\n",
       "      <td>FW3</td>\n",
       "      <td>False</td>\n",
       "      <td>43</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\15_PLA\\data\\OCT mouse\\ROI...</td>\n",
       "      <td>cycle2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2651</th>\n",
       "      <td>1W</td>\n",
       "      <td>40X</td>\n",
       "      <td>FW3</td>\n",
       "      <td>False</td>\n",
       "      <td>44</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\15_PLA\\data\\OCT mouse\\ROI...</td>\n",
       "      <td>cycle1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2652</th>\n",
       "      <td>1W</td>\n",
       "      <td>40X</td>\n",
       "      <td>FW3</td>\n",
       "      <td>False</td>\n",
       "      <td>44</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\15_PLA\\data\\OCT mouse\\ROI...</td>\n",
       "      <td>cycle2</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2653</th>\n",
       "      <td>1W</td>\n",
       "      <td>40X</td>\n",
       "      <td>FW3</td>\n",
       "      <td>False</td>\n",
       "      <td>45</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\15_PLA\\data\\OCT mouse\\ROI...</td>\n",
       "      <td>cycle1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2654</th>\n",
       "      <td>1W</td>\n",
       "      <td>40X</td>\n",
       "      <td>FW3</td>\n",
       "      <td>False</td>\n",
       "      <td>45</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\15_PLA\\data\\OCT mouse\\ROI...</td>\n",
       "      <td>cycle2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2655 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Timepoint Resolution  FOV  AfBleach  ROI  \\\n",
       "0           1M        40X  FW1     False    1   \n",
       "1           1M        40X  FW1     False    1   \n",
       "2           1M        40X  FW1     False    1   \n",
       "3           1M        40X  FW1     False    1   \n",
       "4           1M        40X  FW1     False    1   \n",
       "...        ...        ...  ...       ...  ...   \n",
       "2650        1W        40X  FW3     False   43   \n",
       "2651        1W        40X  FW3     False   44   \n",
       "2652        1W        40X  FW3     False   44   \n",
       "2653        1W        40X  FW3     False   45   \n",
       "2654        1W        40X  FW3     False   45   \n",
       "\n",
       "                                                   Path   Cycle  Z_stack_focus  \n",
       "0     Y:\\coskun-lab\\Thomas\\15_PLA\\data\\OCT mouse\\ROI...  cycle1             11  \n",
       "1     Y:\\coskun-lab\\Thomas\\15_PLA\\data\\OCT mouse\\ROI...  cycle2             15  \n",
       "2     Y:\\coskun-lab\\Thomas\\15_PLA\\data\\OCT mouse\\ROI...  cycle3             14  \n",
       "3     Y:\\coskun-lab\\Thomas\\15_PLA\\data\\OCT mouse\\ROI...  cycle4             15  \n",
       "4     Y:\\coskun-lab\\Thomas\\15_PLA\\data\\OCT mouse\\ROI...  cycle5             11  \n",
       "...                                                 ...     ...            ...  \n",
       "2650  Y:\\coskun-lab\\Thomas\\15_PLA\\data\\OCT mouse\\ROI...  cycle2             15  \n",
       "2651  Y:\\coskun-lab\\Thomas\\15_PLA\\data\\OCT mouse\\ROI...  cycle1             18  \n",
       "2652  Y:\\coskun-lab\\Thomas\\15_PLA\\data\\OCT mouse\\ROI...  cycle2             16  \n",
       "2653  Y:\\coskun-lab\\Thomas\\15_PLA\\data\\OCT mouse\\ROI...  cycle1             13  \n",
       "2654  Y:\\coskun-lab\\Thomas\\15_PLA\\data\\OCT mouse\\ROI...  cycle2             18  \n",
       "\n",
       "[2655 rows x 8 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_blur_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Get shift per cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.registration import phase_cross_correlation\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "def get_shift_between_cycle(imgs, cycles):\n",
    "    \"\"\"Function to get shift within each cycle for the DAPI channel\n",
    "\n",
    "    Args:\n",
    "        df (pd DataFrame) : info dataframe for images in dapi channel accross cycle\n",
    "\n",
    "    Returns:\n",
    "        shift dictionnary\n",
    "    \"\"\"\n",
    "    shift_dict = {}\n",
    "    \n",
    "    # Max shift accross all cycle:\n",
    "    max_shift_x = 0\n",
    "    min_shift_x = 0\n",
    "    max_shift_y = 0\n",
    "    min_shift_y = 0\n",
    "    reference_dapi = imgs[0]\n",
    "    cycles_it = cycles[1:]\n",
    "    for i, img_dapi in enumerate(imgs[1:]):\n",
    "        \n",
    "        # print(f'Registration cycle {cycles[i+1]}', flush=True)\n",
    "        # Get image shift y and x and save to shift_dict\n",
    "        try:\n",
    "            shift, _, _ = phase_cross_correlation(\n",
    "                reference_dapi, img_dapi, \n",
    "                upsample_factor=1\n",
    "            )  # Shift vector required to register moving images with reference images. Axis orderingis constitent with Y,X\n",
    "        except ValueError as err:\n",
    "            print(err)\n",
    "        shift_y, shift_x = shift[0], shift[1]\n",
    "        shift_dict[cycles[i+1]] = {\"shift_x\": shift_x, \"shift_y\": shift_y}\n",
    "\n",
    "        # Update max shift\n",
    "        max_shift_x = shift_x if shift_x > max_shift_x else max_shift_x\n",
    "        min_shift_x = shift_x if shift_x < min_shift_x else min_shift_x\n",
    "        max_shift_y = shift_y if shift_y > max_shift_y else max_shift_y\n",
    "        min_shift_y = shift_y if shift_y < min_shift_y else min_shift_y\n",
    "\n",
    "    max_shift_x = int(max_shift_x)\n",
    "    min_shift_x = int(min_shift_x)\n",
    "    max_shift_y = int(max_shift_y)\n",
    "    min_shift_y = int(min_shift_y)\n",
    "\n",
    "    shift_dict[\"max\"] = {\n",
    "        \"shift_x\": max_shift_x,\n",
    "        \"shift_y\": max_shift_y,\n",
    "    }\n",
    "    shift_dict[\"min\"] = {\n",
    "        \"shift_x\": min_shift_x,\n",
    "        \"shift_y\": min_shift_y,\n",
    "    }\n",
    "\n",
    "    return shift_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cycle = len(df_blur_max.Cycle.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_csv = data_dir / 'OCT mouse' /  'ROI'/  'metadata' / \"shift.csv\"\n",
    "\n",
    "try:\n",
    "    shift_csv.parent.mkdir(parents=True, exist_ok=False)\n",
    "except FileExistsError:\n",
    "    print(\"Folder is already there\")\n",
    "\n",
    "k = '1'    \n",
    "\n",
    "if not shift_csv.is_file():\n",
    "    dfs_shift = []\n",
    "    for row in tqdm(df_imgs.itertuples(), total=len(df_imgs)):\n",
    "        df_query = df_blur_max.query('Timepoint==@row[1] & FOV==@row[3] & ROI==@row[5]')\n",
    "        if len(df_query) < n_cycle:\n",
    "            continue \n",
    "        path = row.Path\n",
    "        \n",
    "        imgs_dapi = []\n",
    "        cycles = []\n",
    "        with h5py.File(path, \"r\") as f:\n",
    "            for k in f.keys():\n",
    "                if f[k].attrs['Channel'] == 1:\n",
    "                    df_c = df_query[df_query['Cycle'] == f[k].attrs['Cycle']]\n",
    "                    best_focus = df_c.Z_stack_focus.item()\n",
    "                    imgs_dapi.append(f[k][best_focus, ...])\n",
    "                    cycles.append(int(k.split('_')[0][-1]))\n",
    "                    \n",
    "        shift = get_shift_between_cycle(imgs_dapi, cycles)\n",
    "        df_temp = pd.DataFrame(shift)\n",
    "        old_idx = df_temp.index.to_frame() # Convert index to dataframe\n",
    "        old_idx.insert(0, 'ROI', row.ROI) # Insert new level at specified location\n",
    "        old_idx.insert(0, 'FOV', row.FOV)\n",
    "        old_idx.insert(0, 'Timepoint', row.Timepoint)\n",
    "        df_temp.index = pd.MultiIndex.from_frame(old_idx) # Convert back to MultiIndex\n",
    "        dfs_shift.append(df_temp)\n",
    "    \n",
    "    df_shift = pd.concat(dfs_shift)\n",
    "    df_shift.to_csv(shift_csv , index=True)\n",
    "else:\n",
    "    df_shift = pd.read_csv(shift_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shift.set_index(['Timepoint', 'FOV', 'ROI', 'Unnamed: 3'], inplace=True)\n",
    "df_shift.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get shift cropped images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import transform\n",
    "from functools import partial\n",
    "\n",
    "def crop_images(imgs, df_shift, cycles, upscale=1):\n",
    "    # Get max shift values\n",
    "    max_shift_x = df_shift.loc['shift_x', 'max']\n",
    "    min_shift_x = df_shift.loc['shift_x', 'min']\n",
    "    max_shift_y = df_shift.loc['shift_y', 'max']\n",
    "    min_shift_y = df_shift.loc['shift_y', 'min']\n",
    "    \n",
    "    imgs_cropped = []\n",
    "    for idx, img in enumerate(imgs):\n",
    "        if cycles[idx] == '1':\n",
    "            # Crop image\n",
    "            res_cropped = img[:, max_shift_y:min_shift_y-1, max_shift_x:min_shift_x-1]\n",
    "        else:\n",
    "            #Apply shift\n",
    "            shift_x, shift_y = (\n",
    "                df_shift.loc['shift_x', cycles[idx]],\n",
    "                df_shift.loc['shift_y', cycles[idx]],\n",
    "            )\n",
    "            # rows, cols = img.shape\n",
    "            # M = np.float32([[1, 0, shift_x], [0, 1, shift_y]])\n",
    "            # res = cv2.warpAffine(img, M, (cols, rows))\n",
    "            shift_x = int(shift_x*upscale)\n",
    "            shift_y = int(shift_y*upscale)\n",
    "            \n",
    "            t = transform.AffineTransform(translation=[-shift_x, -shift_y])\n",
    "            f_partial = partial(transform.warp, inverse_map=t,mode='constant', cval=0, preserve_range=True)\n",
    "            # res = transform.warp(img, t, mode='constant', cval=0, preserve_range=True)\n",
    "            res = Parallel(n_jobs=multiprocessing.cpu_count())(delayed(f_partial)(i) for i in img)\n",
    "            res = np.array(res)\n",
    "            \n",
    "            # Crop image\n",
    "            res_cropped = res[:, max_shift_y:min_shift_y-1, max_shift_x:min_shift_x-1]\n",
    "            res_cropped.astype(img.dtype)\n",
    "        imgs_cropped.append(res_cropped)\n",
    "    return imgs_cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 5\n",
    "# for i, row in tqdm(df_imgs.itertuples(), total=len(df_imgs)):\n",
    "#     path = row.Path\n",
    "#     df_query = df_blur_max.query('Timepoint==@row[1] & FOV==@row[3] & ROI==@row[5]')\n",
    "#     imgs = []\n",
    "#     cycles = []\n",
    "#     channels = []\n",
    "#     markers = []\n",
    "#     with h5py.File(path, \"r\") as f:\n",
    "#         for k in f.keys():\n",
    "#             df_c = df_query[df_query['Cycle'] == f[k].attrs['Cycle']]\n",
    "#             if len(df_c) == 0:\n",
    "#                 continue \n",
    "#             best_focus = df_c.Z_stack_focus.item()\n",
    "#             # imgs.append(f[k][best_focus-n:best_focus+n, ...])\n",
    "#             cycles.append(int(k.split('_')[0][-1]))\n",
    "#             channels.append(int(k.split('_')[-1]))\n",
    "#             markers.append( f[k].attrs['Marker'])\n",
    "#     # df_shift_roi = df_shift.loc[row[1], row[3], row[5]]\n",
    "#     # imgs_cropped = crop_images(imgs, df_shift_roi, cycles)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_reg_path = data_dir / 'OCT mouse' / 'ROI' / 'metadata' / 'imgs_reg.csv'\n",
    "n = 5\n",
    "\n",
    "try:\n",
    "    df_reg_path.parent.mkdir(parents=True, exist_ok=False)\n",
    "except FileExistsError:\n",
    "    print(\"Folder is already there\")\n",
    "    \n",
    "temp_path = data_dir / 'OCT mouse' / 'ROI' / 'hdf5' / 'registered'\n",
    "try:\n",
    "    temp_path.mkdir(parents=True, exist_ok=False)\n",
    "except FileExistsError:\n",
    "    print(\"Folder is already there\")\n",
    "\n",
    "df_exist = df_reg_path.is_file()\n",
    "\n",
    "if not df_exist:\n",
    "    df_reg = df_imgs.copy()\n",
    "    for row in tqdm(df_imgs.itertuples(), total=len(df_imgs)):\n",
    "        # Get Path\n",
    "        path = row.Path\n",
    "        file_name = row.Path.split('\\\\')[-1]\n",
    "        file_path = temp_path / file_name\n",
    "        \n",
    "        # Check if file exist\n",
    "        if file_path.is_file():\n",
    "            print(file_name+' exists!')\n",
    "            df_reg.loc[row.Index, 'Path'] = file_path\n",
    "            continue\n",
    "        \n",
    "        # Query from blur dataframe \n",
    "        df_query = df_blur_max.query('Timepoint==@row[1] & FOV==@row[3] & ROI==@row[5]')\n",
    "        imgs = []\n",
    "        cycles = []\n",
    "        channels = []\n",
    "        markers = []\n",
    "        with h5py.File(path, \"r\") as f:\n",
    "            for k in f.keys():\n",
    "                df_c = df_query[df_query['Cycle'] == f[k].attrs['Cycle']]\n",
    "                if len(df_c) == 0:\n",
    "                    continue \n",
    "                best_focus = df_c.Z_stack_focus.item()\n",
    "                if best_focus < n:\n",
    "                    best_focus = n\n",
    "                elif best_focus > len(f[k])-n:\n",
    "                    best_focus = len(f[k])-n\n",
    "                imgs.append(f[k][best_focus-n:best_focus+n, ...])\n",
    "                cycles.append(int(k.split('_')[0][-1]))\n",
    "                channels.append(int(k.split('_')[-1]))\n",
    "                markers.append( f[k].attrs['Marker'])\n",
    "        \n",
    "        try:\n",
    "            df_shift_roi = df_shift.loc[row[1], row[3], row[5]]\n",
    "            imgs_cropped = crop_images(imgs, df_shift_roi, np.array(cycles).astype(str))\n",
    "        except Exception as e:\n",
    "            print(row, str(e))\n",
    "            continue\n",
    "        info = {\"Cycle\": cycles, \"Channel\": channels, \"Marker\": markers}\n",
    "        \n",
    "        try:\n",
    "            imgs_stacked = np.stack(imgs_cropped)\n",
    "        except:\n",
    "            min_z = imgs_cropped[0].shape[0]\n",
    "            for i in imgs_cropped:\n",
    "                min_z = i.shape[0] if i.shape[0] < min_z else min_z\n",
    "            imgs_stacked = np.stack([i[:min_z,...] for i in imgs_cropped])\n",
    "        # hdf5 as Channel -> Z mapping\n",
    "        save_hdf5(file_path, 'imgs', imgs_stacked, info)\n",
    "        df_reg.loc[row.Index, 'Path'] = file_path\n",
    "        \n",
    "    df_reg.to_csv(df_reg_path, index=False)\n",
    "else:\n",
    "    print('Loaded df')\n",
    "    df_reg = pd.read_csv(df_reg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-thomas-env] *",
   "language": "python",
   "name": "conda-env-.conda-thomas-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
