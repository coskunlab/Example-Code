{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eea5fe6f-b934-48ce-a7c4-bf83e5bcf371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.io\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import trange, tqdm, tqdm_notebook\n",
    "from joblib import Parallel, delayed\n",
    "import re\n",
    "import h5py\n",
    "import tifffile as tiff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7c6540b-3c1a-4afb-a4b5-aac5aa819c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75fac3c6-d12f-4c66-b64b-e4fa8c4c0b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = (Path().cwd().parents[0] / 'data').absolute()\n",
    "data_processed = data_dir / 'processed'\n",
    "data_raw = r'Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\Sensitivity experiment\\18Oct23_multicolor pairs'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8a1297c-f7bd-474d-8ed1-3020d49df8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    " \n",
    "os.environ['JDK_HOME'] = \"C:\\Program Files\\Java\\jdk-17\"\n",
    "os.environ['JAVA_HOME'] = \"C:\\Program Files\\Java\\jdk-17\"\n",
    "\n",
    "os.environ['PATH'] += ';C:\\\\Program Files\\\\Java\\\\jdk-17\\\\jre\\\\bin\\\\server\\\\;C:\\\\Program Files\\\\Java\\\\jdk-17\\\\bin\\\\;C:\\\\Program Files\\\\Java\\\\jdk-17\\\\bin\\\\jar.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b6fef7-439f-4d80-bcf5-2c20bb7b264b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Get info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a032dd3-a666-40e9-8abf-ca1e1d14f37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "markers_map = {\n",
    "    'cycle1': {\n",
    "        1: 'DNA', \n",
    "        3: 'Sox2/Oct4',\n",
    "        4: 'p-P90rsk/NF-Kb',\n",
    "    },\n",
    "    'cycle2': {\n",
    "        1: 'DNA', \n",
    "        3: 'Cyclin D1/CDK4',\n",
    "        4: 'Bim/Tom20',\n",
    "    },\n",
    "    'cycle3': {\n",
    "        1: 'DNA', \n",
    "        2: 'Concanavalin A',\n",
    "        3: 'Phalloidin',\n",
    "        4: 'WGA'\n",
    "    },\n",
    "}\n",
    "\n",
    "def get_info(data_raw, marker_dict):\n",
    "    conditions = []\n",
    "    fovs = []\n",
    "    cycles = []\n",
    "    channels = []\n",
    "    markers = []\n",
    "    paths = [] \n",
    "    \n",
    "    # Loop through image folder\n",
    "    for (dirpath, dirnames, filenames) in os.walk(data_raw):\n",
    "        if 'after nuclease' in dirpath or 'Defocused' in dirpath or 'wrong' in dirpath:\n",
    "            continue\n",
    "        \n",
    "            \n",
    "        for name in sorted(filenames):\n",
    "            if \"tif\" in name and \"sti\" in name \\\n",
    "            and 'overlay' not in name \\\n",
    "            and 'Composite' not in name:\n",
    "                # Get information from image name\n",
    "                row = filenames[-1][1] \n",
    "                if row == 'B':\n",
    "                    condition = 'Control'\n",
    "                elif row == 'C':\n",
    "                    condition = '100nM'\n",
    "                elif row == 'D':\n",
    "                    condition = '25nM'\n",
    "                elif row == 'E':\n",
    "                    condition = '10nM'\n",
    "                elif row == 'F':\n",
    "                    condition = '5nM'\n",
    "                d_split = dirpath.split('\\\\')\n",
    "                \n",
    "                well = d_split[-2].split('_')[2].split(' ')[0]\n",
    "                n_split = name.split('_')\n",
    "                ch = int(n_split[-1][-5])\n",
    "                \n",
    "                cycle = well\n",
    "                try: marker = marker_dict[cycle][ch] \n",
    "                except: continue\n",
    "        \n",
    "                conditions.append(condition)\n",
    "                fovs.append(row)\n",
    "                cycles.append(cycle)\n",
    "                channels.append(ch)\n",
    "                markers.append(marker)\n",
    "                paths.append(os.path.join(dirpath, name))\n",
    "                \n",
    "    info = {\n",
    "            \"Condition\": conditions,\n",
    "            \"FOV\": fovs,\n",
    "            \"Cycle\": cycles,\n",
    "            \"Channels\": channels,\n",
    "            \"Markers\": markers,\n",
    "            \"Path\": paths\n",
    "        }\n",
    "\n",
    "    df = pd.DataFrame(info)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "82a9faa9-3d99-402b-a497-b26fb559f616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created df\n"
     ]
    }
   ],
   "source": [
    "df_meta_path = data_dir / 'sensitivity_v2' / 'metadata' / 'info.csv'\n",
    "df_meta_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "df_exist = df_meta_path.is_file()\n",
    "\n",
    "if not df_exist:\n",
    "    print('Created df')\n",
    "    df = get_info(data_raw, markers_map)\n",
    "    df.to_csv(df_meta_path, index=False)\n",
    "else:\n",
    "    print('Loaded df')\n",
    "    df = pd.read_csv(df_meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b0e47b2-48e6-4c2d-ae50-c3991f3eb79b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Condition\n",
       "100nM      10\n",
       "10nM       10\n",
       "25nM       10\n",
       "5nM        10\n",
       "Control    10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Condition').size()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c2a7c2-c2cd-4e53-a1d8-b31b2abde19e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Save HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6c7510f9-709b-4508-8393-052b8a12153d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "def save_hdf5(\n",
    "    path: str, name: str, data: np.ndarray, attr_dict=None, mode: str = \"a\"\n",
    ") -> None:\n",
    "    # Read h5 file\n",
    "    hf = h5py.File(path, mode)\n",
    "    # Create z_stack_dataset\n",
    "    if hf.get(name) is None:\n",
    "        data_shape = data.shape\n",
    "        data_type = data.dtype\n",
    "        max_shape = (data_shape[0],) + data_shape[1:]\n",
    "        dset = hf.create_dataset(\n",
    "            name,\n",
    "            shape=data_shape,\n",
    "            maxshape=max_shape,\n",
    "            chunks=True,\n",
    "            dtype=data_type,\n",
    "            compression=\"gzip\",\n",
    "        )\n",
    "        dset[:] = data\n",
    "        if attr_dict is not None:\n",
    "            for attr_key, attr_val in attr_dict.items():\n",
    "                dset.attrs[attr_key] = attr_val\n",
    "    else:\n",
    "        print(f\"Dataset {name} exists\")\n",
    "\n",
    "    hf.close()\n",
    "\n",
    "def read_img(path):\n",
    "    return skimage.io.imread(path, as_gray=True)\n",
    "\n",
    "def joblib_loop(task, pics):\n",
    "    return Parallel(n_jobs=20)(delayed(task)(i) for i in pics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "33089984-1c3c-4655-a9d9-67d552161fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created df\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f98c4d090ff049679ccc2dc9acf9e5d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thu71\\Anaconda3\\envs\\PLA2\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_imgs_path = data_dir / 'sensitivity_v2' / 'metadata' / 'imgs.csv'\n",
    "df_imgs_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "temp_path = data_dir  /'sensitivity_v2' /  'hdf5' / 'raw'\n",
    "temp_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_exist = df_imgs_path.is_file()\n",
    "\n",
    "\n",
    "if not df_exist:\n",
    "    print('Created df')\n",
    "    \n",
    "    group = df.groupby(['Condition', 'FOV'])\n",
    "    rows = []\n",
    "\n",
    "    for name, df_group in tqdm(group, total=len(group)):\n",
    "        file_name = '_'.join(np.array(name).astype(str)) + '.hdf5'\n",
    "        file_path = temp_path / file_name\n",
    "        rows.append(list(name)+[file_path])\n",
    "        \n",
    "        group_cycle = df_group.groupby('Cycle')\n",
    "        for cycle, df_cycle in group_cycle:\n",
    "            channels = df_cycle.Channels.to_list()\n",
    "            markers = df_cycle.Markers.to_list()\n",
    "            paths = df_cycle.Path.to_numpy()\n",
    "    \n",
    "            imgs = joblib_loop(read_img, paths)\n",
    "            imgs = np.array(imgs)\n",
    "            info = {\"Channels\": channels, \"Markers\": markers}\n",
    "            \n",
    "            # hdf5 as Channel -> Z mapping\n",
    "            save_hdf5(file_path, cycle, imgs, info)\n",
    "    df_imgs = pd.DataFrame(rows, columns=['Condition', 'FOV', 'Path'])        \n",
    "    df_imgs.to_csv(df_imgs_path, index=False)\n",
    "else:\n",
    "    print('Loaded df')\n",
    "    df_imgs = pd.read_csv(df_imgs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1af25600-6510-4854-b04f-d3e6641bf020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Condition</th>\n",
       "      <th>FOV</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100nM</td>\n",
       "      <td>C</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\sens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10nM</td>\n",
       "      <td>E</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\sens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25nM</td>\n",
       "      <td>D</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\sens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5nM</td>\n",
       "      <td>F</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\sens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Control</td>\n",
       "      <td>B</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\sens...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Condition FOV                                               Path\n",
       "0     100nM   C  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\sens...\n",
       "1      10nM   E  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\sens...\n",
       "2      25nM   D  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\sens...\n",
       "3       5nM   F  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\sens...\n",
       "4   Control   B  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\sens..."
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68f4da0-7daa-481d-ae7f-62d2db3010b0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Save Tiffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e8014bc6-4b77-42a0-825c-05b7b5ec310d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure, util\n",
    "\n",
    "def contrast_str(img, n_min=0.1, n_max=100):\n",
    "    p2, p98 = np.percentile(img, (n_min, n_max))\n",
    "    img_rescale = exposure.rescale_intensity(img, in_range=(p2, p98))\n",
    "    return img_rescale\n",
    "\n",
    "def make_imgs_same_dim(imgs):\n",
    "    # Get max dimensions\n",
    "    shapes = np.array([img.shape[1:] for img in imgs])\n",
    "    min_x, min_y = shapes.min(axis=0)\n",
    "    imgs_cropped = [img[:, :min_x, :min_y] for img in imgs]\n",
    "    # imgs_cropped[0] = contrast_str(imgs_cropped[0])\n",
    "    return imgs_cropped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8765c8f8-bf9b-45fb-90bd-836765b3a089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_path = data_dir /  'sensitivity_v2' /'imgs' / 'raw'\n",
    "save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "group = df_imgs.groupby(['Condition', 'FOV'])\n",
    "for name, df_group in group:\n",
    "    path = df_group.iloc[0].Path\n",
    "             \n",
    "    # Read images\n",
    "    cycles = []\n",
    "    imgs_all = []\n",
    "    channels = []\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        for k in tqdm(f.keys(), total=len(f.keys()), leave=False):\n",
    "            cycle = k.split('_')[0]\n",
    "            channel = f[k].attrs['Channels']\n",
    "\n",
    "            imgs = f[k][:]\n",
    "            cycles.append(cycle)\n",
    "            channels.append(channel)\n",
    "            imgs[0] = contrast_str(imgs[0])\n",
    "            imgs_all.append(imgs)\n",
    "    \n",
    "    imgs_same_shape = make_imgs_same_dim(imgs_all)\n",
    "    \n",
    "    for i, imgs in enumerate(imgs_same_shape):\n",
    "        temp_path = save_path / '_'.join(np.array(name).astype(str))\n",
    "        temp_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        file_name = f'001_{cycles[i]}.tif'\n",
    "        file_path = temp_path / file_name\n",
    "\n",
    "        # Write image\n",
    "        tiff.imwrite(file_path, imgs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ca337f-55e5-4644-8ebd-b8d640ed8a67",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Registration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe3d7770-318a-452e-8a66-31a813f59a93",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing jnius: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mashlar\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fileseries, thumbnail,reg\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mashlar\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscripts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mashlar\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m process_axis_flip\n",
      "File \u001b[1;32m\\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\thomas\\20_mousecoculturematrigel\\src\\ashlar-master\\ashlar\\fileseries.py:7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mskimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m reg\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Classes for reading datasets consisting of TIFF files with a naming pattern.\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# The pattern must include an integer series number, and optionally a channel\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# name or number, and well name.\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# This code is experimental and probably still has a lot of rough edges.\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_to_regex\u001b[39m(s):\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# Translate a restricted subset of the \"format\" pattern language to\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m# a matching regex with named capture.\u001b[39;00m\n",
      "File \u001b[1;32m\\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\thomas\\20_mousecoculturematrigel\\src\\ashlar-master\\ashlar\\reg.py:40\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;66;03m# These settings constrain the memory used by BioFormats to near the minimum\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;66;03m# possible working set without requiring the choice of a max heap size.\u001b[39;00m\n\u001b[0;32m     38\u001b[0m     jnius_config\u001b[38;5;241m.\u001b[39madd_options(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-Xms10m\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-XX:+UseSerialGC\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjnius\u001b[39;00m\n\u001b[0;32m     42\u001b[0m JBoolean \u001b[38;5;241m=\u001b[39m jnius\u001b[38;5;241m.\u001b[39mautoclass(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjava.lang.Boolean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     43\u001b[0m DebugTools \u001b[38;5;241m=\u001b[39m jnius\u001b[38;5;241m.\u001b[39mautoclass(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloci.common.DebugTools\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\jnius\\__init__.py:12\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mPyjnius\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m=======\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03mAll the documentation is available at: http://pyjnius.readthedocs.org\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     10\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1.1.0\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjnius\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreflect\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# XXX monkey patch methods that cannot be in cython.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Cython doesn't allow to set new attribute on methods it compiled\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing jnius: The specified module could not be found."
     ]
    }
   ],
   "source": [
    "from ashlar import fileseries, thumbnail,reg\n",
    "import matplotlib.pyplot as plt\n",
    "from ashlar.scripts.ashlar import process_axis_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d25770be-a6ac-41d9-8525-5358201e2734",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47839fb5200d44db927c980b4760b6d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    assembling thumbnail 1/1\n",
      "    assembling thumbnail 1/1\n",
      "    estimated cycle offset [y x] = [0. 5.]\n",
      "    assembling thumbnail 1/1\n",
      "    estimated cycle offset [y x] = [  4. -15.]\n",
      "    assembling thumbnail 1/1\n",
      "    assembling thumbnail 1/1\n",
      "    estimated cycle offset [y x] = [-14.   2.]\n",
      "    assembling thumbnail 1/1\n",
      "    estimated cycle offset [y x] = [19.  1.]\n",
      "    assembling thumbnail 1/1\n",
      "    assembling thumbnail 1/1\n",
      "    estimated cycle offset [y x] = [-18. -24.]\n",
      "    assembling thumbnail 1/1\n",
      "    estimated cycle offset [y x] = [ 14. -17.]\n",
      "    assembling thumbnail 1/1\n",
      "    assembling thumbnail 1/1\n",
      "    estimated cycle offset [y x] = [-6. -6.]\n",
      "    assembling thumbnail 1/1\n",
      "    estimated cycle offset [y x] = [17. 11.]\n",
      "    assembling thumbnail 1/1\n",
      "    assembling thumbnail 1/1\n",
      "    estimated cycle offset [y x] = [  1. -22.]\n",
      "    assembling thumbnail 1/1\n",
      "    estimated cycle offset [y x] = [ 23. -25.]\n"
     ]
    }
   ],
   "source": [
    "# Loop all images\n",
    "imgs_dir = data_dir / 'sensitivity_v2' /'imgs' / 'raw'\n",
    "save_dir = data_dir / 'sensitivity_v2' /'imgs' / 'registered'\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "imgs_dir_list = os.listdir(imgs_dir)\n",
    "\n",
    "for dir_path in tqdm(imgs_dir_list):\n",
    "    \n",
    "    # Create reader for each cycle\n",
    "    readers = []\n",
    "    for i in range(1, 4):\n",
    "        reader = fileseries.FileSeriesReader(\n",
    "            str(imgs_dir / dir_path),\n",
    "            pattern='{series}_'+f'cycle{i}.tif',\n",
    "            overlap=0.29,\n",
    "            width=1,\n",
    "            height=1,\n",
    "            layout='snake',\n",
    "            direction='horizontal',\n",
    "            pixel_size=0.18872, \n",
    "        )\n",
    "        readers.append(reader)\n",
    "    reader_1 = readers[0]\n",
    "    \n",
    "    # Run stitching\n",
    "    aligner0 = reg.EdgeAligner(reader_1, channel=0, filter_sigma=2, verbose=False,)\n",
    "    aligner0.run()\n",
    "    \n",
    "    # Generate merge image for 1 cycle\n",
    "    # Parramter\n",
    "    mosaic_args = {}\n",
    "    mosaic_args['verbose'] = False\n",
    "\n",
    "    mosaic = reg.Mosaic(\n",
    "            aligner0,aligner0.mosaic_shape,**mosaic_args\n",
    "        )\n",
    "    writer_class = reg.TiffListWriter\n",
    "    writer = writer_class(\n",
    "            [mosaic], str(save_dir / (dir_path + '_cycle1_ch{channel}.ome.tif'))\n",
    "    )\n",
    "    writer.run()\n",
    "    \n",
    "    # Loop through rest of cycles\n",
    "    aligners = list()\n",
    "    aligners.append(aligner0)\n",
    "\n",
    "    for j in range(1, len(readers)):\n",
    "        aligners.append(\n",
    "            reg.LayerAligner(readers[j], aligners[0], channel=0, filter_sigma=2, verbose=False)\n",
    "        )\n",
    "        aligners[j].run()\n",
    "        mosaic = reg.Mosaic(\n",
    "            aligners[j], aligners[0].mosaic_shape,**mosaic_args\n",
    "        )\n",
    "        writer = writer_class(\n",
    "                [mosaic], str(save_dir / (dir_path +'_cycle'+str(j+1)+'_ch{channel}.ome.tif'))\n",
    "        )\n",
    "        writer.run()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95009bd1-e19c-4e13-b07a-79ef7493c5bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6a24a90-d410-447a-b3bf-caa63caf565a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(data_raw, marker_dict):\n",
    "    conditions = []\n",
    "    fovs = []\n",
    "    cycles = []\n",
    "    channels = []\n",
    "    markers = []\n",
    "    paths = [] \n",
    "\n",
    "    # Loop through image folder\n",
    "    for (dirpath, dirnames, filenames) in os.walk(data_raw):\n",
    "        for name in sorted(filenames):\n",
    "            if \"tif\" in name:\n",
    "                # Get information from image name\n",
    "                n_split = name.split('_')\n",
    "                                \n",
    "                cond=n_split[0]\n",
    "                fov=n_split[1]\n",
    "                cycle=n_split[2]\n",
    "                ch = n_split[3][:3]\n",
    "                try:\n",
    "                    marker = marker_dict[cycle][ch]\n",
    "                except:\n",
    "                    continue \n",
    "                    \n",
    "                conditions.append(cond)\n",
    "                fovs.append(fov)\n",
    "                cycles.append(cycle)\n",
    "                channels.append(ch)\n",
    "                markers.append(marker)\n",
    "                paths.append(os.path.join(dirpath, name))\n",
    "                \n",
    "    info = {\n",
    "            \"Condition\": conditions,\n",
    "            \"FOV\": fovs,\n",
    "            \"Cycle\": cycles,\n",
    "            \"Channels\": channels,\n",
    "            \"Markers\": markers,\n",
    "            \"Path\": paths\n",
    "        }\n",
    "\n",
    "    df = pd.DataFrame(info)\n",
    "    return df\n",
    "\n",
    "def joblib_loop(task, pics):\n",
    "    return Parallel(n_jobs=20)(delayed(task)(i) for i in pics)\n",
    "\n",
    "def read_img(path):\n",
    "    return skimage.io.imread(path, as_gray=True)\n",
    "\n",
    "def get_min(imgs):\n",
    "    shapes = np.array([np.array(img.shape) for img in imgs])\n",
    "    return np.min(shapes, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f670875-7c2c-411b-8bbb-aeb5b935feb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "markers_map_new = defaultdict(dict)\n",
    "for k,v in markers_map.items():\n",
    "    for i, (ch,marker) in enumerate(v.items()):\n",
    "        markers_map_new[k][f'ch{i}'] = marker\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2658bbac-0a84-452a-924f-7c5ff0896ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder is already there\n",
      "Created df\n"
     ]
    }
   ],
   "source": [
    "data_raw = data_dir  / 'sensitivity_v2' /'imgs' / 'registered'\n",
    "df_meta_path = data_dir /  'sensitivity_v2' / 'metadata' / 'info_sti.csv'\n",
    "\n",
    "try:\n",
    "    df_meta_path.parent.mkdir(parents=True, exist_ok=False)\n",
    "except FileExistsError:\n",
    "    print(\"Folder is already there\")\n",
    "\n",
    "df_exist = df_meta_path.is_file()\n",
    "\n",
    "if not df_exist:\n",
    "    print('Created df')\n",
    "    df = get_info(data_raw, markers_map_new)\n",
    "    df.to_csv(df_meta_path, index=False)\n",
    "else:\n",
    "    print('Loaded df')\n",
    "    df = pd.read_csv(df_meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "611b0cbb-5d66-428e-bf57-c27a1f7ca0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder is already there\n",
      "Loaded df\n"
     ]
    }
   ],
   "source": [
    "df_imgs_path = data_dir / 'sensitivity_v2' /'metadata' / 'imgs_reg.csv'\n",
    "\n",
    "temp_path =data_dir /  'sensitivity_v2' /'hdf5' / 'registered'\n",
    "try:\n",
    "    temp_path.mkdir(parents=True, exist_ok=False)\n",
    "except FileExistsError:\n",
    "    print(\"Folder is already there\")\n",
    "\n",
    "df_exist = df_imgs_path.is_file()\n",
    "\n",
    "if not df_exist:\n",
    "    print('Created df')\n",
    "    group = df.groupby(['Condition','FOV'])\n",
    "    rows = []\n",
    "\n",
    "    for name, df_group in tqdm(group, total=len(group)):\n",
    "        file_name = '_'.join(np.array(name).astype(str)) + '.hdf5'\n",
    "        file_path = temp_path / file_name\n",
    "        rows.append(list(name)+[file_path])\n",
    "        \n",
    "        # if file_path.exists():\n",
    "        #     continue\n",
    "        \n",
    "        channels = df_group.Channels.to_list()\n",
    "        cycles = df_group.Cycle.to_list()\n",
    "        markers = df_group.Markers.to_list()\n",
    "        paths = df_group.Path.to_numpy()\n",
    "            \n",
    "        imgs = joblib_loop(read_img, paths)\n",
    "        min_shape = get_min(imgs)\n",
    "        imgs_cropped = np.array([img[:min_shape[0], :min_shape[1]] for img in imgs])\n",
    "        info = {\"Cycle\": cycles, \"Channel\": channels, \"Marker\": markers}\n",
    "            \n",
    "            # hdf5 as Channel -> Z mapping\n",
    "        save_hdf5(file_path, 'imgs', imgs_cropped, info)\n",
    "    df_imgs = pd.DataFrame(rows, columns=['Condition', 'FOV', 'Path'])        \n",
    "    df_imgs.to_csv(df_imgs_path, index=False)\n",
    "else:\n",
    "    print('Loaded df')\n",
    "    df_imgs = pd.read_csv(df_imgs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfe4c831-5ba2-48d4-bec8-27d30352fde1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Condition</th>\n",
       "      <th>FOV</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100nM</td>\n",
       "      <td>C</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\sens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10nM</td>\n",
       "      <td>E</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\sens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25nM</td>\n",
       "      <td>D</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\sens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5nM</td>\n",
       "      <td>F</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\sens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Control</td>\n",
       "      <td>B</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\sens...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Condition FOV                                               Path\n",
       "0     100nM   C  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\sens...\n",
       "1      10nM   E  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\sens...\n",
       "2      25nM   D  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\sens...\n",
       "3       5nM   F  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\sens...\n",
       "4   Control   B  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\sens..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c696bf6b-881a-4f38-9afe-0665b8983b1f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95e70d52-fb83-42fb-8730-b8fe715de827",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.exposure import match_histograms, rescale_intensity\n",
    "import cv2\n",
    "from skimage import img_as_ubyte\n",
    "import tensorflow as tf \n",
    "from skimage import exposure, util, filters, restoration\n",
    "\n",
    "def random_crop(image, NEW_IMG_HEIGHT, NEW_IMG_WIDTH):\n",
    "    cropped_image = tf.image.random_crop(\n",
    "      image, size=[3, NEW_IMG_HEIGHT, NEW_IMG_WIDTH])\n",
    "\n",
    "    return cropped_image\n",
    "\n",
    "def make_color_overlay(input_data):\n",
    "    \"\"\"Create a color overlay from 2 channel image data\n",
    "    \n",
    "    Args:\n",
    "        input_data: stack of input images\n",
    "    \n",
    "    Returns:\n",
    "        numpy.array: color-adjusted stack of overlays in RGB mode\n",
    "    \"\"\"\n",
    "    RGB_data = np.zeros(input_data.shape[:3] + (3, ), dtype='float32')\n",
    "    \n",
    "    # rescale channels to aid plotting\n",
    "    for img in range(input_data.shape[0]):\n",
    "        for channel in range(input_data.shape[-1]):\n",
    "            # get histogram for non-zero pixels\n",
    "            percentiles = np.percentile(input_data[img, :, :, channel][input_data[img, :, :, channel] > 0],\n",
    "                                            [0, 100])\n",
    "            rescaled_intensity = rescale_intensity(input_data[img, :, :, channel],\n",
    "                                                       in_range=(percentiles[0], percentiles[1]),\n",
    "                                                       out_range='float32')\n",
    "            RGB_data[img, :, :, channel + 1] = rescaled_intensity\n",
    "        \n",
    "    # create a blank array for red channel\n",
    "    return RGB_data\n",
    "\n",
    "def contrast_str(img, n_min=10, n_max=100):\n",
    "    p2, p98 = np.percentile(img, (n_min, n_max))\n",
    "    img_rescale = rescale_intensity(img, in_range=(p2, p98))\n",
    "    img_rescale = util.img_as_ubyte(img_rescale)\n",
    "    return img_rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9446854a-4ef8-4ba9-8585-bff1706b25de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d596f148b94aee92c8c7aa88e238d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for row in tqdm(df_imgs.itertuples(), total=len(df_imgs)):\n",
    "    path = row.Path\n",
    "    \n",
    "    # Read images\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        \n",
    "        markers = f['imgs'].attrs['Marker']\n",
    "        imgs = f['imgs'][:]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51a31e45-a0df-4b8e-9a38-905bb871b1f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Viewer(axes=Axes(visible=False, labels=True, colored=True, dashed=False, arrows=True), camera=Camera(center=(0.0, 1734.0, 2320.0), zoom=0.3623090227731334, angles=(0.0, 0.0, 90.0), perspective=0.0, interactive=True), cursor=Cursor(position=(1.0, 1.0), scaled=True, size=1, style=<CursorStyle.STANDARD: 'standard'>), dims=Dims(ndim=2, ndisplay=2, last_used=0, range=((0.0, 3469.0, 1.0), (0.0, 4641.0, 1.0)), current_step=(1734, 2320), order=(0, 1), axis_labels=('0', '1')), grid=GridCanvas(stride=1, shape=(-1, -1), enabled=False), layers=[<Image layer 'DNA' at 0x21603017790>, <Image layer 'Sox2/Oct4' at 0x21600272200>, <Image layer 'p-P90rsk/NF-Kb' at 0x216030c3dc0>, <Image layer 'DNA [1]' at 0x2160c350f40>, <Image layer 'Cyclin D1/CDK4' at 0x2160c3bbfd0>, <Image layer 'Bim/Tom20' at 0x2160c4953f0>, <Image layer 'DNA [2]' at 0x2160c4f3e80>, <Image layer 'Concanavalin A' at 0x2160f291750>, <Image layer 'Phalloidin' at 0x2160f31c6d0>, <Image layer 'WGA' at 0x2162bed5ab0>], scale_bar=ScaleBar(visible=False, colored=False, color=array([1., 0., 1., 1.], dtype=float32), ticks=True, position=<Position.BOTTOM_RIGHT: 'bottom_right'>, font_size=10.0, box=False, box_color=array([0. , 0. , 0. , 0.6], dtype=float32), unit=None), text_overlay=TextOverlay(visible=False, color=array([0.5, 0.5, 0.5, 1. ], dtype=float32), font_size=10.0, position=<TextOverlayPosition.TOP_LEFT: 'top_left'>, text=''), overlays=Overlays(interaction_box=InteractionBox(points=None, show=False, show_handle=False, show_vertices=False, selection_box_drag=None, selection_box_final=None, transform_start=<napari.utils.transforms.transforms.Affine object at 0x000002160B762980>, transform_drag=<napari.utils.transforms.transforms.Affine object at 0x000002160B762920>, transform_final=<napari.utils.transforms.transforms.Affine object at 0x000002160B762C20>, transform=<napari.utils.transforms.transforms.Affine object at 0x000002160B762B90>, allow_new_selection=True, selected_vertex=None)), help='', status='Ready', tooltip=Tooltip(visible=False, text=''), theme='dark', title='napari', mouse_over_canvas=False, mouse_move_callbacks=[<function InteractionBoxMouseBindings.initialize_mouse_events.<locals>.mouse_move at 0x0000021600B55F30>], mouse_drag_callbacks=[<function InteractionBoxMouseBindings.initialize_mouse_events.<locals>.mouse_drag at 0x0000021600B563B0>], mouse_double_click_callbacks=[], mouse_wheel_callbacks=[<function dims_scroll at 0x000002163BDFB370>], _persisted_mouse_event={}, _mouse_drag_gen={}, _mouse_wheel_gen={}, keymap={'Shift': <function InteractionBoxMouseBindings.initialize_key_events.<locals>.hold_to_lock_aspect_ratio at 0x0000021600B56170>, 'Control-Shift-R': <function InteractionBoxMouseBindings._reset_active_layer_affine at 0x0000021600B56B00>, 'Control-Shift-A': <function InteractionBoxMouseBindings._transform_active_layer at 0x0000021600B56200>})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import napari \n",
    "\n",
    "napari.view_image(np.stack(imgs), name=markers, channel_axis=0, contrast_limits=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1b26d0d-440c-40c0-b4b8-ad37fb0a7057",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imgs['FOV'] = df_imgs['FOV'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2239577a-8244-48d5-aa50-58fe1d6620e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define markers to use for cytosolic segmentation\n",
    "cyto_markers = ['Concanavalin A', 'Phalloidin']\n",
    "\n",
    "# Define folder and create if don't exsit\n",
    "whole_seg_path = data_dir / 'sensitivity_v2' / 'imgs' / 'segmentation'\n",
    "whole_seg_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save combined images\n",
    "for row in df_imgs.itertuples():\n",
    "    # Read image\n",
    "    path = row.Path\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        imgs = f['imgs'][:]\n",
    "        markers = f['imgs'].attrs['Marker']\n",
    "\n",
    "    # Get dapi and cyto imgaes\n",
    "    indices = np.isin(markers, cyto_markers)\n",
    "    img_dapi = imgs[-4]\n",
    "    imgs_cyto = imgs[indices,:]\n",
    "    \n",
    "    # Contrast streching and combine to rgb image\n",
    "    img_dapi = contrast_str(img_dapi, n_max=99.99)\n",
    "        \n",
    "    imgs_cyto_scaled = []\n",
    "    for img in imgs_cyto:\n",
    "        imgs_cyto_scaled = [contrast_str(img, n_max=99.9)]\n",
    "    img_cyto = np.max(np.array(imgs_cyto_scaled), axis=0)\n",
    "    img_rgb = np.stack([np.zeros(img_dapi.shape),img_cyto, img_dapi], axis=0).astype(np.uint8)\n",
    "    \n",
    "    # Crop and save\n",
    "    file_name = f'{\"_\".join(row[1:3])}.tif'\n",
    "    file_path = whole_seg_path / file_name\n",
    "    tiff.imwrite(file_path, img_rgb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529f3b6d-a8c4-4fc2-9f3d-096cc1414a26",
   "metadata": {},
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4e9f88d-a917-4581-a1ca-860be119ddd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\cellpose\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> GPU activated? YES\n"
     ]
    }
   ],
   "source": [
    "from skimage import exposure, util\n",
    "from cellpose import core, utils, io, models, metrics\n",
    "\n",
    "use_GPU = core.use_gpu()\n",
    "yn = ['NO', 'YES']\n",
    "print(f'>>> GPU activated? {yn[use_GPU]}')\n",
    "\n",
    "def contrast_str(img, n_min=0.01, n_max=99.95):\n",
    "    p2, p98 = np.percentile(img, (n_min, n_max))\n",
    "    img_rescale = exposure.rescale_intensity(img, in_range=(p2, p98))\n",
    "    img_rescale = util.img_as_ubyte(img_rescale)\n",
    "    return img_rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04d7fce7-acc2-4ecd-bc27-7e3368996938",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_seg_path = data_dir / 'sensitivity_v2' / 'imgs' / 'segmentation'\n",
    "mask_path = data_dir  / 'sensitivity_v2' / 'imgs' / 'masks'\n",
    "\n",
    "mask_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4527ae5a-065c-4ef8-8bb2-ddadf1568931",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Could not find a backend to open `\\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\sensitivity_v2\\imgs\\segmentation\\Thumbs.db`` with iomode `r`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32my:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\03_1_processing_sens_v2.ipynb Cell 34\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/y%3A/coskun-lab/Thomas/23_PLA_revision/notebooks/03_1_processing_sens_v2.ipynb#X45sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m masks \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/y%3A/coskun-lab/Thomas/23_PLA_revision/notebooks/03_1_processing_sens_v2.ipynb#X45sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(whole_seg_path):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/y%3A/coskun-lab/Thomas/23_PLA_revision/notebooks/03_1_processing_sens_v2.ipynb#X45sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     img \u001b[39m=\u001b[39m skimage\u001b[39m.\u001b[39;49mio\u001b[39m.\u001b[39;49mimread(whole_seg_path \u001b[39m/\u001b[39;49m p)\u001b[39m.\u001b[39mtranspose((\u001b[39m2\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/y%3A/coskun-lab/Thomas/23_PLA_revision/notebooks/03_1_processing_sens_v2.ipynb#X45sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m# Cyto segmentation\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/y%3A/coskun-lab/Thomas/23_PLA_revision/notebooks/03_1_processing_sens_v2.ipynb#X45sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     model \u001b[39m=\u001b[39m models\u001b[39m.\u001b[39mCellposeModel(gpu\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, model_type\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCP\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\cellpose\\lib\\site-packages\\skimage\\io\\_io.py:53\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(fname, as_gray, plugin, **plugin_args)\u001b[0m\n\u001b[0;32m     50\u001b[0m         plugin \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtifffile\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     52\u001b[0m \u001b[39mwith\u001b[39;00m file_or_url_context(fname) \u001b[39mas\u001b[39;00m fname:\n\u001b[1;32m---> 53\u001b[0m     img \u001b[39m=\u001b[39m call_plugin(\u001b[39m'\u001b[39;49m\u001b[39mimread\u001b[39;49m\u001b[39m'\u001b[39;49m, fname, plugin\u001b[39m=\u001b[39;49mplugin, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mplugin_args)\n\u001b[0;32m     55\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(img, \u001b[39m'\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     56\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\cellpose\\lib\\site-packages\\skimage\\io\\manage_plugins.py:205\u001b[0m, in \u001b[0;36mcall_plugin\u001b[1;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m:\n\u001b[0;32m    203\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCould not find the plugin \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mplugin\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m for \u001b[39m\u001b[39m{\u001b[39;00mkind\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 205\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\cellpose\\lib\\site-packages\\skimage\\io\\_plugins\\imageio_plugin.py:11\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39m@wraps\u001b[39m(imageio_imread)\n\u001b[0;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimread\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m---> 11\u001b[0m     out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(imageio_imread(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n\u001b[0;32m     12\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m out\u001b[39m.\u001b[39mflags[\u001b[39m'\u001b[39m\u001b[39mWRITEABLE\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m     13\u001b[0m         out \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mcopy()\n",
      "File \u001b[1;32mc:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\cellpose\\lib\\site-packages\\imageio\\v3.py:53\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(uri, index, plugin, extension, format_hint, **kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m     call_kwargs[\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m index\n\u001b[1;32m---> 53\u001b[0m \u001b[39mwith\u001b[39;00m imopen(uri, \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mplugin_kwargs) \u001b[39mas\u001b[39;00m img_file:\n\u001b[0;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39masarray(img_file\u001b[39m.\u001b[39mread(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcall_kwargs))\n",
      "File \u001b[1;32mc:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\cellpose\\lib\\site-packages\\imageio\\core\\imopen.py:281\u001b[0m, in \u001b[0;36mimopen\u001b[1;34m(uri, io_mode, plugin, extension, format_hint, legacy_mode, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m         err_msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m    276\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mBased on the extension, the following plugins might add capable backends:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    277\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00minstall_candidates\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         )\n\u001b[0;32m    280\u001b[0m request\u001b[39m.\u001b[39mfinish()\n\u001b[1;32m--> 281\u001b[0m \u001b[39mraise\u001b[39;00m err_type(err_msg)\n",
      "\u001b[1;31mOSError\u001b[0m: Could not find a backend to open `\\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\sensitivity_v2\\imgs\\segmentation\\Thumbs.db`` with iomode `r`."
     ]
    }
   ],
   "source": [
    "# Cyto segmentaion\n",
    "masks = []\n",
    "for p in os.listdir(whole_seg_path):\n",
    "    img = skimage.io.imread(whole_seg_path / p).transpose((2,0,1))\n",
    "    \n",
    "    # Cyto segmentation\n",
    "    model = models.CellposeModel(gpu=True, model_type='CP')\n",
    "    mask_cyto, flows, styles = model.eval(img, \n",
    "                                  channels=[2,3],\n",
    "                                  diameter=250,\n",
    "                                  flow_threshold=0.8,\n",
    "                                  cellprob_threshold=-3\n",
    "                                  )\n",
    "    \n",
    "    file_path = mask_path / p\n",
    "    tiff.imwrite(file_path, mask_cyto)\n",
    "    \n",
    "    # Nuclei segemtnation\n",
    "    model = models.CellposeModel(gpu=True, model_type='nuclei')\n",
    "    mask_nuclei, flows, styles = model.eval(img, \n",
    "                                  channels=[3,3],\n",
    "                                  diameter=80,\n",
    "                                  flow_threshold=0.4,\n",
    "                                  )\n",
    "    \n",
    "        \n",
    "    file_path = mask_path / f'Nuclei_{p}'\n",
    "    tiff.imwrite(file_path, mask_nuclei)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a847c8-cf22-46be-a06a-929dcd265652",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
