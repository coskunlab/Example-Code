{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test torch geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import networkx as nx \n",
    "import pickle \n",
    "import torch_geometric \n",
    "\n",
    "data_dir = r'Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\graphs\\raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thu71\\Anaconda3\\envs\\snowflake\\lib\\site-packages\\torch_geometric\\utils\\convert.py:192: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:204.)\n",
      "  data[key] = torch.tensor(value)\n"
     ]
    }
   ],
   "source": [
    "for f in os.listdir(data_dir):\n",
    "    with open(os.path.join(data_dir, f), 'rb') as file:\n",
    "        G = pickle.load(file)\n",
    "    data = torch_geometric.utils.from_networkx(G)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.io\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import re\n",
    "import tifffile as tiff\n",
    "import pickle\n",
    "\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.utils\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_dir = (Path().cwd().parents[0]).absolute()\n",
    "\n",
    "module_path = str(p_dir / \"src\")\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = (Path().cwd().parents[0] / 'data').absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning.pytorch as pl\n",
    "import PPIGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Define condition mapping\n",
    "condition_mapping = {'HCC827Ctrl': 0, 'HCC827Osim': 1}\n",
    "\n",
    "# Load graph dataset and process if neede\n",
    "graph_path = data_dir / 'OCT Cell Culture' / 'Whole' / 'graphs' \n",
    "\n",
    "dataset = PPIGraph.GraphDataset(graph_path, 'raw', 'pt', condition_mapping=condition_mapping, n_c=2)\n",
    "train_set, val_set, test_set = PPIGraph.train_test_val_split(dataset)\n",
    "\n",
    "# Create Dataloader\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: GraphDataset(2064):\n",
      "======================\n",
      "Number of graphs: 2064\n",
      "Number of features: 5\n",
      "Number of classes: 2\n",
      "Train set: 992, test set: 825, val set: 247\n",
      "Step 1:\n",
      "=======\n",
      "Number of graphs in the current batch: 32\n",
      "DataBatch(edge_index=[2, 12318], pos=[2372, 2], labels=[2372, 5], nuclei=[2372], weight=[12318], condition=[32], fov=[32], id=[32], train_mask=[2372], test_mask=[2372], edge_attr=[12318, 2], x=[2372, 5], y=[32], edge_weight=[12318], name=[32], batch=[2372], ptr=[33])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print some information on the dataset\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('======================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "print(f'Train set: {len(train_set)}, test set: {len(test_set)}, val set: {len(val_set)}')\n",
    "for step, data in enumerate(train_loader):\n",
    "\n",
    "    print(f'Step {step + 1}:')\n",
    "    print('=======')\n",
    "    print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "    print(data)\n",
    "    print()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-fold on filter dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from lightning.pytorch.accelerators import find_usable_cuda_devices\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from torch.utils.data import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out by maximum number of counts per cell\n",
    "min_count = 20\n",
    "max_count = 70\n",
    "\n",
    "graph_path = data_dir / 'OCT Cell Culture' / 'Whole' / 'graphs' \n",
    "dataset = PPIGraph.GraphDataset(graph_path, 'raw', 'pt', condition_mapping=condition_mapping, n_c=2)\n",
    "\n",
    "# Create Dataloader\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Get Indices\n",
    "indices = []\n",
    "for step, data in enumerate(loader):\n",
    "    if len(data.x) <= min_count:\n",
    "        continue \n",
    "    \n",
    "    if (data.x.sum(axis=0) >= max_count).any():\n",
    "        continue\n",
    "    indices.append(step)\n",
    "    \n",
    "# Get subset dataset\n",
    "dataset_filtered = dataset.index_select(indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1522"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = '5PPI'\n",
    "condition = 'Kfold'\n",
    "checkpoint_folder = (Path().cwd().parents[0]).absolute() / 'data' /'OCT Cell Culture' / 'Whole' /\"saved_models\" / dataset_name / f\"Graph_GNNs_{condition}\" \n",
    "project_name = f'PLA_01102024_{dataset_name}_{condition}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "AVAIL_GPUS = [1]\n",
    "\n",
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "NUM_LAYERS = 2\n",
    "HIDDEN_CHANNELS = 16\n",
    "pools = ['mean', 'max', 'sum', 'attention', 'attention2']\n",
    "num_layers = [2,3,4]\n",
    "hiddens = [16, 32, 64]\n",
    "\n",
    "epochs = 50\n",
    "models = ['GINConv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_16_onehot_0\\mean\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_16_onehot_0\\max\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_16_onehot_0\\sum\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_16_onehot_0\\attention\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_16_onehot_0\\attention2\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_32_onehot_0\\mean\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_32_onehot_0\\max\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_32_onehot_0\\sum\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_32_onehot_0\\attention\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_32_onehot_0\\attention2\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_64_onehot_0\\mean\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_64_onehot_0\\max\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_64_onehot_0\\sum\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_64_onehot_0\\attention\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_64_onehot_0\\attention2\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_16_onehot_0\\mean\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_16_onehot_0\\max\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_16_onehot_0\\sum\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_16_onehot_0\\attention\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_16_onehot_0\\attention2\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_32_onehot_0\\mean\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_32_onehot_0\\max\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_32_onehot_0\\sum\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_32_onehot_0\\attention\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_32_onehot_0\\attention2\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_64_onehot_0\\mean\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_64_onehot_0\\max\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_64_onehot_0\\sum\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_64_onehot_0\\attention\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_64_onehot_0\\attention2\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_16_onehot_0\\mean\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_16_onehot_0\\max\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_16_onehot_0\\sum\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_16_onehot_0\\attention\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_16_onehot_0\\attention2\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_32_onehot_0\\mean\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_32_onehot_0\\max\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_32_onehot_0\\sum\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_32_onehot_0\\attention\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_32_onehot_0\\attention2\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_64_onehot_0\\mean\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_64_onehot_0\\max\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_64_onehot_0\\sum\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_64_onehot_0\\attention\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_64_onehot_0\\attention2\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_16_onehot_1\\mean\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_16_onehot_1\\max\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_16_onehot_1\\sum\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_16_onehot_1\\attention\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_16_onehot_1\\attention2\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_32_onehot_1\\mean\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_32_onehot_1\\max\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_32_onehot_1\\sum\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_32_onehot_1\\attention\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_32_onehot_1\\attention2\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_64_onehot_1\\mean\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_64_onehot_1\\max\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_64_onehot_1\\sum\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_64_onehot_1\\attention\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_64_onehot_1\\attention2\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_16_onehot_1\\mean\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_16_onehot_1\\max\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_16_onehot_1\\sum\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_16_onehot_1\\attention\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_16_onehot_1\\attention2\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_32_onehot_1\\mean\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_32_onehot_1\\max\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_32_onehot_1\\sum\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_32_onehot_1\\attention\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_32_onehot_1\\attention2\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_64_onehot_1\\mean\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_64_onehot_1\\max\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_64_onehot_1\\sum\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_64_onehot_1\\attention\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_64_onehot_1\\attention2\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_16_onehot_1\\mean\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_16_onehot_1\\max\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_16_onehot_1\\sum\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_16_onehot_1\\attention\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_16_onehot_1\\attention2\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_32_onehot_1\\mean\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_32_onehot_1\\max\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_32_onehot_1\\sum\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_32_onehot_1\\attention\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_32_onehot_1\\attention2\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_64_onehot_1\\mean\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_64_onehot_1\\max\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_64_onehot_1\\sum\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_64_onehot_1\\attention\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_64_onehot_1\\attention2\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_16_onehot_2\\mean\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_16_onehot_2\\max\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_16_onehot_2\\sum\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_16_onehot_2\\attention\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_16_onehot_2\\attention2\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_32_onehot_2\\mean\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_32_onehot_2\\max\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_32_onehot_2\\sum\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_32_onehot_2\\attention\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_32_onehot_2\\attention2\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_64_onehot_2\\mean\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_64_onehot_2\\max\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_64_onehot_2\\sum\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_64_onehot_2\\attention\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_64_onehot_2\\attention2\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_16_onehot_2\\mean\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_16_onehot_2\\max\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_16_onehot_2\\sum\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_16_onehot_2\\attention\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_16_onehot_2\\attention2\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_32_onehot_2\\mean\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_32_onehot_2\\max\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_32_onehot_2\\sum\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_32_onehot_2\\attention\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_32_onehot_2\\attention2\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_64_onehot_2\\mean\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_64_onehot_2\\max\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_64_onehot_2\\sum\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_64_onehot_2\\attention\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_3_64_onehot_2\\attention2\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_16_onehot_2\\mean\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_16_onehot_2\\max\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_16_onehot_2\\sum\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_16_onehot_2\\attention\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_16_onehot_2\\attention2\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_32_onehot_2\\mean\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_32_onehot_2\\max\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_32_onehot_2\\sum\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_32_onehot_2\\attention\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_32_onehot_2\\attention2\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_64_onehot_2\\mean\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_64_onehot_2\\max\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_64_onehot_2\\sum\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_64_onehot_2\\attention\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_4_64_onehot_2\\attention2\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_16_onehot_3\\mean\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_16_onehot_3\\max\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_16_onehot_3\\sum\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_16_onehot_3\\attention\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_16_onehot_3\\attention2\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_32_onehot_3\\mean\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_32_onehot_3\\max\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_32_onehot_3\\sum\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_32_onehot_3\\attention\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_32_onehot_3\\attention2\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_64_onehot_3\\mean\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n",
      "y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\OCT Cell Culture\\Whole\\saved_models\\5PPI\\Graph_GNNs_Kfold\\GINConv_2_64_onehot_3\\max\\GraphLevelGINConv\\GraphLevelGINConv.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mthoomas\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "964924ce8d1e431aa30f88ca226f8c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333330477276, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_102644-k1102qae</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/k1102qae' target=\"_blank\">GINConv_2_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/k1102qae' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/k1102qae</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\Anaconda3\\envs\\snowflake\\lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 13.2 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.4 K    Total params\n",
      "0.062     Total estimated model params size (MB)\n",
      "C:\\Users\\thu71\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:478: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\thu71\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\thu71\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightning\\pytorch\\utilities\\data.py:77: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "C:\\Users\\thu71\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\thu71\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:280: PossibleUserWarning: The number of training batches (5) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a6d4bae18be4917ba74bd309100fc4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▅▄▅▅▅▆▆▇▇▇▇▇▇██▇▇▇▇▇██▇██▇██▇█▇█▇▇█▇▇▇</td></tr><tr><td>train_auc</td><td>▅▆██▆▆▄▃▂▃▂▄▃▂▂▃▂▃▃▂▃▃▃▁▂▁▁▂▂▂▂▃▂▂▃▃▃▃▃▃</td></tr><tr><td>train_f1</td><td>▁▄▂▅▂▆▅▄▅▇▇▇▇▆▆█▇▇▇▆▆▇▇▇▇█▇▅▇█▅█▆█▆▅▇▇▆▇</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▆▁▆▄▇▇▇▇██▇▇███████▇▇██▇████████████████</td></tr><tr><td>val_auc</td><td>▃▆██▇▆▄▃▃▄▄▅▄▄▆▆▇█▇▇▇▇▇▅▄▄▂▃▅▁▃▆▅▅▃▆▄▆▅▅</td></tr><tr><td>val_f1</td><td>▁▄▇▆██▆▅█▇▇▇█▆██▇▇▆▅▆▆▆▄▇▆▅▆▇▅▆███▄▆▇▇▅▇</td></tr><tr><td>val_loss_epoch</td><td>▃█▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>▃█▃▄▁▁▂▁▁▁▂▂▁▂▁▁▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.73892</td></tr><tr><td>train_auc</td><td>0.54879</td></tr><tr><td>train_f1</td><td>0.63279</td></tr><tr><td>train_loss_epoch</td><td>0.52729</td></tr><tr><td>train_loss_step</td><td>0.54122</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.76645</td></tr><tr><td>val_auc</td><td>0.76781</td></tr><tr><td>val_f1</td><td>0.64677</td></tr><tr><td>val_loss_epoch</td><td>0.46748</td></tr><tr><td>val_loss_step</td><td>0.45023</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/k1102qae' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/k1102qae</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_102644-k1102qae\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7753a64b12f242b5b6cf9c71ae0247f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.017183333332650364, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_103959-dwr8xi31</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/dwr8xi31' target=\"_blank\">GINConv_2_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/dwr8xi31' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/dwr8xi31</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\Anaconda3\\envs\\snowflake\\lib\\site-packages\\torch_geometric\\deprecation.py:12: UserWarning: 'nn.glob.GlobalAttention' is deprecated, use 'nn.aggr.AttentionalAggregation' instead\n",
      "  warnings.warn(out)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 13.2 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "15.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.5 K    Total params\n",
      "0.062     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7e075c310924b52b01396509f0fd818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▅▆▇▆▆▆▇▇▇▆▇▆▇▇▇▇▆▇▇█▇▆▆▅▇█▇▇▇▇▇▇▇█▇▇▇</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇▇▇████████</td></tr><tr><td>train_f1</td><td>▁▇▇▅▇▇▇▇▇▇▇▇▆▇▇▆▇▇▇▇█▇███▅█▇█▇█▆▇▇█▇██▇█</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▃▃▃▂▂▃▃▃▃▃▃▂▂▃▃▂▂▂▂▂▄▄▃▁▂▂▂▁▂▁▂▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>▇▄▃▇▇▁█▃▄▅▄▄▆▄▂▂▇▂▂▄▃▅▁█▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▃▆▇██▇█▇███▇▇█▇██▇███▇▇██▇█▇▇██▇███▇▇▇▇</td></tr><tr><td>val_auc</td><td>▁▄▃▄▅▅▃▇▅█▅▇▆▄▅▅▇▄▃▄▆▆▆▄▄▅▅▇▄▅▇▅▄▆▅▅▅▅▅▁</td></tr><tr><td>val_f1</td><td>▁▂▆▆▇▆▄▆▆▅▄▄▆▃▄▃▅▅▃▄▆▃▅▂▁▅▆█▂▂▅▄▃▄▁▄▄▂▂▄</td></tr><tr><td>val_loss_epoch</td><td>██▄▃▄▂▂▂▂▂▂▂▂▄▃▂▂▃▃▂▃▂▂▃▂▃▃▃▂▃▂▂▂▁▃▂▂▃▂▃</td></tr><tr><td>val_loss_step</td><td>█▇▅▄▃▃▃▃▄▃▃▃▄▇▄▄▃▄▄▃▃▃▂▃▃▄▃▃▃▄▃▃▃▁▃▃▃▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.74877</td></tr><tr><td>train_auc</td><td>0.81722</td></tr><tr><td>train_f1</td><td>0.66075</td></tr><tr><td>train_loss_epoch</td><td>0.50577</td></tr><tr><td>train_loss_step</td><td>0.54284</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.75658</td></tr><tr><td>val_auc</td><td>0.82737</td></tr><tr><td>val_f1</td><td>0.63366</td></tr><tr><td>val_loss_epoch</td><td>0.49418</td></tr><tr><td>val_loss_step</td><td>0.5149</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/dwr8xi31' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/dwr8xi31</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_103959-dwr8xi31\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "122daed9733a43e5a812d68ef3b254be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666495924, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_105532-q0gltmiw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/q0gltmiw' target=\"_blank\">GINConv_2_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/q0gltmiw' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/q0gltmiw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 13.2 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "19.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "19.6 K    Total params\n",
      "0.078     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a94783756d4f48b13cba0ce9d0c78f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▇▇▆▆▆█▇▆▇▇▇▇▇▇█▇▇▇▇▇▇▇███▇▇██▇▇█▇████</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇██▇▇▇▇▇█▇██████</td></tr><tr><td>train_f1</td><td>▁▇▇▇▇▇▇▇█▇▇▇▇▇█▇▇▇█▇▇▇▇▇▇▇█▇▇▇█▇█▇█▇████</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▃▄▃▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>▇▆▄▅▄█▇▇▆▃▂█▅▄▃▁▆▄▅▅▅▄█▂▆</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▁▄▇██▇███▇████████████████▇█▇▇███▇▇█▇▇▇</td></tr><tr><td>val_auc</td><td>▁▃▃▅▃▅▂▅▆▃▅█▅▄▆▆▆▇▆▅▇▆▇▇▇▆▇▁▆▅▅▆▆▆▃▅▄▄▅▂</td></tr><tr><td>val_f1</td><td>▂▂▄▇▄▄▁▅▄▅▇█▂▄▆▅▄▆▆▅▇▅▆▄▃█▆▂▆▇▇▆▇▅▃▄▅▃▅▇</td></tr><tr><td>val_loss_epoch</td><td>▇█▆▄▁▃▂▂▁▃▄▃▂▂▂▁▁▂▂▂▁▁▃▃▁▃▂▂▂▃▃▃▃▂▁▁▃▂▁▂</td></tr><tr><td>val_loss_step</td><td>▆█▅▄▂▂▃▁▂▂▄▄▂▂▃▂▂▂▂▂▃▁▃▂▂▃▂▂▂▄▂▂▃▂▂▂▄▃▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.75205</td></tr><tr><td>train_auc</td><td>0.81379</td></tr><tr><td>train_f1</td><td>0.65837</td></tr><tr><td>train_loss_epoch</td><td>0.5083</td></tr><tr><td>train_loss_step</td><td>0.54593</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.74671</td></tr><tr><td>val_auc</td><td>0.82674</td></tr><tr><td>val_f1</td><td>0.67782</td></tr><tr><td>val_loss_epoch</td><td>0.50268</td></tr><tr><td>val_loss_step</td><td>0.49713</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/q0gltmiw' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/q0gltmiw</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_105532-q0gltmiw\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "817a47a4787f47f28a07b82406498cf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333330477276, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_111420-mlbw5o4a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/mlbw5o4a' target=\"_blank\">GINConv_3_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/mlbw5o4a' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/mlbw5o4a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.6 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cc2591d15114b3a85ac22dde42175b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▅▆▇▇▇▆▇▇▇▇▇█▇▇▇▇▇▇▇█▇█▇▇▇█▇█▇███▇███▇</td></tr><tr><td>train_auc</td><td>▁▃▄▆▆▇▇▇▇▇▇▇█▇▇▇█▇█▇█▇█▇█▇█████▇▇██████▇</td></tr><tr><td>train_f1</td><td>▃▁▂▅▆▇▇▇▇▇█▇▇▇▇▇▇█▇█▇████▇█▇█▇██████████</td></tr><tr><td>train_loss_epoch</td><td>█▇▆▄▃▃▃▂▂▂▂▂▂▂▂▂▁▂▁▂▂▂▁▂▂▁▂▁▁▁▂▁▁▂▂▁▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▃▆▁▄▅▅▅▁▃▄▆▁▂▃▄▁▄▅▃▃▃▄▆▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▁▃▅▆▇▆▅▆▆▆▆▆▇▇▆▇▆▆▇▇▇▇▆██▇▇▆▇▇▇▇▇▇█▇▇█▆</td></tr><tr><td>val_auc</td><td>▁▄▃▅▆▄▄▄▆▅▆▇▆▇▇▅█▇▇█▇▆▇▆██▇█▇▇▆▇▇▇▆▇▇▇▇▇</td></tr><tr><td>val_f1</td><td>▁▁▄▆▇▇▇▆▇▇▇▇█████▇▇▇▇▇▇▇██▇▇██▇▇██▇▇█▇██</td></tr><tr><td>val_loss_epoch</td><td>█▇▇▄▃▂▂▃▃▁▄▄▄▃▆▄▂▃▃▂▃▂▂▃▃▃▃▃▃▂▂▃▃▂▂▂▃▄▃▄</td></tr><tr><td>val_loss_step</td><td>▇▆▆▂▂▃▂▂▂▃▅▅▃▃█▃▃▃▂▂▂▁▁▃▂▄▂▂▃▁▂▂▃▁▃▃▃▅▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.72824</td></tr><tr><td>train_auc</td><td>0.76962</td></tr><tr><td>train_f1</td><td>0.61645</td></tr><tr><td>train_loss_epoch</td><td>0.54868</td></tr><tr><td>train_loss_step</td><td>0.55029</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.75987</td></tr><tr><td>val_auc</td><td>0.83601</td></tr><tr><td>val_f1</td><td>0.66968</td></tr><tr><td>val_loss_epoch</td><td>0.51754</td></tr><tr><td>val_loss_step</td><td>0.54573</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/mlbw5o4a' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/mlbw5o4a</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_111420-mlbw5o4a\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0690d2c84d0463590a757ed535840c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_112801-oni0noih</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/oni0noih' target=\"_blank\">GINConv_3_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/oni0noih' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/oni0noih</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.6 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e49c7bebb8d4c3fa12eed7daaa3a928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇████████▇▇</td></tr><tr><td>train_auc</td><td>▁▁▂▃▃▄▅▅▅▅▆▅▅▆▅▅▆▆▆▆▇▅▆▆▇▇▇▇▇▇▇▇▇███▇▇▇▇</td></tr><tr><td>train_f1</td><td>▆▂▁▁▂▃▄▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇██████▇▇█▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▁▁▁▂▁▁▁▂▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▆▃▅▅▆▅▂▃▄▄▂▂▃▄▁▁▂▃▃▂▅▆▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▁▁▁▃▄▆▆▅▆▅▆▄▄▄▅▆▆▆▄▆▇█▆▇▆▅▅▅▅▅▅▅▅▆▅▆▇▅▆</td></tr><tr><td>val_auc</td><td>▁▆▇▇▅▇▇▇▇▇██▇▇███▇▇██████████▇██▇██▇██▇█</td></tr><tr><td>val_f1</td><td>▁▁▁▁▃▄▆▆▅▇▆▅▆▆▆▇█▇▇▆▇▇█▇▇▇▇▆▆▆▆▆▆▆▆▆▇▇▆▇</td></tr><tr><td>val_loss_epoch</td><td>███▆▆▄▃▃▃▁▄▄▄▃▅▄▂▂▃▂▃▃▂▂▃▃▃▂▂▂▁▃▃▂▂▂▂▄▃▃</td></tr><tr><td>val_loss_step</td><td>███▅▅▅▃▂▃▃▆▅▂▂▇▃▂▁▄▂▂▃▂▂▁▄▂▂▂▁▂▂▃▁▂▂▃▅▂▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.69622</td></tr><tr><td>train_auc</td><td>0.71349</td></tr><tr><td>train_f1</td><td>0.55314</td></tr><tr><td>train_loss_epoch</td><td>0.56813</td></tr><tr><td>train_loss_step</td><td>0.54627</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.75</td></tr><tr><td>val_auc</td><td>0.81423</td></tr><tr><td>val_f1</td><td>0.60825</td></tr><tr><td>val_loss_epoch</td><td>0.54389</td></tr><tr><td>val_loss_step</td><td>0.58278</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/oni0noih' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/oni0noih</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_112801-oni0noih\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7537a25f8ca74233829d266d6ab1231c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_114358-qn2njg9k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/qn2njg9k' target=\"_blank\">GINConv_3_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/qn2njg9k' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/qn2njg9k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.6 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f96a3000b34f93969df743bf0a825a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▃▃▄▅▅▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇█▇▇▇██▇████▇█▇██▇█</td></tr><tr><td>train_auc</td><td>▁▄▃▄▃▃▄▄▅▅▅▅▆▅▆▅▇▆█▇▇▇▇▇▇█▇█▇█▇█▇██▇████</td></tr><tr><td>train_f1</td><td>▁▄▄▄▂▄▄▄▆▄▅▄▅▅▅▇▆▆▆▆▆▇▇▆▆▇█▇▇▇▇█▇▆▇▆██▆▇</td></tr><tr><td>train_loss_epoch</td><td>█▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▂▆▇▇▇▇▇████████████████████████████████</td></tr><tr><td>val_auc</td><td>▄▅▁▁▄▅▆▇▇▇██████████████████████████████</td></tr><tr><td>val_f1</td><td>▃▄█▇▃▁▁▁▄▅▆▅▆██▇▇█▇▇███▇▇▇▇▆▆▇█▆█▇▇▆▇▇█▇</td></tr><tr><td>val_loss_epoch</td><td>█▅▂▂▁▁▁▁▁▁▂▂▁▂▂▂▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▂▂▁▁</td></tr><tr><td>val_loss_step</td><td>█▄▂▂▂▂▁▂▂▂▂▂▂▂▃▂▂▂▂▂▂▁▂▂▂▃▂▂▁▁▂▂▂▂▂▂▂▃▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.7225</td></tr><tr><td>train_auc</td><td>0.72771</td></tr><tr><td>train_f1</td><td>0.57215</td></tr><tr><td>train_loss_epoch</td><td>0.54177</td></tr><tr><td>train_loss_step</td><td>0.51601</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.77632</td></tr><tr><td>val_auc</td><td>0.84331</td></tr><tr><td>val_f1</td><td>0.63441</td></tr><tr><td>val_loss_epoch</td><td>0.5003</td></tr><tr><td>val_loss_step</td><td>0.52297</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/qn2njg9k' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/qn2njg9k</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_114358-qn2njg9k\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89eb2272f71d488eababedbb73f83bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_120306-nxorn0ls</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/nxorn0ls' target=\"_blank\">GINConv_3_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/nxorn0ls' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/nxorn0ls</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.6 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f52d4f1df78457e9af80c9af624cf4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▅▆▆▆▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇█▇▇▇▇███▇█▇▇██▇█▇</td></tr><tr><td>train_auc</td><td>▁▄▅▆▇▆▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇▇▇▇██▇████▇███████</td></tr><tr><td>train_f1</td><td>▃▁▃▆▇▇▇▇▇▇▇▇█▇▇██▇▇█▇███▇▇█▇▇█████▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▇▅▄▄▃▃▂▃▃▂▃▃▂▂▂▂▂▂▂▂▃▂▂▂▂▂▂▂▁▂▂▂▂▁▂▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>██▄▅▅▄▇▅▄▆▄▆▄▄▁▅▄▄▅▂█▅▄▂▆</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▁▄▅▅▄▄▅▆▆▆▆▇▆▇▇▇▇▅▇▆▇▇▆█▇▇▇▇▇▇▇▆▆▇▇█▇▇▇</td></tr><tr><td>val_auc</td><td>▁▁▄▄▆▄▄▆▆▆▇▆▇▆▇██▇▅▇█▇█▇██▇▆███▇▆▅▇▇████</td></tr><tr><td>val_f1</td><td>▁▁▄▅▆▅▅▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇██▇▇▇████▇▇▇▇███▇</td></tr><tr><td>val_loss_epoch</td><td>█▇▇▄▂▄▃▃▄▂▂▁▂▃▂▃▃▃▃▂▁▃▃▃▃▃▃▃▄▄▃▃▂▄▂▂▅▃▂▃</td></tr><tr><td>val_loss_step</td><td>██▇▄▄▄▂▄▂▃▂▁▄▅▂▃▃▄▄▂▃▄▄▃▃▄▃▃▅▆▃▃▃▅▃▃█▄▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.72906</td></tr><tr><td>train_auc</td><td>0.78588</td></tr><tr><td>train_f1</td><td>0.60621</td></tr><tr><td>train_loss_epoch</td><td>0.54813</td></tr><tr><td>train_loss_step</td><td>0.59311</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.76645</td></tr><tr><td>val_auc</td><td>0.83471</td></tr><tr><td>val_f1</td><td>0.5848</td></tr><tr><td>val_loss_epoch</td><td>0.50522</td></tr><tr><td>val_loss_step</td><td>0.54581</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/nxorn0ls' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/nxorn0ls</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_120306-nxorn0ls\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5adf944ee3f4023ace4416a5109ced3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_122205-s7fcbtl9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/s7fcbtl9' target=\"_blank\">GINConv_3_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/s7fcbtl9' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/s7fcbtl9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.6 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "2.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd88b10cbc0b488ab7ed194cdd760583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▃▆▆▆▇▇▇▇▇▇▇▇█▇▇▇▇██▇▇████▇█▇▇▇▇▇▇▇█▇██</td></tr><tr><td>train_auc</td><td>▁▃▅▆▆▇▇▇▇▇█▇█▇▇▇▇████████▇███▇██████████</td></tr><tr><td>train_f1</td><td>▃▁▁▅▇▆▇▇▇▇▇▇▇▇█▇▇█████▇▇██▇██▇▇▇▇██▇████</td></tr><tr><td>train_loss_epoch</td><td>█▇▆▄▄▃▃▃▂▃▂▂▂▂▂▃▂▁▁▂▁▁▂▁▂▂▁▁▂▂▁▂▁▁▁▁▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▃▄▅▄▂▆▁▂▅▁▄▃▅▄▃▁▂▃▄▂▂▃▁▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▁▁▅▆▆▆▆▆▇▇▇▆▇▇▇▇▆▇▇▇▇██▇▇█▇▇█▇▇▇▇▇█▇▇█▇</td></tr><tr><td>val_auc</td><td>▁▄▄▇▅▆▆▆▇▇▇▇▇█▇█▆▆▇██▇██▇█████▇▇▇▆█▇███▇</td></tr><tr><td>val_f1</td><td>▁▁▂▅▆▇▇▇▆▇▇█▇█▇▇▇▇██▇▇▇▇▇▇██▇█▇▇▇▇▇█████</td></tr><tr><td>val_loss_epoch</td><td>█▇▆▄▃▄▂▂▁▂▁▁▃▂▃▂▃▂▃▂▂▃▂▃▃▃▄▂▂▁▂▂▂▁▂▂▂▃▂▃</td></tr><tr><td>val_loss_step</td><td>█▇▆▅▃▂▂▃▃▃▁▁▃▃▃▃▃▃▄▃▃▅▂▃▃▅▄▃▂▁▃▃▃▂▃▃▃▃▃▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.73399</td></tr><tr><td>train_auc</td><td>0.78443</td></tr><tr><td>train_f1</td><td>0.62061</td></tr><tr><td>train_loss_epoch</td><td>0.54503</td></tr><tr><td>train_loss_step</td><td>0.57868</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.77303</td></tr><tr><td>val_auc</td><td>0.83534</td></tr><tr><td>val_f1</td><td>0.65327</td></tr><tr><td>val_loss_epoch</td><td>0.52333</td></tr><tr><td>val_loss_step</td><td>0.5781</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/s7fcbtl9' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/s7fcbtl9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_122205-s7fcbtl9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec02b931c914d7e8e17b9e635319735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_124045-xqc1rv6j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/xqc1rv6j' target=\"_blank\">GINConv_3_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/xqc1rv6j' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/xqc1rv6j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 5.8 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "6.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.4 K     Total params\n",
      "0.025     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "402dd39358ba4983b84923eb40917b60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇█▇█▇▇▇▇▇█</td></tr><tr><td>train_auc</td><td>▁▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█████▇▇█████████</td></tr><tr><td>train_f1</td><td>▁▁▆▇▇▇▇▇██▇█▇▇▇▇▇▇▇▇▇██▇██▇██▇██████████</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▄▃▃▃▃▂▃▃▃▂▂▃▂▂▂▂▂▂▂▂▂▂▁▂▂▁▂▂▁▂▁▂▂▂▂▂▁</td></tr><tr><td>train_loss_step</td><td>▆▇▇▅▅▆▂▄▄▄▇▃▁▂▅▁▆▃▂▂▅▄█▂▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▄▆▃▁▄▇▇███▇█▆██▇▇▇▇▇▇▇▇▇▇▇▇▆▆▇▇█▆▇▇▇▇█▇▇</td></tr><tr><td>val_auc</td><td>▁▇▆▇█▇▇██████▇▇▇▇▇▇▇▇▇███▇▇▇▇▇▇▇▇▇▇▇▇██▇</td></tr><tr><td>val_f1</td><td>▁█▇▇▇█▇██▇▇█▆▇██▇▇▇▇▇▇▇███▇▇█▇▇▇▇▇██▇██▇</td></tr><tr><td>val_loss_epoch</td><td>▆▅▅█▄▃▁▃▁▂▂▁▂▃▂▂▂▃▂▂▃▂▂▂▂▁▂▂▃▁▂▂▂▂▁▂▂▃▃▂</td></tr><tr><td>val_loss_step</td><td>▆▅▆█▄▂▂▄▃▂▃▁▂▅▂▂▂▅▃▂▂▂▂▃▃▂▃▃▄▁▂▂▄▃▃▃▂▄▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.75862</td></tr><tr><td>train_auc</td><td>0.81791</td></tr><tr><td>train_f1</td><td>0.66284</td></tr><tr><td>train_loss_epoch</td><td>0.50992</td></tr><tr><td>train_loss_step</td><td>0.52557</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.75329</td></tr><tr><td>val_auc</td><td>0.82341</td></tr><tr><td>val_f1</td><td>0.65116</td></tr><tr><td>val_loss_epoch</td><td>0.48045</td></tr><tr><td>val_loss_step</td><td>0.46326</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/xqc1rv6j' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/xqc1rv6j</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_124045-xqc1rv6j\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e6dcc23ff29429996a0b8f0b2a6fce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_125735-ze2zlghf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/ze2zlghf' target=\"_blank\">GINConv_3_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/ze2zlghf' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/ze2zlghf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 5.8 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "6.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.4 K     Total params\n",
      "0.025     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4c72649e57545e68021927b8f8d38c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▄▅▅▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▆▇▆▇▇▇▇▇█▇▇</td></tr><tr><td>train_auc</td><td>▁▃▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████▇█</td></tr><tr><td>train_f1</td><td>▃▁▃▄▆▆▆▇▇▆▆▇▇▇▇▇██▇▇██▇▇▇▇▇▇▇▇▇▇█▇▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▅▅▄▄▄▃▃▃▃▃▃▃▂▃▃▂▂▂▃▂▃▂▂▃▂▂▃▃▂▂▂▂▂▂▁▂▂</td></tr><tr><td>train_loss_step</td><td>▆▆█▅▅▅▂▅▃▃▇▃▁▁▄▃▅▄▃▁▃▃▆▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▅▅▃▅▅▆▆▅▇▆▆▇▆▇▆▇█▇▇▅▅▅▆▅▆▅▇▆▇▇▆▆▄▇▇▇▇▆▇</td></tr><tr><td>val_auc</td><td>▁▅▆▅▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇████████▇█</td></tr><tr><td>val_f1</td><td>▁▅▇▇█████████▇▇▇██▇▇▆▆▆▇▆▇▆▇▇▇▇▆▆▄▇▇▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>██▇▅▅▅▃▅▃▃▃▁▃▄▂▃▂▄▂▂▅▂▃▃▂▂▃▃▃▁▃▃▃▄▂▂▁▃▂▂</td></tr><tr><td>val_loss_step</td><td>██▇▆▅▅▄▇▅▄▄▁▄▆▂▄▄▆▄▄▃▂▃▄▄▃▃▃▅▁▃▃▆▆▃▄▂▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.73481</td></tr><tr><td>train_auc</td><td>0.7905</td></tr><tr><td>train_f1</td><td>0.62045</td></tr><tr><td>train_loss_epoch</td><td>0.53288</td></tr><tr><td>train_loss_step</td><td>0.52393</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.75329</td></tr><tr><td>val_auc</td><td>0.81892</td></tr><tr><td>val_f1</td><td>0.5509</td></tr><tr><td>val_loss_epoch</td><td>0.50671</td></tr><tr><td>val_loss_step</td><td>0.52319</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/ze2zlghf' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/ze2zlghf</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_125735-ze2zlghf\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3afa83ce670842bc994b6579d92f3d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_130913-9issj72k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/9issj72k' target=\"_blank\">GINConv_3_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/9issj72k' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/9issj72k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 5.8 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "6.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.4 K     Total params\n",
      "0.025     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5935fe27278a419fb74e617a46c38107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▄▅▅▆▆▆▇▇▇▇▇██▇▇██████▇█████▇████▇▇▇▇█</td></tr><tr><td>train_auc</td><td>▃█▇▆▅▄▂▃▂▂▃▂▃▂▃▁▂▃▄▃▄▄▃▄▃▃▃▂▄▃▂▂▄▄▄▃▄▄▄▃</td></tr><tr><td>train_f1</td><td>▁▆▄▂▆▄▄▅▆▆▆▆▇▇▇▇▇▆█▇▇█▇▇▇▇▇▇█▇▆█▆█▇▆▇▆▇▆</td></tr><tr><td>train_loss_epoch</td><td>█▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▃▂▂▂▁▂▁▂▂▁▁▁▂▁▂▂▁▁▂▂▂▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▃▇▇▇▇▇▆▇▇▇▇▇▇▇██▇██▇▇▇▇█████▇██▇█▇████▇</td></tr><tr><td>val_auc</td><td>▇▇▆▆▃▂▂▂▁▂▂▂▂▂▁▂▁▂▄▃▂▃▂▂▃▄▄▂▃▂▂▃▂▇▇▆▆▇█▇</td></tr><tr><td>val_f1</td><td>▄▅▁▅▇▆▆▆▇▇▇▇▇▇▆▇▇▇▇▇▆▆▆▇▇▇█▇▇▇▇▇▆█▇▇▇▇█▇</td></tr><tr><td>val_loss_epoch</td><td>█▆▂▂▂▂▂▃▂▂▂▂▂▂▂▂▂▂▁▁▂▁▂▂▁▁▂▂▁▂▁▂▂▂▁▁▁▂▂▁</td></tr><tr><td>val_loss_step</td><td>█▅▃▂▂▂▂▃▂▂▂▁▂▃▂▂▂▃▁▂▁▁▂▂▂▁▂▂▂▂▁▂▂▂▂▂▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.73071</td></tr><tr><td>train_auc</td><td>0.48211</td></tr><tr><td>train_f1</td><td>0.56499</td></tr><tr><td>train_loss_epoch</td><td>0.53263</td></tr><tr><td>train_loss_step</td><td>0.52635</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.77303</td></tr><tr><td>val_auc</td><td>0.7469</td></tr><tr><td>val_f1</td><td>0.65327</td></tr><tr><td>val_loss_epoch</td><td>0.46832</td></tr><tr><td>val_loss_step</td><td>0.46285</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/9issj72k' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/9issj72k</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_130913-9issj72k\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67855c97daa4546b4422d696f128638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_132121-is5qrefd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/is5qrefd' target=\"_blank\">GINConv_3_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/is5qrefd' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/is5qrefd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 5.8 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "6.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.4 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80c2cb63fbcb4fcc864b12157fc56319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇███▇▇▇</td></tr><tr><td>train_auc</td><td>▁▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇█▇▇█████████▇█</td></tr><tr><td>train_f1</td><td>▁▁▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█▇▇█▇▇▇▇▇██▇████▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▂▂▂▂▁▁▁▁▁▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▄▆▃▂▁▄▃▄▄▄▄▃▅▄▅▃▅▃▂▂▃▄▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▄▃▁▇▅▇▇▇█▇▇▇▆▇▇▇▇▇▇█▇▇██▇▆▇▇▇▇▇▇██▇██▇▆█</td></tr><tr><td>val_auc</td><td>▁▆▇▆▇▇▇█▇▇▇▇▆▇▇▆▇▆▇▇▆▆▇▇▇▇██▇▇▇▇█▇▇▇▇▇▅▇</td></tr><tr><td>val_f1</td><td>▁▇▇███▇██▇██▇▇▇▇█▇▇█████▇███▇▇█████████▇</td></tr><tr><td>val_loss_epoch</td><td>▇▇█▃▄▂▂▃▂▁▂▃▂▃▂▁▂▃▁▂▄▂▂▂▄▄▂▃▃▃▃▂▂▃▃▂▃▃▄▃</td></tr><tr><td>val_loss_step</td><td>▆▆█▄▅▄▂▅▃▃▃▃▃▄▂▃▄▅▁▃▃▂▃▃▂▅▃▄▄▃▄▃▂▄▂▃▄▃▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.74631</td></tr><tr><td>train_auc</td><td>0.80665</td></tr><tr><td>train_f1</td><td>0.64028</td></tr><tr><td>train_loss_epoch</td><td>0.51615</td></tr><tr><td>train_loss_step</td><td>0.47588</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.77961</td></tr><tr><td>val_auc</td><td>0.82529</td></tr><tr><td>val_f1</td><td>0.63784</td></tr><tr><td>val_loss_epoch</td><td>0.51912</td></tr><tr><td>val_loss_step</td><td>0.56944</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/is5qrefd' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/is5qrefd</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_132121-is5qrefd\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16c962b839fd4f3088199d9056488593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333330477276, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_133805-p9is08v4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/p9is08v4' target=\"_blank\">GINConv_3_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/p9is08v4' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/p9is08v4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 5.8 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "7.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.4 K     Total params\n",
      "0.030     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "294afdd0d4b34d3098f2adcb44811c05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▆▆▆▆▇▆▇▆▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇█▇██████▇▇█████</td></tr><tr><td>train_auc</td><td>▁▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████████</td></tr><tr><td>train_f1</td><td>▁▂▇█▇▇▇▇█▇▇▇▇▇█▇██▇█▇▇▇▇██▇██████▇█████▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▃▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▂▂▂▂</td></tr><tr><td>train_loss_step</td><td>▆▃▅▄▃▄▄▃▄▃▅▃█▃▃▅▄▃▆▃▃▁▃▁▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▅▅▁▃▆█▇███▇██▇▇▇▇█▇▇▇▇▇▇▇█▇▇▇▇▇▇▇█▇▇▇▇▇▇</td></tr><tr><td>val_auc</td><td>▁▄▇▇▄█▇█████▇█▇▆▇▇▇▆▇▅▇▆▇▆▇▇▆▆▆▇▇▇▆▆▆▇▇▆</td></tr><tr><td>val_f1</td><td>▁▇▇▇▇█▇███▇▇▇▇█▇▇▇▇█▇▆▇█▇▆▇▇███▇██▇▇███▇</td></tr><tr><td>val_loss_epoch</td><td>▅▅█▆▃▂▂▂▃▃▂▁▂▂▃▃▂▂▁▂▂▁▂▂▁▂▂▂▃▂▃▁▂▂▃▃▃▃▃▂</td></tr><tr><td>val_loss_step</td><td>▅▅█▆▅▃▂▃▃▃▃▁▃▃▄▃▃▄▂▃▃▂▂▃▃▂▃▃▄▃▃▃▄▂▃▃▅▄▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.74631</td></tr><tr><td>train_auc</td><td>0.81222</td></tr><tr><td>train_f1</td><td>0.61993</td></tr><tr><td>train_loss_epoch</td><td>0.51884</td></tr><tr><td>train_loss_step</td><td>0.55746</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.75658</td></tr><tr><td>val_auc</td><td>0.81916</td></tr><tr><td>val_f1</td><td>0.63366</td></tr><tr><td>val_loss_epoch</td><td>0.47119</td></tr><tr><td>val_loss_step</td><td>0.43236</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/p9is08v4' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/p9is08v4</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_133805-p9is08v4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2e1731cf8c744c0ad836d8a7a8a93fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_135055-7jh1pfh5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/7jh1pfh5' target=\"_blank\">GINConv_3_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/7jh1pfh5' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/7jh1pfh5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 21.8 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "24.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.0 K    Total params\n",
      "0.096     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eca06fed6f5542f2a37abb4c370aa10d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▅▆▆▆▆▆▆▇▆▆▆▆▇▆▇▆▆▇▅▆▆▆▆▇▇▇▇▇██▇█▇▇█▇▇</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▆▆▆▆▇▇▆▇▆▇▆▇▇▆▇▆▆▇▆▇▇▇▇▇▇████▇███▇</td></tr><tr><td>train_f1</td><td>▁▇▆▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇▇▇▇▇▇▇█▇███████████</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▅▄▄▃▃▃▃▃▃▄▃▄▃▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▁▂▂▁▂▂▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▆▃▄▅▅▃▄▇▇▄▃▃▂▆▃▃▃▃▂▄▃▂▁▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▂▆████▇████████▇█▇▇█▇█▇▇▇████▇█▇▇▇▇▇▇▇▇</td></tr><tr><td>val_auc</td><td>▆▇█▇▇█▇▇▇█▇▇▆▇▇▆▅▆▄▄▄▃▆▆▄▃▅▆▅▅▆▆▃▄▁▁▆▃▄▂</td></tr><tr><td>val_f1</td><td>▂▃▇▇█▇▅▁▇█▇▇▅▅▆▆▇▆▃▃▇▇▇▄▇▇▄▅▇▇▅▆▄▅▄▄▇▆▅▁</td></tr><tr><td>val_loss_epoch</td><td>▇█▂▁▂▂▁▁▂▂▁▂▂▁▂▂▂▁▂▂▂▂▂▁▂▂▁▁▂▂▂▂▁▁▂▂▂▂▂▂</td></tr><tr><td>val_loss_step</td><td>▆█▂▂▂▂▂▂▂▂▁▃▂▂▃▂▃▂▃▃▃▂▂▂▂▃▂▂▃▃▂▂▁▂▂▂▂▃▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.75123</td></tr><tr><td>train_auc</td><td>0.81361</td></tr><tr><td>train_f1</td><td>0.65993</td></tr><tr><td>train_loss_epoch</td><td>0.50131</td></tr><tr><td>train_loss_step</td><td>0.53641</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.73026</td></tr><tr><td>val_auc</td><td>0.79998</td></tr><tr><td>val_f1</td><td>0.5</td></tr><tr><td>val_loss_epoch</td><td>0.53368</td></tr><tr><td>val_loss_step</td><td>0.5741</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/7jh1pfh5' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/7jh1pfh5</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_135055-7jh1pfh5\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "473553d1e38448a99e8823af6a229a80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_140649-zsmgpu1h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/zsmgpu1h' target=\"_blank\">GINConv_3_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/zsmgpu1h' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/zsmgpu1h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 21.8 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "24.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.0 K    Total params\n",
      "0.096     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ce87776d6c4fa38f06bc73df7a69a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▄▆▅▅▆▆▆▆▆▆▆▆▆▇▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▆▇▆▇█▇▇</td></tr><tr><td>train_auc</td><td>▁▄▄▄▅▅▆▆▆▆▆▆▆▆▆▆▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇█▇▇▇▇███▇</td></tr><tr><td>train_f1</td><td>▁▅▄▅▆▆▅▅▆▆▆▆▆▆▆▆▇▇▇▆▆▇▇▆▇▆▇▇▇▆▇▇▇▆▇▆▆█▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▅▄▄▄▃▄▃▃▃▃▃▃▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▁▂▂▂▂▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>▇▇▃▅▆▅▂▅█▇▃▄▆▁▅▂▂▃▂▂▄▄▂▁▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▂▆▇▇▇█▇▇▇██▇▇▇▇▇▇▇▇▇▇▇▇▇▇████▇▇███▇█▇▇█</td></tr><tr><td>val_auc</td><td>▁▅▆▆▆▆▆▆▇▆▇▇▇▆▇▇▆▇▆▆▆▇▇▆▇▇▇▇▆▇▆▆▇▇▇▆██▆▇</td></tr><tr><td>val_f1</td><td>▄▅▇▇█▅█▅▃▄▆▄▆▅▅▇▇▆▇▅▁▇▇▆▅▆▇▆▆▇▆▆▇▇▆▄█▇▂▆</td></tr><tr><td>val_loss_epoch</td><td>▇█▄▃▂▂▂▂▂▂▂▂▃▂▂▃▂▁▃▂▂▂▂▂▂▂▁▂▃▂▂▃▁▂▂▃▂▂▃▃</td></tr><tr><td>val_loss_step</td><td>▆█▃▃▃▃▃▂▃▃▂▃▂▃▃▃▃▁▄▃▃▂▂▃▃▂▃▂▅▃▂▂▂▃▃▃▃▄▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.73892</td></tr><tr><td>train_auc</td><td>0.81028</td></tr><tr><td>train_f1</td><td>0.65584</td></tr><tr><td>train_loss_epoch</td><td>0.50581</td></tr><tr><td>train_loss_step</td><td>0.53092</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.76316</td></tr><tr><td>val_auc</td><td>0.82196</td></tr><tr><td>val_f1</td><td>0.59091</td></tr><tr><td>val_loss_epoch</td><td>0.54301</td></tr><tr><td>val_loss_step</td><td>0.62376</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/zsmgpu1h' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/zsmgpu1h</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_140649-zsmgpu1h\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dda760964fd3460c9e2e0ebe74dae1c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_142448-orggxcea</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/orggxcea' target=\"_blank\">GINConv_3_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/orggxcea' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/orggxcea</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 21.8 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "24.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.0 K    Total params\n",
      "0.096     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dd278b6204d4cb4bb0e399e926e1396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▂▁▄▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇▇▇▇▇█▇▇▇▇██▇</td></tr><tr><td>train_auc</td><td>▁▆▂▁▃▃▃▃▄▅▅▆▆▆▆▆▇▆▆▅▆▆▇▇▇▇▆▇█▇▆▇█▇▇▇█▇██</td></tr><tr><td>train_f1</td><td>▁▆▂▁▄▄▃▄▆▄▅▆▆▅▅▆▆▇▇▆▆▆█▇▇▆▆▇▇▇▆▆▇▆█▆▇▇█▇</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▂▂▂▂▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▃▇▆▇▇█▇▇▇█████▇█████████████████▇████▇█</td></tr><tr><td>val_auc</td><td>▄▆▁▂▃▅▇▇▆▆▇▇▇▇█▇████▇▇▇█████████████████</td></tr><tr><td>val_f1</td><td>▁▃▃▆▆▇██▇▅▆█▅▅▆▆▇▇▆▆▅▇▇▆▆▇▇▇█▇▆▄▇▇▇▇██▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.75287</td></tr><tr><td>train_auc</td><td>0.7611</td></tr><tr><td>train_f1</td><td>0.64038</td></tr><tr><td>train_loss_epoch</td><td>0.50511</td></tr><tr><td>train_loss_step</td><td>0.53242</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.78289</td></tr><tr><td>val_auc</td><td>0.85507</td></tr><tr><td>val_f1</td><td>0.67961</td></tr><tr><td>val_loss_epoch</td><td>0.5028</td></tr><tr><td>val_loss_step</td><td>0.55562</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/orggxcea' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/orggxcea</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_142448-orggxcea\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72f0b374925b422a9fded96bba4d0fa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666495924, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_144551-0rxaspv3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/0rxaspv3' target=\"_blank\">GINConv_3_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/0rxaspv3' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/0rxaspv3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 21.8 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "24.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.0 K    Total params\n",
      "0.096     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f02d321cf6e64b7f985a41e6d22123d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▆▅▆▆▆▆▆▆▆▆▇▆▇▇▆▆▇▇▇▇▆▆▇▇▇▆▆▇▇▇▇█████</td></tr><tr><td>train_auc</td><td>▁▅▅▆▆▆▆▇▆▇▇▆▇▆▇▆▇▇▇▆▇▇▇▇▇▇█▇▇▇▇▇▇███████</td></tr><tr><td>train_f1</td><td>▁▇▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇█▆█▇█▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▄▅▄▄▄▃▃▃▃▃▃▃▃▃▃▃▂▃▃▂▂▂▂▃▂▁▂▂▃▃▂▂▂▁▂▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>▃▇▄▂▆▆▅█▆▄▄▂▃▄▁▄▆▅▆▃▆▃▃▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▁▃▇███▇██▇███▇███▇██▇███▇██▇█▇▇▇▇▇▇▇▇██</td></tr><tr><td>val_auc</td><td>▁▃▇█▇▇▇▆▆▇▇▇▇██▆█▆▅▇▇▇█▇▇▆▇▇▅▄▆▇▄▅▅▅▆▅▇▅</td></tr><tr><td>val_f1</td><td>▁▁▃█▅▇█▆▄▆▄▆▂▅▃▃▇▂▆▇▇▇█▅▅▅▅▅▅▃▃█▇▅▄▃▆▆▆▅</td></tr><tr><td>val_loss_epoch</td><td>▆█▅▂▂▂▂▂▂▂▁▂▂▂▁▁▂▂▂▁▂▂▂▁▂▁▁▂▁▁▁▁▂▁▂▂▂▁▁▂</td></tr><tr><td>val_loss_step</td><td>▅█▅▂▂▂▂▂▂▂▁▂▂▂▂▂▂▃▂▂▂▂▂▂▂▁▂▂▂▁▂▂▃▁▂▂▂▁▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.76437</td></tr><tr><td>train_auc</td><td>0.83061</td></tr><tr><td>train_f1</td><td>0.66433</td></tr><tr><td>train_loss_epoch</td><td>0.49117</td></tr><tr><td>train_loss_step</td><td>0.48562</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.77303</td></tr><tr><td>val_auc</td><td>0.81993</td></tr><tr><td>val_f1</td><td>0.63874</td></tr><tr><td>val_loss_epoch</td><td>0.52822</td></tr><tr><td>val_loss_step</td><td>0.59213</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/0rxaspv3' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/0rxaspv3</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_144551-0rxaspv3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "510e6c6e8b164468a46fd1beca7ecb76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.017183333332650364, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_150430-hn0trgp7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/hn0trgp7' target=\"_blank\">GINConv_3_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/hn0trgp7' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/hn0trgp7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 21.8 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "28.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "28.2 K    Total params\n",
      "0.113     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70161101c4f649129f335aec420cc545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▅▇▆▇▆▇▇▇▆▆▆▇▇▇▇▇▇▇▇▇▆▆▇▇▇▇▇▇█▇▇██▇▇█▆█</td></tr><tr><td>train_auc</td><td>▁▅▅▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██████▇█</td></tr><tr><td>train_f1</td><td>▁▇▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇██▇█▇▇▇▇█▇█▇██████▇█▇█</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▄▄▄▄▃▃▄▃▃▃▃▃▂▃▃▃▃▃▃▂▂▃▃▃▂▂▂▃▂▁▂▂▂▂▂▂</td></tr><tr><td>train_loss_step</td><td>▅▅▆▄▇▆▆▃▃▃▃▆█▅▂▅▆▃▃▄▁▂▂▃▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▃▆▆█▇██████▇▇▇███▇██▇██▇▇▇▇▇▇▇▇▇▇█▇▇▇▆▆</td></tr><tr><td>val_auc</td><td>▆▇▇▇▇▆█▇▇▇▇▇▃▇▅▆▆▆▇▇█▄▅▆▇▇▆▅▅▅▅▅▆▁▁▆▁▅▆▄</td></tr><tr><td>val_f1</td><td>▁▃▇▇▆▃▆▄▅▅▆▄▅▆▃▅▇▅▆▇█▂▄▇▇▆▆▄▃▁▅▆▂▂▃▃▇▇▆▆</td></tr><tr><td>val_loss_epoch</td><td>█▇▅▃▂▂▂▂▁▁▂▂▂▂▂▂▃▃▂▁▂▂▁▂▂▂▂▁▂▂▂▄▃▃▂▁▃▂▃▃</td></tr><tr><td>val_loss_step</td><td>██▆▂▂▂▃▃▃▂▂▃▃▂▂▃▂▄▁▂▂▂▁▃▃▁▃▂▂▃▃▂▆▅▂▂▃▁▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.75616</td></tr><tr><td>train_auc</td><td>0.82558</td></tr><tr><td>train_f1</td><td>0.65744</td></tr><tr><td>train_loss_epoch</td><td>0.49512</td></tr><tr><td>train_loss_step</td><td>0.55353</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.69079</td></tr><tr><td>val_auc</td><td>0.818</td></tr><tr><td>val_f1</td><td>0.64925</td></tr><tr><td>val_loss_epoch</td><td>0.53744</td></tr><tr><td>val_loss_step</td><td>0.50615</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/hn0trgp7' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/hn0trgp7</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_150430-hn0trgp7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3847a573384a495ba60b7871325aca27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_152440-a2yhbpzu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/a2yhbpzu' target=\"_blank\">GINConv_4_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/a2yhbpzu' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/a2yhbpzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 2.2 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90c6add283a64751b84a4bda588a0518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▇▇▇▇▇▇▇▇█████▇▇█████▇███▇███▇████▇▇▇</td></tr><tr><td>train_auc</td><td>▁▁▃▄▆▇▇▇▇█▇▇▇▇███▇█████▇████▇▇█▇████████</td></tr><tr><td>train_f1</td><td>▄▂▁▄▇▇▇▇▇▇▇▆▇█▇▇█▇▇▇██▇▇▇▇██▇█▇▇▇▇▇▇▇▆▆▆</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▂▃▂▂▂▂▂▂▂▁▂▂▂▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▆▂▂▄▃▂▃▂▄▃▁▂▂▂▂▁▄▃▁▂▃▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▂▃▄▄▆▆▄▇▅▆▆▆▆▇▆▆▆▇▆▆▆▆▆▇█▆▆▇▇█▇▇▇▇▇█▆▇▇</td></tr><tr><td>val_auc</td><td>▁▁▆▇▆▅▇▅▇▆▇▇▇████▆▇▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇█▇█▆▇▇</td></tr><tr><td>val_f1</td><td>▇▁▃▄▅▆▆▇▇▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇███▇▇▇▇█████▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▆▅▃▁▄▂▃▁▂▂▃▃▁▁▂▃▁▂▂▁▃▂▂▂▁▄▂▃▃▁▂▄▂▁▃▁▂▂▂</td></tr><tr><td>val_loss_step</td><td>█▇▆▄▄▃▂▅▄▃▃▄▃▁▁▃▃▁▂▃▃▄▂▃▃▁▄▃▅▅▃▃▇▃▃▃▂▄▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.71018</td></tr><tr><td>train_auc</td><td>0.77135</td></tr><tr><td>train_f1</td><td>0.55597</td></tr><tr><td>train_loss_epoch</td><td>0.54319</td></tr><tr><td>train_loss_step</td><td>0.54153</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.76645</td></tr><tr><td>val_auc</td><td>0.82196</td></tr><tr><td>val_f1</td><td>0.62032</td></tr><tr><td>val_loss_epoch</td><td>0.47863</td></tr><tr><td>val_loss_step</td><td>0.46341</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/a2yhbpzu' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/a2yhbpzu</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_152440-a2yhbpzu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d11f14606b6426c876ebab2fcc23577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_154556-ifxap8pb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/ifxap8pb' target=\"_blank\">GINConv_4_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/ifxap8pb' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/ifxap8pb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 2.2 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5f1fdcba31e44f4b19c62d2c38b72d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▅▅▆▆▆█▇▇▇▇█▇▇▇▇▇▇▇███▇█▇█▇██▇█▇█▇█▇▇▇</td></tr><tr><td>train_auc</td><td>▂▁▁▃▄▅▆▅▆▇▆▇▆▇▇▇▇▇▇▇▇█▇▇████▇▇█▇█▇▇▇█▇▇█</td></tr><tr><td>train_f1</td><td>▄▁▁▃▄▅▅▆▇▇▆▆▆█▆▅█▇▆▇▇▆▇▇▆▇▇█▇▇▇█▇▇▇▇▇▆▆▅</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▂▂▂▁▁▁▁▁▂▂▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▇▃▂▄▃▃▄▃▄▃▂▁▃▁▂▂▂▃▂▃▂▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▆▆▇▇▇▇▇▇▇████▇▇██▇▇█▇████▇█▇▇▇▇▇▇█████▇</td></tr><tr><td>val_auc</td><td>▁▃▄▅▅▆▆▆▆▆▇▇▇▇▇▇▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▅▆███▇▇▇</td></tr><tr><td>val_f1</td><td>▆▁▁▄▅▆▇▆▆▆▇▆█▇▆▆▇▇▆▅▇▅▇▇▆▇▇▇▄▄▅▆▇▇▇▆▇█▇▆</td></tr><tr><td>val_loss_epoch</td><td>█▆▆▅▃▄▃▃▂▂▂▃▃▁▂▂▃▁▂▂▂▃▂▂▂▂▃▂▃▄▂▃▄▂▁▂▂▂▃▂</td></tr><tr><td>val_loss_step</td><td>█▇▆▅▅▄▄▄▄▄▃▄▄▂▂▄▄▁▃▄▄▅▃▃▄▂▄▄▄▆▃▃▆▄▃▃▃▄▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.69787</td></tr><tr><td>train_auc</td><td>0.75804</td></tr><tr><td>train_f1</td><td>0.51064</td></tr><tr><td>train_loss_epoch</td><td>0.56073</td></tr><tr><td>train_loss_step</td><td>0.58152</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.73684</td></tr><tr><td>val_auc</td><td>0.82785</td></tr><tr><td>val_f1</td><td>0.47368</td></tr><tr><td>val_loss_epoch</td><td>0.49665</td></tr><tr><td>val_loss_step</td><td>0.48631</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/ifxap8pb' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/ifxap8pb</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_154556-ifxap8pb\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "130ccf19567643338264321c9512f986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_160230-y1zcbi8k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/y1zcbi8k' target=\"_blank\">GINConv_4_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/y1zcbi8k' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/y1zcbi8k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 2.2 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2e03cdaa7c94c0f965d2185ff6f8c60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▂▁▃▄▃▅▆▆▆▅▇▆▆▇▇▇▇▇▇█▇█▇██▇▇███▇▇█▇▇▇▇▇</td></tr><tr><td>train_auc</td><td>████▇▇▇▆▆▅▄▄▄▃▄▃▂▃▃▂▂▁▂▂▂▁▂▁▂▂▁▂▂▁▂▁▁▁▂▂</td></tr><tr><td>train_f1</td><td>▃▁▃▄▃▅▄▅▆▇▆▅▇▅▆█▆█▆▆▆▇▇█▅▇▇▆▅▆▇▆▆▅█▆▇▅▆▆</td></tr><tr><td>train_loss_epoch</td><td>█▅▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▃▃▂█▇▇███▇▇▇▇▇▇▇█▇▇▇███████████████████</td></tr><tr><td>val_auc</td><td>▇██▇▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_f1</td><td>▄▁▄▅███▇▇▇▆▄▅▄▄▄▄▅▄▃▄▄▅▆▄▅▄▅▅▅▅▅▄▅▅▆▅▅▆▄</td></tr><tr><td>val_loss_epoch</td><td>▇█▅▃▁▁▁▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>▇█▄▃▂▂▁▂▂▂▂▂▁▁▁▂▂▁▁▁▂▂▁▁▁▁▁▁▂▂▁▁▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.70608</td></tr><tr><td>train_auc</td><td>0.31241</td></tr><tr><td>train_f1</td><td>0.52267</td></tr><tr><td>train_loss_epoch</td><td>0.56476</td></tr><tr><td>train_loss_step</td><td>0.55467</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.76974</td></tr><tr><td>val_auc</td><td>0.1566</td></tr><tr><td>val_f1</td><td>0.5625</td></tr><tr><td>val_loss_epoch</td><td>0.47054</td></tr><tr><td>val_loss_step</td><td>0.45553</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/y1zcbi8k' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/y1zcbi8k</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_160230-y1zcbi8k\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baf3851b9a4c4342bc72a032df815d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_161842-9ssvjrxe</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/9ssvjrxe' target=\"_blank\">GINConv_4_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/9ssvjrxe' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/9ssvjrxe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 2.2 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "2.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44f7fdca51274d03856061defca2581e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▇▇▇▆▇▇▇▇▇▇█▇▇▇▇▇▇▇▇█▇████▇▇▇█▇▇█████</td></tr><tr><td>train_auc</td><td>▁▂▄▅▇█▇▇▇▇▇▇██▇▇████████▇▇█▇███▇████████</td></tr><tr><td>train_f1</td><td>▄▁▁▄▇▇▆▆█▇▆▇▇▇█▇▇▇▇▇▇█▇█▇▇█▇▇▇▇▇████▇█▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▂▂▃▃▂▂▂▂▂▂▂▂▁▂▂▁▁▂▁▂▁▂▁▁▂▂▁▁▁▁▁▁▁▁▂▂</td></tr><tr><td>train_loss_step</td><td>█▆▃▆▅▆▅▄▃▆▄▃▃▅▅▅▄▆▅▆▃▃▃▁▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▄▆▅▇▆▆▆▇▇▇▆▆▇▇█▇▇▇█▆▇▇▇▇▇▇▇▆▆▇▇▇▆▆▇██▇▇</td></tr><tr><td>val_auc</td><td>▁▇▇▇███████▇████████▇████████▇██████████</td></tr><tr><td>val_f1</td><td>▆▁▄▃▇▆▅▆▇▆▇▇▆▇██▇▇▇█▅▆▇█▇▇▇▇▇▇▇▇███▇██▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▇▆▄▂▂▃▂▁▁▂▂▃▂▁▂▁▂▂▂▂▁▂▃▂▂▂▂▃▃▂▂▃▅▃▃▃▂▃▂</td></tr><tr><td>val_loss_step</td><td>█▇▆▅▃▃▄▃▃▃▃▄▃▄▁▃▃▃▂▃▃▂▄▄▄▃▃▃▅▅▃▃▅▇▃▃▅▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.72824</td></tr><tr><td>train_auc</td><td>0.74738</td></tr><tr><td>train_f1</td><td>0.59486</td></tr><tr><td>train_loss_epoch</td><td>0.55372</td></tr><tr><td>train_loss_step</td><td>0.5644</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.76316</td></tr><tr><td>val_auc</td><td>0.83041</td></tr><tr><td>val_f1</td><td>0.65049</td></tr><tr><td>val_loss_epoch</td><td>0.49606</td></tr><tr><td>val_loss_step</td><td>0.50468</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/9ssvjrxe' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/9ssvjrxe</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_161842-9ssvjrxe\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6429dd37dd334b71b8e1ea8839b56ec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666495924, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_163250-mhp8b4mi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/mhp8b4mi' target=\"_blank\">GINConv_4_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/mhp8b4mi' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/mhp8b4mi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 2.2 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "2.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.7 K     Total params\n",
      "0.011     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "878b96b11665421cb0339a95be89ad8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▇▇▇▇▇▇█▇▇██▇▇█▇█████████▇▇█▇████████</td></tr><tr><td>train_auc</td><td>▁▁▃▅▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█████▇▇███████████</td></tr><tr><td>train_f1</td><td>▅▁▁▄█▇▆▇▇▇█▇▇▇█▇▇▇▇█▇▇████▇▇▆▆█▇▇▇███▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▇▅▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▄▅▆▆▆▄▄▄█▃▄▃▇▄▆▃▄▃▅▃▄▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▂▄▅▇▆▇▇▆▆▆▆▆▇▇▇▅▇▇▇█▇▇▆▅▅█▆▇▇▇▇▇▇▇▇▇███</td></tr><tr><td>val_auc</td><td>▁▆▇▇▇▇▇▇██▇█████▇█████▇▇▇▇▇▇█▇██▇▇▇▇████</td></tr><tr><td>val_f1</td><td>▇▁▄▅█▇██▇▇▇▇▇▇█▇▇▇██▇▇▇▇█▇█▆▇█▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▇▆▄▃▃▃▄▄▃▃▂▃▃▂▂▂▃▃▂▂▄▂▂▃▃▃▃▄▃▂▂▃▂▂▂▃▃▃▁</td></tr><tr><td>val_loss_step</td><td>█▇▆▄▄▄▅▆▃▄▄▄▃▅▃▃▄▄▄▄▃▇▃▄▄▄▃▄▅▄▄▃▄▂▃▃▆▄▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.7381</td></tr><tr><td>train_auc</td><td>0.78558</td></tr><tr><td>train_f1</td><td>0.62069</td></tr><tr><td>train_loss_epoch</td><td>0.53579</td></tr><tr><td>train_loss_step</td><td>0.46272</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.77632</td></tr><tr><td>val_auc</td><td>0.82978</td></tr><tr><td>val_f1</td><td>0.60465</td></tr><tr><td>val_loss_epoch</td><td>0.43718</td></tr><tr><td>val_loss_step</td><td>0.37568</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/mhp8b4mi' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/mhp8b4mi</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_163250-mhp8b4mi\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc84684a2c60442c944e6c21dff5f5a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.017183333332650364, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_164730-yomhghu6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/yomhghu6' target=\"_blank\">GINConv_4_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/yomhghu6' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/yomhghu6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 8.0 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "8.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.6 K     Total params\n",
      "0.034     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc3ed01e1234435092cfdb2428fdbcb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▆▆▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█▇▇▇█▇███▇▇▇▇▇</td></tr><tr><td>train_auc</td><td>▁▄▆▆▇▇▇▇▇█▇▇▇▇▇█████▇▇█████████▇████████</td></tr><tr><td>train_f1</td><td>▃▁▆▇▇▇▇▇▇█▇▇█▇████████▇██████▇██████████</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▄▃▃▃▂▃▂▃▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▂▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>▆█▆▂▆▄▃▅▄█▃▅▅▄▄▇▄▃▃▃▁▄▆▃▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▂▆▁▁▅▇▇█▆██▇▇▇▇█▇█▆█▇█▇▆▇▆▆▆▇▇▇▇▇█▇▄▆▇▆▆</td></tr><tr><td>val_auc</td><td>▁▄▅▆▇▇▇█▇▇████▇▇▇▇███▇▇▇█▇▇▇▇▇▆▇▇▇▇▅▇▆▇▆</td></tr><tr><td>val_f1</td><td>▁▇▇▇▇█▇█▇▇▇▇▇▇██▇███▇█▇█████▇█▇▇▇█▇▇▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▇▆▇▃▂▁▁▁▂▂▃▄▁▁▃▁▅▄▂▂▃▁▃▃▅▃▃▁▂▂▃▂▃▂▄▄▂▂▃</td></tr><tr><td>val_loss_step</td><td>█▇▆▇▄▄▂▁▄▃▄▄▃▁▂▃▄▇▄▃▃▅▁▄▃▇▅▃▂▃▄▄▂▄▆▄▅▄▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.74466</td></tr><tr><td>train_auc</td><td>0.80172</td></tr><tr><td>train_f1</td><td>0.65406</td></tr><tr><td>train_loss_epoch</td><td>0.5155</td></tr><tr><td>train_loss_step</td><td>0.51451</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.74013</td></tr><tr><td>val_auc</td><td>0.80578</td></tr><tr><td>val_f1</td><td>0.62911</td></tr><tr><td>val_loss_epoch</td><td>0.49936</td></tr><tr><td>val_loss_step</td><td>0.48879</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/yomhghu6' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/yomhghu6</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_164730-yomhghu6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc63a12a1aa944f2b278ea3987662862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_170405-ybeejla8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/ybeejla8' target=\"_blank\">GINConv_4_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/ybeejla8' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/ybeejla8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 8.0 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "8.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.6 K     Total params\n",
      "0.034     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7e7e7ee0f40464b85d83553a92441e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▃▄▆▆▆▆▆▇▆▆▇█▇▇▇▇▇▇▇▇▇█▇▇▇█▇▇▇▇▇██▆▇█▇█</td></tr><tr><td>train_auc</td><td>▁▂▃▃▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█████▇▇▇▇</td></tr><tr><td>train_f1</td><td>▂▁▄▄▆▆▆▆▆▆▆▆▇█▇▇▇▇▇▇█▇▇█▇▇▇▇█▆▇█▇██▆█▇▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▃▃▃▃▃▂▃▂▃▂▂▂▃▂▂▂▂▂▂▁▂▂▂▂▂▂▁▂▂▁▁▂▂▁▁▂</td></tr><tr><td>train_loss_step</td><td>▆█▆▁▇▄▃▄▃▇▄▄▃▃▃▆▃▃▃▁▁▅▅▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▃▂▃▂▃▆▇▆▆▄▆▆▆▇▆▅▆▅▆█▅▇▅▃▇▇▇▆▆▆▆▆▆▆▇▆▆▅▇</td></tr><tr><td>val_auc</td><td>▁▆▇▇▇█████▇█████████████████████████████</td></tr><tr><td>val_f1</td><td>▁▆▇▇▇█▇█▇▇▆▇▇▇▇▆▇▇▇▇▇▇████▇▇▆▆▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>██▇▅▅▄▂▂▁▂▄▃▃▁▂▃▃▃▂▂▂▃▂▃▄▄▂▁▂▂▂▂▂▂▁▁▃▂▁▂</td></tr><tr><td>val_loss_step</td><td>██▆▅▆▅▁▁▃▃▅▄▃▁▂▃▄▄▃▃▃▅▂▄▄▅▃▃▂▂▃▃▂▃▃▃▄▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.73317</td></tr><tr><td>train_auc</td><td>0.76201</td></tr><tr><td>train_f1</td><td>0.61538</td></tr><tr><td>train_loss_epoch</td><td>0.54333</td></tr><tr><td>train_loss_step</td><td>0.50688</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.75987</td></tr><tr><td>val_auc</td><td>0.81708</td></tr><tr><td>val_f1</td><td>0.58757</td></tr><tr><td>val_loss_epoch</td><td>0.48981</td></tr><tr><td>val_loss_step</td><td>0.47199</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/ybeejla8' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/ybeejla8</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_170405-ybeejla8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e62241120374c879c3ab7b11fc2392d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_171804-0tmd9s5n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/0tmd9s5n' target=\"_blank\">GINConv_4_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/0tmd9s5n' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/0tmd9s5n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 8.0 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "8.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.6 K     Total params\n",
      "0.034     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd43fcf38eb64d3caa8296cc73833aeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▁▃▃▃▄▄▅▅▅▆▇▇▆▇▇▇▇▇▇▇█▇▇▇▇▇▇▇██▇██▇██▇█</td></tr><tr><td>train_auc</td><td>▇█▇▇█▇█▇▇▆▆▅▅▃▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>train_f1</td><td>▁▃▂▂▂▂▂▂▃▃▃▅▆▆▅▇▆▆▆▇▇▅▇█▆▅▇▇▇▆██▆▇█▇▇▇▆▇</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▄▂▄▂▂▂▂▂▁▂▂▁▂▂▁▂▁▁▁▂▂▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▆▆▇▇▇▇▇▇▇█▇█▇█▇████████████████████████</td></tr><tr><td>val_auc</td><td>▆▆▆▆███▇▆▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_f1</td><td>▆▄▁▅▇▇▇▇▇▇▇██▇█▇▇█▇█████████▇██████▇███▇</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▂▃▂▂▂▂▂▂▂▂▁▁▂▁▂▂▁▂▂▁▂▁▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▃▁▂▃▃▂▁▂▂▂▂▂▁▁▂▂▂▂▂▂▃▁▂▂▃▂▂▁▁▂▂▂▂▂▁▂▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.73974</td></tr><tr><td>train_auc</td><td>0.30212</td></tr><tr><td>train_f1</td><td>0.61482</td></tr><tr><td>train_loss_epoch</td><td>0.52996</td></tr><tr><td>train_loss_step</td><td>0.50731</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.77961</td></tr><tr><td>val_auc</td><td>0.15336</td></tr><tr><td>val_f1</td><td>0.64921</td></tr><tr><td>val_loss_epoch</td><td>0.45638</td></tr><tr><td>val_loss_step</td><td>0.43265</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/0tmd9s5n' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/0tmd9s5n</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_171804-0tmd9s5n\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d87ad8b560ef4996a392bd7d40b0fdea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333330477276, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_173207-z1eu2m32</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/z1eu2m32' target=\"_blank\">GINConv_4_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/z1eu2m32' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/z1eu2m32</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 8.0 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "8.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.6 K     Total params\n",
      "0.035     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f74a7881e754bb6b1503582f4affeb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇██▇▇█▇█▇██▇███</td></tr><tr><td>train_auc</td><td>▁▄▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇███████</td></tr><tr><td>train_f1</td><td>▄▁▆▇▇▇▇▇▇▇▇▇█▇██▇██▇█▇███▇██▇██▇████████</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▃▃▃▃▃▃▂▂▃▃▃▂▂▂▂▂▂▃▂▂▂▂▂▂▃▂▂▂▂▂▁▁▁▂▁▂</td></tr><tr><td>train_loss_step</td><td>▇█▃▄▂▃▄▅▄▄▄▁▄▄▃▁▆▇▇▂▄▂▂▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▅▇▁▁████▇▇█▇█▇█▇▇▇█▇▇▇▇▇██▇▇███▇▇▇▇█▇▇▇▇</td></tr><tr><td>val_auc</td><td>▁▅▅██▇▇▇▇▇▇▇▇▇▇▇▇▆█▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▇▆▇▆▅▆</td></tr><tr><td>val_f1</td><td>▁▇▇▇█▇▇▇▇▇▇▇█▇█▇██▇▇████▇████▇██▇███▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>▅▅▆█▁▁▁▁▂▄▂▁▂▁▃▂▃▃▂▂▂▂▄▂▂▃▂▃▃▁▃▂▂▃▃▂▂▂▂▂</td></tr><tr><td>val_loss_step</td><td>▆▆▆█▃▃▁▂▃▂▃▁▃▂▄▃▃▃▂▃▄▂▆▃▃▄▃▄▃▁▄▃▃▄▃▃▃▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.75287</td></tr><tr><td>train_auc</td><td>0.80757</td></tr><tr><td>train_f1</td><td>0.65912</td></tr><tr><td>train_loss_epoch</td><td>0.51145</td></tr><tr><td>train_loss_step</td><td>0.50102</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.72697</td></tr><tr><td>val_auc</td><td>0.80481</td></tr><tr><td>val_f1</td><td>0.64069</td></tr><tr><td>val_loss_epoch</td><td>0.50791</td></tr><tr><td>val_loss_step</td><td>0.48406</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/z1eu2m32' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/z1eu2m32</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_173207-z1eu2m32\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf8c43869fb14e538b797a7db81f0eed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666495924, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_174601-ukc9t247</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/ukc9t247' target=\"_blank\">GINConv_4_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/ukc9t247' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/ukc9t247</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 8.0 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "9.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "9.7 K     Total params\n",
      "0.039     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1246fd0e24634b36b46ff031071ff9a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇██▇▇▇▇█▇█▇██</td></tr><tr><td>train_auc</td><td>▁▃▅▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇▇▇▇▇▇▇██</td></tr><tr><td>train_f1</td><td>▄▁▆▇▇▇▇▇▇▇▇▇██▇█▇▇█▇██▇▇▇███████████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▃▃▃▃▃▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▂▂▂▂▂▂▂▁▁</td></tr><tr><td>train_loss_step</td><td>███▁▄█▆▅▆▄▃▃▃▃▃▂▄▆▅▁▅▆▂▄▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▄▇▃▁▇▇▇▇▇▇▇█▆▇▇▇▇█▇▇▇█▇▇█▇▇▇▇▇███▇▇▆▇▇▇▆</td></tr><tr><td>val_auc</td><td>▁▆▆▇▇▇██▇▇▇█▇███▇█▇██▇█▇█▇█▇▇▇████▇▇█▇▇▇</td></tr><tr><td>val_f1</td><td>▁▅▇▇████▇▇██████▇█▇▇▇█▇███████████▇███▇█</td></tr><tr><td>val_loss_epoch</td><td>▆▅▅█▁▂▃▃▂▃▃▂▃▂▂▃▃▃▁▂▂▃▁▂▂▃▄▂▃▂▂▃▃▂▃▃▂▃▂▄</td></tr><tr><td>val_loss_step</td><td>▆▆▅█▃▃▄▄▃▃▄▃▄▃▂▃▃▄▁▃▃▅▂▃▄▃▃▃▄▂▃▃▅▃▄▅▂▅▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.75287</td></tr><tr><td>train_auc</td><td>0.80392</td></tr><tr><td>train_f1</td><td>0.66369</td></tr><tr><td>train_loss_epoch</td><td>0.50318</td></tr><tr><td>train_loss_step</td><td>0.50961</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.70395</td></tr><tr><td>val_auc</td><td>0.81104</td></tr><tr><td>val_f1</td><td>0.65649</td></tr><tr><td>val_loss_epoch</td><td>0.56615</td></tr><tr><td>val_loss_step</td><td>0.57985</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/ukc9t247' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/ukc9t247</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_174601-ukc9t247\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aded6a0dea44471a938d5c6d6276a37e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_180031-s0hc9zkj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/s0hc9zkj' target=\"_blank\">GINConv_4_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/s0hc9zkj' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/s0hc9zkj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 30.4 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "32.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "32.5 K    Total params\n",
      "0.130     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20e44f0290814e8580749b1e1e55653b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▇▇▆▇▆▇▆▆▇▇▇▆▇▇▇▇▇▆▇▇▇▇▇▇▇▇██▇▇▇██▇▇▇</td></tr><tr><td>train_auc</td><td>▁▆▆▆▇▆▇▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████▇██████</td></tr><tr><td>train_f1</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇██▇▇▇█▇█████████▇█</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▃▃▃▃▂▃▃▃▃▂▃▃▂▂▂▃▃▂▂▂▂▂▁▁▂▁▂▁▂▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>▇█▃█▅▅▇▇▅▄▅▆▆▅▂▁▃▃▆▅▆▃▃▆▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▄▂▁▃▇▇██▇▇█▇▇▇██▇▆▆█▇▇█▇▇▇▇████▇▇▇█▇▇▇██</td></tr><tr><td>val_auc</td><td>▁▇▅█████▇█▇▇▆▇▆▇▅▇▆▇▅▇█▆▇▇▆█▇▇▆▇▇▄▇▆▅▆▆▇</td></tr><tr><td>val_f1</td><td>▅▃▃▄▇██▇▃▅▆▅▅▅▆▆▇▆▅▅▄▁▇▇▆▇▆▇▇▅▄▆▆▆▆▄▅▄▅█</td></tr><tr><td>val_loss_epoch</td><td>▄▆█▃▁▂▁▁▂▁▁▁▁▂▂▁▂▂▂▁▂▁▁▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▂</td></tr><tr><td>val_loss_step</td><td>▄▅█▂▃▂▂▁▂▂▂▁▂▂▂▃▂▂▂▂▂▂▂▂▂▃▂▂▃▃▂▂▃▂▂▂▂▃▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.75698</td></tr><tr><td>train_auc</td><td>0.82614</td></tr><tr><td>train_f1</td><td>0.67686</td></tr><tr><td>train_loss_epoch</td><td>0.48393</td></tr><tr><td>train_loss_step</td><td>0.50296</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.76974</td></tr><tr><td>val_auc</td><td>0.8235</td></tr><tr><td>val_f1</td><td>0.70085</td></tr><tr><td>val_loss_epoch</td><td>0.51413</td></tr><tr><td>val_loss_step</td><td>0.51073</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/s0hc9zkj' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/s0hc9zkj</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_180031-s0hc9zkj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a4e94a05afc4e27aa5639c2604c7fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666883975, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_182001-am7jjfqr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/am7jjfqr' target=\"_blank\">GINConv_4_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/am7jjfqr' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/am7jjfqr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 30.4 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "32.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "32.5 K    Total params\n",
      "0.130     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64526611add74b34a9929aa741412a76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇█▇▇██▇██▇▇▇▇▇▇█</td></tr><tr><td>train_auc</td><td>▁▄▅▅▆▅▆▆▆▅▆▅▆▆▆▆▆▇▇▆▇▆▇█▇▇▇▇▇▇▇▇█▇██▇█▇█</td></tr><tr><td>train_f1</td><td>▁▃▅▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█▇█▇█▇██▇▇██▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▃▃▃▃▃▂▃▂▃▃▂▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂▁▂▁▁▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▇▄▆▄▄▅▇▅▄▆▄▄▄▂▁▃▂▅▄▅▃▁▄▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▆▃▁▂▇█▇▇▇████▇▇▇▇▇▇▇▇▇███▇▇██▇█▇██▇▆▇███</td></tr><tr><td>val_auc</td><td>▁▅▇█▇▇▇▇▇█▇▇▇▇▇▇██▇██████▇███▇▇▇███▇▇███</td></tr><tr><td>val_f1</td><td>▁▅▅▅█▇▇▇██▇▆▅▅▅▂▄▅▃▇▇▇█▆▇▆▃▅▄▃▆▇▆▇█▆▇▅▆▇</td></tr><tr><td>val_loss_epoch</td><td>▆▆█▆▃▃▂▁▃▂▂▁▁▂▂▁▃▂▂▂▃▂▂▃▃▃▂▂▃▂▃▃▃▂▃▃▂▂▃▂</td></tr><tr><td>val_loss_step</td><td>▆▆█▄▄▃▂▁▃▃▃▁▃▃▂▃▃▂▃▄▃▂▃▃▃▃▃▃▄▃▃▂▄▂▄▃▂▄▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.75205</td></tr><tr><td>train_auc</td><td>0.78796</td></tr><tr><td>train_f1</td><td>0.65991</td></tr><tr><td>train_loss_epoch</td><td>0.51152</td></tr><tr><td>train_loss_step</td><td>0.52707</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.76645</td></tr><tr><td>val_auc</td><td>0.80665</td></tr><tr><td>val_f1</td><td>0.64322</td></tr><tr><td>val_loss_epoch</td><td>0.49081</td></tr><tr><td>val_loss_step</td><td>0.44879</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/am7jjfqr' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/am7jjfqr</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_182001-am7jjfqr\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6df92740db940849049734ea26ef11f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_183750-x5x9bkbl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/x5x9bkbl' target=\"_blank\">GINConv_4_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/x5x9bkbl' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/x5x9bkbl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 30.4 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "32.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "32.5 K    Total params\n",
      "0.130     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b7b37cd34ad46c0b206ea3b8ee6c748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▃▄▅▄▆▆▆▆▆▇▇▇▇▇▇█▇█▇█████▇▇█████▇▇▇██▇█</td></tr><tr><td>train_auc</td><td>▁▄▅▅▆▆▃▄▅▄▃▅▆▇▇▆▇▇▇▇▇▆▇█▇▆▆▇▆▅▆▆▇▄▅▄▅▄▃▅</td></tr><tr><td>train_f1</td><td>▁▄▄▆▄▅▄▅▅▆▆▇▆▇▇▇▇▇▇█▆▇█▇██▇▇█▇█▇█▇▇▇█▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▃▂▁▂▂▂▁▁▂▂▂▁▁▁▁▁▂▂▂▁▁▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▃▄▆▆▇▇▇▇▇▇▇█▇▇▇█████████████████████▇██</td></tr><tr><td>val_auc</td><td>▁▃▆▆▇█▅▅▆▅▆▇▇▇▇▇▇██████▇█▇▇▇▇▇▇▇▇▇▇▇███▇</td></tr><tr><td>val_f1</td><td>▁▃▄▅▅▆▆▅▇▇▇▇█▄▄▄▆▆▇▇▆▇█▇▇▇▇▆██▇▇▇▆█▇▇▅█▆</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.75041</td></tr><tr><td>train_auc</td><td>0.63406</td></tr><tr><td>train_f1</td><td>0.65057</td></tr><tr><td>train_loss_epoch</td><td>0.52411</td></tr><tr><td>train_loss_step</td><td>0.5441</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.76645</td></tr><tr><td>val_auc</td><td>0.81679</td></tr><tr><td>val_f1</td><td>0.64322</td></tr><tr><td>val_loss_epoch</td><td>0.50016</td></tr><tr><td>val_loss_step</td><td>0.53488</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/x5x9bkbl' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/x5x9bkbl</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_183750-x5x9bkbl\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa3b6aee4c51463a8ce8038e258258f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_185734-oh3naa7e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/oh3naa7e' target=\"_blank\">GINConv_4_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/oh3naa7e' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/oh3naa7e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 30.4 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "32.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "32.6 K    Total params\n",
      "0.130     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "558addb7017140689cf84b40fc993e6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▇▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇▇███▇██████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▇▇▆▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇█▇▇▇▇▇██████▇██</td></tr><tr><td>train_f1</td><td>▁▆▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇▇▇██▇██▇███</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▃▃▃▄▃▂▃▃▃▃▃▂▂▃▂▂▃▂▂▂▁▂▂▂▂▂▁▂▁▁▁▂▂▁▁</td></tr><tr><td>train_loss_step</td><td>▄▅▇▆▄▇▄▆▇▂▃▄▆▅▃▂▂▅▄▄▂▅▂▁█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▂▄▆██▇█████▇██▇██▇██▇▇████▇▇▇▇▇▇▇▇▇▇▇█▇</td></tr><tr><td>val_auc</td><td>▃█▇▅▅▇▆▆▆▆▇▇▆▆▅▆▇▅▄▇▇▅▇▆▇▅▅▁▄▅▆▄▃▅▄▃▂▃▄▂</td></tr><tr><td>val_f1</td><td>▂▃▅▇▂▇▇▆▅▁▅▇▂▄▇▇█▇▅█▇▆▂▆▇▆▃▄▅▅▆▇▂▂▄▆▃▃▅▅</td></tr><tr><td>val_loss_epoch</td><td>▆█▇▄▂▃▃▃▂▃▂▃▁▂▃▃▂▃▃▂▂▂▃▃▂▂▂▄▂▃▄▃▂▁▄▃▃▄▂▃</td></tr><tr><td>val_loss_step</td><td>▆█▆▄▃▃▄▅▄▃▃▅▄▃▃▃▄▄▄▄▄▃▅▃▄▃▃▄▃▃▄▃▃▁▄▄▅▆▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.7578</td></tr><tr><td>train_auc</td><td>0.83134</td></tr><tr><td>train_f1</td><td>0.65658</td></tr><tr><td>train_loss_epoch</td><td>0.48927</td></tr><tr><td>train_loss_step</td><td>0.59082</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.74342</td></tr><tr><td>val_auc</td><td>0.79665</td></tr><tr><td>val_f1</td><td>0.61</td></tr><tr><td>val_loss_epoch</td><td>0.54742</td></tr><tr><td>val_loss_step</td><td>0.59252</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/oh3naa7e' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/oh3naa7e</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_185734-oh3naa7e\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b017343a6d44b1ac72311c4fa71b56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.0171999999981684, max=1.0))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_191257-j015umdh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/j015umdh' target=\"_blank\">GINConv_4_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/j015umdh' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/j015umdh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 30.4 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "36.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "36.7 K    Total params\n",
      "0.147     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45b6a485576449c2a1449f720bbf8b87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▇▇▆▇▇▇▇▇▇▇▇▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇███▇</td></tr><tr><td>train_auc</td><td>▁▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇████▇▇████</td></tr><tr><td>train_f1</td><td>▁▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇██▇▇▇████▇███</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▄▃▃▄▃▄▃▃▃▃▃▃▃▃▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▂▂▁▂▁▂</td></tr><tr><td>train_loss_step</td><td>▆▅▅▆▄█▆▄▁▄▅▇▅▆▅▅▂▄▄▅▂▆▂▄▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▃▁▅▆█▇▇█▇▇█████▇▇█▇█▇███▇▇▇▆▇█▆▇▇██▇█▇█▇</td></tr><tr><td>val_auc</td><td>▁▆▆▇▆▅▇▇▇▇▇▇▇▆▇▁▅▇▅▆▇█▆█▇▆▅▃▄▆▃▆▄▇▇▃▅▂▃▅</td></tr><tr><td>val_f1</td><td>▅▄▇▇▅▄▆▅▇█▅▆▇▇▆▂▃▅██▆▆▇█▆▇▆▁▅▇▆▅▆▇▇▅█▆▄▂</td></tr><tr><td>val_loss_epoch</td><td>▇█▄▆▃▂▁▂▃▃▃▃▃▃▃▃▃▂▄▃▂▂▃▄▂▃▂▃▃▁▃▃▃▂▃▂▂▂▄▂</td></tr><tr><td>val_loss_step</td><td>▇█▄█▃▄▁▃▃▄▄▄▄▄▅▃▄▃▅▄▃▃▄▄▄▄▄▄▅▁▄▄▅▂▄▄▂▂▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.74795</td></tr><tr><td>train_auc</td><td>0.82183</td></tr><tr><td>train_f1</td><td>0.68383</td></tr><tr><td>train_loss_epoch</td><td>0.49804</td></tr><tr><td>train_loss_step</td><td>0.4939</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.73684</td></tr><tr><td>val_auc</td><td>0.81341</td></tr><tr><td>val_f1</td><td>0.55056</td></tr><tr><td>val_loss_epoch</td><td>0.47898</td></tr><tr><td>val_loss_step</td><td>0.45886</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/j015umdh' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/j015umdh</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_191257-j015umdh\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cecd94e5a1a4b919b17b45b9d6e9743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_192839-0two42g9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/0two42g9' target=\"_blank\">GINConv_2_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/0two42g9' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/0two42g9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.0 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f789ca66fe0744fabfa8a8f66480f226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▅▆▆▇▇▇▇▇▇▇█▇▇▇▇███▇▇███▇▇██▇█▇▇█▇▇███</td></tr><tr><td>train_auc</td><td>▁▁▄▄▆▇▇▇▇▇▇▇▇█▇▇████████████████████████</td></tr><tr><td>train_f1</td><td>▄▁▂▃▆▆▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇██▇▇██▇█▇▇▇▇▇█▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▇▆▅▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▁▁▁▂▁▂▁▁▁▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▄▅▃▄▁▄▄▅▃▄▃▂▂▃▁▂▂▃▅▄▃▂▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▂▁▃▆▆▅▄▅▇▇▇▆▇█▇▇▆▇▇▇▅▆▇▆▇▇▆▇█▅▇▇▆▅▆▇▇███</td></tr><tr><td>val_auc</td><td>▁▅▅▆▆▆▆▆▆▆▇▆▆▆▆▇▆▆▆▆▆▅▇▆▆▅▆▆▅▆▆▆▇▇▅▇▅▇█▇</td></tr><tr><td>val_f1</td><td>▂▁▄▆▇▅▅▆█▇▇▇██▇▇▇██▇▆▇▇▇▇▇▇██▆▇█▆▆▇▇███▇</td></tr><tr><td>val_loss_epoch</td><td>█▇▆▆▄▆▆▂▁▁▃▃▄▃▅▅▃▃▂▄▃▄▂▄▂▂▃▂▃▂▅▃▃▃▂▃▆▁▃▁</td></tr><tr><td>val_loss_step</td><td>▇▆▆▇▄▅▆▁▄▄▄▃▃▃▇▄▄▄▃▄▄▅▃▄▄▂▄▄▃▁▄▃▄▃▄▃█▁▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.75452</td></tr><tr><td>train_auc</td><td>0.79796</td></tr><tr><td>train_f1</td><td>0.60292</td></tr><tr><td>train_loss_epoch</td><td>0.52615</td></tr><tr><td>train_loss_step</td><td>0.48683</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.73026</td></tr><tr><td>val_auc</td><td>0.78742</td></tr><tr><td>val_f1</td><td>0.63717</td></tr><tr><td>val_loss_epoch</td><td>0.53883</td></tr><tr><td>val_loss_step</td><td>0.50466</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/0two42g9' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/0two42g9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_192839-0two42g9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25ba406db9344da986586b0b23076bfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_194344-6lixnq2v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/6lixnq2v' target=\"_blank\">GINConv_2_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/6lixnq2v' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/6lixnq2v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.0 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b70170a2064b4196b7364e407674bd50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▅▆▅▆▆▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇██████▇▇▇█▇█▇█</td></tr><tr><td>train_auc</td><td>▁▁▃▃▅▅▅▅▆▆▆▇▆▇▆▇▇▇▇▇▇▇█▇█▇███████▇██▇███</td></tr><tr><td>train_f1</td><td>▃▁▁▂▃▃▄▅▅▅▅▅▆▅▄▅▅▄▇▇▆▆▆▆█▆█▇█▇▇▇▆▅▇▇▇▇▆█</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▂▂▁▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▇▄▅▄▆▅▆▄▅▄▂▄▃▁▃▃▃▅▄▅▅▄▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▁▁▂▅▆▅▅▅▆▆▆▆▆▅█▄▆█▅▆▅▄▆▄▄▄▄▅▂▅▆▅▄▄▅▃▂▄▃</td></tr><tr><td>val_auc</td><td>▁▅▆▆▇▇▇▇▇█▇▇▇█▇▇▇▇▇▇████▇▇▇▇▇▇▇▇████████</td></tr><tr><td>val_f1</td><td>▁▁▁▂▅▅▅▅▅▆▆▆▇▆▆█▅▇█▆▆▆▅▆▅▅▅▅▆▄▆▇▆▄▅▆▄▄▄▅</td></tr><tr><td>val_loss_epoch</td><td>█▇▇▇▅▄▅▂▁▃▃▄▄▃▅▄▃▃▁▄▃▃▃▄▂▂▄▃▅▁▆▂▂▄▃▄▄▄▅▃</td></tr><tr><td>val_loss_step</td><td>▇▇▇█▆▅▇▃▆▅▄▅▄▅█▄▆▅▃▅▅▅▄▄▆▂▆▅▇▁▅▄▄▅▅▅▆▅▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.72906</td></tr><tr><td>train_auc</td><td>0.76745</td></tr><tr><td>train_f1</td><td>0.56</td></tr><tr><td>train_loss_epoch</td><td>0.547</td></tr><tr><td>train_loss_step</td><td>0.49358</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.61513</td></tr><tr><td>val_auc</td><td>0.76062</td></tr><tr><td>val_f1</td><td>0.30769</td></tr><tr><td>val_loss_epoch</td><td>0.60584</td></tr><tr><td>val_loss_step</td><td>0.58896</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/6lixnq2v' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/6lixnq2v</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_194344-6lixnq2v\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96cbc0e2e23d4a2d8e224e5a157df58d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_195826-6l5e9f93</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/6l5e9f93' target=\"_blank\">GINConv_2_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/6l5e9f93' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/6l5e9f93</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.0 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "377a6a1fec004f4aad6ece972da5439a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▄▂▃▄▄▄▆▅▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇▇██▇▇▇</td></tr><tr><td>train_auc</td><td>▁▁▁▂▃▂▂▂▃▃▄▄▅▅▅▅▅▆▅▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇█▇▇</td></tr><tr><td>train_f1</td><td>▁▁▂▃▃▃▃▂▆▄▅▄▆▅▅▅▅▅▇▅▆▅▅▆▅▆▇▅▇▆▄▆▆▆▆▇█▆▆▆</td></tr><tr><td>train_loss_epoch</td><td>█▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▂▁▁▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▆▅▆▅▅▆▇███▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>val_auc</td><td>▇▁▂▅▄▄▄▄▅▆▆▆▇▇▇▇██████▇▇█▇▇█████████████</td></tr><tr><td>val_f1</td><td>█▂▁▃▂▁▄▅▇▆▆▆▆▆▅▅▆▇▆▇▆▆▆▅▆▆▆▇▆▆▇▇▆▇▆▇▇▇▆▆</td></tr><tr><td>val_loss_epoch</td><td>█▅▅▃▂▂▂▁▁▁▂▂▂▂▂▂▁▁▂▁▁▂▁▂▂▁▂▁▁▁▂▁▁▁▁▁▂▁▂▁</td></tr><tr><td>val_loss_step</td><td>█▄▅▄▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▂▂▂▂▂▂▂▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.72824</td></tr><tr><td>train_auc</td><td>0.76666</td></tr><tr><td>train_f1</td><td>0.5472</td></tr><tr><td>train_loss_epoch</td><td>0.54524</td></tr><tr><td>train_loss_step</td><td>0.50485</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.68092</td></tr><tr><td>val_auc</td><td>0.77807</td></tr><tr><td>val_f1</td><td>0.54028</td></tr><tr><td>val_loss_epoch</td><td>0.54252</td></tr><tr><td>val_loss_step</td><td>0.49717</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/6l5e9f93' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/6l5e9f93</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_195826-6l5e9f93\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26ab3b8c72064380acdf2cca74ec766b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_201414-oh9he15g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/oh9he15g' target=\"_blank\">GINConv_2_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/oh9he15g' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/oh9he15g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.0 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d44d32319e1f4ef286d73e8721ed0d64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇█▇▇▇█▇████▇██</td></tr><tr><td>train_auc</td><td>▁▂▄▅▆▇▇▇▇▇▇▇█▇████████████████▇█████████</td></tr><tr><td>train_f1</td><td>▃▁▁▃▆▇▇▇▇▇▇▇▇▆██▇█▇▇█▇▇█▇████▇▇█▇███▇███</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▂▃▃▃▃▂▂▂▃▂▂▂▁▂▂▂▂▂▁▁▁▂▁▂▁▂▁▂▁▂▁▁▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▇▃▅▄▅▃▂▂▃▁▄▁▂▅▅▄▃▃▃▂▄▃▄▆</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▁▃▅▆▆▇▇▇▇▆▆▇▇█▇▆▆▆▇▇▆▇▇▇▇▆▆▇▇▇▇▆▇▇▇▇▇▇▇</td></tr><tr><td>val_auc</td><td>▁▅▄▆▅▆▆▆▆▆▇▇█▇▇▇▇█▆▆█▇▇█▇▆▆▇▇▇▇▇▆▇▇▇▇▇▆█</td></tr><tr><td>val_f1</td><td>▁▁▃▆▆▆▇▇▇▇▇▆█▇█▇▆▆▆▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▆▇▆▄▅▅▃▄▆▂▄▂▅▄▁▃▄▃▂▄▅▂▃▄▃▄▅▁▄▃▅▃▂▃▂▂▁▄▃</td></tr><tr><td>val_loss_step</td><td>█▇▇▆▅▄▇▄▄▄▂▅▄█▆▅▅▅▃▃▃▇▃▄▄▄▄▄▁▆▃▅▃▃▅▄▃▁▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.75287</td></tr><tr><td>train_auc</td><td>0.80863</td></tr><tr><td>train_f1</td><td>0.61558</td></tr><tr><td>train_loss_epoch</td><td>0.51975</td></tr><tr><td>train_loss_step</td><td>0.59797</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.73026</td></tr><tr><td>val_auc</td><td>0.79025</td></tr><tr><td>val_f1</td><td>0.65254</td></tr><tr><td>val_loss_epoch</td><td>0.55103</td></tr><tr><td>val_loss_step</td><td>0.54743</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/oh9he15g' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/oh9he15g</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_201414-oh9he15g\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e5eb3693b1142198923e89cb35f8373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_202949-zarzj8sb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/zarzj8sb' target=\"_blank\">GINConv_2_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/zarzj8sb' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/zarzj8sb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.0 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "1.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.4 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3beca8eb59a24103a266d96b181c8682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▅▆▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇███▇█▇▇█▇██▇███▇█▇█</td></tr><tr><td>train_auc</td><td>▁▂▃▄▆▆▇▇▇▇▇▇█▇▇▇▇█████▇█████████████████</td></tr><tr><td>train_f1</td><td>▄▁▁▃▆▇██▇▇██▇▇█▇█▇▇█▇███▇███████████▇███</td></tr><tr><td>train_loss_epoch</td><td>█▇▆▅▃▄▃▂▂▂▂▂▂▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▂▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▆▄▄▃▄▃▄▄▃▄▃▃▃▅▄▄▃▃▃▁▅▄▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▁▁▃▆▇▇▅▇▇▇▇▇██▇▆▆▇█▇█▇██▇▇▇▇█▇█████▇▇▇▆</td></tr><tr><td>val_auc</td><td>▁▄▆▆▇▇▆▇▆▇▇▇▇▇▇▇▇▇▇█▇██▇██▇█▇███████▇▇▇▇</td></tr><tr><td>val_f1</td><td>▁▁▁▄▆▇▇▆▇██████▇▇▇██▇█████▇▇██▇████████▇</td></tr><tr><td>val_loss_epoch</td><td>█▇▇▆▃▄▄▅▄▅▄▃▄▃▃▂▄▆▄▄▁▄▃▄▁▁▃▁▅▃▂▂▃▄▄▃▃▂▃▆</td></tr><tr><td>val_loss_step</td><td>▆▆▆▆▅▄▄▅▄▃▄▄▃▄▃▄▄▇▄▄▅▅▄▃▄▁▄▄▆▃▄▄▃▅▃▄▄▂▄█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.75287</td></tr><tr><td>train_auc</td><td>0.81185</td></tr><tr><td>train_f1</td><td>0.59813</td></tr><tr><td>train_loss_epoch</td><td>0.50662</td></tr><tr><td>train_loss_step</td><td>0.46207</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.69737</td></tr><tr><td>val_auc</td><td>0.78113</td></tr><tr><td>val_f1</td><td>0.58929</td></tr><tr><td>val_loss_epoch</td><td>0.63775</td></tr><tr><td>val_loss_step</td><td>0.7353</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/zarzj8sb' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/zarzj8sb</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_202949-zarzj8sb\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e1b965728f4adb9df006c907031cb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_204525-csxu97sl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/csxu97sl' target=\"_blank\">GINConv_2_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/csxu97sl' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/csxu97sl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 3.6 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.1 K     Total params\n",
      "0.016     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1630cf38cb63454a9400ef0d22d48b85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▇▇▇▇▇▇▇▇█▇▇▇██▇▇▇▇▇█▇▇█▇█▇███▇█▇█▇█▇</td></tr><tr><td>train_auc</td><td>▁▂▅▅▇▅▆▆▇▇▇▇▇▆▆▆▆▆▅▆▅▅▅▅▆▆▆▆▆▆▆▇█▇█▇▇███</td></tr><tr><td>train_f1</td><td>▆▁▄▇▇▇▇▇██▇█▇▇████▇▇█▇████████▇████▇█▇█▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▂▁▂▂▂▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆█▅▇▄▆▅▃▅▂▄▄▅▅▇▅▃▄▃▄▇▃▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▁▅▇▇▇▆██▇▇█▇▇█▇▆▆▇▇▅▆█▇██▇▇▇▇▇▇██▇▆▇▇█▇</td></tr><tr><td>val_auc</td><td>▁▇▇▇█▇██████████████▇██▇█████████████▇██</td></tr><tr><td>val_f1</td><td>▁▁▅██████▇▇▇▇▇██▇▇▇▇▆▆▇▇██▇█▇▇▇▇▇▇▇▇▇▇██</td></tr><tr><td>val_loss_epoch</td><td>█▆▅▃▄▅▄▄▄▄▃▃▄▃▃▄▂▂▆▆▄▄▆▄▄▅▅▂▄▆▃▂▄▃▄▃▁▃▃▂</td></tr><tr><td>val_loss_step</td><td>▆▅▅▃▄▄▄▅▃▄▂▃▄▃▃▃▅▂▇▅▅▅█▄▄▆▄▄▄█▄▄▅▄▄▄▁▄▄▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.75534</td></tr><tr><td>train_auc</td><td>0.73004</td></tr><tr><td>train_f1</td><td>0.61598</td></tr><tr><td>train_loss_epoch</td><td>0.492</td></tr><tr><td>train_loss_step</td><td>0.43925</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.71053</td></tr><tr><td>val_auc</td><td>0.76952</td></tr><tr><td>val_f1</td><td>0.65079</td></tr><tr><td>val_loss_epoch</td><td>0.53939</td></tr><tr><td>val_loss_step</td><td>0.49844</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/csxu97sl' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/csxu97sl</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_204525-csxu97sl\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48ce6b76255a4f508e0776c22f4713b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_210228-v56hmomx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/v56hmomx' target=\"_blank\">GINConv_2_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/v56hmomx' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/v56hmomx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 3.6 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.1 K     Total params\n",
      "0.016     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "758d505f5ea74a238269c210cccab501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▃▄▅▆▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇█▇▇▇▇▇█▇</td></tr><tr><td>train_auc</td><td>▁▂▂▃▄▃▄▄▄▅▅▆▅▅▆▆▆▆▆▇▆▆▇▇▆▆▇▇██▇██▇▇▇▇███</td></tr><tr><td>train_f1</td><td>▃▁▂▄▅▆▅▆▆▆▆▇▆▆▆▆▇▇▇▇▇▇▇▇▇▆█▇█▇▇▇▇▇▇▇▇▇██</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▅▅▄▄▄▄▃▄▃▃▃▃▃▂▂▂▂▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▇▇█▄▅▅▃▇▁▄▄▄▅▆▅▁▅▃▄▄▂▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▄▅▆▆▆▆▇▇▅▅▆▅▇▅▇▅▆▄▇▄▃▆▃▅▇▇▄▄▅█▆▅▆▄▆▄▆▆▅</td></tr><tr><td>val_auc</td><td>▁▅▆▆▇▇▇▇▇▇█▇███▇███████▇▇█▇▇▇███▇▇██▇▇▇▇</td></tr><tr><td>val_f1</td><td>▁▇▇▇▇█▇▇█▄▅▆▅▇▅▇▄▅▄▇▃▁▆▂▅▇█▃▄▅█▆▅▆▃▆▃▇▅▄</td></tr><tr><td>val_loss_epoch</td><td>█▇▆▅▄▅▂▄▄▄▁▂▂▂▂▄▁▁▆▆▂▆▇█▄▄▃▄▄▆▃▁▄▃▅▁▂▃▄▃</td></tr><tr><td>val_loss_step</td><td>▆▅▅▄▃▃▂▄▃▃▁▂▃▃▂▂▄▁▆▅▃▆█▃▃▅▄▃▄▇▃▃▄▄▃▄▁▄▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.74466</td></tr><tr><td>train_auc</td><td>0.75684</td></tr><tr><td>train_f1</td><td>0.61557</td></tr><tr><td>train_loss_epoch</td><td>0.50663</td></tr><tr><td>train_loss_step</td><td>0.46859</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.67763</td></tr><tr><td>val_auc</td><td>0.75779</td></tr><tr><td>val_f1</td><td>0.51</td></tr><tr><td>val_loss_epoch</td><td>0.58063</td></tr><tr><td>val_loss_step</td><td>0.55128</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/v56hmomx' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/v56hmomx</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_210228-v56hmomx\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3829a5e25db843f3a34bfc0661634304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333330477276, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_212328-gayy2ot0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/gayy2ot0' target=\"_blank\">GINConv_2_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/gayy2ot0' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/gayy2ot0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 3.6 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.1 K     Total params\n",
      "0.016     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64843346cc5c4de088143d46a360c33c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▂▃▄▃▄▄▅▆▆▇▇▇▆▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇█▇██▇▇██</td></tr><tr><td>train_auc</td><td>▄▄▃▃▃▄▄▇▆▆▆███▇▇▇▇▇▇▆▆▇▆▆▆▇▇▅▅▆▄▄▅▄▃▄▄▃▁</td></tr><tr><td>train_f1</td><td>▁▃▄▄▄▄▅▄▄▆▇▇█▇▆▇▇▆▇▇▇▆██▇▇█▇▇▇▇▇█▇████▇█</td></tr><tr><td>train_loss_epoch</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▃▃▃▂▂▂▂▂▁▂▂▂▂▂▃▁▂▁▂▂▂▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▄▁▄▄███▇▇████▇██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇</td></tr><tr><td>val_auc</td><td>▅▅▅▄▅▆▆▇▇███████████████▇▇▇▇▇▇▇▇▇▇▇▇▅▄▃▁</td></tr><tr><td>val_f1</td><td>▅▄▆▆▇█▇▃▄▆▅▅▅▄▅▆▄▄▅▃▂▃▄▃▅▅▅▅▄▄▅▅▄▅▅▅▄▁▃▅</td></tr><tr><td>val_loss_epoch</td><td>▄█▄▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▃▂▂▂▃▂▃▃▂▁▂▃▂▂▂▂▂▁▁▂▂▁</td></tr><tr><td>val_loss_step</td><td>▆█▅▄▄▄▄▅▄▃▃▃▃▃▃▃▄▃▆▄▃▃▇▄▃▅▃▃▄▆▃▄▄▃▃▃▁▃▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.75944</td></tr><tr><td>train_auc</td><td>0.43817</td></tr><tr><td>train_f1</td><td>0.62096</td></tr><tr><td>train_loss_epoch</td><td>0.50463</td></tr><tr><td>train_loss_step</td><td>0.49986</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.69408</td></tr><tr><td>val_auc</td><td>0.31517</td></tr><tr><td>val_f1</td><td>0.62348</td></tr><tr><td>val_loss_epoch</td><td>0.53918</td></tr><tr><td>val_loss_step</td><td>0.49507</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/gayy2ot0' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/gayy2ot0</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_212328-gayy2ot0\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c64109719974907ad0b6b4f7c9a697e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_213908-arvsquyh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/arvsquyh' target=\"_blank\">GINConv_2_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/arvsquyh' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/arvsquyh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 3.6 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.1 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "600868198edd45608586622527cd4517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▆▇▇▇▇█▇▇▇█▇▇▇▇▇███▇▇▇███████████████</td></tr><tr><td>train_auc</td><td>▁▂▃▄▆▆▆▆▆▆▆▇▇▇▇▇▇█▇▇▇▇▇▇███▇█▇█▇████████</td></tr><tr><td>train_f1</td><td>▅▁▅▆▇▇▇▇▇▇▇█▇█▇█▇▇█▇██▇▇█████▇█▇███▇▇█▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▃▂▂▃▂▂▂▂▂▂▂▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▅▇▄▄▄▃▂▄▃▆▃▅▂▄▃▂▅▂▁▂▂▂▁▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▂▅▇█▇██▇▇▇█▇▇▇▆▇▇▇▇▇▇█▇▆▇██▆▆▇▇▇▇▆▆▇██▇</td></tr><tr><td>val_auc</td><td>▁▇▇▇████████▇██▇████████▇███▇██████▇███▇</td></tr><tr><td>val_f1</td><td>▁▂▆██████▇▇█▇▇▇▇▇▇▇▇████▇███▆▇▇▇▇█▇▇███▇</td></tr><tr><td>val_loss_epoch</td><td>█▆▅▄▃▄▄▂▂▂▁▃▁▁▄▄▃▂▁▂▃▄▄▄▃▃▃▃▄▂▅▃▃▃▂▂▃▁▂▂</td></tr><tr><td>val_loss_step</td><td>█▇▇▆▄▄▇▃▅▅▂▅▅▁▆▅▅▃▂▄▅▆▇▄▅▄▅▅▅▂▆▅▄▅▅▅▄▃▅▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.76026</td></tr><tr><td>train_auc</td><td>0.77</td></tr><tr><td>train_f1</td><td>0.63772</td></tr><tr><td>train_loss_epoch</td><td>0.51253</td></tr><tr><td>train_loss_step</td><td>0.5862</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.71382</td></tr><tr><td>val_auc</td><td>0.76602</td></tr><tr><td>val_f1</td><td>0.63291</td></tr><tr><td>val_loss_epoch</td><td>0.54646</td></tr><tr><td>val_loss_step</td><td>0.49589</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/arvsquyh' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/arvsquyh</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_213908-arvsquyh\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5092843aa104598b29222ad6740ad14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_215741-sx0i1ym3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/sx0i1ym3' target=\"_blank\">GINConv_2_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/sx0i1ym3' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/sx0i1ym3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 3.6 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "5.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.2 K     Total params\n",
      "0.021     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9ff82f6b08146b5b34997c50b664ae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▇▇▇▇▇█▇▇▇▇▇▇▇█▇▇██▇███████▇███▇█████</td></tr><tr><td>train_auc</td><td>▁▂▃▄▆▆▆▆▇▇▆▇▇▇▇▇▆▇▇▇▇▇▇▇█▇▇▇██▇▇█▇▇▇█▇██</td></tr><tr><td>train_f1</td><td>▅▁▄▆▇▇▇█▇█▇▇▇▇▇▇▇▇▇█▇▇▇█▇█▇█▇▇▇▇█▇▇▇▇▇█▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▁▂▂▂▂▂▁▂▂▁▂▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>▇▇▅▆▇▄▃▂▅▆▅▂▁▅▄▄▄█▅▃▅▃▅▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▂▅▇▆██▇▆▇▇▇▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇▇▆▇▇█▇</td></tr><tr><td>val_auc</td><td>▁▆▅▇▇▇██▇███▇▇▇█▇▇▇██▇█▇█▇█▇█▇██▇█▇█▇███</td></tr><tr><td>val_f1</td><td>▁▃▆████▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇█▇</td></tr><tr><td>val_loss_epoch</td><td>█▆▆▅▅▃▄▄▂▄▄▁▃▃▄▃▃▆▅▃▃▄▃▄▃▃▃▄▅▅▆▃▄▃▃▄▄▃▄▂</td></tr><tr><td>val_loss_step</td><td>▇▆▆▅▅▅▅▆▅▅▆▁▅▄▅▅▅█▆▅▄▅▃▄▅▄▄▅▇▆▄▅▅▃▄▅▅▅▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.7619</td></tr><tr><td>train_auc</td><td>0.78907</td></tr><tr><td>train_f1</td><td>0.6375</td></tr><tr><td>train_loss_epoch</td><td>0.49929</td></tr><tr><td>train_loss_step</td><td>0.51549</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.73026</td></tr><tr><td>val_auc</td><td>0.79154</td></tr><tr><td>val_f1</td><td>0.63393</td></tr><tr><td>val_loss_epoch</td><td>0.53291</td></tr><tr><td>val_loss_step</td><td>0.4852</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/sx0i1ym3' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/sx0i1ym3</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_215741-sx0i1ym3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdc5da954b604dda999462b87bdd4c08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666495924, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_221302-fposfe2u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/fposfe2u' target=\"_blank\">GINConv_2_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/fposfe2u' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/fposfe2u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 13.2 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.4 K    Total params\n",
      "0.062     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e715c4f9932644aea6c9b5d7da581ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▅▅▆▆▆▆▆▇▇▅▆▆▇▇▇▆▆▇▇▇▇█▇▇▇▇▆▆▇▇▇▆█▇▇▇█</td></tr><tr><td>train_auc</td><td>▁▅▅▆▆▆▆▆▆▆▇▇▆▆▇▇▇▇▇▇▇▇█▇▇█▇▇▇▇▇▇▇▇▇███▇█</td></tr><tr><td>train_f1</td><td>▁▇▅▇▆▇▆▇▆▇▇▇▆▆▇█▇▇▇▇▇▇▇██▇▇█▇▇▇▇▇▇▇██▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▅▃▃▃▄▃▃▃▃▃▃▃▂▂▂▃▂▂▂▃▂▂▂▂▂▂▂▂▃▂▂▁▂▂▂▁</td></tr><tr><td>train_loss_step</td><td>▅▆▇▃▄▆█▃█▃▂▅▃▂▅▄▃▂▂▅▅▁▆▄▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▄▄▇█▇██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▆▇▇██</td></tr><tr><td>val_auc</td><td>▁▇▆▅▇▆█▇▆▆▅▆▅█▇▅█▇▆▅▇▅▅▆▆▇▄▇█▆▇█▆▅▆▇▇▆█▄</td></tr><tr><td>val_f1</td><td>▄▆▆█▇▅▆▆▄▅▅▃▃▄▅▆▄▄▄▅▆▆▂▃▄▂▂▃▅▂▃▇▅▁▂▁▆▄▆▅</td></tr><tr><td>val_loss_epoch</td><td>█▅▄▅▃▃▁▅▄▂▂▂▂▂▂▂▂▆▃▃▃▂▃▃▃▄▂▃▄▃▄▄▂▄▂▃▂▃▃▃</td></tr><tr><td>val_loss_step</td><td>▇▆▃▆▄▄▁▆▄▄▂▂▄▃▂▄▄█▄▄▄▂▄▄▄▅▄▄▅▃▃▄▂▄▄▅▃▄▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.76519</td></tr><tr><td>train_auc</td><td>0.82838</td></tr><tr><td>train_f1</td><td>0.64951</td></tr><tr><td>train_loss_epoch</td><td>0.48215</td></tr><tr><td>train_loss_step</td><td>0.49917</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.72697</td></tr><tr><td>val_auc</td><td>0.76837</td></tr><tr><td>val_f1</td><td>0.64681</td></tr><tr><td>val_loss_epoch</td><td>0.57086</td></tr><tr><td>val_loss_step</td><td>0.55911</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/fposfe2u' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/fposfe2u</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_221302-fposfe2u\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72fd1ba0abe044a4969fb6db329205ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_222803-rsg82tkf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/rsg82tkf' target=\"_blank\">GINConv_2_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/rsg82tkf' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/rsg82tkf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 13.2 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.4 K    Total params\n",
      "0.062     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "763d75d1e8b24f4281ee8774abfc607a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▅▆▆▆▆▅▆▆▆▆▆▆▆▇▆▇▇█▇▇▇██▇███▇▇▇████▇█</td></tr><tr><td>train_auc</td><td>▁▃▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▆▇██▇▇█</td></tr><tr><td>train_f1</td><td>▁▅▄▆▆▅▅▇▆▅▇▆▅▇▅█▇▇▆▇▇▇▆█▇▇▇▇█▇█▇▇▇▇██▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▅▄▄▄▄▄▃▃▃▃▄▄▃▃▃▃▃▃▂▃▂▂▂▃▂▂▁▂▂▃▂▁▂▂▂▁</td></tr><tr><td>train_loss_step</td><td>▇▆█▅▅▇▇▄▇▃▃▅▂▂▂▃▃▁▁▄▄▁▅▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▃▇▁▇▇▇▇▆▅▅▄▆▇▄█▄▆▅█▆▅▇▆▅▇█▇▆▆▇▇▇▄▇▆▆██▇▇</td></tr><tr><td>val_auc</td><td>▁▅▄█▆▆▇▆▆▆▅█▅▇▇▇▆█▆▆▆▆▅▅█▇▇▇▆▇▇▇▇▅▃▅▅▇▅▆</td></tr><tr><td>val_f1</td><td>▇▇▇▆▅▆▆▅▃▄▁▅▆▂█▁▆▃▇▄▃▇▆▃▆▇▆▅▅▆▇▇▁▆▅▅▇▇▇█</td></tr><tr><td>val_loss_epoch</td><td>▇▃▅▄▃▃▁▅▅▃▃▁▂▃▂▃▂█▃▂▂▂▃▄▃▂▁▄▄▂▅▆▃▄▂▅▃▃▂▂</td></tr><tr><td>val_loss_step</td><td>▅▄▃▅▃▃▁▅▃▃▂▁▄▂▂▃▃█▄▃▄▂▃▃▃▂▃▃▄▂▃▃▂▄▄▄▃▃▄▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.76683</td></tr><tr><td>train_auc</td><td>0.84191</td></tr><tr><td>train_f1</td><td>0.65196</td></tr><tr><td>train_loss_epoch</td><td>0.4657</td></tr><tr><td>train_loss_step</td><td>0.44907</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.72697</td></tr><tr><td>val_auc</td><td>0.77076</td></tr><tr><td>val_f1</td><td>0.68199</td></tr><tr><td>val_loss_epoch</td><td>0.55809</td></tr><tr><td>val_loss_step</td><td>0.51968</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/rsg82tkf' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/rsg82tkf</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_222803-rsg82tkf\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "038ac213b26248488926c8082514e9e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666883975, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_224316-a6vcxylw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/a6vcxylw' target=\"_blank\">GINConv_2_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/a6vcxylw' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/a6vcxylw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 13.2 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.4 K    Total params\n",
      "0.062     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b0e8ce9c33041b2b7d1fda56d55c907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▂▃▄▁▃▅▅▅▇▇▇▇▇▇▇▇▇▇▆█▇▇▇█▇▇█▇▇███▇▇▇█▇█▇█</td></tr><tr><td>train_auc</td><td>▆█▅▃▄▂▁▁▃▃▄▃▄▄▅▄▆▅▅▅▄▅█▇▇▆█▇██▆▇▆▇▆▇▇▆▆▆</td></tr><tr><td>train_f1</td><td>▁▅▁▃▄▄▂▄▆▅▆▇▇▆▆▆▆▇▅▇▆▇▇▇▆▆▇▆▆▆▇▇▆▆▅█▆▇▆▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▄▂▁▂▂▂▂▁▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▇▃▇█▆▇██▇██▇▇██▇▇▇▇▇█▇▇▇▇▆▇▆▇▇▇▆▇▆▇▇▆▇▆</td></tr><tr><td>val_auc</td><td>▅▃▃▆▇▄▁▅▇▆▇▇▇▇▇▇████▇████████████▇▇███▇▇</td></tr><tr><td>val_f1</td><td>▅▇▆▇█▁▅▆▆▄▆▇▄▅▆▆▅▅▄▄▄▆▃▅▅▃▂▄▂▃▃▃▂▃▂▄▄▂▃▂</td></tr><tr><td>val_loss_epoch</td><td>█▂▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▃▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.7578</td></tr><tr><td>train_auc</td><td>0.64948</td></tr><tr><td>train_f1</td><td>0.62033</td></tr><tr><td>train_loss_epoch</td><td>0.49977</td></tr><tr><td>train_loss_step</td><td>0.49016</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.68421</td></tr><tr><td>val_auc</td><td>0.76997</td></tr><tr><td>val_f1</td><td>0.56364</td></tr><tr><td>val_loss_epoch</td><td>0.54693</td></tr><tr><td>val_loss_step</td><td>0.5156</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/a6vcxylw' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/a6vcxylw</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_224316-a6vcxylw\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ea0bd65a8ae4a61bc38ca635b6fd215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333330477276, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_225831-iacngnwk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/iacngnwk' target=\"_blank\">GINConv_2_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/iacngnwk' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/iacngnwk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 13.2 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "15.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.5 K    Total params\n",
      "0.062     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4fe9a9d48fe45cc8d9921dadeedcc10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▆▅▅▆▆▇▆▇▆▇▇▇▇▇█▇█▇▇██▇▇▆▆▇▇▇▇▇█▇▇▇▇▇▇▇</td></tr><tr><td>train_auc</td><td>▁▆▆▅▇▇▇▇▇▇▇▇█▇█▇█▇█▇█████▇█▇██▇██▇██████</td></tr><tr><td>train_f1</td><td>▁▆▆▆▆▇▅▇▆▇▆▇▆▇▇▇▇▇▇▇▇▇█▇█▅█▆▇▇▇▆█▆█▅▇▇▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▃▃▃▃▃▃▃▁▂▁▂▂▂▂▂▂▁▂▂▂▄▂▃▁▁▂▁▁▂▂▂▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▄▆▅▃▅▂▁▅▃▃▄▃▁▅▃▂▃▃▄▃▄▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▂▇▇█▇▇▇▇▇██▇▇▇█▇▇▇▇▇█▇▇▅▇██▇██▇▇▇▇██▇▇▇</td></tr><tr><td>val_auc</td><td>▂▁▆▆▇▇▇▆▂▇▆▅▆▆▇▆▇▂▆▂▆▃▇▆▆▃▇▆▇▅▆▆█▂▇▆▇▂▆▅</td></tr><tr><td>val_f1</td><td>▆▆▇▇▇▆▅▇▆▆▇▇▆▅▆▇▆▇▇▅▅▇▇▄▁▇██▇▇█▅▅▅▅▇▇▆▅▅</td></tr><tr><td>val_loss_epoch</td><td>█▆▃▂▂▂▂▁▃▂▁▁▂▃▁▁▃▃▃▄▃▃▂▃▃▂▃▂▃▃▁▂▃▂▂▂▂▃▁▂</td></tr><tr><td>val_loss_step</td><td>█▇▄▃▃▃▃▁▃▃▂▁▃▅▂▃▃▅▄▃▃▄▃▃▄▃▃▃▅▅▃▄▅▃▃▃▃▄▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.75534</td></tr><tr><td>train_auc</td><td>0.82177</td></tr><tr><td>train_f1</td><td>0.65668</td></tr><tr><td>train_loss_epoch</td><td>0.48959</td></tr><tr><td>train_loss_step</td><td>0.46363</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.70395</td></tr><tr><td>val_auc</td><td>0.77741</td></tr><tr><td>val_f1</td><td>0.59459</td></tr><tr><td>val_loss_epoch</td><td>0.57679</td></tr><tr><td>val_loss_step</td><td>0.57446</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/iacngnwk' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/iacngnwk</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_225831-iacngnwk\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa5e67b25544d0d8424d00d8feeff92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_231339-s85olzm3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/s85olzm3' target=\"_blank\">GINConv_2_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/s85olzm3' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/s85olzm3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 13.2 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "19.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "19.6 K    Total params\n",
      "0.078     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "497524f1ea0945a0820e68e27d49c3b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▅▆▆▆▆▇▇▇▅▆▆▇▇▇▆▇▆▇▆▆▆▇▇▇▇▇▇▇▇▇█▇▇█▇▇▇</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇████▇▇▇██▇████</td></tr><tr><td>train_f1</td><td>▁▇▇▆▇▆▇▇█▇█▆▇▇█▇▇▇▇▇█▇▇▇█▇▇▇▇████████▇██</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▃▃▃▃▃▂▃▃▃▂▃▃▃▃▃▂▂▃▃▃▂▂▂▂▂▂▂▂▂▁▂▃▂▂▁▁</td></tr><tr><td>train_loss_step</td><td>▆█▃▆▄▆▄▃▄▅▇▂▆▆▅▄▆█▂▄▁▅▆▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▃▃▆▇▆▇▆▆▆▆▆▆▇▇▅▅▆▆▆▆▆█▇▆▆▆▆▆▆▆▇▇▆▅▆▆▆▆▅</td></tr><tr><td>val_auc</td><td>▅▂▆▆█▆▅▅▆▆▄▅▆▇▄▃▅▆▂▆▄▂▅▇▄▆▄▃▆▂▃▆▄▅▁▆▆▄▆▂</td></tr><tr><td>val_f1</td><td>▅▆▆▆▆▆▅▄▃▄▅▄▂▆▅▁▂▄▃▄▅▄█▅▄▄▅▅▄▃▄▆▇▄▃▃▅▃▄▁</td></tr><tr><td>val_loss_epoch</td><td>▆█▅▃▃▂▃▃▄▂▃▄▂▃▃▃▄▄▄▃▂▃▄▄▃▄▃▂▁▄▂▂▃▂▃▄▄▄▃▄</td></tr><tr><td>val_loss_step</td><td>██▇▆▅▆▆▆▆▆▅█▆▆▄▆▆▇▆▆▆▄█▆▆▇▆▅▁▆▆▆▆▄▅▅█▇▅▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.76847</td></tr><tr><td>train_auc</td><td>0.83153</td></tr><tr><td>train_f1</td><td>0.66024</td></tr><tr><td>train_loss_epoch</td><td>0.48262</td></tr><tr><td>train_loss_step</td><td>0.45884</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.68421</td></tr><tr><td>val_auc</td><td>0.76868</td></tr><tr><td>val_f1</td><td>0.55556</td></tr><tr><td>val_loss_epoch</td><td>0.60602</td></tr><tr><td>val_loss_step</td><td>0.61628</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/s85olzm3' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/s85olzm3</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_231339-s85olzm3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4472f86303514044a4bc1e2d4126360a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333330477276, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_232832-h8ii9svn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/h8ii9svn' target=\"_blank\">GINConv_3_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/h8ii9svn' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/h8ii9svn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.6 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "542a4fcd311743d39fac32b09450442d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▃▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇█▇█▇▇▇▇███</td></tr><tr><td>train_auc</td><td>▁▃▄▆▆▆▇▇▇▇▇▇▇▇▇▇█▇█▇█▇▇▇▇▇▇██▇███▇█▇▇███</td></tr><tr><td>train_f1</td><td>▃▁▂▅▆▆▇▇█▇▇▇▇▇▇██▇██▇█████▇████▇██▇▇████</td></tr><tr><td>train_loss_epoch</td><td>█▇▆▄▄▄▃▂▂▃▃▂▂▂▂▂▂▂▂▃▂▂▂▂▃▂▂▂▂▂▁▂▂▂▂▂▂▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▄▄▅▅▂▅▄▃▆▃▆▄▂▄▂▃▁▂▂▄▆█▆▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▁▂▆▇▇▇▇▇▇█▇▇███▇▇▇██▇▇▇█▇▇▇▇▇▇▆▇▇▇▇▇▇▇█</td></tr><tr><td>val_auc</td><td>▁▃▆▇▆▇▄▇▆██▆█▆▆▇▇▆██▇▇██▇█▆▇▆▆▄▅▇▇▆▇▆▄▆▇</td></tr><tr><td>val_f1</td><td>▁▁▃▆▇▇▇▇█████████▇████▇██▇▇▇██▇▇██▇█▇▇██</td></tr><tr><td>val_loss_epoch</td><td>█▇▇▅▄▆▃▄▁▄▁▄▃▃▃▂▃▃▁▁▄▂▄▄▄▃▂▁▃▄▄▃▃▂▂▄▄▅▃▂</td></tr><tr><td>val_loss_step</td><td>███▆▅▄▃▆▅▄▁▅▄▄▃▅▅▄▁▄▄▃▅▅▄▃▅▅▄▆▅▄▃▂▄▅▅▆▆▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.74713</td></tr><tr><td>train_auc</td><td>0.79734</td></tr><tr><td>train_f1</td><td>0.60614</td></tr><tr><td>train_loss_epoch</td><td>0.50742</td></tr><tr><td>train_loss_step</td><td>0.4703</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.72697</td></tr><tr><td>val_auc</td><td>0.78038</td></tr><tr><td>val_f1</td><td>0.67451</td></tr><tr><td>val_loss_epoch</td><td>0.52478</td></tr><tr><td>val_loss_step</td><td>0.4676</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/h8ii9svn' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/h8ii9svn</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_232832-h8ii9svn\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbefd7a66c134b97b3acf88a8113786f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.0171999999981684, max=1.0))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240112_234313-f3kgusfp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/f3kgusfp' target=\"_blank\">GINConv_3_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/f3kgusfp' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/f3kgusfp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.6 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc6158b720d4d92bbd3a41c626b8fbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▆▆▇▆▆▆▆▇▆▆▇▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇█</td></tr><tr><td>train_auc</td><td>▁▂▂▃▃▃▄▆▅▅▅▆▆▅▆▇▇▆▇▇▆▆▆▆▇▇▇▇▇▆▆▆▇▆▇▇▇▇▇█</td></tr><tr><td>train_f1</td><td>▆▃▁▂▄▅▅▆▆▅▆▆▆▅▅▇▆▅▆▇▆▇▇▇▇▇▇▇▇▇▇▆█▇▆▇▇▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▆▆▅▆▄▇▆▆▆▆▇▅▄▄▃▄▃▃▄▄▇▇▄▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▁▁▁▃▅▄▄▄▃▅▅▄▅▆▇▅▅▇▇▆▇▆▇▇▆▇▅▆▆▄▃█▃▃▄▄▇█▇</td></tr><tr><td>val_auc</td><td>▁▃▅▆▇▆▆▆▆▆▆▆▆▇▇▇▇▆▇▇▇▇▇▇██▇█▇▇██▇▇▇▇▇▇▇▇</td></tr><tr><td>val_f1</td><td>▁▁▁▁▄▆▅▄▅▅▆▆▅▆▇▇▆▆▇▇▇▇▇▇█▇▇▆▇▇▅▄█▅▄▅▅▇█▇</td></tr><tr><td>val_loss_epoch</td><td>███▇▅▅▃▇▂▄▂▃▅▃▃▂▃▃▂▁▄▁▄▃▃▂▁▁▄▄▄▃▃▃▄▅▄▄▂▃</td></tr><tr><td>val_loss_step</td><td>▇▇▇▆▅▄▃█▅▅▂▃▄▃▃▄▄▃▂▃▃▁▅▄▃▁▄▄▅▄▅▃▃▂▄▅▄▄▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.75287</td></tr><tr><td>train_auc</td><td>0.7734</td></tr><tr><td>train_f1</td><td>0.6096</td></tr><tr><td>train_loss_epoch</td><td>0.52452</td></tr><tr><td>train_loss_step</td><td>0.47731</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.69737</td></tr><tr><td>val_auc</td><td>0.77781</td></tr><tr><td>val_f1</td><td>0.54455</td></tr><tr><td>val_loss_epoch</td><td>0.58066</td></tr><tr><td>val_loss_step</td><td>0.5698</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/f3kgusfp' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/f3kgusfp</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240112_234313-f3kgusfp\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db6af52bd0684b42bd08ef28fdfb77cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.017183333332650364, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240113_000021-8p8nze8q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/8p8nze8q' target=\"_blank\">GINConv_3_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/8p8nze8q' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/8p8nze8q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.6 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb400da0e864e53810e8e249a6177b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▃▃▅▅▄▆▆▇▆▇▇▇▆▇▇▇▇█▇▇▇▇▇▇▇▇█▇▇▇██▇█████</td></tr><tr><td>train_auc</td><td>▁▅▅▄▃▁▂▄▁▃▃▄▅▃▃▅▅▄▆▅▅▄▇▄▆▅▅▇▆▆▅▇▇▅▅▇▇▇▆█</td></tr><tr><td>train_f1</td><td>▁▃▄▄▄▃▃▆▄▅▄▅▆▅▅▆▆▅▆▇▇▆▆▅▆▆▇▇▇▇▇▆▇▇▇▇▇▇██</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▃▂▂▁▂▁▁▂▂▂▂▁▂▁▁▁▁▁▁▂▂▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▆▅▇▆▇█▇▇▇█▇▇▇██▇▇▇▇▇▇▆▆▇▇▇▆▇█▇▇█▇▇▇▇▇▇▇</td></tr><tr><td>val_auc</td><td>▃▅▄▃▃▂▁▁▁▂▂▃▄▄▅▅▅▅▅▅▆▆▆▆▇▇▆▆▇▇▇▇██▇█████</td></tr><tr><td>val_f1</td><td>▆███▁▄▆▅▄▄▅▄▃▄▆▆▃▃▃▄▅▅▃▃▄▅▅▂▅▇▆▄▆▅▄▅▄▄▆▄</td></tr><tr><td>val_loss_epoch</td><td>█▂▂▂▂▂▁▂▁▂▁▁▂▁▁▁▁▁▁▁▂▁▂▁▁▁▁▁▁▁▂▁▁▁▁▂▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▃▃▃▃▂▂▃▃▂▁▂▂▂▂▂▂▂▁▂▂▁▃▂▂▁▂▂▂▂▂▂▁▁▂▂▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.75452</td></tr><tr><td>train_auc</td><td>0.64709</td></tr><tr><td>train_f1</td><td>0.59649</td></tr><tr><td>train_loss_epoch</td><td>0.50683</td></tr><tr><td>train_loss_step</td><td>0.46496</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.68092</td></tr><tr><td>val_auc</td><td>0.77519</td></tr><tr><td>val_f1</td><td>0.5446</td></tr><tr><td>val_loss_epoch</td><td>0.53885</td></tr><tr><td>val_loss_step</td><td>0.49973</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/8p8nze8q' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/8p8nze8q</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240113_000021-8p8nze8q\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c9723c896c542f4b6241f3052c097af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666883975, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240113_002011-pteoswsm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/pteoswsm' target=\"_blank\">GINConv_3_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/pteoswsm' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/pteoswsm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.6 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67fd19701dfa41f58522c40af1914ed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▅▅▅▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇█▇███</td></tr><tr><td>train_auc</td><td>▁▃▄▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇▇▇███████</td></tr><tr><td>train_f1</td><td>▃▁▃▆▆▇▇▆▇▇▇▇▇▇▇█▇▇▇▇▇▇█▇▇███████▇███▇███</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▃▄▃▃▃▃▃▃▃▂▂▂▂▂▂▃▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▁▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>▇▅▅▅▆▄▂█▃▂▄▅▁▅▄▄▂▁▅▃▅▃▂▅▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▁▃▃▃▆▆▆▆▇▆▇█▇▆▆▇▇██▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇█▇▇▇</td></tr><tr><td>val_auc</td><td>▁▅▆▆▆▆▇▇▇▇▆▇▇▆▇▇▇█▇▇▇▇▇█▇▇██▇▇▆▇▇█▇▆█▆▇▇</td></tr><tr><td>val_f1</td><td>▁▁▃▄▄▇▇▇█▇▇▇█▇▇▇██████▇▇▇██▇▇▇▇█▇▇▇▇███▇</td></tr><tr><td>val_loss_epoch</td><td>█▇▇▄▅▆▄▃▅▃▂▃▃▃▃▄▄▃▅▄▄▃▆▄▃▅▂▂▄▃▂▃▅▃▄▄▁▃▂▄</td></tr><tr><td>val_loss_step</td><td>▇▆▇▃▆▄▄▃▃▄▁▃▄▃▃▅▄▄▇▃▄▄█▄▄▇▄▄▆▃▄▅▆▃▄▄▁▃▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.76026</td></tr><tr><td>train_auc</td><td>0.81032</td></tr><tr><td>train_f1</td><td>0.61478</td></tr><tr><td>train_loss_epoch</td><td>0.49869</td></tr><tr><td>train_loss_step</td><td>0.48531</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.72697</td></tr><tr><td>val_auc</td><td>0.7748</td></tr><tr><td>val_f1</td><td>0.64069</td></tr><tr><td>val_loss_epoch</td><td>0.57797</td></tr><tr><td>val_loss_step</td><td>0.58061</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/pteoswsm' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/pteoswsm</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240113_002011-pteoswsm\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eac25678fd0410aa490d7d8fef56552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666883975, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240113_003841-b49j89su</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/b49j89su' target=\"_blank\">GINConv_3_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/b49j89su' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/b49j89su</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.6 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "2.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd28573b71fd45f5a2c4530181a2738f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▃▅▇▇▇▇▇▆▆▇▇█▇▇▇▇▇▇█▇▇▇▇█▇▇▇▇██████▇█▇▇</td></tr><tr><td>train_auc</td><td>▁▃▅▆▇▇▇▇▇▇▇█▇▇▇█▇▇▇▇█▇█▇████▇▇▇████████▇</td></tr><tr><td>train_f1</td><td>▃▁▂▅▇▇▇▇▇▇▇█▇█▇▇▇▇███▇▇▇██▇█████████████</td></tr><tr><td>train_loss_epoch</td><td>█▇▆▄▃▃▃▃▃▂▃▂▂▂▂▂▃▂▂▂▁▃▂▂▁▁▂▂▂▂▂▁▁▁▂▂▂▂▂▂</td></tr><tr><td>train_loss_step</td><td>█▅▇▄▄▄▅▄▅▄▅▆▄▇▅▄▃▆▄▄▁▃▆▄▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▁▂▄▇▆▅▆█▇▇█▅▇▇▇▇▇▇▇▆▇▇▇▇▆▇▇▇▆▆█▇▆▆▇▆▆▇▇</td></tr><tr><td>val_auc</td><td>▁▂▇▇▆▅▇▇▇▇▅▆▇▅▇▇▇██▇▆▆▇▇▆▇▇▇▇▇▆▇▆▇▇▆▇▇▇▆</td></tr><tr><td>val_f1</td><td>▁▁▂▅▇▆▆▇████▆▇██▇▇█▇▇▇▇█▇▇▇▇▇▇▇██▇▇▇▇▇▇█</td></tr><tr><td>val_loss_epoch</td><td>██▇▅▄▆▆▄▄▄▅▄▄▆▃▃▆▄▄▄▃▄▂▄▅▅▁▄▃▅▄▇▅▅▅▄▄▄▄▅</td></tr><tr><td>val_loss_step</td><td>█▇▇▅▅▅█▄▅▅▅▅▅▇▄▄▄▅▅▅▅▄▁▄▅▆▅▄▃▆▃▄▇▇▅▄▅▄▅▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.74302</td></tr><tr><td>train_auc</td><td>0.76864</td></tr><tr><td>train_f1</td><td>0.6033</td></tr><tr><td>train_loss_epoch</td><td>0.52073</td></tr><tr><td>train_loss_step</td><td>0.53345</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.72368</td></tr><tr><td>val_auc</td><td>0.77245</td></tr><tr><td>val_f1</td><td>0.66929</td></tr><tr><td>val_loss_epoch</td><td>0.58956</td></tr><tr><td>val_loss_step</td><td>0.61596</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/b49j89su' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/b49j89su</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240113_003841-b49j89su\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b1c15b2c13747039e7f03369647659b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666883975, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240113_005511-sw8p6pm6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/sw8p6pm6' target=\"_blank\">GINConv_3_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/sw8p6pm6' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/sw8p6pm6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 5.8 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "6.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.4 K     Total params\n",
      "0.025     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff7b7ad040e44ac5bdeae2a4e10130fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▆▆▇▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇█▇▇▇███</td></tr><tr><td>train_auc</td><td>▁▅▆▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇▇▇██▇█▇██████████████</td></tr><tr><td>train_f1</td><td>▂▁▅▇▇▇▇▇▇▇▇████▇█▇▇▇▇▇█▇▇▇██▇▇▇█▇███████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▃▃▃▂▂▃▃▂▂▂▂▂▂▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▂▁▂▁</td></tr><tr><td>train_loss_step</td><td>▆▅▄▆▆▇▄▂▄▇▅█▄▃▅▆▆▂▁▂▂▄█▄▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▆▃▁▅▆▇▇▇▇▇▆▇██▆▇▇▇▇▆▇▇▇▆█▇▆▆▆▆▇▇▇▇▇▆▆▇▆</td></tr><tr><td>val_auc</td><td>▁▆▆▇▇█▇███▇▇███▇████▇█▇▇▆██▇█▇▇▇█▇▇█▇█▇▇</td></tr><tr><td>val_f1</td><td>▁▇█▇██▇▇▇█▇▇▇██▇▇▇██████▇██▇▇▇▇█████▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>▆▄▅█▅▃▃▄▂▃▃▄▃▃▂▂▂▁▂▄▄▁▁▂▂▂▂▃▂▄▁▃▂▃▂▃▃▃▂▃</td></tr><tr><td>val_loss_step</td><td>▅▅▅█▄▃▃▆▃▃▃▅▃▄▃▃▃▁▃▃▄▁▁▄▄▂▃▃▃▅▃▃▃▃▃▃▄▄▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77422</td></tr><tr><td>train_auc</td><td>0.81936</td></tr><tr><td>train_f1</td><td>0.64146</td></tr><tr><td>train_loss_epoch</td><td>0.48494</td></tr><tr><td>train_loss_step</td><td>0.48782</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.68421</td></tr><tr><td>val_auc</td><td>0.76718</td></tr><tr><td>val_f1</td><td>0.57895</td></tr><tr><td>val_loss_epoch</td><td>0.57308</td></tr><tr><td>val_loss_step</td><td>0.57058</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/sw8p6pm6' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/sw8p6pm6</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240113_005511-sw8p6pm6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40057bfaa1264e4fae86186ae0ed7f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666883975, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240113_011032-tpiz674e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/tpiz674e' target=\"_blank\">GINConv_3_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/tpiz674e' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/tpiz674e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 5.8 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "6.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.4 K     Total params\n",
      "0.025     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd059826197b49b5ad6ac4cd8bfe528c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▃▄▅▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇███▇▇▇</td></tr><tr><td>train_auc</td><td>▁▂▃▄▅▆▆▆▇▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇███▇█</td></tr><tr><td>train_f1</td><td>▄▁▁▃▇▇▇▆▇▇▇▇▇█▇▇▇▇█▇▇▇█▇▇▇█▇█▇██▇█▇██▇█▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▅▄▄▄▃▃▃▃▂▂▂▂▂▃▃▂▂▃▂▂▁▂▂▂▂▂▂▂▂▂▁▁▁▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▇▆█▆▆▄▄▅▅▆▇▅▄▅▆▅▃▁▃▃▄▇▄▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▁▂▅▅▇▆▇▇▇█▆▇▆▆▆▆▇▇▅▆▆█▇▃▇▇▅▄▅▇▇▆▆▅▇▆▅▆▇</td></tr><tr><td>val_auc</td><td>▁▅▅▆▆▇▇█▇▇▇▇███▇█▇███████▇▇▇▇█▇▇▇▇▇█▇▇▇▇</td></tr><tr><td>val_f1</td><td>▁▁▃▆██▇▇▇▇█▇█▇▇▇▇█▇▆▇▇█▇▅▇▇▆▅▆▇▇▇▇▇▇▇▆▇█</td></tr><tr><td>val_loss_epoch</td><td>██▇▆▅▅▄▅▄▄▄▄▄▄▃▃▃▃▄▅▄▂▁▂▄▄▅▄▃▅▂▄▃▃▃▅▄▆▄▃</td></tr><tr><td>val_loss_step</td><td>███▆▆▅▅█▅▅▅▅▅▆▄▆▅▃▆▄▅▃▁▅▆▄▆▆▃▆▅▅▄▄▄▅▅▇▆▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.74056</td></tr><tr><td>train_auc</td><td>0.79221</td></tr><tr><td>train_f1</td><td>0.57979</td></tr><tr><td>train_loss_epoch</td><td>0.51749</td></tr><tr><td>train_loss_step</td><td>0.49597</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.71382</td></tr><tr><td>val_auc</td><td>0.76784</td></tr><tr><td>val_f1</td><td>0.66148</td></tr><tr><td>val_loss_epoch</td><td>0.54869</td></tr><tr><td>val_loss_step</td><td>0.51249</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/tpiz674e' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/tpiz674e</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240113_011032-tpiz674e\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ae83e25601145c2bfb3b1f4250d59dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.017183333332650364, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240113_012600-5i6fkzpf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/5i6fkzpf' target=\"_blank\">GINConv_3_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/5i6fkzpf' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/5i6fkzpf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 5.8 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "6.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.4 K     Total params\n",
      "0.025     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b08077981684bbba9d691148788cfbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▄▄▄▆▆▇▇▇▇▇▇█▇▇█▇▇██▇██▇▇██████████████</td></tr><tr><td>train_auc</td><td>▂▅▄▄▃▂▁▁▁▁▂▂▂▂▃▃▃▂▄▄▄▄▄▅▅▅▆▆▆█▆▇▇▇▇▇█▇▇█</td></tr><tr><td>train_f1</td><td>▁▅▅▂▅▅▆▆▇▆▅▆▇█▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇▇▇▇▇▇██▇</td></tr><tr><td>train_loss_epoch</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▂▂▁▁▂▂▂▂▂▁▂▂▂▁▁▁▁▁▂▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▄▁▅▆█▇▇█▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇▇███▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>val_auc</td><td>▅▇▆▅▄▂▁▁▂▃▃▃▃▃▄▅▆▆▆▇▇▇██████████████████</td></tr><tr><td>val_f1</td><td>▂▂▆▆█▅▄▆▄▂▂▄▃▃▄▃▁▃▂▃▅▅▄▄▁▃▅▆▇▆▁▃▂▂▄▅▅▅▄▄</td></tr><tr><td>val_loss_epoch</td><td>▃█▂▂▂▂▁▂▁▂▁▂▂▂▁▁▁▁▂▂▂▁▁▁▁▁▂▁▂▂▁▁▁▁▁▂▂▂▁▁</td></tr><tr><td>val_loss_step</td><td>▅█▃▃▂▂▂▃▂▂▂▂▂▃▂▂▂▁▂▂▂▁▁▂▂▂▂▂▂▃▂▂▂▂▂▂▂▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.75452</td></tr><tr><td>train_auc</td><td>0.6703</td></tr><tr><td>train_f1</td><td>0.60397</td></tr><tr><td>train_loss_epoch</td><td>0.49758</td></tr><tr><td>train_loss_step</td><td>0.49182</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.69737</td></tr><tr><td>val_auc</td><td>0.77422</td></tr><tr><td>val_f1</td><td>0.62602</td></tr><tr><td>val_loss_epoch</td><td>0.54059</td></tr><tr><td>val_loss_step</td><td>0.48176</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/5i6fkzpf' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/5i6fkzpf</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240113_012600-5i6fkzpf\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb731ad1ac84672a02505c823ff2aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666495924, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240113_014405-o3ecabs6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/o3ecabs6' target=\"_blank\">GINConv_3_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/o3ecabs6' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/o3ecabs6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 5.8 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "6.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.4 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b14106a18bd46ed8b9c91cbf65337ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▆▇▇▇▆▇▇▇▇▇▇▇▇█▇▇█▇██▇███▇█▇█▇██▇█▇███▇</td></tr><tr><td>train_auc</td><td>▁▄▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████▇█████▇████</td></tr><tr><td>train_f1</td><td>▂▁▇█▇█▇▇▇▇▇▇▇▇▇██▇█▇███▇█▇██▇████▇██████</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▃▃▃▃▃▃▂▃▃▃▂▃▂▂▃▂▂▂▂▂▂▂▂▂▁▂▂▂▂▁▂▂▂▂▁▂▂</td></tr><tr><td>train_loss_step</td><td>█▅▅▅▃▃▇▂▃▃▄▆▅▄▅▄▂▂▄▇▂▃▄▁▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▆▁▆▆▇▇▇▇▇▇▇▇▇▇▆▅▇▇▇█▇▇▇▇▆▇█▇▇▇▆█▆▆▆██▇▅</td></tr><tr><td>val_auc</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇█████▆▇▇▇█▇▇██▇█▇▇▇▇█▇█</td></tr><tr><td>val_f1</td><td>▁█▇███▇▇███▇▇█▇▆▆▇█▇▇▇▇▇▇▇██▇▇▇▇█▇▇▇██▇▆</td></tr><tr><td>val_loss_epoch</td><td>█▇█▄▅▄▅▅▂▅▃▅▂▁▄▅▅▄▃▄▁▃▃▃▃▃▂▄▄▄▅▅▃▄▃▄▃▄▃▅</td></tr><tr><td>val_loss_step</td><td>▇▇█▄▅▄▆▆▅▅▄▆▅▁▆▄▄▅▃▄▄▄▄▄▅▄▄▄▆▅▄▄▄▅▄▃▄▆▅▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.75616</td></tr><tr><td>train_auc</td><td>0.82069</td></tr><tr><td>train_f1</td><td>0.62735</td></tr><tr><td>train_loss_epoch</td><td>0.49112</td></tr><tr><td>train_loss_step</td><td>0.51628</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.67105</td></tr><tr><td>val_auc</td><td>0.78485</td></tr><tr><td>val_f1</td><td>0.47917</td></tr><tr><td>val_loss_epoch</td><td>0.61451</td></tr><tr><td>val_loss_step</td><td>0.63468</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/o3ecabs6' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/o3ecabs6</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240113_014405-o3ecabs6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f739d7ede8c9461d913145273230637d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240113_020109-l4po2u6n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/l4po2u6n' target=\"_blank\">GINConv_3_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/l4po2u6n' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/l4po2u6n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 5.8 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "7.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.4 K     Total params\n",
      "0.030     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec6ac30962134d19a59b1e8af9ce4b40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▆▆▆▇▆▆▆▆▇▆▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇█▇█▇▇█▇█▇▇▇</td></tr><tr><td>train_auc</td><td>▁▄▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇██████▇▇███████████</td></tr><tr><td>train_f1</td><td>▂▁▅▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇█▇▇██▇█████████▇██</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▃▂▁▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▁▂</td></tr><tr><td>train_loss_step</td><td>▇▅▄▃▃▃█▄▃▄▄▅▄▄▅▂▄▃▁▃▃▁▂▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▃▂▁▆▇▇▇▇▇▆▇▇▇█▇▇▆▇▆▇▇▆▆▇█▇▆▆▇█▆▇▇▆▇▇▇▆▇</td></tr><tr><td>val_auc</td><td>▁▃▄▅▇▇▇▇▆▇▆▇█▇▇▇▆▆▇▇▆▇▇▆██▇▅▆▇█▇▇▇▇▆▅█▅▇</td></tr><tr><td>val_f1</td><td>▁▄▇▇████▇▇▇▇▇██▇▇▇▇▇█▇▇▇███▇▇▇█▇██▇█▇▇▇█</td></tr><tr><td>val_loss_epoch</td><td>▆▅▆█▅▄▂▃▃▂▄▁▄▂▄▃▂▅▂▂▃▂▄▂▄▂▃▆▄▁▅▁▂▁▃▅▅▃▃▂</td></tr><tr><td>val_loss_step</td><td>▇▆▇▇▄▄▂▅▄▅▆▁▃▃▆▄▅█▃▄▄▂▆▄▄▃▄▃▇▁▅▅▂▁▄▄▇▅▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.76847</td></tr><tr><td>train_auc</td><td>0.81431</td></tr><tr><td>train_f1</td><td>0.64838</td></tr><tr><td>train_loss_epoch</td><td>0.50191</td></tr><tr><td>train_loss_step</td><td>0.48527</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.72368</td></tr><tr><td>val_auc</td><td>0.77984</td></tr><tr><td>val_f1</td><td>0.66667</td></tr><tr><td>val_loss_epoch</td><td>0.54745</td></tr><tr><td>val_loss_step</td><td>0.53047</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/l4po2u6n' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/l4po2u6n</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240113_020109-l4po2u6n\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9556c90aa3c4a1195bb0f8e2752a57e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240113_021705-h4x0zdjp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/h4x0zdjp' target=\"_blank\">GINConv_3_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/h4x0zdjp' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/h4x0zdjp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 21.8 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "24.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.0 K    Total params\n",
      "0.096     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c51f4112936496587db478b18f125f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▆▆▇▆▆▆▇▇▇▇▇▇▆▇▇▇▇▇█▇▇▇▇▇▆█▇▇▇▇█▇▇█▇█</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▇▇▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇████▇███</td></tr><tr><td>train_f1</td><td>▁▆▆▇▆▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇███▇█▇█▇█▇▇▇██▇████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▃▂▂▂▁▁▁▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>██▃▆▃▃▂▆▆▆▃▄▂▃▃▄▁▄▅▂▁▂▄▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▁▇▇█▇▇▇█▇▇█▇▇▇▇▇▇▇▇█▆▇▇▇█▇█▆▇▇▆▇▇▅▇▇▆▆▇</td></tr><tr><td>val_auc</td><td>▁▆▆▇██▅▇▆▇▆▇▇▇█▇▆▄█▇█▇▇████▇▇██▆▄▇▃▇▆▇▇▅</td></tr><tr><td>val_f1</td><td>▆▆▇▆█▇▅▆▅▄▄▆▅▅▅▄▆▄▅▆▆▁▆▅▄▆▄▇▃▅▅▄▆▅▁▅▆▂▂▅</td></tr><tr><td>val_loss_epoch</td><td>▇█▃▃▃▃▂▃▃▃▃▃▄▂▃▃▃▂▃▃▂▆▃▂▁▁▂▃▄▃▃▃▄▂▅▂▄▄▃▃</td></tr><tr><td>val_loss_step</td><td>▅█▄▄▄▃▂▄▄▄▄▄▃▃▄▃▄▂▃▃▄▇▃▃▄▁▃▄▅▄▄▄▅▃▄▄▄▅▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77997</td></tr><tr><td>train_auc</td><td>0.8348</td></tr><tr><td>train_f1</td><td>0.68322</td></tr><tr><td>train_loss_epoch</td><td>0.46691</td></tr><tr><td>train_loss_step</td><td>0.46004</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.70395</td></tr><tr><td>val_auc</td><td>0.75845</td></tr><tr><td>val_f1</td><td>0.625</td></tr><tr><td>val_loss_epoch</td><td>0.58621</td></tr><tr><td>val_loss_step</td><td>0.57358</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/h4x0zdjp' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/h4x0zdjp</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240113_021705-h4x0zdjp\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfd6b80e962a4d6ab8daac299173f2bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240113_023252-2p1sckn3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/2p1sckn3' target=\"_blank\">GINConv_3_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/2p1sckn3' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/2p1sckn3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 21.8 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "24.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.0 K    Total params\n",
      "0.096     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cd6055eef254eb088ac1bb117a46123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▅▅▆▆▆▅▆▇▆▇▆▆▇▇▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇█</td></tr><tr><td>train_auc</td><td>▁▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇█▇███████</td></tr><tr><td>train_f1</td><td>▁▅▅▆▆▆▆▇▆▆▇▇▇▇▇▇▇▆▇▇▆▇▇▇▇▇▇▇█▇▇▇█▇█▇▆█▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▃▃▃▃▃▃▃▃▃▃▂▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▄▆▃▂▂▃▅█▄▄▂▂▂▃▁▄▄▄▁▃▃▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▅▁▇▇▇▅▅▆▇▅▅▇▅▆▇▆▆█▆▅▆▆▆▇▆▆▇█▆▇▆▅▆▆▆▇▆▇▆</td></tr><tr><td>val_auc</td><td>▁▅▅▇▆▆▅▆▆█▇▇▇▇▆▆▅▆█▇▇▆▅▅▇▇▆▇██▅▆▆▆▅▅▆▄▅▄</td></tr><tr><td>val_f1</td><td>▇█▇█▅▅▃▃▅▆▁▃▅▂▅█▆▅█▄▂▅▄▅▆▅▅▆▇▅▆▅▃▅▅▆▇▆▆▄</td></tr><tr><td>val_loss_epoch</td><td>█▅█▄▃▄▃▅▃▃▇▃▄▄▄▄▃▂▃▇▃▅▃▃▂▁▃▃▅▃▂▃▃▃▇▃▃▅▃▅</td></tr><tr><td>val_loss_step</td><td>▇▆▆▆▅▅▃▆▅▄█▅▅▄▆▅▅▂▅▅▆▇▄▅▆▁▅▅▇▅▅▅▃▃▅▅▄▇▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77668</td></tr><tr><td>train_auc</td><td>0.82703</td></tr><tr><td>train_f1</td><td>0.6699</td></tr><tr><td>train_loss_epoch</td><td>0.46924</td></tr><tr><td>train_loss_step</td><td>0.46939</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.6875</td></tr><tr><td>val_auc</td><td>0.74981</td></tr><tr><td>val_f1</td><td>0.54106</td></tr><tr><td>val_loss_epoch</td><td>0.62361</td></tr><tr><td>val_loss_step</td><td>0.58411</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/2p1sckn3' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/2p1sckn3</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240113_023252-2p1sckn3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a8f35b64834d2eb475ecd1ed25fee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240113_024913-5dn391m7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/5dn391m7' target=\"_blank\">GINConv_3_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/5dn391m7' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/5dn391m7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 21.8 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "24.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.0 K    Total params\n",
      "0.096     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cab7533643c2446989707be2b7e07201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▂▃▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇█████▇███▇██</td></tr><tr><td>train_auc</td><td>▁▅▄▆▄▄▅▅▆▅▆▆▇▆▆▄▇▆▇▆▅▆█▆▅▅▅▆▇▅▅▇▅▅▄▄▄▅▆▃</td></tr><tr><td>train_f1</td><td>▂▆▁▅▃▅▇▇▅▆▇▇▆▆▇█▆▇█▇▇██▇▇▇▇▇██▇███▇██▇██</td></tr><tr><td>train_loss_epoch</td><td>█▃▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▃▁▇▆▇███▇▇▇█▇▆██▇▇▇▇█▇▇▇█▇▇▇▇▇▇▆▇▆▇▇▇▆▇▇</td></tr><tr><td>val_auc</td><td>▁▄▄▃▁▅▅▅▇▇▇█▅▅▅▅▅▅▅▅▅▅▅▅▅▅▆▅▅▅▅▄▆▆▇▇▆▆▇▆</td></tr><tr><td>val_f1</td><td>▁▆▃▇▄▇██▄▅▆▆▅▄▆▇▅▇▅▅▆▅▆▅▇▅▃▅▆▅▆▄▆▅▅▆▅▄▆▆</td></tr><tr><td>val_loss_epoch</td><td>██▃▄▂▃▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▇▂▄▂▂▁▂▂▂▂▂▁▁▂▁▂▁▂▁▂▂▁▁▂▁▂▂▂▁▂▂▂▁▂▂▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.76601</td></tr><tr><td>train_auc</td><td>0.63485</td></tr><tr><td>train_f1</td><td>0.62939</td></tr><tr><td>train_loss_epoch</td><td>0.49367</td></tr><tr><td>train_loss_step</td><td>0.51613</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.71711</td></tr><tr><td>val_auc</td><td>0.77409</td></tr><tr><td>val_f1</td><td>0.65041</td></tr><tr><td>val_loss_epoch</td><td>0.56064</td></tr><tr><td>val_loss_step</td><td>0.54819</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/5dn391m7' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/5dn391m7</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240113_024913-5dn391m7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "174be15957cb4fcb9990e5fd8153409a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240113_030706-996vxkfb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/996vxkfb' target=\"_blank\">GINConv_3_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/996vxkfb' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/996vxkfb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 21.8 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "24.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.0 K    Total params\n",
      "0.096     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▅▆▆▆▆▆▆▆▆▆▇▇▆▆▇▇▇▇▇▇▇▆▇▇█▇▇▇▇█▇██▇█▇█</td></tr><tr><td>train_auc</td><td>▁▆▅▅▆▆▆▆▆▆▆▆▇▇▇▇▆▆▇▇▇▇▇▇▇▇▇██▇██████████</td></tr><tr><td>train_f1</td><td>▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇█▇█▇█▇██▇██▇█▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▄▅▅▄▃▄▄▄▃▃▄▃▃▃▃▃▃▃▃▃▂▃▃▂▂▂▂▂▂▂▂▁▁▁▂▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>▄▆▄█▃▃▄▆▅▅▆▆▆▆▂▄▂▅▂▄▃▄▂▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▃▆▇▇▇▇▇▇▇▇▇▇▇▆▇▇▅▅▇▇▆███▇▆▆▇▆▆▇▇▇▆▅▇▆▆▆</td></tr><tr><td>val_auc</td><td>▁▆▅▆▆▅▅▇▆▆▆▇▅▅▄▆▄▅▆▆▅▄▆▅█▅▆▇▆▄▄▄▆▅▄▄▆▃▆▅</td></tr><tr><td>val_f1</td><td>▆▆▇▇▇█▇▅▇▆▆▅▅▆▆▅▇▂▁▆▆▄▇██▇▃▃▆▃▅▆▆▆▄▂▆▅▅▅</td></tr><tr><td>val_loss_epoch</td><td>█▆▃▁▂▃▃▃▂▁▂▂▁▂▃▃▂▄▅▂▁▄▂▃▃▂▃▄▂▁▄▄▃▆▄▅▁▄▁▄</td></tr><tr><td>val_loss_step</td><td>▆▆▃▂▃▃▄▄▃▃▄▃▃▃▄▃▃▄▅▃▃▅▄▄▂▂▄▄▃▁▃▄▄█▅▃▁▅▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77504</td></tr><tr><td>train_auc</td><td>0.84362</td></tr><tr><td>train_f1</td><td>0.6514</td></tr><tr><td>train_loss_epoch</td><td>0.46202</td></tr><tr><td>train_loss_step</td><td>0.42804</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.68092</td></tr><tr><td>val_auc</td><td>0.77178</td></tr><tr><td>val_f1</td><td>0.56502</td></tr><tr><td>val_loss_epoch</td><td>0.63489</td></tr><tr><td>val_loss_step</td><td>0.66261</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/996vxkfb' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/996vxkfb</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240113_030706-996vxkfb\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "675e7ed9b4784f359dc89367bbf6a9c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240113_032536-9atsurw1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/9atsurw1' target=\"_blank\">GINConv_3_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/9atsurw1' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/9atsurw1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 21.8 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "28.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "28.2 K    Total params\n",
      "0.113     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96cf1f52f4ca490da1bc94ccea3ef03c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▄▅▆▆▆▇▆▆▆▆▆▇▆▆▆▆▇▆▇▆▆▇▇▇▇▇▇▇▆▇▇█▇▇█▆█</td></tr><tr><td>train_auc</td><td>▁▅▅▅▆▆▆▆▆▆▆▆▇▆▆▆▇▇▆▇▇▇▆▇▇▇▇▇▇▇█▇▇▇█▇██▇█</td></tr><tr><td>train_f1</td><td>▁▇▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇▇█▇█▇█▇█▇▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▅▄▄▄▄▃▄▃▄▃▃▃▃▃▃▃▂▂▃▃▃▃▃▂▂▂▂▂▂▂▂▁▂▁▂▂▁</td></tr><tr><td>train_loss_step</td><td>▇▆▅▇▅█▇▅▇▄▄▅▃▇▃▆▄▄▃▄▅▃▁▄▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▆▇██▅▅▇▇▆▆▇▇▇█▇▇▇█▆▇▇▆█▇▇█▇▆▇▇▆██▇▇▆▆▆▇</td></tr><tr><td>val_auc</td><td>▆▃▅█▆▆▆▆▆█▆█▆▇▆▆▇▇▅▇▅▇▁▇▄▇▆▆▄▄▇▁▆▇▅▅▅▃▅▅</td></tr><tr><td>val_f1</td><td>▆▇▇█▇▁▁▆▇▄▄▆▅▅█▆▆█▇▄▆▇▆█▆▆█▆▅▆▆▄█▇▅▆▅▄▅▆</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▂▂▅▆▃▄▃▃▁▃▄▂▃▄▄▃▃▃▁▄▄▃▃▂▅▃▃▃▃▂▂▄▅▂▃▄▃</td></tr><tr><td>val_loss_step</td><td>█▆▅▃▅▆█▄▄▅▄▁▅▆▃▄▄▇▄▄▄▁▅▅▅▆▄▅▄▅▆▅▃▄▄▆▂▃▅▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.78489</td></tr><tr><td>train_auc</td><td>0.83596</td></tr><tr><td>train_f1</td><td>0.67168</td></tr><tr><td>train_loss_epoch</td><td>0.45828</td></tr><tr><td>train_loss_step</td><td>0.42337</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.69737</td></tr><tr><td>val_auc</td><td>0.76443</td></tr><tr><td>val_f1</td><td>0.61345</td></tr><tr><td>val_loss_epoch</td><td>0.57751</td></tr><tr><td>val_loss_step</td><td>0.52641</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/9atsurw1' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/9atsurw1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240113_032536-9atsurw1\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1f34face6cf48b9b79488e9d0203647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240113_034144-b1q4sfl7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/b1q4sfl7' target=\"_blank\">GINConv_4_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/b1q4sfl7' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/b1q4sfl7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 2.2 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bab74d55fa3b4091a01d112c75101bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▇▇▇▇▇▇▇▇▇█▇██▇███▇██████████████████</td></tr><tr><td>train_auc</td><td>▁▂▃▄▆▇▇▇▇▇█▇▇█▇██████▇█▇████████████████</td></tr><tr><td>train_f1</td><td>▅▃▁▄▇▇▇▆▆▇▇▇▇█▇██▇▇▇█▇▇▇▇█▇▇██▇█▇▇███▇██</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▁▁▂▂▂▁▁▂▂▁▂▁▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▇█▄▄▃▂▂▃▂▅▄▃▃▄▃▁▃▃▁▃▆▂▄▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▆▁▃▃▄▆▆████▇▇█▇▆▇▇▆▇▆▆▆▇▄▆▆▆▇▇▇█▇▆▇▇▇▇▅▆</td></tr><tr><td>val_auc</td><td>▁▄▄▆▅▆▇▆██▇▇▇██▇████▇▇▆▇▆▇▇▇▇▇▆▇▇▆▆▅▇▇▆▆</td></tr><tr><td>val_f1</td><td>█▁▃▃▅▇▇████▇▇█▇▇█▇▇▇▇▇▇▇▆▇▇▇██▇█▇▇▇▇▇▇▆▇</td></tr><tr><td>val_loss_epoch</td><td>█▇▇▅▆▄▃▂▅▂▃▃▂▃▂▃▄▃▅▃▂▆▄▃▅▄▃▃▄▃▂▃▁▄▃▃▄▁▄▃</td></tr><tr><td>val_loss_step</td><td>▇▇▇▅▆▆▄▂▄▅▅▄▅▄▃▄▄▄▇▅▅█▅▅▅▆▅▄▆▄▄▄▁▅▅▅▅▁▅▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.74548</td></tr><tr><td>train_auc</td><td>0.79492</td></tr><tr><td>train_f1</td><td>0.61153</td></tr><tr><td>train_loss_epoch</td><td>0.50782</td></tr><tr><td>train_loss_step</td><td>0.52216</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.68421</td></tr><tr><td>val_auc</td><td>0.76545</td></tr><tr><td>val_f1</td><td>0.55963</td></tr><tr><td>val_loss_epoch</td><td>0.56353</td></tr><tr><td>val_loss_step</td><td>0.52541</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/b1q4sfl7' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/b1q4sfl7</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240113_034144-b1q4sfl7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cd2ed421a0649d9aaf0dc9399e64317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240113_035721-7t2oz1hn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/7t2oz1hn' target=\"_blank\">GINConv_4_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/7t2oz1hn' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/7t2oz1hn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 2.2 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de71ae29da9a44ecb2cd73f1a4bb134e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇█████▇█▇▇█▇▇▇█</td></tr><tr><td>train_auc</td><td>▁▁▂▂▄▅▅▆▆▆▇▇▆▇▆▇▇▇▇▇▇▇▇▇███▇█▇█▇█▇█▇▇▇██</td></tr><tr><td>train_f1</td><td>▄▁▁▃▄▆▅▅▅▆▆▆▇▆▆▆▇▇▆▆▇▇▇▇▇▇█▇███▇▇▇▇▇▆▆▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▅▄▃▃▃▃▃▂▂▂▃▂▂▂▁▂▂▂▂▂▂▁▁▂▂▂▂▂▂▂▁▂▂▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▆▇▅▆▃▂▃▄▃▅▅▄▃▅▄▁▄▃▃▅▆▄▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▄▅▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████▇▇▇▇▇▇▇█▇▇▇▇█▇</td></tr><tr><td>val_auc</td><td>▂▁▁▄▆▆▆▆▇▇▇▆▇▇▇▇▇▇███████▇▇▇▇▇▇▇██▇█▇▇██</td></tr><tr><td>val_f1</td><td>▇▁▃▄▅▇▇▇▇▇▇█▇▇▇▇▇▇▆▇██████▇▇▇▇▇▇▇██▇▇▇█▇</td></tr><tr><td>val_loss_epoch</td><td>█▇▇▆▄▃▃▁▃▂▂▂▁▃▂▂▄▃▃▂▁▄▃▂▃▃▂▃▃▂▂▃▂▃▂▃▃▂▃▁</td></tr><tr><td>val_loss_step</td><td>█▇▇▆▅▄▃▁▄▄▃▃▄▄▂▄▄▅▅▄▄▇▄▄▄▄▄▃▅▃▄▄▂▅▄▄▄▂▄▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.72742</td></tr><tr><td>train_auc</td><td>0.76978</td></tr><tr><td>train_f1</td><td>0.56201</td></tr><tr><td>train_loss_epoch</td><td>0.5403</td></tr><tr><td>train_loss_step</td><td>0.55076</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.71053</td></tr><tr><td>val_auc</td><td>0.7868</td></tr><tr><td>val_f1</td><td>0.57282</td></tr><tr><td>val_loss_epoch</td><td>0.54692</td></tr><tr><td>val_loss_step</td><td>0.50627</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/7t2oz1hn' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/7t2oz1hn</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240113_035721-7t2oz1hn\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91b3af50013b47aeab59ee4ed4463f04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666883975, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240113_041248-fgjgx2vh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/fgjgx2vh' target=\"_blank\">GINConv_4_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/fgjgx2vh' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/fgjgx2vh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 2.2 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dbd3ef214ab419fac86da83c32ac82d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▃▃▃▃▄▄▅▅▅▆▇▆▆▆▇▇▆▇█▇▇▇▇▇▇▇▇▇██▇▇██▇▇▇▇</td></tr><tr><td>train_auc</td><td>▇▇▇█▆▆▇▇▆▆▆▆▅▅▅▅▄▃▄▃▃▃▂▃▃▂▂▃▂▁▂▂▂▁▂▁▂▂▁▁</td></tr><tr><td>train_f1</td><td>▂▁▄▅▃▄▄▅▅▅▅▅▆▆▄▄▅▅▄▅█▆▆▆▅▆▆▅▆▆▆▆▆▆▇▇▆▅▆▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▃▆▅▁████▇█▇▆▇▇▆▆▇▇▇▇▇▇▆▇█▇▇▆██▇████▇▆▆▇█</td></tr><tr><td>val_auc</td><td>▇██▆▄▄▅▅▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_f1</td><td>▆▂▇▆▇█▇▅▄▅▂▁▄▄▂▁▂▂▂▂▄▄▃▃▄▄▃▃▅▅▄▅▅▅▅▄▃▃▅▅</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▂▂▁▂▁▂▁▂▂▁▂▁▁▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▄▄▃▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▃▂▂▂▂▂▂▂▁▂▂▁▂▂▂▂▁▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.72414</td></tr><tr><td>train_auc</td><td>0.25312</td></tr><tr><td>train_f1</td><td>0.56589</td></tr><tr><td>train_loss_epoch</td><td>0.53247</td></tr><tr><td>train_loss_step</td><td>0.56735</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.68421</td></tr><tr><td>val_auc</td><td>0.2241</td></tr><tr><td>val_f1</td><td>0.57522</td></tr><tr><td>val_loss_epoch</td><td>0.57348</td></tr><tr><td>val_loss_step</td><td>0.56102</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/fgjgx2vh' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/fgjgx2vh</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240113_041248-fgjgx2vh\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa8142186794590a719fdef2ded682c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333330477276, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240113_042807-9gnxzlsc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/9gnxzlsc' target=\"_blank\">GINConv_4_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/9gnxzlsc' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/9gnxzlsc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 2.2 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "2.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "472cf56507444cb9acc075536402c99f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▇▆▇▇▇▇▇▇▇▇▇████▇██▇████████▇█▇██████</td></tr><tr><td>train_auc</td><td>▁▂▃▅▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇██▇█████▇▇▇██████</td></tr><tr><td>train_f1</td><td>▅▂▁▅▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▆▇▇██▇█▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▃▃▃▃▃▃▂▃▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>▇█▅▅▃▆▅▃▆▄▄▅▅▃▄▆▂▅▃▅▄▄▄▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▅▁▂▃▅▇▄▄▇▇█▇▇▇▇▆▇▆▇▇▇▇▇▇▇▆▇▇██▇▇▇▇▇▇▆▇▇▇</td></tr><tr><td>val_auc</td><td>▁▄▇█▇▇▇▇██▇█▇█▇▇▇▇██▇▇▇██▇▇▇▇████▇██▇▇██</td></tr><tr><td>val_f1</td><td>▆▁▂▄▆▇▅▅▇██▇▇█▇▇▇▇▇█████▇▇█████▇███▇▇██▇</td></tr><tr><td>val_loss_epoch</td><td>█▆▅▆▅▄▄█▄▂▃▄▁▃▅▃▂▄▄▃▄▄▂▄▃▃▂▂▄▄▃▄▃▂▄▆▃▄▃▄</td></tr><tr><td>val_loss_step</td><td>▇▇▃▇▆▆▂█▅▄▃▅▅▃▇▄▄▄▄▃▄▄▁▄▄▃▄▄▅▅▃▅▃▁▃▄▃▅▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.74548</td></tr><tr><td>train_auc</td><td>0.80472</td></tr><tr><td>train_f1</td><td>0.58667</td></tr><tr><td>train_loss_epoch</td><td>0.50685</td></tr><tr><td>train_loss_step</td><td>0.46189</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.70724</td></tr><tr><td>val_auc</td><td>0.78007</td></tr><tr><td>val_f1</td><td>0.62128</td></tr><tr><td>val_loss_epoch</td><td>0.58251</td></tr><tr><td>val_loss_step</td><td>0.60858</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/9gnxzlsc' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/9gnxzlsc</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240113_042807-9gnxzlsc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9165e426016f430392e9c6c95e214a6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666495924, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240113_044409-p4rrbqb5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/p4rrbqb5' target=\"_blank\">GINConv_4_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/p4rrbqb5' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/p4rrbqb5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 2.2 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "2.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.7 K     Total params\n",
      "0.011     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d44a0e2582754999afba1b025faddc89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▇▇▇▇▇▇▇▇▇█▇▇█▇▇▇█▇▇██████▇██▇█▇████▇</td></tr><tr><td>train_auc</td><td>▁▂▃▅▆▇▇▇▇█▇▇▇█▇▇▇▇▇██▇████▇██▇██████████</td></tr><tr><td>train_f1</td><td>▃▁▁▃▇▆▆▇▆▆▆▇▆██▇█▆▇█▇▇▆▇▇█▇▇█▆▇▇▇▇▆█▇▇▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▃▃▂▃▂▂▂▂▂▂▂▃▂▂▂▂▂▂▂▁▂▂▂▂▂▂▁▂▂▁▂▂▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▅▄▆▅▂▅▅▆▄▅▄▅▂▆▃▅▃▁▄▂▅▁▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▆▁▂▃▇█▇▆▇▇▇▇▆▇█▇████▇▇█▇▆▆▇▇▆▆▆▇▅▇▇▇▇▇█▇</td></tr><tr><td>val_auc</td><td>▁▅▅▆▇▇▇▇▆▇▇▇▇▇▇▇████▇█▇█▇▇▇▇█▇████████▇█</td></tr><tr><td>val_f1</td><td>▇▁▂▃▇▇▇▆▇██▇▇▇█▇█████▇█▇▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▇▇▅▃▄▅▆▄▃▃▁▃▄▃▃▄▂▃▄▅▃▃▃▅▄▃▄▃▃▄▁▃▅▃▁▃▃▅▂</td></tr><tr><td>val_loss_step</td><td>█▇█▅▄▄▆▇▄▄▄▁▄▆▄▄▄▃▄▄▄▄▃▅▄▅▄▃▅▄▄▄▄▇▄▄▄▅▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.73974</td></tr><tr><td>train_auc</td><td>0.78366</td></tr><tr><td>train_f1</td><td>0.59618</td></tr><tr><td>train_loss_epoch</td><td>0.5227</td></tr><tr><td>train_loss_step</td><td>0.51905</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.71053</td></tr><tr><td>val_auc</td><td>0.77896</td></tr><tr><td>val_f1</td><td>0.64228</td></tr><tr><td>val_loss_epoch</td><td>0.55253</td></tr><tr><td>val_loss_step</td><td>0.5385</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/p4rrbqb5' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/p4rrbqb5</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240113_044409-p4rrbqb5\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ee98c0fe1e3442a99af57aaae449053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333330477276, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240113_050216-pw5yfuit</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/pw5yfuit' target=\"_blank\">GINConv_4_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/pw5yfuit' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/pw5yfuit</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 8.0 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "8.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.6 K     Total params\n",
      "0.034     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca8ffb05d09e459a95edf204305086c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▇▇▇▆▇▇▇▇▇▇▇▇▇██▇▇▇▇▇▇██████▇█████▇▇██</td></tr><tr><td>train_auc</td><td>▁▅▆▇▇▇▇▇▇▇▇▇▇▇▇████▇▇▇▇▇█▇▇█████████████</td></tr><tr><td>train_f1</td><td>▄▁▅▇█▇▇▇▇█▇█▇▇▇▇███▇▇▇▇▇████████▇███▇███</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▂▂▁▂▁▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>▆▅▅█▃▂▄▄▂▆▁▂▃▅▂▅▆▁▃▂▄▃▄▇▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▁▅▂▆▆▇▇▇▇▆▇▇▇▇▇▆▅▇▇▆▆▇▆▆▆▇▇▇▇▇▇█▆▆▆█▇▇▇</td></tr><tr><td>val_auc</td><td>▁▅▅▆▇▇▇▆▇▇▆▇█▇▆█▇█▇▇▇▇█▆▇▇▇▇▇▇█▇▇▆▇▇▇▇█▇</td></tr><tr><td>val_f1</td><td>▁▁███████▇▇▇██▇▇▇▆▇▇▇▇█▇▇▇█▇█▇▇▇█▇▇▇██▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▇▅█▃▇▂▂▃▅▃▂▁▂▃▃▂▅▂▂▂▃▃▂▄▂▅▅▃▃▁▃▁▄▃▃▁▄▂▃</td></tr><tr><td>val_loss_step</td><td>▇▇▅█▅▄▃▂▄▄▃▂▄▂▂▄▅▆▂▄▄▄▄▃▄▃▃▄▃▃▄▄▁▅▄▄▁▆▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.76437</td></tr><tr><td>train_auc</td><td>0.82064</td></tr><tr><td>train_f1</td><td>0.64871</td></tr><tr><td>train_loss_epoch</td><td>0.48422</td></tr><tr><td>train_loss_step</td><td>0.4749</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.72368</td></tr><tr><td>val_auc</td><td>0.78733</td></tr><tr><td>val_f1</td><td>0.63158</td></tr><tr><td>val_loss_epoch</td><td>0.56158</td></tr><tr><td>val_loss_step</td><td>0.56942</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/pw5yfuit' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/pw5yfuit</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240113_050216-pw5yfuit\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f00ea8b64ad44535bed1646c971fae6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666883975, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240113_051809-cgdmzneu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/cgdmzneu' target=\"_blank\">GINConv_4_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/cgdmzneu' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/cgdmzneu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 8.0 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "8.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.6 K     Total params\n",
      "0.034     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36cd4cdb4199465d8d9adc7b4ae19a98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▅▅▆▆▆▆▇▇▇▇█▇▇▇█▇██▇▇▇█▇██▇███████▇▇██</td></tr><tr><td>train_auc</td><td>▁▃▃▅▆▆▆▆▆▆▆▇▆▇▇▇█▇██▇▇▇▇██▇▇█▇▇█▇█▇██▇▇█</td></tr><tr><td>train_f1</td><td>▄▁▂▃▆▇▇▇▆▇▇▇▇██▇██▇██▇▇████▇█▇██████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▃▃▃▃▂▂▂▂▂▁▂▂▂▁▂▂▂▂▁▁▂▁▁▁▁▁▁▂▁▂▁▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▆▇▄▃▅▅▂▆▂▂▄▅▂▇▅▁▅▂▄▃▆▆▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▁▁▄▆▅▅▇▆▇█▇▆██▇▇▇▇▇▄▅▇▅▇▅▅▅▆▅▇▆▇▇▅▅▄▄▃▆</td></tr><tr><td>val_auc</td><td>▁▅▇▇▇███████████████████████████████████</td></tr><tr><td>val_f1</td><td>▁▁▁▆▇███▇██▇▆██▇█▇▇█▅▆▇▇▇▆▆▆▇▆█▇██▇▆▆▅▄▇</td></tr><tr><td>val_loss_epoch</td><td>██▆▅▄▆▃▃▃▄▁▁▂▂▂▃▂▄▃▂▂▃▄▄▃▃▅▆▂▃▂▃▁▃▄▂▂▄▄▄</td></tr><tr><td>val_loss_step</td><td>██▆▅▅▅▄▄▄▃▁▁▅▂▂▄▄▇▄▅▆▂▅▄▄▄▄▄▃▄▄▄▁▄▄▄▂▆▅▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.7422</td></tr><tr><td>train_auc</td><td>0.74678</td></tr><tr><td>train_f1</td><td>0.61893</td></tr><tr><td>train_loss_epoch</td><td>0.5175</td></tr><tr><td>train_loss_step</td><td>0.48751</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.70066</td></tr><tr><td>val_auc</td><td>0.76647</td></tr><tr><td>val_f1</td><td>0.62857</td></tr><tr><td>val_loss_epoch</td><td>0.59843</td></tr><tr><td>val_loss_step</td><td>0.6339</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/cgdmzneu' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/cgdmzneu</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240113_051809-cgdmzneu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c72a5404fc91444d9b19a61352bf610d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240113_053459-vln9x18s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/vln9x18s' target=\"_blank\">GINConv_4_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/vln9x18s' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/vln9x18s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 8.0 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "8.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.6 K     Total params\n",
      "0.034     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e5d04c13ad3413bb058a2898fef5713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▃▄▄▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█████▇█▇███</td></tr><tr><td>train_auc</td><td>▁▇▂▅▃▇▆▇▆▅▅▅▃▃▅▃▄▆▆▃▆▅▄▇▆▅▇▄▆▆▇▅▄▇█▅▄▄▃▂</td></tr><tr><td>train_f1</td><td>▁▄▅▄▄▆▅▄▅▆▆▇▇▇▇▇▇▆▇▇▇▇▇▇▆▇▇▇▇▇██▇▇▇█▇███</td></tr><tr><td>train_loss_epoch</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▄▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▃▆▇▆▇█▇██▇▇▇████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇</td></tr><tr><td>val_auc</td><td>▁▂▁▁▆▇▇▆▆▆▆▅▃▃▃▄▄▄▆▆▇▇▇████████████▇▇▄▂▅</td></tr><tr><td>val_f1</td><td>▁▆▄▅▇█▇▄▇▇▅▅▅▆▇▇▆▅▅▅▅▄▅▆▅▆▆▆▅▅▅▅▄▆▅▅█▆▅▆</td></tr><tr><td>val_loss_epoch</td><td>▇█▆▅▃▃▂▄▃▂▂▁▁▁▂▂▁▃▂▂▁▂▂▂▂▁▂▂▂▁▁▂▁▂▂▂▁▂▁▂</td></tr><tr><td>val_loss_step</td><td>█▄▃▂▄▂▂▄▃▂▂▁▃▁▃▃▃▅▃▃▃▂▃▂▂▁▂▃▃▁▃▂▁▂▂▂▂▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.75041</td></tr><tr><td>train_auc</td><td>0.48532</td></tr><tr><td>train_f1</td><td>0.60825</td></tr><tr><td>train_loss_epoch</td><td>0.50698</td></tr><tr><td>train_loss_step</td><td>0.51238</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.70724</td></tr><tr><td>val_auc</td><td>0.63189</td></tr><tr><td>val_f1</td><td>0.63071</td></tr><tr><td>val_loss_epoch</td><td>0.60457</td></tr><tr><td>val_loss_step</td><td>0.63061</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/vln9x18s' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/vln9x18s</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240113_053459-vln9x18s\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0db505c6060440481328342b2cfd2d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333330477276, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240113_055351-la43zhqc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/la43zhqc' target=\"_blank\">GINConv_4_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/la43zhqc' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/la43zhqc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 8.0 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "8.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.6 K     Total params\n",
      "0.035     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b2325bf895141d9ae1346bf3ef3b98c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇▇█▇▇▇▆▇▇█▇█▇██▇█</td></tr><tr><td>train_auc</td><td>▁▄▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇▇█████████</td></tr><tr><td>train_f1</td><td>▄▁▆▇▇▇▇▇▇█▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇██▇███</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▄▃▃▃▃▃▃▂▃▂▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▁▁▂▂▂▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▄▇▅▅▅▃▄▆▄▅▄▂▆▃▅▄▅▄▄▃▁▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▂▆▁▇▇▇▇█▇████▇▇▇▇█▇█▇▇▆▇▇▇█▇▇██▇▇▆▆▇▇█▇▇</td></tr><tr><td>val_auc</td><td>▁▆▇▇█▇█▇█▇█▇▇▇██████████████████▇▇████▇▇</td></tr><tr><td>val_f1</td><td>▁▇▇█▇▇▇█▇█████▇▇█▇██▇▇▆▇▇▇█▇██▇▇▇▆▆█▇██▇</td></tr><tr><td>val_loss_epoch</td><td>█▆█▅▃▃▆▃▃▃▂▃▃▃▄▂▂▂▃▃▅▁▆▄▂▃▃▂▁▄▃▁█▄▇▃▂▃▃▂</td></tr><tr><td>val_loss_step</td><td>▅▅▆▅▃▄▇▄▃▃▂▃▄▃▄▃▃▂▄▃▃▂▆▃▄▃▃▃▁▅▃▄█▃▃▄▂▃▄▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.7775</td></tr><tr><td>train_auc</td><td>0.8276</td></tr><tr><td>train_f1</td><td>0.66667</td></tr><tr><td>train_loss_epoch</td><td>0.4817</td></tr><tr><td>train_loss_step</td><td>0.45644</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.70395</td></tr><tr><td>val_auc</td><td>0.76762</td></tr><tr><td>val_f1</td><td>0.64286</td></tr><tr><td>val_loss_epoch</td><td>0.55194</td></tr><tr><td>val_loss_step</td><td>0.50998</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/la43zhqc' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/la43zhqc</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240113_055351-la43zhqc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "554bd4b7b6fb4daf81470cf9d4e40c74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333330477276, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240113_061028-ntpuldy9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/ntpuldy9' target=\"_blank\">GINConv_4_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/ntpuldy9' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/ntpuldy9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 8.0 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "9.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "9.7 K     Total params\n",
      "0.039     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05f701f03bda4fd6afbca92a3cffa90e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇▇█▇▇</td></tr><tr><td>train_auc</td><td>▁▄▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇█▇████████▇████</td></tr><tr><td>train_f1</td><td>▃▁▅▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇███▇▇▇█▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▃▃▃▂▂▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▂▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>▇██▄▆▆▇▅█▅▅▄▄▄▅▅▄▄▁▃▃▅▄▆▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▃▃▂▆██▇▇██▇▆▆███▆▇▆▇▆▆█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▅</td></tr><tr><td>val_auc</td><td>▁▆▇█▇███▇███▇▇▇▇▇▇▇▇██▇█▇▇█▇████▇█▆█▇▇▇▇</td></tr><tr><td>val_f1</td><td>▁▄██████▇▇█▇▆▇▇██▇▇▇█▇▇▇▇▇▇▇█▇▇██▇▇███▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▆▅▇▃▃▃▃▂▃▂▃▅█▄▁▁▄▄▆▃▄▄▆▃▄▄▄▂▄▃▃▃▅▅▂▄▆▅▅</td></tr><tr><td>val_loss_step</td><td>▅▅▄▅▃▃▃▃▃▃▁▂▃█▃▃▃▄▄▄▃▃▃▃▃▃▃▃▂▄▃▃▂▅▃▃▄▅▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.75944</td></tr><tr><td>train_auc</td><td>0.80727</td></tr><tr><td>train_f1</td><td>0.6277</td></tr><tr><td>train_loss_epoch</td><td>0.49372</td></tr><tr><td>train_loss_step</td><td>0.44463</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.67434</td></tr><tr><td>val_auc</td><td>0.74299</td></tr><tr><td>val_f1</td><td>0.56769</td></tr><tr><td>val_loss_epoch</td><td>0.61146</td></tr><tr><td>val_loss_step</td><td>0.60946</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/ntpuldy9' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/ntpuldy9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240113_061028-ntpuldy9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c1c78213404d89965b5964486f621a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333330477276, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240113_062226-b9ua6sqa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/b9ua6sqa' target=\"_blank\">GINConv_4_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/b9ua6sqa' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/b9ua6sqa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 30.4 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "32.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "32.5 K    Total params\n",
      "0.130     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c95144ab1eb4060b53808c3f9ff0f31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▆▆▆▆▇▇▇▆▆▆▇▆▇▇▆▇▇▇▇█▇▇▇█▇▇█▇█▇███▇█▇</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▇▆▇▇▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇█▇█████▇██</td></tr><tr><td>train_f1</td><td>▁▅▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█▇█████████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▃▄▃▃▃▄▄▃▃▃▃▃▃▂▂▂▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▆▅▆▅█▅▆▄▄▃▅▄▆▄▂▁▃▃▇▇▃▂▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▃▁▄▆█▇▇▇▇▇▇▇▇▆▇█▇▇██▆▇▇█▇▇▇█▇▇▆▆▇▇██▇██▇</td></tr><tr><td>val_auc</td><td>▁▂█▇▇▅▅▇▇▃▇█▇▅▅▅█▅▅▆▅▆▆▅▆▄▆▅▄▄▂▂▅▂▇▆▄▃▄▃</td></tr><tr><td>val_f1</td><td>▅▄▆▇█▅▅▅▅▄▅▅▄▁▆▇▅▅▇▇▃▅▆▇▂▅▆▇▇▅▂▂▄▅▇█▄▆▇▁</td></tr><tr><td>val_loss_epoch</td><td>▄█▆▂▂▂▂▁▂▃▁▂▂▂▁▂▂▃▂▂▂▃▂▃▁▄▃▂▂▂▃▃▂▃▃▄▃▂▃▄</td></tr><tr><td>val_loss_step</td><td>▆██▃▄▄▄▂▃▄▃▃▃▂▁▄▃▅▃▄▄▆▄▄▄▇▄▄▄▄▄▄▄▄▃▄▅▂▃▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77094</td></tr><tr><td>train_auc</td><td>0.84325</td></tr><tr><td>train_f1</td><td>0.65767</td></tr><tr><td>train_loss_epoch</td><td>0.46181</td></tr><tr><td>train_loss_step</td><td>0.46848</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.68421</td></tr><tr><td>val_auc</td><td>0.74831</td></tr><tr><td>val_f1</td><td>0.51515</td></tr><tr><td>val_loss_epoch</td><td>0.68237</td></tr><tr><td>val_loss_step</td><td>0.7295</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/b9ua6sqa' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/b9ua6sqa</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240113_062226-b9ua6sqa\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "128e6578dd7a47bfae0f6bdf60febfd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333330477276, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240113_063500-em9tgofv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/em9tgofv' target=\"_blank\">GINConv_4_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/em9tgofv' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/em9tgofv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 30.4 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "32.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "32.5 K    Total params\n",
      "0.130     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6be28bc852784c2c87eff0ea4b6a4c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▆▇██▇▇▇█▇███▇█▇█▇██</td></tr><tr><td>train_auc</td><td>▁▄▅▆▆▆▆▆▆▇▆▆▇▆▇▇▇▇▇▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█</td></tr><tr><td>train_f1</td><td>▁▂▆▇▇▇▇▇▇█▇▇▇▇▇▇██▇▇▇▇▇███▇██▇███▇███▇██</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▄▄▃▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▅▆▄▅▃▅▄▃▃▄▄▅▃▂▂▂▃▅▅▂▃▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▂▂▁▅▆█▇▅█▇▇██▅▇▄▇▇▆▇▆▆▅▅▇▇▇█▆▅▆▅▆▆▇▆▅▅▆▅</td></tr><tr><td>val_auc</td><td>▁▇▇█▇█▇▇█▇███▇▇▇▇▇▇▇███▇▇██▇▇▆▅▆▇▇▇▇▇▇▇▇</td></tr><tr><td>val_f1</td><td>▁█▇███▇▆██▇██▆█▄▇▇▇▇▆▆▆▆▇█▇█▇▆▆▆▇▇▇▇▅▅▆▆</td></tr><tr><td>val_loss_epoch</td><td>▅▅█▂▃▂▃▃▃▃▂▂▂▂▁▂▂▃▂▄▂▄▄▃▂▄▂▂▃▄▃▄▄▂▅▄▄▃▃▄</td></tr><tr><td>val_loss_step</td><td>▅▅█▃▃▃▄▃▂▂▃▃▃▁▁▃▃▄▂▃▃▅▅▃▄▆▃▃▄▄▃▄▆▂▃▄▃▃▃▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.76847</td></tr><tr><td>train_auc</td><td>0.8074</td></tr><tr><td>train_f1</td><td>0.64662</td></tr><tr><td>train_loss_epoch</td><td>0.48833</td></tr><tr><td>train_loss_step</td><td>0.4773</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.66447</td></tr><tr><td>val_auc</td><td>0.76027</td></tr><tr><td>val_f1</td><td>0.51887</td></tr><tr><td>val_loss_epoch</td><td>0.65143</td></tr><tr><td>val_loss_step</td><td>0.71329</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/em9tgofv' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/em9tgofv</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240113_063500-em9tgofv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf5d3cdd774141688d235e0c42fc93b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666495924, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240113_064614-5dam6jmv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/5dam6jmv' target=\"_blank\">GINConv_4_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/5dam6jmv' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/5dam6jmv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 30.4 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "32.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "32.5 K    Total params\n",
      "0.130     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a9d1def651d4c779437a30bf8baecb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▂▄▅▆▆▆▆▇▇▇▇▇▇█▇▇█▇█▇▇▇██▇▇██████▇█▇███</td></tr><tr><td>train_auc</td><td>▁▃▅▄▆▅▅▅▇▇▆▆▇▆▇█▆█▇▇▇▇▇▇▇▆▆▇▇▇▇▅▆▇▆▆▅▆▅▇</td></tr><tr><td>train_f1</td><td>▁▁▅▃▆▅▄▆▄▅▇▆▅▆▇▇▆▆▇▇█▇▆▆▇▆▆▇▆▇▇▇█▇▇▇▇▇██</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▁▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▁▂▅▇█▇████▇█▇▇▇▇▆▆▇▇█▇▇▇▆▇▇▇▆▇▆▇▆▇▇▇▇▇▇▇</td></tr><tr><td>val_auc</td><td>▁▃▆▇▅▅▆█████▇▇▇▇▇▇▇█▇███▇██▇██▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>val_f1</td><td>▃▃▆▆▇▆██▆▇▇▇▅▅▅▆▁▂▄▄▇▄▂▃▁▂▂▄▁▅▃▃▂▄▃▂▃▃▅▃</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▄▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▄▂▆▂▂▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77094</td></tr><tr><td>train_auc</td><td>0.70347</td></tr><tr><td>train_f1</td><td>0.65598</td></tr><tr><td>train_loss_epoch</td><td>0.48428</td></tr><tr><td>train_loss_step</td><td>0.4958</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.69408</td></tr><tr><td>val_auc</td><td>0.75535</td></tr><tr><td>val_f1</td><td>0.59031</td></tr><tr><td>val_loss_epoch</td><td>0.6509</td></tr><tr><td>val_loss_step</td><td>0.73048</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/5dam6jmv' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/5dam6jmv</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240113_064614-5dam6jmv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1a6a87cf625425ea12020dbed7d0d78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.017183333332650364, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240113_065746-6to7jtng</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/6to7jtng' target=\"_blank\">GINConv_4_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/6to7jtng' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/6to7jtng</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 30.4 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "32.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "32.6 K    Total params\n",
      "0.130     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e842d4ded78b4ddea7f5cd8fd3607a6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇█▇▇█▇▇██████▇</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇██▇███████</td></tr><tr><td>train_f1</td><td>▁▅▇▆▇▇▆█▇▇▇▇▇▇▇▇▇▇▇██▇█▇██▇██▇█▇▇███▇█▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▄▃▃▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▇▄▄▃▆▆▅▇▂▄▃▄▇█▃▄▃▄▂▃▃▁▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▄▁▅▄▇▇▇▆▇▇▇▇▇▇▆▇▇▇▇▇▇▇▆▇▆▇▆▆▇█▇█▇▇▇▆▆▆▇▆</td></tr><tr><td>val_auc</td><td>▅▃▅█▂▄▆▂▆▆▄▄█▃▄▄▄▅▇▇▇▄▃▅▁▇▅▅▃▇▄▆▆▇▇▃▅▅▅▄</td></tr><tr><td>val_f1</td><td>▆▅▇▆▅▆▇▃▆▄▅▄▅▆▃▅▆▅▅▅▆▅▅▅▁▃▁▂▇█▅█▇█▆▂▄▁▄▂</td></tr><tr><td>val_loss_epoch</td><td>▅█▄▄▂▃▁▄▂▁▂▃▂▂▃▃▃▃▂▂▃▃▃▃▃▄▂▃▂▂▂▃▂▂▃▃▃▅▂▅</td></tr><tr><td>val_loss_step</td><td>▅█▄▃▃▃▁▅▃▃▂▄▃▂▅▃▃▄▃▃▃▅▄▃▄▅▄▃▂▃▃▃▂▂▃▄▄▆▄▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.76437</td></tr><tr><td>train_auc</td><td>0.83732</td></tr><tr><td>train_f1</td><td>0.63439</td></tr><tr><td>train_loss_epoch</td><td>0.45913</td></tr><tr><td>train_loss_step</td><td>0.45339</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.67434</td></tr><tr><td>val_auc</td><td>0.76022</td></tr><tr><td>val_f1</td><td>0.53081</td></tr><tr><td>val_loss_epoch</td><td>0.68943</td></tr><tr><td>val_loss_step</td><td>0.78426</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/6to7jtng' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/6to7jtng</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240113_065746-6to7jtng\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6629cd7bab741c3b49eb2b623f0fdc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240113_070918-epx9kbl2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/epx9kbl2' target=\"_blank\">GINConv_4_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/epx9kbl2' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/epx9kbl2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 30.4 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "36.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "36.7 K    Total params\n",
      "0.147     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▆▆▆▇▆▆▆▇▇▇▇▇▇▆▇▇█▇▇▇▇▇▇▇▇▇███▇█████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▇▆▆▇▇▆▆▆▇▇▇▇▇▇▆▆▇▇▇▇▇▇▇▇██▇█████████</td></tr><tr><td>train_f1</td><td>▁▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▆▇▇██▇▇▇▇▇▇█▇▇███▇█▇███</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▄▄▃▃▃▄▄▃▃▃▃▃▃▄▃▃▂▂▃▂▃▃▂▂▂▂▂▂▂▁▂▂▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>▅▅▃▂▅█▆▄▃▆▆▄▆▅▃▇▁▃▁▄▄▂▃▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▂▁▂▂▃▃▃▃▄▄▂▄▂▄▂▅▃▅▃▆▆▆▃▃▇▇▇▃▇▄█▄█▄</td></tr><tr><td>val_acc</td><td>▇▁▅▇▇▇▇█▇▇▇█▇▇▇█▆█▆▇▆▇█▇▇▇▇▇▇▇▆▇▇█▇▇▇▇██</td></tr><tr><td>val_auc</td><td>▆▅▁▇▆▆▆▇▆██▆▅▆▅█▆██▇▆▂█▆▄▅▇▇▆▆▄▆▆▇▆▆▆▆▆▆</td></tr><tr><td>val_f1</td><td>▇▅▆█▇▇▅▆▆▄▆█▄▅▅▇▃▇▇▆▄▅▇▅▆▆▇▆▆▆▁▃▄▇▆▅▇▇██</td></tr><tr><td>val_loss_epoch</td><td>▃█▃▂▂▂▂▂▂▃▂▁▃▂▂▂▃▁▂▂▂▂▁▂▂▁▂▁▁▂▂▃▃▁▂▂▁▂▃▂</td></tr><tr><td>val_loss_step</td><td>▄█▄▂▃▃▂▄▃▃▃▁▃▄▃▃▃▂▄▃▃▄▂▃▃▁▃▃▁▃▃▃▅▁▃▃▁▃▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77668</td></tr><tr><td>train_auc</td><td>0.84681</td></tr><tr><td>train_f1</td><td>0.69845</td></tr><tr><td>train_loss_epoch</td><td>0.46498</td></tr><tr><td>train_loss_step</td><td>0.46039</td></tr><tr><td>trainer/global_step</td><td>249</td></tr><tr><td>val_acc</td><td>0.73684</td></tr><tr><td>val_auc</td><td>0.7647</td></tr><tr><td>val_f1</td><td>0.71014</td></tr><tr><td>val_loss_epoch</td><td>0.5633</td></tr><tr><td>val_loss_step</td><td>0.53545</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/epx9kbl2' target=\"_blank\">https://wandb.ai/thoomas/PLA_01102024_5PPI_Kfold/runs/epx9kbl2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240113_070918-epx9kbl2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k_folds = 5\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_ids, valid_ids) in enumerate(kfold.split(dataset_filtered)):\n",
    "    train_subset = dataset_filtered.index_select(train_ids.tolist())\n",
    "    val_subset = dataset_filtered.index_select(valid_ids.tolist())\n",
    "    for NUM_LAYERS, HIDDEN_CHANNELS, pool, model in list(itertools.product(*[num_layers, hiddens, pools, models])):\n",
    "            # Path to the folder where the pretrained models are saved\n",
    "        CHECKPOINT_PATH = checkpoint_folder / f'{model}_{NUM_LAYERS}_{HIDDEN_CHANNELS}_onehot_{fold}' / pool\n",
    "        CHECKPOINT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Skip already trained kfold and pool\n",
    "        checkpoint = CHECKPOINT_PATH / f\"GraphLevel{model}\" / f\"GraphLevel{model}.ckpt\" \n",
    "        if checkpoint.exists():\n",
    "            print(checkpoint)\n",
    "            continue\n",
    "\n",
    "        # Run training\n",
    "        run = wandb.init(project=project_name, name=f'{model}_{NUM_LAYERS}_{HIDDEN_CHANNELS}_onehot_{fold}', \n",
    "                        group=f'{model}_{pool}', \n",
    "                        # mode=\"disabled\"\n",
    "                        )\n",
    "        PPIGraph.train_graph_classifier_kfold(model, \n",
    "                                                train_subset, \n",
    "                                                val_subset, \n",
    "                                                dataset, \n",
    "                                                CHECKPOINT_PATH, \n",
    "                                                AVAIL_GPUS, \n",
    "                                                in_channels=5,\n",
    "                                                hidden_channels=HIDDEN_CHANNELS, \n",
    "                                                out_channels = HIDDEN_CHANNELS,\n",
    "                                                num_layers=NUM_LAYERS, \n",
    "                                                epochs=epochs,\n",
    "                                                embedding=False,\n",
    "                                                batch_size=256, \n",
    "                                                graph_pooling=pool)\n",
    "        run.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
