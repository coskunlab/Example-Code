{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.io\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.utils\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_dir = (Path().cwd().parents[0]).absolute()\n",
    "\n",
    "module_path = str(p_dir / \"src\")\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = (Path().cwd().parents[0] / 'data').absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning.pytorch as pl\n",
    "import PPIGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Define condition mapping\n",
    "condition_mapping = {'control': 0, '100nM': 1}\n",
    "\n",
    "# Load graph dataset and process if neede\n",
    "graph_path = data_dir / '13cyc_3D' / 'graphs' \n",
    "\n",
    "dataset = PPIGraph.GraphDataset2D3D(graph_path, 'raw', '2D3D_pt', condition_mapping=condition_mapping, n_c=2)\n",
    "train_set, val_set, test_set = PPIGraph.train_test_val_split(dataset)\n",
    "\n",
    "# Create Dataloader\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: GraphDataset2D3D(2492):\n",
      "======================\n",
      "Number of graphs: 2492\n",
      "Number of features: 13\n",
      "Number of classes: 2\n",
      "Train set: 1197, test set: 996, val set: 299\n",
      "Step 1:\n",
      "=======\n",
      "Number of graphs in the current batch: 32\n",
      "DataBatch(edge_index=[2, 58354], pos=[4657, 2], labels=[4657, 13], nuclei=[4657], weight=[58354], condition=[32], fov=[32], id=[32], pos3D=[4657, 3], edge_attr=[58354, 1], x=[4657, 13], y=[32], edge_weight_2D=[58354], edge_weight_3D=[58354], name=[32], batch=[4657], ptr=[33])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print some information on the dataset\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('======================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "print(f'Train set: {len(train_set)}, test set: {len(test_set)}, val set: {len(val_set)}')\n",
    "for step, data in enumerate(train_loader):\n",
    "\n",
    "    print(f'Step {step + 1}:')\n",
    "    print('=======')\n",
    "    print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "    print(data)\n",
    "    print()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print some information on the dataset\n",
    "# print(f'Dataset: {dataset}:')\n",
    "# print('======================')\n",
    "# print(f'Number of graphs: {len(dataset)}')\n",
    "# print(f'Number of features: {dataset.num_features}')\n",
    "# print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "# print(f'Train set: {len(train_set)}, test set: {len(test_set)}, val set: {len(val_set)}')\n",
    "# for step, data in enumerate(train_loader):\n",
    "\n",
    "#     print(f'Step {step + 1}:')\n",
    "#     print('=======')\n",
    "#     print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "#     print(data)\n",
    "#     print()\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1474, 0.0617, 0.1485,  ..., 0.3465, 0.2191, 0.4646])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_weight_2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.6719e-03, 2.9284e-01, 3.3703e-03,  ..., 6.6989e-09, 1.0734e-08,\n",
       "        2.2192e-21])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_weight_3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-fold on filter dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from lightning.pytorch.accelerators import find_usable_cuda_devices\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from torch.utils.data import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out by maximum number of counts per cell\n",
    "min_count = 20\n",
    "max_count = 50\n",
    "\n",
    "graph_path = data_dir / '13cyc_3D' / 'graphs' \n",
    "dataset = PPIGraph.GraphDataset2D3D(graph_path, 'raw', '2D3D_pt', condition_mapping=condition_mapping, n_c=2)\n",
    "\n",
    "# Create Dataloader\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Get Indices\n",
    "indices = []\n",
    "for step, data in enumerate(loader):\n",
    "    if len(data.x) <= min_count:\n",
    "        continue \n",
    "    \n",
    "    if (data.x.sum(axis=0) >= max_count).any():\n",
    "        continue\n",
    "    indices.append(step)\n",
    "    \n",
    "# Get subset dataset\n",
    "dataset_filtered = dataset.index_select(indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2153"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = '13PPI_2D3D_fusion'\n",
    "condition = 'Kfold'\n",
    "checkpoint_folder = (Path().cwd().parents[0]).absolute() / 'data' / '13cyc_3D' /\"saved_models_fusion\" / dataset_name / f\"Graph_GNNs_{condition}\" \n",
    "project_name = f'PLA_01122024_{dataset_name}_{condition}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "AVAIL_GPUS = [0]\n",
    "\n",
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "epochs = 65\n",
    "\n",
    "# NUM_LAYERS = 2\n",
    "# HIDDEN_CHANNELS = 16\n",
    "# pools = ['mean', 'max', 'sum', 'attention', 'attention2']\n",
    "# num_layers = [2,3,4]\n",
    "# hiddens = [16, 32, 64]\n",
    "\n",
    "\n",
    "# # model = 'GAT'\n",
    "# model = 'GINConv'\n",
    "params = [[2,64,'attention','MLP'], \n",
    "[2,16,'attention','GraphConv'],\n",
    "[2,64,'attention2','GCN'],\n",
    "[3,64,'attention','GAT'],\n",
    "[3,16,'mean','GINConv']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 64, 'attention', 'MLP'],\n",
       " [2, 16, 'attention', 'GraphConv'],\n",
       " [2, 64, 'attention2', 'GCN'],\n",
       " [3, 64, 'attention', 'GAT'],\n",
       " [3, 16, 'mean', 'GINConv']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PPIGraph\n",
    "import torch\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion = 'bilinear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mthoomas\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0abe592c47124cbe8974dc158c51077c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240123_102326-rs825mq3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/rs825mq3' target=\"_blank\">MLP_2_64_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/rs825mq3' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/rs825mq3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\Anaconda3\\envs\\snowflake\\lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thu71\\Anaconda3\\envs\\snowflake\\lib\\site-packages\\torch_geometric\\deprecation.py:12: UserWarning: 'nn.glob.GlobalAttention' is deprecated, use 'nn.aggr.AttentionalAggregation' instead\n",
      "  warnings.warn(out)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model2D     | MLPModel         | 5.1 K \n",
      "2  | model3D     | MLPModel         | 5.1 K \n",
      "3  | head        | BilinearFusion   | 686 K \n",
      "4  | pred        | Sequential       | 130   \n",
      "5  | loss_module | CrossEntropyLoss | 0     \n",
      "6  | train_acc   | BinaryAccuracy   | 0     \n",
      "7  | train_auroc | BinaryAUROC      | 0     \n",
      "8  | train_f1    | BinaryF1Score    | 0     \n",
      "9  | valid_acc   | BinaryAccuracy   | 0     \n",
      "10 | valid_auroc | BinaryAUROC      | 0     \n",
      "11 | valid_f1    | BinaryF1Score    | 0     \n",
      "12 | pool2D      | GlobalAttention  | 65    \n",
      "13 | pool3D      | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "696 K     Trainable params\n",
      "0         Non-trainable params\n",
      "696 K     Total params\n",
      "2.788     Total estimated model params size (MB)\n",
      "c:\\Users\\thu71\\Anaconda3\\envs\\snowflake\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\thu71\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightning\\pytorch\\utilities\\data.py:77: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "c:\\Users\\thu71\\Anaconda3\\envs\\snowflake\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "`Trainer.fit` stopped: `max_epochs=65` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fdf48f261b6448185db624c71b4acda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▇▇▇▇▇▇▇▇█▇█▇█▇▇▇▇█▇▇█▇▇█████▇▇██████▇▇</td></tr><tr><td>train_auc</td><td>▁▃▇▇▇▇▇▇█████████▇█████████████▇████████</td></tr><tr><td>train_f1</td><td>▁▄▇▇█▇▇█████████████████████████████████</td></tr><tr><td>train_loss_epoch</td><td>█▇▃▂▂▂▃▂▂▁▂▁▁▁▂▁▂▂▂▁▂▁▁▁▂▁▁▁▁▁▂▂▁▁▁▁▁▁▂▂</td></tr><tr><td>train_loss_step</td><td>█▇▄▃▆▃▆▄▁▁▄▄▃▃▁▂▅▃▄▄▃▂▃▂▂▃▂▃▂▄▃▃▃▁▂▂▂▁▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▁▁▃▃▃▃▃▄▂▂▂▂▂▂▅▅▅▅▆▆▂▂▂▂▃▃▇▇▇███▃</td></tr><tr><td>val_acc</td><td>▁▇█▇▆▇▇███████▇█▇███████████████████████</td></tr><tr><td>val_auc</td><td>▁▃▄▆▇▇▇▇▇▇████████████████████▇█▇███▇▇██</td></tr><tr><td>val_f1</td><td>▁▇█▇▇███████████████████████████████████</td></tr><tr><td>val_loss_epoch</td><td>█▆▂▂▄▂▂▁▂▁▂▁▁▁▁▁▁▁▁▂▂▁▁▁▁▁▁▁▁▂▂▂▁▁▁▁▁▁▂▁</td></tr><tr><td>val_loss_step</td><td>█▅▄▄▇▁▁▂▄▂▄▃▂▃▁▂▁▃▂▄▄▂▃▂▃▂▃▂▂▄▄▄▂▂▂▂▃▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>64</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.76597</td></tr><tr><td>train_auc</td><td>0.83972</td></tr><tr><td>train_f1</td><td>0.73746</td></tr><tr><td>train_loss_epoch</td><td>0.53559</td></tr><tr><td>train_loss_step</td><td>0.56504</td></tr><tr><td>trainer/global_step</td><td>909</td></tr><tr><td>val_acc</td><td>0.81439</td></tr><tr><td>val_auc</td><td>0.8848</td></tr><tr><td>val_f1</td><td>0.80392</td></tr><tr><td>val_loss_epoch</td><td>0.491</td></tr><tr><td>val_loss_step</td><td>0.49656</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">MLP_2_64_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/rs825mq3' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/rs825mq3</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240123_102326-rs825mq3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b341a609dd964541826458f0158f0994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666656966, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240123_112113-xgzw5e1u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/xgzw5e1u' target=\"_blank\">GraphConv_2_16_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/xgzw5e1u' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/xgzw5e1u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model2D     | GNNModel         | 992   \n",
      "2  | model3D     | GNNModel         | 992   \n",
      "3  | head        | BilinearFusion   | 19.6 K\n",
      "4  | pred        | Sequential       | 34    \n",
      "5  | loss_module | CrossEntropyLoss | 0     \n",
      "6  | train_acc   | BinaryAccuracy   | 0     \n",
      "7  | train_auroc | BinaryAUROC      | 0     \n",
      "8  | train_f1    | BinaryF1Score    | 0     \n",
      "9  | valid_acc   | BinaryAccuracy   | 0     \n",
      "10 | valid_auroc | BinaryAUROC      | 0     \n",
      "11 | valid_f1    | BinaryF1Score    | 0     \n",
      "12 | pool2D      | GlobalAttention  | 17    \n",
      "13 | pool3D      | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "21.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "21.7 K    Total params\n",
      "0.087     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=65` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▆▇▇▇▇█▇█▇█▇▇██▇████▇██</td></tr><tr><td>train_auc</td><td>▁▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇████▇██▇███████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇███████▇███████▇██</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▃▃▃▃▃▂▂▃▂▃▂▂▂▃▂▂▂▂▁▂▂▂▁▂▂▁▂▂▁▁▁▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▇▃▃▄▄▅▄▄▅▄▅▄▄▅▂▂▄▄▃▃▂▂▁▂▄▂▂▂▂▃▃▂▄▂▁▃▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▁▁▃▃▃▃▃▄▂▂▂▂▂▂▅▅▅▅▆▆▂▂▂▂▃▃▇▇▇███▃</td></tr><tr><td>val_acc</td><td>▁▂▃▄▄▄▅▄▅▄▆▆▅▇▅▆▇▆█▆▆▆█▆▅▆▄▅▃▆▇▃▅▆▄▆█▅▆▅</td></tr><tr><td>val_auc</td><td>▁▂▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▆▇█▇▇▇</td></tr><tr><td>val_f1</td><td>▂▂▄▄▄▃▄▄▅▃▆▅▄▇▅▆▇▅█▆▅▆█▅▃▅▁▅▁▇▆▁▆▄▂▆█▃▅▃</td></tr><tr><td>val_loss_epoch</td><td>█▅▃▃▃▄▃▃▃▃▂▂▃▂▂▂▂▂▁▂▃▂▁▃▃▂▅▂▄▁▂▅▂▃▄▂▁▃▂▄</td></tr><tr><td>val_loss_step</td><td>▆▄▂▃▃▆▄▄▃▄▃▃▄▂▂▃▂▄▁▃▅▄▂▅▅▄█▃▇▁▃▇▃▅█▃▃▆▄▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>64</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86005</td></tr><tr><td>train_auc</td><td>0.91622</td></tr><tr><td>train_f1</td><td>0.8489</td></tr><tr><td>train_loss_epoch</td><td>0.45113</td></tr><tr><td>train_loss_step</td><td>0.53552</td></tr><tr><td>trainer/global_step</td><td>909</td></tr><tr><td>val_acc</td><td>0.81671</td></tr><tr><td>val_auc</td><td>0.90548</td></tr><tr><td>val_f1</td><td>0.78933</td></tr><tr><td>val_loss_epoch</td><td>0.51105</td></tr><tr><td>val_loss_step</td><td>0.61182</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_2_16_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/xgzw5e1u' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/xgzw5e1u</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240123_112113-xgzw5e1u\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "901faaf600c14f94ab8c8a6441eb91c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240123_122123-a08khwkz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/a08khwkz' target=\"_blank\">GCN_2_64_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/a08khwkz' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/a08khwkz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model2D     | GNNModel         | 5.2 K \n",
      "2  | model3D     | GNNModel         | 5.2 K \n",
      "3  | head        | BilinearFusion   | 686 K \n",
      "4  | pred        | Sequential       | 130   \n",
      "5  | loss_module | CrossEntropyLoss | 0     \n",
      "6  | train_acc   | BinaryAccuracy   | 0     \n",
      "7  | train_auroc | BinaryAUROC      | 0     \n",
      "8  | train_f1    | BinaryF1Score    | 0     \n",
      "9  | valid_acc   | BinaryAccuracy   | 0     \n",
      "10 | valid_auroc | BinaryAUROC      | 0     \n",
      "11 | valid_f1    | BinaryF1Score    | 0     \n",
      "12 | pool2D      | Attention_module | 4.2 K \n",
      "13 | pool3D      | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "705 K     Trainable params\n",
      "0         Non-trainable params\n",
      "705 K     Total params\n",
      "2.822     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=65` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86dcc950ed9f4f36b59641c21f51e89a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▅▆▆▆▇▇▇▇▇▇▆▇▇▇▇▇▇█▇▇█▇▇▇▇▇█▇█▇█▇█▇█▇</td></tr><tr><td>train_auc</td><td>▁▄▅▅▅▇▆▆▇▇█▇▇▇▆▇▇▇██▇█▇██▇▇████▇█▇██████</td></tr><tr><td>train_f1</td><td>▁▄▆▅▅▆▆▆▇▇▇▇▇▇▆▇▇▇▇▇▇██▇██▇▇█▇█▇█▇█▇███▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▃▃▂▂▂▂▂▂▂▃▂▂▂▁▁▂▁▂▁▁▂▂▂▂▁▂▂▁▂▁▂▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▄▃▆▅▃▄▄▄▂▄▃▄▃▅▅▄▄▃▃▃▄▃▁▃▃▅▂▅▃▃▂▂▃▃▂▅▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▁▁▃▃▃▃▃▄▂▂▂▂▂▂▅▅▅▅▆▆▂▂▂▂▃▃▇▇▇███▃</td></tr><tr><td>val_acc</td><td>▁▃▇▆▇▇▇▇▇▆▇▅▇▇▇▇█▇▆▇█▆▇▇▆▆▆█▇▇▆█▇█▆▇█▇▇▇</td></tr><tr><td>val_auc</td><td>▁▃▅▆▅▅▆▇▇▇▅▇▇▄▇▇▇▆▆▆▇▇▇▇▅▆▅█▆█▃█▆▇▅▆▇▇▇▆</td></tr><tr><td>val_f1</td><td>▁▄▇▆█▇███▇▇▅█▇█▇██▇██▇▇▇▇▇▇█▇█▇█▇█▇████▇</td></tr><tr><td>val_loss_epoch</td><td>█▇▃▄▂▂▁▁▁▃▂▅▁▃▂▂▁▂▃▁▂▂▂▂▂▃▃▁▂▁▃▁▂▂▂▁▁▁▂▂</td></tr><tr><td>val_loss_step</td><td>█▇▄▅▃▂▂▂▃▅▄▇▂▄▃▄▂▃▅▂▃▁▄▃▂▄▄▂▄▁▅▂▄▃▂▂▂▂▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>64</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83972</td></tr><tr><td>train_auc</td><td>0.9094</td></tr><tr><td>train_f1</td><td>0.82308</td></tr><tr><td>train_loss_epoch</td><td>0.46151</td></tr><tr><td>train_loss_step</td><td>0.40681</td></tr><tr><td>trainer/global_step</td><td>909</td></tr><tr><td>val_acc</td><td>0.82599</td></tr><tr><td>val_auc</td><td>0.90948</td></tr><tr><td>val_f1</td><td>0.80519</td></tr><tr><td>val_loss_epoch</td><td>0.48722</td></tr><tr><td>val_loss_step</td><td>0.55028</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_64_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/a08khwkz' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/a08khwkz</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240123_122123-a08khwkz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b223870f3bbf400f8ab23139a55f74dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240123_131756-uriwezfm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/uriwezfm' target=\"_blank\">GAT_3_64_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/uriwezfm' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/uriwezfm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model2D     | GAT              | 44.6 K\n",
      "2  | model3D     | GAT              | 44.6 K\n",
      "3  | head        | BilinearFusion   | 686 K \n",
      "4  | pred        | Sequential       | 130   \n",
      "5  | loss_module | CrossEntropyLoss | 0     \n",
      "6  | train_acc   | BinaryAccuracy   | 0     \n",
      "7  | train_auroc | BinaryAUROC      | 0     \n",
      "8  | train_f1    | BinaryF1Score    | 0     \n",
      "9  | valid_acc   | BinaryAccuracy   | 0     \n",
      "10 | valid_auroc | BinaryAUROC      | 0     \n",
      "11 | valid_f1    | BinaryF1Score    | 0     \n",
      "12 | pool2D      | GlobalAttention  | 65    \n",
      "13 | pool3D      | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "776 K     Trainable params\n",
      "0         Non-trainable params\n",
      "776 K     Total params\n",
      "3.104     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=65` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f0f9094cf7940c0b715fac717dd49ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▄▆▅▆▇▆▆▇▇▆▇▇▆▇▇▇▇▇▆▇▆▇▇▇▇▇▇███▇█▇▇█▇▇</td></tr><tr><td>train_auc</td><td>▁▃▄▅▆▆▆▆▆▆▆▇▆▇▆▆▇▇▇▇▇▇█▇▇██▇▇▇█▇█▇█▇██▇▇</td></tr><tr><td>train_f1</td><td>▁▄▄▅▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇███▇█▇▇█▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▄▃▃▃▃▃▂▃▃▃▃▂▂▂▂▂▃▂▃▂▁▂▂▂▂▁▁▁▂▁▂▂▂▂▂</td></tr><tr><td>train_loss_step</td><td>▆█▅▄▅▃▄▄▃▄▄▅▃▃▃▅▃▂▁▅▅▄▃▄▂▂▄▂▃▂▁▂▃▂▃▄▂▁▃▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▁▁▃▃▃▃▃▄▂▂▂▂▂▂▅▅▅▅▆▆▂▂▂▂▃▃▇▇▇███▃</td></tr><tr><td>val_acc</td><td>▁▆▅▇█▆▇▇▇▆█▇▇██▇████▇█████▇███▇█▇▇█▇█▇██</td></tr><tr><td>val_auc</td><td>▁▁▃▃▅▄▄▅▅▄▆▅▅▇▆▅▇▆▇▇▇▇▇█▇█▆▇▇█▇▇▅▆▇▆▆▇██</td></tr><tr><td>val_f1</td><td>▁▅▄▇▇▆▇▇▇▆█▇▇█▇▇▇███▇▇▇▇▇█▇▇▇█▇▇▇▇▇▇▇▇██</td></tr><tr><td>val_loss_epoch</td><td>█▄▄▂▂▃▂▂▂▃▁▂▂▁▁▁▁▁▁▁▁▂▁▁▁▁▂▁▂▁▁▁▂▂▁▂▁▂▁▁</td></tr><tr><td>val_loss_step</td><td>▃▃▁▄▃▁▂▂▂▁▅▂▄▃▃▃▄▇▂▅▂█▂▇▆▄▁▆▇▂▁▂▃▂▄▁▆▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>64</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.82636</td></tr><tr><td>train_auc</td><td>0.88979</td></tr><tr><td>train_f1</td><td>0.81016</td></tr><tr><td>train_loss_epoch</td><td>0.48435</td></tr><tr><td>train_loss_step</td><td>0.58471</td></tr><tr><td>trainer/global_step</td><td>909</td></tr><tr><td>val_acc</td><td>0.82367</td></tr><tr><td>val_auc</td><td>0.91906</td></tr><tr><td>val_f1</td><td>0.8326</td></tr><tr><td>val_loss_epoch</td><td>0.46635</td></tr><tr><td>val_loss_step</td><td>0.37609</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GAT_3_64_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/uriwezfm' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/uriwezfm</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240123_131756-uriwezfm\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fcdedff80e44ddfb3c64a402a12cd99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240123_141847-15rw7ln0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/15rw7ln0' target=\"_blank\">GINConv_3_16_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/15rw7ln0' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/15rw7ln0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model2D     | GIN              | 1.7 K \n",
      "2  | model3D     | GIN              | 1.7 K \n",
      "3  | head        | BilinearFusion   | 19.6 K\n",
      "4  | pred        | Sequential       | 34    \n",
      "5  | loss_module | CrossEntropyLoss | 0     \n",
      "6  | train_acc   | BinaryAccuracy   | 0     \n",
      "7  | train_auroc | BinaryAUROC      | 0     \n",
      "8  | train_f1    | BinaryF1Score    | 0     \n",
      "9  | valid_acc   | BinaryAccuracy   | 0     \n",
      "10 | valid_auroc | BinaryAUROC      | 0     \n",
      "11 | valid_f1    | BinaryF1Score    | 0     \n",
      "--------------------------------------------------\n",
      "23.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "23.2 K    Total params\n",
      "0.093     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=65` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0b194e4b714ce19037367eeb56da78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇█████████████▇███</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇██▇▇▇█▇███▇█████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇█████████████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▃▃▃▃▂▂▂▃▂▂▂▂▂▂▁▂▂▂▂▂▂▁▁▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▄▅▃▄▃▄▄█▃▄▃▂▃▂▃▂▂▃▂▃▄▂▂▂▄▂▂▃▃▄▂▃▂▂▂▃▁▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▁▁▃▃▃▃▃▄▂▂▂▂▂▂▅▅▅▅▆▆▂▂▂▂▃▃▇▇▇███▃</td></tr><tr><td>val_acc</td><td>▁▃▆▆▅▆█▇▇▆▆▇▅▆▆▇▇▆▆▇▆▅▆█▇▆▇▇▆▃▄▆▅█▄▇▇▇▇▆</td></tr><tr><td>val_auc</td><td>▃▄▆▅▄▅▇▄▅▁▆▆▅▅▇▆▆▅▆▆▅▆▆▆▆▅▇▇▅▂▅▇▇▇▅▆█▆▇▇</td></tr><tr><td>val_f1</td><td>▁▅▆▇▆▇█▇▇▇▆█▆▇▆▆▇▆▅▇▇▃▇█▆▆▆▇▆▄▅▆▆█▆▇█▇▇▆</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▃▂▂▁▁▂▂▂▁▂▂▂▁▁▂▂▁▁▄▁▁▂▂▂▂▂▃▃▂▂▁▂▂▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>▇▂▃▃▂▂▂▁▄▃▃▂▂▂▄▂▂▂▅▂▁█▂▂▃▃▄▃▃▂▁▄▁▂▂▂▁▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>64</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84437</td></tr><tr><td>train_auc</td><td>0.89903</td></tr><tr><td>train_f1</td><td>0.82821</td></tr><tr><td>train_loss_epoch</td><td>0.46254</td></tr><tr><td>train_loss_step</td><td>0.39405</td></tr><tr><td>trainer/global_step</td><td>909</td></tr><tr><td>val_acc</td><td>0.84223</td></tr><tr><td>val_auc</td><td>0.90825</td></tr><tr><td>val_f1</td><td>0.82741</td></tr><tr><td>val_loss_epoch</td><td>0.455</td></tr><tr><td>val_loss_step</td><td>0.42771</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/15rw7ln0' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/15rw7ln0</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240123_141847-15rw7ln0\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "228d6ca4ca0a4d6ea0db4fa1427a75be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666656966, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240123_151623-nxnkh7tf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/nxnkh7tf' target=\"_blank\">MLP_2_64_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/nxnkh7tf' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/nxnkh7tf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model2D     | MLPModel         | 5.1 K \n",
      "2  | model3D     | MLPModel         | 5.1 K \n",
      "3  | head        | BilinearFusion   | 686 K \n",
      "4  | pred        | Sequential       | 130   \n",
      "5  | loss_module | CrossEntropyLoss | 0     \n",
      "6  | train_acc   | BinaryAccuracy   | 0     \n",
      "7  | train_auroc | BinaryAUROC      | 0     \n",
      "8  | train_f1    | BinaryF1Score    | 0     \n",
      "9  | valid_acc   | BinaryAccuracy   | 0     \n",
      "10 | valid_auroc | BinaryAUROC      | 0     \n",
      "11 | valid_f1    | BinaryF1Score    | 0     \n",
      "12 | pool2D      | GlobalAttention  | 65    \n",
      "13 | pool3D      | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "696 K     Trainable params\n",
      "0         Non-trainable params\n",
      "696 K     Total params\n",
      "2.788     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=65` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40aabd4c9e9f45f28cdbf7ecc9562515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▇▇▇▇█▇█▇█████▇███▇▇██▇███▇▇▇████▇███▇█</td></tr><tr><td>train_auc</td><td>▁▄▇▇███████████▇████████████▇███████████</td></tr><tr><td>train_f1</td><td>▁▅▇▇███████████▇████████████▇███████████</td></tr><tr><td>train_loss_epoch</td><td>█▆▃▂▂▂▂▂▂▂▂▁▁▁▁▂▁▁▁▁▂▁▁▂▁▁▁▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▃▂▃▄▂▃▂▄▃▂▂▂▃▃▄▃▂▂▂▂▂▂▂▃▂▅▁▂▄▁▄▃▁▄▃▃▂▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▁▁▃▃▃▃▃▄▂▂▂▂▂▂▅▅▅▅▆▆▂▂▂▂▃▃▇▇▇███▃</td></tr><tr><td>val_acc</td><td>▁▅▇██▇█▇██▇▇██▇▇██▇██▆████▇▆█▇█▇█████▇██</td></tr><tr><td>val_auc</td><td>▄▁▅▆▇▇▇▇██▇▇███▇▇████▇██████▇▇▇█▇▇▇██▇▇▇</td></tr><tr><td>val_f1</td><td>▁█▇████████████▇███████████▆█▇█▇████████</td></tr><tr><td>val_loss_epoch</td><td>█▄▂▁▁▂▁▁▁▂▁▁▁▁▁▃▁▁▁▂▁▂▁▁▁▁▁▄▁▃▁▃▁▂▂▁▁▁▁▂</td></tr><tr><td>val_loss_step</td><td>▇▃▄▃▂▁▃▃▃▄▃▃▃▂▂▆▃▃▁▄▃▁▃▃▄▃▂█▂▆▃▆▂▅▄▃▃▂▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>64</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.79501</td></tr><tr><td>train_auc</td><td>0.85902</td></tr><tr><td>train_f1</td><td>0.78645</td></tr><tr><td>train_loss_epoch</td><td>0.50969</td></tr><tr><td>train_loss_step</td><td>0.46062</td></tr><tr><td>trainer/global_step</td><td>909</td></tr><tr><td>val_acc</td><td>0.7587</td></tr><tr><td>val_auc</td><td>0.82914</td></tr><tr><td>val_f1</td><td>0.71739</td></tr><tr><td>val_loss_epoch</td><td>0.54032</td></tr><tr><td>val_loss_step</td><td>0.53818</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">MLP_2_64_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/nxnkh7tf' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/nxnkh7tf</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240123_151623-nxnkh7tf\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a22922f3444fd995bbda74c2290af4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240123_161221-uqye5b9h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/uqye5b9h' target=\"_blank\">GraphConv_2_16_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/uqye5b9h' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/uqye5b9h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model2D     | GNNModel         | 992   \n",
      "2  | model3D     | GNNModel         | 992   \n",
      "3  | head        | BilinearFusion   | 19.6 K\n",
      "4  | pred        | Sequential       | 34    \n",
      "5  | loss_module | CrossEntropyLoss | 0     \n",
      "6  | train_acc   | BinaryAccuracy   | 0     \n",
      "7  | train_auroc | BinaryAUROC      | 0     \n",
      "8  | train_f1    | BinaryF1Score    | 0     \n",
      "9  | valid_acc   | BinaryAccuracy   | 0     \n",
      "10 | valid_auroc | BinaryAUROC      | 0     \n",
      "11 | valid_f1    | BinaryF1Score    | 0     \n",
      "12 | pool2D      | GlobalAttention  | 17    \n",
      "13 | pool3D      | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "21.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "21.7 K    Total params\n",
      "0.087     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=65` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e33404c096a486e85a8cd8bfc56df67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇█▇█████▇██▇██▇▇</td></tr><tr><td>train_auc</td><td>▁▃▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇█████▇███████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇█████████████████</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▁▂▁▁▁▁▁▂▁▁▁▁▁▂▂</td></tr><tr><td>train_loss_step</td><td>█▃▄▆▃▃▇▄▂▃▃▄▅▃▃▅▂▄▄▄▁▂▁▂▂▂▄▃▁▂▂▁▂▃▃▃▂▁▄▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▁▁▃▃▃▃▃▄▂▂▂▂▂▂▅▅▅▅▆▆▂▂▂▂▃▃▇▇▇███▃</td></tr><tr><td>val_acc</td><td>▁▂▁▄▄▅▄▅▄▇▄▆▂▆▅▅▆▅▆▆▇▄▃▄▆▅▇▅▄▆▄▄▇▄▄▆▇▆█▅</td></tr><tr><td>val_auc</td><td>▁▂▃▄▄▅▅▅▆▇▆▆▆▆▆▇▇▇▇▆▇▇▆█▇▇▇▇████▇█▇█▇▇█▇</td></tr><tr><td>val_f1</td><td>▃▁▃▂▅▅▄▅▅▇▆▅▅▄▅▆▆▅▇▅▇▆▅▆▆▆▆▆▆▇▆▆▆▆▅▇▆▆█▆</td></tr><tr><td>val_loss_epoch</td><td>█▆▄▅▃▃▃▃▃▂▃▃▄▄▃▂▃▃▂▄▂▃▃▃▂▂▂▂▃▂▃▃▂▃▃▁▃▂▁▂</td></tr><tr><td>val_loss_step</td><td>▆▆▁█▂▄▄▅▄▄▂▅▂█▅▃▅▄▃▇▃▃▂▂▅▂▄▂▂▃▂▁▅▂▂▃▆▄▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>64</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83856</td></tr><tr><td>train_auc</td><td>0.89744</td></tr><tr><td>train_f1</td><td>0.82405</td></tr><tr><td>train_loss_epoch</td><td>0.46845</td></tr><tr><td>train_loss_step</td><td>0.50991</td></tr><tr><td>trainer/global_step</td><td>909</td></tr><tr><td>val_acc</td><td>0.7819</td></tr><tr><td>val_auc</td><td>0.87676</td></tr><tr><td>val_f1</td><td>0.77512</td></tr><tr><td>val_loss_epoch</td><td>0.49632</td></tr><tr><td>val_loss_step</td><td>0.37557</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_2_16_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/uqye5b9h' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/uqye5b9h</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240123_161221-uqye5b9h\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2651e5827fc2416da4dbc5d5693715f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333333145128, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240123_170758-iw1pc14u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/iw1pc14u' target=\"_blank\">GCN_2_64_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/iw1pc14u' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/iw1pc14u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model2D     | GNNModel         | 5.2 K \n",
      "2  | model3D     | GNNModel         | 5.2 K \n",
      "3  | head        | BilinearFusion   | 686 K \n",
      "4  | pred        | Sequential       | 130   \n",
      "5  | loss_module | CrossEntropyLoss | 0     \n",
      "6  | train_acc   | BinaryAccuracy   | 0     \n",
      "7  | train_auroc | BinaryAUROC      | 0     \n",
      "8  | train_f1    | BinaryF1Score    | 0     \n",
      "9  | valid_acc   | BinaryAccuracy   | 0     \n",
      "10 | valid_auroc | BinaryAUROC      | 0     \n",
      "11 | valid_f1    | BinaryF1Score    | 0     \n",
      "12 | pool2D      | Attention_module | 4.2 K \n",
      "13 | pool3D      | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "705 K     Trainable params\n",
      "0         Non-trainable params\n",
      "705 K     Total params\n",
      "2.822     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=65` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c5b08205ccf4359bd0870e775705465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▅▆▆▇▆▇▆▇▇▇▆▇▇█▇▇▇██▇▇▇▇▇▇▇███▇▇█▇██▇</td></tr><tr><td>train_auc</td><td>▁▄▅▅▆▇▆▇▇▇▆▇▇▇▇▇▇██▇▇██▇█▇███████▇██▇███</td></tr><tr><td>train_f1</td><td>▁▄▆▅▅▆▆▇▆▇▆▇▇▇▆▇▇█▇▇▇██▇▇█▇▇▇▇████▇█▇██▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▃▃▂▃▂▃▂▂▂▃▂▂▁▂▂▂▁▁▂▂▁▂▁▂▁▁▁▁▂▂▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>▇▄▄▂█▃▄▃▄▃▃▃▅▄▅▁▅▂▇▂▄▁▃▃▂▁▄▄▁▄▃▆▁▂▃▄▅▂▃▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▁▁▃▃▃▃▃▄▂▂▂▂▂▂▅▅▅▅▆▆▂▂▂▂▃▃▇▇▇███▃</td></tr><tr><td>val_acc</td><td>▁▃▆▇▇▆▆▇▅▇▇█▇▆▇█▇█▇▆▇██▇█▇█▇▇▇█▇▅█▅▇▇▆▇▆</td></tr><tr><td>val_auc</td><td>▁▃▄▆▇▆▆▇▇▇▇█▇▇▇█▇█▇▇██▇▇████▇██▇▇███▆█▇█</td></tr><tr><td>val_f1</td><td>▁▃▇▇▇▇▇█▇█████▇████▇▇███████████▇█▇██▇▇█</td></tr><tr><td>val_loss_epoch</td><td>█▇▃▃▂▂▂▁▃▂▂▁▁▂▂▁▂▁▁▂▂▁▂▂▁▂▁▁▂▁▁▁▃▁▃▁▂▂▂▂</td></tr><tr><td>val_loss_step</td><td>██▄▄▃▂▂▂▁▃▂▂▃▂▃▃▂▂▃▂▃▂▃▂▃▂▂▂▂▂▃▂▁▃▁▂▂▁▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>64</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85017</td></tr><tr><td>train_auc</td><td>0.91327</td></tr><tr><td>train_f1</td><td>0.83835</td></tr><tr><td>train_loss_epoch</td><td>0.45646</td></tr><tr><td>train_loss_step</td><td>0.41756</td></tr><tr><td>trainer/global_step</td><td>909</td></tr><tr><td>val_acc</td><td>0.79582</td></tr><tr><td>val_auc</td><td>0.90392</td></tr><tr><td>val_f1</td><td>0.79147</td></tr><tr><td>val_loss_epoch</td><td>0.48756</td></tr><tr><td>val_loss_step</td><td>0.37827</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_64_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/iw1pc14u' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/iw1pc14u</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240123_170758-iw1pc14u\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d621941b843c4844a3d5df4ce7d74be1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240123_180420-opoujm1u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/opoujm1u' target=\"_blank\">GAT_3_64_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/opoujm1u' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/opoujm1u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model2D     | GAT              | 44.6 K\n",
      "2  | model3D     | GAT              | 44.6 K\n",
      "3  | head        | BilinearFusion   | 686 K \n",
      "4  | pred        | Sequential       | 130   \n",
      "5  | loss_module | CrossEntropyLoss | 0     \n",
      "6  | train_acc   | BinaryAccuracy   | 0     \n",
      "7  | train_auroc | BinaryAUROC      | 0     \n",
      "8  | train_f1    | BinaryF1Score    | 0     \n",
      "9  | valid_acc   | BinaryAccuracy   | 0     \n",
      "10 | valid_auroc | BinaryAUROC      | 0     \n",
      "11 | valid_f1    | BinaryF1Score    | 0     \n",
      "12 | pool2D      | GlobalAttention  | 65    \n",
      "13 | pool3D      | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "776 K     Trainable params\n",
      "0         Non-trainable params\n",
      "776 K     Total params\n",
      "3.104     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=65` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5714e64fb4294332895406d48dd53937",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▅▆▆▆▆▆▇▆▇▇▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████</td></tr><tr><td>train_auc</td><td>▁▃▅▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇███▇█</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇█▇▇▇▇▇█▇█▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▄▄▄▃▃▄▄▃▃▂▃▃▃▂▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▁</td></tr><tr><td>train_loss_step</td><td>▅█▆▅▇▆▁▆▆▇▃▆▅▂▆▄▆▇▂▇█▅▂▃▄▃▂▅▄▄▇▃▃▅▄▄▂▄▅▆</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▁▁▃▃▃▃▃▄▂▂▂▂▂▂▅▅▅▅▆▆▂▂▂▂▃▃▇▇▇███▃</td></tr><tr><td>val_acc</td><td>▁▃▆▇▇▇▇█▇██▇▆█▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▆█▆▇▇▇▇▇▇█▇</td></tr><tr><td>val_auc</td><td>▁▁▂▃▄▅▅▆▅▅▆▆▆▆▆▆▅▆▆▆▇▆▅▇▆▇▆▆▇█▇██▇███▇▇▇</td></tr><tr><td>val_f1</td><td>▁▃▅▆▇▇▇▇▆▆█▇▆█▇▇▇█▇▇▆▆▆▇▇▇▇▆▆▆▇▆▇▇▆▇▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▆▃▂▂▂▂▁▂▂▂▁▃▁▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▃▁▂▂▂▂▃▁▃▁▂</td></tr><tr><td>val_loss_step</td><td>▂▂▄▅▅▅▃▅▂█▄▄▁▄▃▄▄▃▂▁▃▂▄▂▄▂▃▂▁▁▄▂▃▂▁▂▃▂▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>64</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83798</td></tr><tr><td>train_auc</td><td>0.90336</td></tr><tr><td>train_f1</td><td>0.82218</td></tr><tr><td>train_loss_epoch</td><td>0.46953</td></tr><tr><td>train_loss_step</td><td>0.47297</td></tr><tr><td>trainer/global_step</td><td>909</td></tr><tr><td>val_acc</td><td>0.76334</td></tr><tr><td>val_auc</td><td>0.88102</td></tr><tr><td>val_f1</td><td>0.75714</td></tr><tr><td>val_loss_epoch</td><td>0.51289</td></tr><tr><td>val_loss_step</td><td>0.42141</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GAT_3_64_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/opoujm1u' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/opoujm1u</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240123_180420-opoujm1u\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2809c01800b24c1091f35ca2569d28f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240123_194536-xje4sc9t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/xje4sc9t' target=\"_blank\">GINConv_3_16_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/xje4sc9t' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/xje4sc9t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model2D     | GIN              | 1.7 K \n",
      "2  | model3D     | GIN              | 1.7 K \n",
      "3  | head        | BilinearFusion   | 19.6 K\n",
      "4  | pred        | Sequential       | 34    \n",
      "5  | loss_module | CrossEntropyLoss | 0     \n",
      "6  | train_acc   | BinaryAccuracy   | 0     \n",
      "7  | train_auroc | BinaryAUROC      | 0     \n",
      "8  | train_f1    | BinaryF1Score    | 0     \n",
      "9  | valid_acc   | BinaryAccuracy   | 0     \n",
      "10 | valid_auroc | BinaryAUROC      | 0     \n",
      "11 | valid_f1    | BinaryF1Score    | 0     \n",
      "--------------------------------------------------\n",
      "23.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "23.2 K    Total params\n",
      "0.093     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=65` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "663db425b6fe4ea8b8d8f5839d6a710c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇█▇█████▇█▇█████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇███▇██▇██▇▇</td></tr><tr><td>train_f1</td><td>▁▄▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇██▇██▇███████▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▂▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▄▆▂▅▅▅▅▅▄▅▁▅▂▄▃▂▂▅▂▂▃▂▃▂▂▁▃▃▂▂▃▄▄▂▃▃▁▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▁▁▃▃▃▃▃▄▂▂▂▂▂▂▅▅▅▅▆▆▂▂▂▂▃▃▇▇▇███▃</td></tr><tr><td>val_acc</td><td>▃▁▅▃▃▆▆▆▆▆▆▇▆▅▇▆▃▆▅▄███▄▇▆▇▇█▆▇▅▇▇▆▇▆█▇▆</td></tr><tr><td>val_auc</td><td>▁▃▄▄▄▅▆▆▆▅▄▆▇▆▆▇▄▅▅▇▇█▇▆▇▆█▇▇▇▇▆▇█▆▇▇▇▆█</td></tr><tr><td>val_f1</td><td>▃▂▅▃▄▆▇▆▅▆▄▇▅▄▆▇▁▇▄▄█▇▆▄▆▆▇█▆▅▆▆▇▆▅▇▇▇▆▇</td></tr><tr><td>val_loss_epoch</td><td>█▅▃▄▄▃▂▂▃▂▄▂▂▃▂▃▄▃▃▃▁▁▂▄▂▂▁▂▂▂▂▃▂▁▂▂▂▂▂▂</td></tr><tr><td>val_loss_step</td><td>█▃▃▂▂▄▄▂▄▃▅▂▃▂▂▁▅▂▃▂▂▂▄▂▃▂▁▁▄▂▄▂▃▁▂▃▁▃▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>64</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85656</td></tr><tr><td>train_auc</td><td>0.90057</td></tr><tr><td>train_f1</td><td>0.85021</td></tr><tr><td>train_loss_epoch</td><td>0.4568</td></tr><tr><td>train_loss_step</td><td>0.44803</td></tr><tr><td>trainer/global_step</td><td>909</td></tr><tr><td>val_acc</td><td>0.80046</td></tr><tr><td>val_auc</td><td>0.88897</td></tr><tr><td>val_f1</td><td>0.78922</td></tr><tr><td>val_loss_epoch</td><td>0.47753</td></tr><tr><td>val_loss_step</td><td>0.36456</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/xje4sc9t' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/xje4sc9t</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240123_194536-xje4sc9t\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4b86239402348d985f1e9d583a7decb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240123_204126-0r5d9ahj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/0r5d9ahj' target=\"_blank\">MLP_2_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/0r5d9ahj' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/0r5d9ahj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model2D     | MLPModel         | 5.1 K \n",
      "2  | model3D     | MLPModel         | 5.1 K \n",
      "3  | head        | BilinearFusion   | 686 K \n",
      "4  | pred        | Sequential       | 130   \n",
      "5  | loss_module | CrossEntropyLoss | 0     \n",
      "6  | train_acc   | BinaryAccuracy   | 0     \n",
      "7  | train_auroc | BinaryAUROC      | 0     \n",
      "8  | train_f1    | BinaryF1Score    | 0     \n",
      "9  | valid_acc   | BinaryAccuracy   | 0     \n",
      "10 | valid_auroc | BinaryAUROC      | 0     \n",
      "11 | valid_f1    | BinaryF1Score    | 0     \n",
      "12 | pool2D      | GlobalAttention  | 65    \n",
      "13 | pool3D      | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "696 K     Trainable params\n",
      "0         Non-trainable params\n",
      "696 K     Total params\n",
      "2.788     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=65` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d9865e6df94b19add79086558c0ca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▇▇▇▇▇█▆▇▇▇▇█▇▇▇▇███▇▇▇█▇████▇▇█▇██████</td></tr><tr><td>train_auc</td><td>▁▅▇▇▇███▇█████▇████████▇██████▇█████████</td></tr><tr><td>train_f1</td><td>▁▅▇█████▇▇████▇████████▇████████████████</td></tr><tr><td>train_loss_epoch</td><td>█▆▃▂▂▂▂▁▃▂▂▁▂▁▂▂▂▂▁▂▂▁▁▂▁▂▂▁▂▁▂▁▁▂▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▄▅▄▄▃▃▆▄▄▃▅▃▃▃▃▄▁▃▄▃▃▅▂▄▂▅▁▂▁▂▂▃▂▄▄▁▃▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▁▁▃▃▃▃▃▄▂▂▂▂▂▂▅▅▅▅▆▆▂▂▂▂▃▃▇▇▇███▃</td></tr><tr><td>val_acc</td><td>▁▅▇▇▆█▇▇▆█▆▇▇▇▇▇▇██▇▇▇▇▅▇▇▇▇▇▆█▇▇▇▇█▇██▇</td></tr><tr><td>val_auc</td><td>▃▁▅▇▇▇███▇██████████████████████████████</td></tr><tr><td>val_f1</td><td>▁▇▇▇▆█▇▇██▇▇▇▇█▇███▇▇█▇▅█████▆█▇█▇██▇███</td></tr><tr><td>val_loss_epoch</td><td>█▄▂▃▄▁▂▂▂▁▃▂▃▃▁▂▁▁▁▃▂▁▂▅▁▁▂▁▁▄▁▂▁▃▁▁▂▁▁▁</td></tr><tr><td>val_loss_step</td><td>▇▃▄▅▇▂▄▄▁▃▅▄▅▅▂▄▁▃▂▅▄▂▄█▃▂▃▃▂▇▂▄▃▅▃▂▄▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>64</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.79384</td></tr><tr><td>train_auc</td><td>0.85912</td></tr><tr><td>train_f1</td><td>0.77991</td></tr><tr><td>train_loss_epoch</td><td>0.51204</td></tr><tr><td>train_loss_step</td><td>0.45344</td></tr><tr><td>trainer/global_step</td><td>909</td></tr><tr><td>val_acc</td><td>0.77958</td></tr><tr><td>val_auc</td><td>0.85512</td></tr><tr><td>val_f1</td><td>0.77108</td></tr><tr><td>val_loss_epoch</td><td>0.50947</td></tr><tr><td>val_loss_step</td><td>0.45868</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">MLP_2_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/0r5d9ahj' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/0r5d9ahj</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240123_204126-0r5d9ahj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ec42e28575a41d29a75ef1ecb438819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240123_213726-q64eh42v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/q64eh42v' target=\"_blank\">GraphConv_2_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/q64eh42v' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/q64eh42v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model2D     | GNNModel         | 992   \n",
      "2  | model3D     | GNNModel         | 992   \n",
      "3  | head        | BilinearFusion   | 19.6 K\n",
      "4  | pred        | Sequential       | 34    \n",
      "5  | loss_module | CrossEntropyLoss | 0     \n",
      "6  | train_acc   | BinaryAccuracy   | 0     \n",
      "7  | train_auroc | BinaryAUROC      | 0     \n",
      "8  | train_f1    | BinaryF1Score    | 0     \n",
      "9  | valid_acc   | BinaryAccuracy   | 0     \n",
      "10 | valid_auroc | BinaryAUROC      | 0     \n",
      "11 | valid_f1    | BinaryF1Score    | 0     \n",
      "12 | pool2D      | GlobalAttention  | 17    \n",
      "13 | pool3D      | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "21.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "21.7 K    Total params\n",
      "0.087     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=65` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "669d1ec8adbf43dd8f19a46cff9e295b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆██████▇▇▇█████▇</td></tr><tr><td>train_auc</td><td>▁▄▅▅▅▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████▇▇▇██████▇</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▃▁▁▁▁▁▁▂▂▁▁▁▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▅▄▄▄▃▆▃▂▃▃▄▃▁▁▃▃▃▃▃▃▂▃▂▃▂▃▂▃▃▂▂▄▂▂▃▁▃▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▁▁▃▃▃▃▃▄▂▂▂▂▂▂▅▅▅▅▆▆▂▂▂▂▃▃▇▇▇███▃</td></tr><tr><td>val_acc</td><td>▂▁▅▂▄▄▄▅▅▃▆▅▆▅▇▅▆▅█▇▆▆▆▆▆▇█▇▇█▇▇█▇███▆▆▆</td></tr><tr><td>val_auc</td><td>▁▂▄▄▃▃▃▃▅▄▆▅▆▅▆▅▆▄█▆▄▆▇▆▇▆▆▇▇▇▆▅▇▇▇██▇▇▅</td></tr><tr><td>val_f1</td><td>▅▁▆▁▄▄▅▅▆▃▆▅▇▅▇▆▇▅█▇▆▇▆▆█▇▇▇▇▇▇▆█▇▇█▇▅▆▆</td></tr><tr><td>val_loss_epoch</td><td>█▇▃▇▅▅▅▄▃▅▃▄▃▄▃▃▂▄▂▂▃▃▃▃▂▂▃▂▂▂▂▃▂▃▂▁▂▄▄▃</td></tr><tr><td>val_loss_step</td><td>▅▇▃█▅▅▄▄▄▆▄▄▂▆▄▃▃▅▃▃▄▂▄▄▁▃▄▄▄▄▁▄▄▅▃▂▄▆▆▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>64</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83275</td></tr><tr><td>train_auc</td><td>0.90052</td></tr><tr><td>train_f1</td><td>0.81323</td></tr><tr><td>train_loss_epoch</td><td>0.4667</td></tr><tr><td>train_loss_step</td><td>0.4054</td></tr><tr><td>trainer/global_step</td><td>909</td></tr><tr><td>val_acc</td><td>0.79814</td></tr><tr><td>val_auc</td><td>0.86727</td></tr><tr><td>val_f1</td><td>0.7563</td></tr><tr><td>val_loss_epoch</td><td>0.50882</td></tr><tr><td>val_loss_step</td><td>0.54124</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_2_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/q64eh42v' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/q64eh42v</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240123_213726-q64eh42v\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c493d7f2744ad395d59d40c60fda59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240123_223533-g64k3ba1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/g64k3ba1' target=\"_blank\">GCN_2_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/g64k3ba1' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/g64k3ba1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model2D     | GNNModel         | 5.2 K \n",
      "2  | model3D     | GNNModel         | 5.2 K \n",
      "3  | head        | BilinearFusion   | 686 K \n",
      "4  | pred        | Sequential       | 130   \n",
      "5  | loss_module | CrossEntropyLoss | 0     \n",
      "6  | train_acc   | BinaryAccuracy   | 0     \n",
      "7  | train_auroc | BinaryAUROC      | 0     \n",
      "8  | train_f1    | BinaryF1Score    | 0     \n",
      "9  | valid_acc   | BinaryAccuracy   | 0     \n",
      "10 | valid_auroc | BinaryAUROC      | 0     \n",
      "11 | valid_f1    | BinaryF1Score    | 0     \n",
      "12 | pool2D      | Attention_module | 4.2 K \n",
      "13 | pool3D      | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "705 K     Trainable params\n",
      "0         Non-trainable params\n",
      "705 K     Total params\n",
      "2.822     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=65` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e34af984cce1427599336ccb5260247c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▅▇▆▆▆▆▆▇▇▇▇▆▇▆▇▇▇▇▇▆▇▇▇▇▇█▇▇▇▇▇▇█▇▇▇</td></tr><tr><td>train_auc</td><td>▁▄▅▆▆▇▆▇▇▇▇▇▇█▇▇█▇█▇███▇▇█▇█▇███████████</td></tr><tr><td>train_f1</td><td>▁▄▅▅▄▇▆▆▆▆▆▇▇▇▇▆▇▆▇▇▇██▆▇▇▇▇▇▇█▇▇█▇███▇█</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▂▃▂▂▂▂▂▂▁▂▂▂▂▁▂▁▁▁▂▂▂▁▂▂▁▁▂▁▁▁▁▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▅█▃▆▄▅▆▇▂▇▄▆▄▇▁▅▅▂▃▄▄▂▄▆▃▄▃▄▅▆▅▃▃▃▅▄▅▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▁▁▃▃▃▃▃▄▂▂▂▂▂▂▅▅▅▅▆▆▂▂▂▂▃▃▇▇▇███▃</td></tr><tr><td>val_acc</td><td>▁▂▄▇▇█▇▇▇██▇███▇▇█▇▇▅▇█▆▇▇█▇█▇█████▇██▄█</td></tr><tr><td>val_auc</td><td>▁▂▅▅▆▆▆▆▅▇▇▆▇▆█▆█▇▇▇▆▇▆▇▄▂▅▅▇▆▇▇█▇▅▅▇▇██</td></tr><tr><td>val_f1</td><td>▁▃▅▇▇██▇███████▇██▇█▆██▆▇▇█████████▇██▇█</td></tr><tr><td>val_loss_epoch</td><td>█▇▅▃▃▂▁▂▂▁▁▁▁▂▁▂▁▁▂▁▄▁▁▄▂▂▂▂▁▁▁▁▂▁▂▃▁▂▃▁</td></tr><tr><td>val_loss_step</td><td>█▇▆▄▄▃▂▄▃▂▃▂▃▃▃▃▂▃▄▂▅▂▃▅▄▃▃▃▂▂▃▂▄▂▃▄▂▄▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>64</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8525</td></tr><tr><td>train_auc</td><td>0.91799</td></tr><tr><td>train_f1</td><td>0.84224</td></tr><tr><td>train_loss_epoch</td><td>0.45327</td></tr><tr><td>train_loss_step</td><td>0.3866</td></tr><tr><td>trainer/global_step</td><td>909</td></tr><tr><td>val_acc</td><td>0.81903</td></tr><tr><td>val_auc</td><td>0.88952</td></tr><tr><td>val_f1</td><td>0.78453</td></tr><tr><td>val_loss_epoch</td><td>0.4966</td></tr><tr><td>val_loss_step</td><td>0.5482</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/g64k3ba1' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/g64k3ba1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240123_223533-g64k3ba1\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a4d265818f4b718de3e1694ec8bb8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240123_233157-yp9he2c0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/yp9he2c0' target=\"_blank\">GAT_3_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/yp9he2c0' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/yp9he2c0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model2D     | GAT              | 44.6 K\n",
      "2  | model3D     | GAT              | 44.6 K\n",
      "3  | head        | BilinearFusion   | 686 K \n",
      "4  | pred        | Sequential       | 130   \n",
      "5  | loss_module | CrossEntropyLoss | 0     \n",
      "6  | train_acc   | BinaryAccuracy   | 0     \n",
      "7  | train_auroc | BinaryAUROC      | 0     \n",
      "8  | train_f1    | BinaryF1Score    | 0     \n",
      "9  | valid_acc   | BinaryAccuracy   | 0     \n",
      "10 | valid_auroc | BinaryAUROC      | 0     \n",
      "11 | valid_f1    | BinaryF1Score    | 0     \n",
      "12 | pool2D      | GlobalAttention  | 65    \n",
      "13 | pool3D      | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "776 K     Trainable params\n",
      "0         Non-trainable params\n",
      "776 K     Total params\n",
      "3.104     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=65` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae717bc2c6cd40d880a1e324c58a0634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇██▇█▇▇▇███▇</td></tr><tr><td>train_auc</td><td>▁▃▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇███████████████</td></tr><tr><td>train_f1</td><td>▁▄▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇██████▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▁▂▂▂▂▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>▇▇▆▅▅▆▇▄▅▃▄▅▄▃▅█▅▅▇▄▆▃▃▅▄▄▅█▆▆▇▄▄▅▄▄▁▄▄▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▁▁▃▃▃▃▃▄▂▂▂▂▂▂▅▅▅▅▆▆▂▂▂▂▃▃▇▇▇███▃</td></tr><tr><td>val_acc</td><td>▁▁▇▇▇▇▇██▇▇▇▇▇█▇████▇███▇███▇██████▇████</td></tr><tr><td>val_auc</td><td>▁▂▁▃▄▅▅▆▆▅▅▅▅▆▇▅▆▆▆▇▇█▆▇▅▇▇▆▅▆█▅█▆▇▅█▇██</td></tr><tr><td>val_f1</td><td>▁▁▇▆▇▇▇▇█▇▇▇▆▇▇▇▇▇▇█▆██▇▇▆██▇▇█▇█▇█▅████</td></tr><tr><td>val_loss_epoch</td><td>▇█▂▃▂▂▂▂▁▂▂▂▂▁▁▂▁▂▁▁▂▁▁▂▂▂▁▁▂▁▁▂▁▂▁▃▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>▂▁▃▆▄▄▄▄▃▄▃▂▄▃▄▂▄▆▄▃▆▂▃▄▃▄▃▄▃▄▂▄▃▄▄█▂▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>64</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83449</td></tr><tr><td>train_auc</td><td>0.90336</td></tr><tr><td>train_f1</td><td>0.82243</td></tr><tr><td>train_loss_epoch</td><td>0.47227</td></tr><tr><td>train_loss_step</td><td>0.48181</td></tr><tr><td>trainer/global_step</td><td>909</td></tr><tr><td>val_acc</td><td>0.81206</td></tr><tr><td>val_auc</td><td>0.88636</td></tr><tr><td>val_f1</td><td>0.79597</td></tr><tr><td>val_loss_epoch</td><td>0.48156</td></tr><tr><td>val_loss_step</td><td>0.42894</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GAT_3_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/yp9he2c0' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/yp9he2c0</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240123_233157-yp9he2c0\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bdd20f4ee694d819a7852a0802e86f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240124_002837-2p48kc9k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/2p48kc9k' target=\"_blank\">GINConv_3_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/2p48kc9k' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/2p48kc9k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model2D     | GIN              | 1.7 K \n",
      "2  | model3D     | GIN              | 1.7 K \n",
      "3  | head        | BilinearFusion   | 19.6 K\n",
      "4  | pred        | Sequential       | 34    \n",
      "5  | loss_module | CrossEntropyLoss | 0     \n",
      "6  | train_acc   | BinaryAccuracy   | 0     \n",
      "7  | train_auroc | BinaryAUROC      | 0     \n",
      "8  | train_f1    | BinaryF1Score    | 0     \n",
      "9  | valid_acc   | BinaryAccuracy   | 0     \n",
      "10 | valid_auroc | BinaryAUROC      | 0     \n",
      "11 | valid_f1    | BinaryF1Score    | 0     \n",
      "--------------------------------------------------\n",
      "23.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "23.2 K    Total params\n",
      "0.093     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=65` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▆▆▆▇▇▇▇▇▇▇▇▇▇▇██▇█▇█▇███████▇██▇▇▇████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇███▇█▇▇▇▇█▇██▇▇▇█▇▇█▇███</td></tr><tr><td>train_f1</td><td>▁▄▆▆▆▇▇▇█▇▇▇█▇█▇██████▇██████████▇▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▁▂▂▂▂▂▂▂▁▂▂▂▂▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▃▆▅▄▆▄▄▂▄▄▅▃▃▆▅▃▃▄▄▅▄▅▃▄▃▅▃▅▁▂▄▆▄▃▂▃▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▁▁▃▃▃▃▃▄▂▂▂▂▂▂▅▅▅▅▆▆▂▂▂▂▃▃▇▇▇███▃</td></tr><tr><td>val_acc</td><td>▁▃▃▃▃▃▃▆▅▄▆▅▅▅▅▆▇▇▅▆▅▂█▅▅▆▃▅▄▇▃▅▅▄▄▂▄▃▆▄</td></tr><tr><td>val_auc</td><td>▁▄▄▂▆▆▅▅▇▅▆▇▆▆▆▆▇█▇▇▆▇▇▅▇▇▆▇▆▆▆▆█▄▅▅▅▃▆▄</td></tr><tr><td>val_f1</td><td>▁▆▅▅▄▆▅▅▆▅▇▆▅▆▆▇▇▇▅▆▆▆█▅▅█▂▇▂▇▆▆▅▅▄▄▃▁▆▅</td></tr><tr><td>val_loss_epoch</td><td>█▃▄▄▃▂▃▄▂▂▂▂▃▂▁▂▁▁▃▂▂▃▁▃▃▁▄▂▅▁▂▂▂▃▄▃▄▅▂▂</td></tr><tr><td>val_loss_step</td><td>█▃▄▄▅▂▅▆▃▄▄▄▅▃▂▂▄▃▅▄▄▁▄▅▆▃▇▃█▃▁▅▃▄▅▄▇▇▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>64</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85134</td></tr><tr><td>train_auc</td><td>0.9091</td></tr><tr><td>train_f1</td><td>0.84158</td></tr><tr><td>train_loss_epoch</td><td>0.45668</td></tr><tr><td>train_loss_step</td><td>0.48002</td></tr><tr><td>trainer/global_step</td><td>909</td></tr><tr><td>val_acc</td><td>0.80278</td></tr><tr><td>val_auc</td><td>0.86589</td></tr><tr><td>val_f1</td><td>0.7769</td></tr><tr><td>val_loss_epoch</td><td>0.48994</td></tr><tr><td>val_loss_step</td><td>0.44243</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/2p48kc9k' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/2p48kc9k</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240124_002837-2p48kc9k\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc4ae40a1186494e8855abf77b38078d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.017183333333135428, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240124_012424-ylaqef7p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/ylaqef7p' target=\"_blank\">MLP_2_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/ylaqef7p' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/ylaqef7p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model2D     | MLPModel         | 5.1 K \n",
      "2  | model3D     | MLPModel         | 5.1 K \n",
      "3  | head        | BilinearFusion   | 686 K \n",
      "4  | pred        | Sequential       | 130   \n",
      "5  | loss_module | CrossEntropyLoss | 0     \n",
      "6  | train_acc   | BinaryAccuracy   | 0     \n",
      "7  | train_auroc | BinaryAUROC      | 0     \n",
      "8  | train_f1    | BinaryF1Score    | 0     \n",
      "9  | valid_acc   | BinaryAccuracy   | 0     \n",
      "10 | valid_auroc | BinaryAUROC      | 0     \n",
      "11 | valid_f1    | BinaryF1Score    | 0     \n",
      "12 | pool2D      | GlobalAttention  | 65    \n",
      "13 | pool3D      | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "696 K     Trainable params\n",
      "0         Non-trainable params\n",
      "696 K     Total params\n",
      "2.788     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=65` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec66aa18c6142e7926cb9ab94cbff98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▆▇▇▇▇▇▇█▇██▇▇▇██████████████▇███████▇█</td></tr><tr><td>train_auc</td><td>▁▆▇▇█▇▇▇▇████▇█▇██████████████████████▇█</td></tr><tr><td>train_f1</td><td>▁▄▇██▇▇██████▇████████████████████████▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▃▂▂▂▂▂▂▁▂▂▁▃▂▂▁▁▁▁▂▁▁▁▁▁▂▁▁▁▂▁▂▁▁▂▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▆▅▅▅▄▃▄▄▃▃▃▁▅▅▅▃▄▄▅▄▃▅▄▃▅▃▅▅▄▄▄▄▄▃▄▄▅▄▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▁▁▃▃▃▃▃▄▂▂▂▂▂▂▅▅▅▅▆▆▂▂▂▂▃▃▇▇▇███▃</td></tr><tr><td>val_acc</td><td>▁▅▇▇▇█▇█████████████▇██▇██▇██▇█████████▇</td></tr><tr><td>val_auc</td><td>▃▁▂▅▆▇▇▆▆▇▇▇█▇▇▇██████████████▇▇▇█▇███▇▇</td></tr><tr><td>val_f1</td><td>▁▆█▇▇█▇███▇██▇██████▇██▇█████▇██████████</td></tr><tr><td>val_loss_epoch</td><td>█▅▂▃▂▁▂▂▁▁▂▁▂▃▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂</td></tr><tr><td>val_loss_step</td><td>█▇▂▅▄▃▄▃▂▃▄▃▃▅▁▂▂▃▃▁▅▂▃▃▁▃▃▂▁▃▂▂▃▃▁▃▁▁▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>64</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.78062</td></tr><tr><td>train_auc</td><td>0.84133</td></tr><tr><td>train_f1</td><td>0.76551</td></tr><tr><td>train_loss_epoch</td><td>0.52286</td></tr><tr><td>train_loss_step</td><td>0.44014</td></tr><tr><td>trainer/global_step</td><td>909</td></tr><tr><td>val_acc</td><td>0.77907</td></tr><tr><td>val_auc</td><td>0.88817</td></tr><tr><td>val_f1</td><td>0.75325</td></tr><tr><td>val_loss_epoch</td><td>0.50341</td></tr><tr><td>val_loss_step</td><td>0.47477</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">MLP_2_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/ylaqef7p' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/ylaqef7p</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240124_012424-ylaqef7p\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d2f83756ed6428d8cbffd041baf49bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240124_022040-ulum0v44</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/ulum0v44' target=\"_blank\">GraphConv_2_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/ulum0v44' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/ulum0v44</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model2D     | GNNModel         | 992   \n",
      "2  | model3D     | GNNModel         | 992   \n",
      "3  | head        | BilinearFusion   | 19.6 K\n",
      "4  | pred        | Sequential       | 34    \n",
      "5  | loss_module | CrossEntropyLoss | 0     \n",
      "6  | train_acc   | BinaryAccuracy   | 0     \n",
      "7  | train_auroc | BinaryAUROC      | 0     \n",
      "8  | train_f1    | BinaryF1Score    | 0     \n",
      "9  | valid_acc   | BinaryAccuracy   | 0     \n",
      "10 | valid_auroc | BinaryAUROC      | 0     \n",
      "11 | valid_f1    | BinaryF1Score    | 0     \n",
      "12 | pool2D      | GlobalAttention  | 17    \n",
      "13 | pool3D      | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "21.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "21.7 K    Total params\n",
      "0.087     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=65` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44f79177e9db4ce28e02c0b6c66cf28a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▅▆▆▆▆▆▇▇▆▆▇▇▆▇▇▇▇▇▇▇▇█▇▇██▇▇████▇▇▇▇█</td></tr><tr><td>train_auc</td><td>▁▄▅▅▅▆▅▆▆▇▇▆▆▇▇▇▇▇▇██████▇▇██▇███▇█▇▇▇██</td></tr><tr><td>train_f1</td><td>▁▆▆▆▇▇▇▇▆▇▇▇▇▇█▇█▇▇████▇█▇▇██▇▇████▇▇███</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▃▄▃▃▃▂▃▃▂▂▃▂▂▂▂▂▂▂▂▁▂▂▂▁▂▂▁▁▁▁▂▂▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▅▅▆▅▄▃▃▄▅▄▃▅▃▃▄▃▅▃▄▄▁▃▃▂▄▃▅▄▄▅▄▄▃▂▆▂▃▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▁▁▃▃▃▃▃▄▂▂▂▂▂▂▅▅▅▅▆▆▂▂▂▂▃▃▇▇▇███▃</td></tr><tr><td>val_acc</td><td>▁▃▅▃▄▁▆▆▆▆▆▄▆▆▆▇▇▆▇█▇▇▇▆████▆▅▆▇▅▆▇▄▆▇▅█</td></tr><tr><td>val_auc</td><td>▁▃▅▄▄▄▆▅▅▅▅▄▆▇▆▆▆▅▆▇▇▇▆▆▇▇▇▇▆▆▆▆▅▅▆▆█▇██</td></tr><tr><td>val_f1</td><td>▁▃▅▃▂▃▅▄▆▅▅▄▅▄▄▆▇▅▇▇▅▆█▆███▇▅▆▆▇▄▅▇▁▇▇▆▇</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▃▃▄▂▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▂▂▂▂▂▂▂▄▂▂▂▁</td></tr><tr><td>val_loss_step</td><td>█▄▃▃▅▂▄▅▃▄▃▂▃▄▄▃▃▂▃▄▅▄▃▃▂▂▂▂▄▁▃▃▅▃▂█▂▄▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>64</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83691</td></tr><tr><td>train_auc</td><td>0.89569</td></tr><tr><td>train_f1</td><td>0.81477</td></tr><tr><td>train_loss_epoch</td><td>0.46999</td></tr><tr><td>train_loss_step</td><td>0.48428</td></tr><tr><td>trainer/global_step</td><td>909</td></tr><tr><td>val_acc</td><td>0.85116</td></tr><tr><td>val_auc</td><td>0.91021</td></tr><tr><td>val_f1</td><td>0.82796</td></tr><tr><td>val_loss_epoch</td><td>0.45413</td></tr><tr><td>val_loss_step</td><td>0.42949</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_2_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/ulum0v44' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/ulum0v44</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240124_022040-ulum0v44\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d0b17af87ab4c44a9e3ca5850ecba06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240124_031634-2s8722oz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/2s8722oz' target=\"_blank\">GCN_2_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/2s8722oz' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/2s8722oz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model2D     | GNNModel         | 5.2 K \n",
      "2  | model3D     | GNNModel         | 5.2 K \n",
      "3  | head        | BilinearFusion   | 686 K \n",
      "4  | pred        | Sequential       | 130   \n",
      "5  | loss_module | CrossEntropyLoss | 0     \n",
      "6  | train_acc   | BinaryAccuracy   | 0     \n",
      "7  | train_auroc | BinaryAUROC      | 0     \n",
      "8  | train_f1    | BinaryF1Score    | 0     \n",
      "9  | valid_acc   | BinaryAccuracy   | 0     \n",
      "10 | valid_auroc | BinaryAUROC      | 0     \n",
      "11 | valid_f1    | BinaryF1Score    | 0     \n",
      "12 | pool2D      | Attention_module | 4.2 K \n",
      "13 | pool3D      | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "705 K     Trainable params\n",
      "0         Non-trainable params\n",
      "705 K     Total params\n",
      "2.822     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=65` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ccf4dc3bcc047c6a3dcf0bc1d63743f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▆▆▆▆▆▆▇▆▇▆▇▇▇▆▆▇▇███▇▇▇▇▇▇▇▇██▇████</td></tr><tr><td>train_auc</td><td>▁▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆█▇███▇▇▇▇▇██▇███████</td></tr><tr><td>train_f1</td><td>▁▄▅▅▆▆▆▆▆▆▆▇▆▇▆▇▆▇▆▆▇▇▇▇█▆▇▇▇▇▇▇▇██▇▇███</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▃▂▂▁▁▁▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▇▇▄▅▅▄▄▆▄▆▄▁▇▂▅▅▄▄▃▄▅▆▂▃▂▇▃▆▇▅▆▃▄▆▄▅▆▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▁▁▃▃▃▃▃▄▂▂▂▂▂▂▅▅▅▅▆▆▂▂▂▂▃▃▇▇▇███▃</td></tr><tr><td>val_acc</td><td>▁▅▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇██▇███████▇█▇██▇██</td></tr><tr><td>val_auc</td><td>▁▄▅▅▅▅▆▆▇▇███▆▅▆▇▇▅▇▅▇▇▇▅▅▇▇▇▇▇██▇▇▇▇▅█▇</td></tr><tr><td>val_f1</td><td>▁▆▇▇██▇██▇█▇████████████████████████████</td></tr><tr><td>val_loss_epoch</td><td>█▅▂▂▂▁▂▁▁▂▁▂▁▁▂▂▁▂▂▁▁▁▁▁▂▂▁▁▁▁▁▂▁▁▂▁▁▂▁▁</td></tr><tr><td>val_loss_step</td><td>█▅▃▃▂▁▃▂▂▃▁▃▁▂▂▂▁▃▂▂▂▂▂▂▂▃▁▂▂▂▂▃▁▂▃▂▁▃▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>64</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85432</td></tr><tr><td>train_auc</td><td>0.91382</td></tr><tr><td>train_f1</td><td>0.84084</td></tr><tr><td>train_loss_epoch</td><td>0.45382</td></tr><tr><td>train_loss_step</td><td>0.44101</td></tr><tr><td>trainer/global_step</td><td>909</td></tr><tr><td>val_acc</td><td>0.84186</td></tr><tr><td>val_auc</td><td>0.92085</td></tr><tr><td>val_f1</td><td>0.82474</td></tr><tr><td>val_loss_epoch</td><td>0.46236</td></tr><tr><td>val_loss_step</td><td>0.45495</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/2s8722oz' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/2s8722oz</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240124_031634-2s8722oz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "771148f68de34888a164684f31cfa01c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240124_041237-g34npmia</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/g34npmia' target=\"_blank\">GAT_3_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/g34npmia' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/g34npmia</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model2D     | GAT              | 44.6 K\n",
      "2  | model3D     | GAT              | 44.6 K\n",
      "3  | head        | BilinearFusion   | 686 K \n",
      "4  | pred        | Sequential       | 130   \n",
      "5  | loss_module | CrossEntropyLoss | 0     \n",
      "6  | train_acc   | BinaryAccuracy   | 0     \n",
      "7  | train_auroc | BinaryAUROC      | 0     \n",
      "8  | train_f1    | BinaryF1Score    | 0     \n",
      "9  | valid_acc   | BinaryAccuracy   | 0     \n",
      "10 | valid_auroc | BinaryAUROC      | 0     \n",
      "11 | valid_f1    | BinaryF1Score    | 0     \n",
      "12 | pool2D      | GlobalAttention  | 65    \n",
      "13 | pool3D      | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "776 K     Trainable params\n",
      "0         Non-trainable params\n",
      "776 K     Total params\n",
      "3.104     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=65` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e31cd4e496548cbb442b47a00a38419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▇▆▆▆▇▆▇▇▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇███▇█</td></tr><tr><td>train_auc</td><td>▁▄▅▅▆▇▆▆▇▇▆▇▇▇▇▇▇▆▇▇▇▇▇▇██▇▇█▇████████▇█</td></tr><tr><td>train_f1</td><td>▁▄▅▅▆▇▆▆▇▇▆▆▇▇▇▇█▆▇▇▆▇▇▇▇▇▇▇▇▇▇█▇▇▇███▇█</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▂▃▃▃▃▃▂▂▂▂▂▂▃▂▂▂▂▂▁▂▂▂▂▂▂▁▁▁▂▂▁▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▆▄▄▇▅▅▅▆▆▅▃▅▄▆▇▁▃▄▄▅▃▄▄▂▄▇▃▅▄▂█▄▇▁▃▅▁▅▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▁▁▃▃▃▃▃▄▂▂▂▂▂▂▅▅▅▅▆▆▂▂▂▂▃▃▇▇▇███▃</td></tr><tr><td>val_acc</td><td>▁▁▅▇▇▇▇▆▆▆▇▇▆▆▆▅▆▇▇█▇▇▇▇▇█▆▇▇▇█▇▇▆▇▇██▇█</td></tr><tr><td>val_auc</td><td>▃▃▅▂▅▄▁▄▅▃▅▄▂▅▄▄▅▅▄▅▆▆▄▃▆▆▇▇▅▅▇▇█▅▄▅██▇▇</td></tr><tr><td>val_f1</td><td>▁▁▅▆▇▇▆▅▆▆▇▆▆▆▆▅▆▆▆▇▇▆▆▆▆▇▆▇▆▇█▇▇▅▆▆▇▇▇█</td></tr><tr><td>val_loss_epoch</td><td>██▃▂▂▂▂▃▂▃▂▂▂▂▃▄▃▂▂▁▂▂▂▂▂▁▃▂▂▂▁▂▂▃▂▂▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>▃▁▁▄▄▅▆▁▂▂▃▄▂▂▁▁▁▂▄▄▂▃▄▄▂▅▁▂▂▃▄▃▂▁▄█▃▃▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>64</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83343</td></tr><tr><td>train_auc</td><td>0.90195</td></tr><tr><td>train_f1</td><td>0.81708</td></tr><tr><td>train_loss_epoch</td><td>0.4688</td></tr><tr><td>train_loss_step</td><td>0.46927</td></tr><tr><td>trainer/global_step</td><td>909</td></tr><tr><td>val_acc</td><td>0.84419</td></tr><tr><td>val_auc</td><td>0.90666</td></tr><tr><td>val_f1</td><td>0.83538</td></tr><tr><td>val_loss_epoch</td><td>0.46338</td></tr><tr><td>val_loss_step</td><td>0.39307</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GAT_3_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/g34npmia' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/g34npmia</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240124_041237-g34npmia\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53b2f0528c334cb4b611bcf5b2a63fec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240124_050931-9yrl5gq5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/9yrl5gq5' target=\"_blank\">GINConv_3_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/9yrl5gq5' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/9yrl5gq5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model2D     | GIN              | 1.7 K \n",
      "2  | model3D     | GIN              | 1.7 K \n",
      "3  | head        | BilinearFusion   | 19.6 K\n",
      "4  | pred        | Sequential       | 34    \n",
      "5  | loss_module | CrossEntropyLoss | 0     \n",
      "6  | train_acc   | BinaryAccuracy   | 0     \n",
      "7  | train_auroc | BinaryAUROC      | 0     \n",
      "8  | train_f1    | BinaryF1Score    | 0     \n",
      "9  | valid_acc   | BinaryAccuracy   | 0     \n",
      "10 | valid_auroc | BinaryAUROC      | 0     \n",
      "11 | valid_f1    | BinaryF1Score    | 0     \n",
      "--------------------------------------------------\n",
      "23.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "23.2 K    Total params\n",
      "0.093     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=65` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d719e24caa40449d93b56511044cab9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▇▇▇▇▇▇▇▇█▇▇▇█▇█▇██▇████▇████████▇███</td></tr><tr><td>train_auc</td><td>▁▅▆▆▇▇▇█▇▇▇▇██▇▇█▇█▇▇█▇█████████████████</td></tr><tr><td>train_f1</td><td>▁▆▇▇▇▇▇█▇▇▇▇█████▇█▇████████████████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▃▃▂▃▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▁▂▁▂▁▂▂▁▂▁▁▂▁▂▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▅▄▂▅▄▃▃▂▅▄▃▂▄▃▄▂▄▃▂▃▃▃▄▂▃▁▂▃▃▄▃▃▃▂▅▃▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▁▁▃▃▃▃▃▄▂▂▂▂▂▂▅▅▅▅▆▆▂▂▂▂▃▃▇▇▇███▃</td></tr><tr><td>val_acc</td><td>▂▄▃▃▄▆▅▃▅▃▅█▅▅▆▄▇▆▅▆▅▅▆▆▃▄▁▆▅▆▄▅▇▄▄▇▆▅▆▆</td></tr><tr><td>val_auc</td><td>▁▄▂▃▅▆▇▆▄▃▆▆▅▆▆▆▅▅▇▆▇███▆▆▅▇▅▆▄▆▆▄▅▅█▅▇▆</td></tr><tr><td>val_f1</td><td>▁▅▄▆▅▆▆▅▅▂▇█▆▆▆▆▇▆▇▇▇▇▇▇▃▆▅▇▅▆▆▅▆▆▅▆▇▆▆▇</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▂▂▂▂▂▂▃▂▁▂▂▂▂▁▁▁▁▂▁▁▂▂▂▃▁▂▁▂▂▂▂▂▂▁▂▂▁</td></tr><tr><td>val_loss_step</td><td>█▄▄▂▃▂▂▂▂▄▂▂▂▂▂▂▃▂▁▂▂▁▂▂▂▂▁▁▃▁▂▂▃▂▂▃▂▂▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>64</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85781</td></tr><tr><td>train_auc</td><td>0.90171</td></tr><tr><td>train_f1</td><td>0.84325</td></tr><tr><td>train_loss_epoch</td><td>0.451</td></tr><tr><td>train_loss_step</td><td>0.41696</td></tr><tr><td>trainer/global_step</td><td>909</td></tr><tr><td>val_acc</td><td>0.82791</td></tr><tr><td>val_auc</td><td>0.8997</td></tr><tr><td>val_f1</td><td>0.81592</td></tr><tr><td>val_loss_epoch</td><td>0.45639</td></tr><tr><td>val_loss_step</td><td>0.34796</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/9yrl5gq5' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/9yrl5gq5</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240124_050931-9yrl5gq5\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc4477a4d8de49599222c8bfed01fc9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240124_060626-vcmhnlui</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/vcmhnlui' target=\"_blank\">MLP_2_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/vcmhnlui' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/vcmhnlui</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model2D     | MLPModel         | 5.1 K \n",
      "2  | model3D     | MLPModel         | 5.1 K \n",
      "3  | head        | BilinearFusion   | 686 K \n",
      "4  | pred        | Sequential       | 130   \n",
      "5  | loss_module | CrossEntropyLoss | 0     \n",
      "6  | train_acc   | BinaryAccuracy   | 0     \n",
      "7  | train_auroc | BinaryAUROC      | 0     \n",
      "8  | train_f1    | BinaryF1Score    | 0     \n",
      "9  | valid_acc   | BinaryAccuracy   | 0     \n",
      "10 | valid_auroc | BinaryAUROC      | 0     \n",
      "11 | valid_f1    | BinaryF1Score    | 0     \n",
      "12 | pool2D      | GlobalAttention  | 65    \n",
      "13 | pool3D      | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "696 K     Trainable params\n",
      "0         Non-trainable params\n",
      "696 K     Total params\n",
      "2.788     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=65` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f1e99f14aa4327a5ca9d0200c02534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▇▇▇▇██▇▇█████████████████▇▇███████████</td></tr><tr><td>train_auc</td><td>▁▆▇▇█▇███▇█████████████████▇████████████</td></tr><tr><td>train_f1</td><td>▁▃▇▇█████▇█████████████████▇████████████</td></tr><tr><td>train_loss_epoch</td><td>█▆▂▂▂▂▂▁▂▂▁▁▁▁▂▁▁▁▁▁▂▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▅▃▆▄▃▂▂▃▅▃▂▁▃▃▂▃▃▂▄▃▅▂▂▃▄▃▁▃▁▃▄▄▃▃▂▂▃▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▁▁▃▃▃▃▃▄▂▂▂▂▂▂▅▅▅▅▆▆▂▂▂▂▃▃▇▇▇███▃</td></tr><tr><td>val_acc</td><td>▁▄█▇▆▇▇▇▆▇█▆▇▇▇▇█▇▇▇▇▇▇█▇▇█▇▇▇▇█▇▇▇▇███▇</td></tr><tr><td>val_auc</td><td>▁▁▅▆▆▆▇▇▇███▇▇████▇▇▇▇████▇▇████████████</td></tr><tr><td>val_f1</td><td>▁▅█▇▆▇▇▇▇▇█▇▇█▇███████▇██████▇██▇██▇███▇</td></tr><tr><td>val_loss_epoch</td><td>█▆▂▂▅▃▃▂▄▂▁▃▂▁▂▁▁▂▁▁▂▂▂▁▁▁▁▁▂▃▁▁▃▂▁▃▁▁▁▂</td></tr><tr><td>val_loss_step</td><td>██▃▄▇▅▅▄▆▄▃▅▄▃▄▃▃▃▃▂▃▁▄▂▂▃▂▂▃▅▃▃▅▃▂▅▂▂▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>64</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77887</td></tr><tr><td>train_auc</td><td>0.84768</td></tr><tr><td>train_f1</td><td>0.76023</td></tr><tr><td>train_loss_epoch</td><td>0.52525</td></tr><tr><td>train_loss_step</td><td>0.56988</td></tr><tr><td>trainer/global_step</td><td>909</td></tr><tr><td>val_acc</td><td>0.73953</td></tr><tr><td>val_auc</td><td>0.84314</td></tr><tr><td>val_f1</td><td>0.71282</td></tr><tr><td>val_loss_epoch</td><td>0.54665</td></tr><tr><td>val_loss_step</td><td>0.54655</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">MLP_2_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/vcmhnlui' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/vcmhnlui</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240124_060626-vcmhnlui\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01aaf9e464834c02b81443d63052a713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240124_070225-xxkj7vw8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/xxkj7vw8' target=\"_blank\">GraphConv_2_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/xxkj7vw8' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/xxkj7vw8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model2D     | GNNModel         | 992   \n",
      "2  | model3D     | GNNModel         | 992   \n",
      "3  | head        | BilinearFusion   | 19.6 K\n",
      "4  | pred        | Sequential       | 34    \n",
      "5  | loss_module | CrossEntropyLoss | 0     \n",
      "6  | train_acc   | BinaryAccuracy   | 0     \n",
      "7  | train_auroc | BinaryAUROC      | 0     \n",
      "8  | train_f1    | BinaryF1Score    | 0     \n",
      "9  | valid_acc   | BinaryAccuracy   | 0     \n",
      "10 | valid_auroc | BinaryAUROC      | 0     \n",
      "11 | valid_f1    | BinaryF1Score    | 0     \n",
      "12 | pool2D      | GlobalAttention  | 17    \n",
      "13 | pool3D      | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "21.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "21.7 K    Total params\n",
      "0.087     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=65` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4864e637a0074d07b119b4588be4eca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇█▇▇████▇███████</td></tr><tr><td>train_auc</td><td>▁▄▆▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇██▇████▇███████</td></tr><tr><td>train_f1</td><td>▁▆▇▆▇▇▇▇▇▇▇▇▇▇█▇█▇▇████▇▇██▇████▇███████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▃▃▃▃▂▂▂▃▂▂▃▂▂▂▂▂▂▂▂▂▁▂▂▂▁▁▁▂▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▅▅▄▄▄▄▂▅▄▃▅▂▄▄▃▃▃▅▃▄▃▃▃▃▄▃▃▄▁▃▂▂▃▄▃▃▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▁▁▃▃▃▃▃▄▂▂▂▂▂▂▅▅▅▅▆▆▂▂▂▂▃▃▇▇▇███▃</td></tr><tr><td>val_acc</td><td>▁▂▃▄▃▄▅▆▅▇▇▆▇▆▇▅▆▇▆█▇▇▄▇▆██▇▆▆█▇▇▆▇▆▆▆█▅</td></tr><tr><td>val_auc</td><td>▁▂▃▄▄▅▅▇▇▇▇▇▇▇▇▇▇▇▇███▇███▇██████▇█▇█▇█▇</td></tr><tr><td>val_f1</td><td>▃▄▄▄▂▅▆▆▅▆▇▇▇▇▇▇▇▇▇▇▇█▁▆███▇▆▅██▇▇██▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▄▄▃▄▃▂▂▂▂▂▂▂▂▂▂▁▂▁▁▂▁▄▂▁▂▁▁▂▂▁▁▁▂▁▂▁▂▂▂</td></tr><tr><td>val_loss_step</td><td>▇▄▄▄▅▃▄▃▄▄▄▂▄▂▅▁▂▄▂▅▅▃█▅▁▅▄▄▅▆▄▃▄▂▂▁▂▁▅▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>64</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86303</td></tr><tr><td>train_auc</td><td>0.9131</td></tr><tr><td>train_f1</td><td>0.84595</td></tr><tr><td>train_loss_epoch</td><td>0.44816</td></tr><tr><td>train_loss_step</td><td>0.43537</td></tr><tr><td>trainer/global_step</td><td>909</td></tr><tr><td>val_acc</td><td>0.76977</td></tr><tr><td>val_auc</td><td>0.87811</td></tr><tr><td>val_f1</td><td>0.79503</td></tr><tr><td>val_loss_epoch</td><td>0.51378</td></tr><tr><td>val_loss_step</td><td>0.4117</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GraphConv_2_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/xxkj7vw8' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/xxkj7vw8</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240124_070225-xxkj7vw8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38a5dd9a496f499982951d377f896179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240124_075809-vd7a742v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/vd7a742v' target=\"_blank\">GCN_2_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/vd7a742v' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/vd7a742v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model2D     | GNNModel         | 5.2 K \n",
      "2  | model3D     | GNNModel         | 5.2 K \n",
      "3  | head        | BilinearFusion   | 686 K \n",
      "4  | pred        | Sequential       | 130   \n",
      "5  | loss_module | CrossEntropyLoss | 0     \n",
      "6  | train_acc   | BinaryAccuracy   | 0     \n",
      "7  | train_auroc | BinaryAUROC      | 0     \n",
      "8  | train_f1    | BinaryF1Score    | 0     \n",
      "9  | valid_acc   | BinaryAccuracy   | 0     \n",
      "10 | valid_auroc | BinaryAUROC      | 0     \n",
      "11 | valid_f1    | BinaryF1Score    | 0     \n",
      "12 | pool2D      | Attention_module | 4.2 K \n",
      "13 | pool3D      | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "705 K     Trainable params\n",
      "0         Non-trainable params\n",
      "705 K     Total params\n",
      "2.822     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=65` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd9037a1c30b412b99b59570fcd20495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▅▆▅▇▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇█▇▇▇█▇▆▇▇▆▇▇█▆▇█▇</td></tr><tr><td>train_auc</td><td>▁▄▆▅▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇██▇███▇█▇▇███▇██▇</td></tr><tr><td>train_f1</td><td>▁▄▅▅▅▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇█▆▇█▇▇▇▇▇▇▇▇▆▇██▆▇█▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▃▃▂▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▃▂▁▁▂▂▁▂</td></tr><tr><td>train_loss_step</td><td>▇▆▇█▆▄▇▄▇▄▇▆▆▃▄▅▆▅▅▃▅▅▅▃▁▆▄▅▃▃▆▃▆▄▆▄▂▁▄▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▁▁▃▃▃▃▃▄▂▂▂▂▂▂▅▅▅▅▆▆▂▂▂▂▃▃▇▇▇███▃</td></tr><tr><td>val_acc</td><td>▁▅▆▇▇▇▆▆▆▇▇▇▇▇▇█▆█▆▇▆▇▇▇▇▅▇█▆▇▆█▆▇█▇█▇█▇</td></tr><tr><td>val_auc</td><td>▁▁▄▅▅▆▅▆▆▆▆▆▆▇▆▇▄▇▂▇▆▇▇▆▇▆▇▇▅▇▅▇▇▇▇▇▇██▇</td></tr><tr><td>val_f1</td><td>▁▅▇▇██▇▇██▇█████▇█▇█▆█▇▇█▇██▇█▇██▇█████▇</td></tr><tr><td>val_loss_epoch</td><td>█▅▃▂▂▂▃▃▂▁▂▂▁▁▂▁▂▁▃▁▄▁▂▂▁▂▁▂▂▁▂▁▂▂▁▂▁▁▁▂</td></tr><tr><td>val_loss_step</td><td>█▅▄▃▃▁▄▅▂▃▄▃▂▃▃▃▃▃▃▂▆▂▄▄▂▁▃▃▂▃▄▃▁▄▂▃▃▂▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>64</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84388</td></tr><tr><td>train_auc</td><td>0.90986</td></tr><tr><td>train_f1</td><td>0.82612</td></tr><tr><td>train_loss_epoch</td><td>0.46141</td></tr><tr><td>train_loss_step</td><td>0.50486</td></tr><tr><td>trainer/global_step</td><td>909</td></tr><tr><td>val_acc</td><td>0.79302</td></tr><tr><td>val_auc</td><td>0.89346</td></tr><tr><td>val_f1</td><td>0.78346</td></tr><tr><td>val_loss_epoch</td><td>0.50587</td></tr><tr><td>val_loss_step</td><td>0.53928</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/vd7a742v' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/vd7a742v</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240124_075809-vd7a742v\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af4c09f90ae148ccb687bad987323206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240124_085408-94qpkatg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/94qpkatg' target=\"_blank\">GAT_3_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/94qpkatg' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/94qpkatg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model2D     | GAT              | 44.6 K\n",
      "2  | model3D     | GAT              | 44.6 K\n",
      "3  | head        | BilinearFusion   | 686 K \n",
      "4  | pred        | Sequential       | 130   \n",
      "5  | loss_module | CrossEntropyLoss | 0     \n",
      "6  | train_acc   | BinaryAccuracy   | 0     \n",
      "7  | train_auroc | BinaryAUROC      | 0     \n",
      "8  | train_f1    | BinaryF1Score    | 0     \n",
      "9  | valid_acc   | BinaryAccuracy   | 0     \n",
      "10 | valid_auroc | BinaryAUROC      | 0     \n",
      "11 | valid_f1    | BinaryF1Score    | 0     \n",
      "12 | pool2D      | GlobalAttention  | 65    \n",
      "13 | pool3D      | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "776 K     Trainable params\n",
      "0         Non-trainable params\n",
      "776 K     Total params\n",
      "3.104     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GAT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=65` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3edab009b2c543e4b3a4710d7d5bc26f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▅▆▆▆▅▅▆▇▆▆▆▆▅▇▇▇▆▇▇▇▇▇▇▇▇▇██▇▇██▇▇███▇</td></tr><tr><td>train_auc</td><td>▁▂▆▆▆▆▆▆▇▇▇▇▇▇▆▇▇▇▇▇██████▇████▇████████</td></tr><tr><td>train_f1</td><td>▁▂▅▆▆▆▅▅▆▇▆▆▆▆▆▇▇▇▆▇▆▇▇▇▇▇█▇█▇▇▇██▇▇███▇</td></tr><tr><td>train_loss_epoch</td><td>█▇▄▃▄▃▃▄▃▂▃▂▃▃▃▂▂▂▃▂▂▂▂▂▂▂▁▂▂▁▂▂▁▂▂▂▁▁▂▂</td></tr><tr><td>train_loss_step</td><td>▆▃▂▆▂▅▃▄▄▁▃▃▄▄▂▅▄▂█▃▁▃▄▂▃▂▃▄▃▂▄▂▂▃▃▄▃▃▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▁▁▃▃▃▃▃▄▂▂▂▂▂▂▅▅▅▅▆▆▂▂▂▂▃▃▇▇▇███▃</td></tr><tr><td>val_acc</td><td>▁▁▅▇▇▇▆▇▇▇▇▇▇▇▇▅██▆█▇██▆▆███▇▇▇▇██▇█████</td></tr><tr><td>val_auc</td><td>▁▃▄▅▅▅▆▄▅▅▆▅▆▇▆▆▇▆▆▇▆▇▇▄▆▇▇▇▇▇▇▇▇█▇▇████</td></tr><tr><td>val_f1</td><td>▁▁▄▇▆▇▆▇▇▇▇▇▇▇▇▅▇▇▆▇▆▇▇▃▆▇▇█▇▇▅▄██▇█▇█▇█</td></tr><tr><td>val_loss_epoch</td><td>▆█▃▂▂▂▂▂▂▂▁▂▁▂▂▃▂▁▂▁▂▁▁▃▃▂▁▁▁▂▂▃▁▁▁▁▂▁▂▁</td></tr><tr><td>val_loss_step</td><td>▃▁▁▃▃▃▂▂▃▂▃▁▂▂▂▁▅▅▂▅▁▅▄█▁▆▃▄▃▃▇█▅▅▂▅▆▅▆▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>64</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.82763</td></tr><tr><td>train_auc</td><td>0.89398</td></tr><tr><td>train_f1</td><td>0.79864</td></tr><tr><td>train_loss_epoch</td><td>0.47856</td></tr><tr><td>train_loss_step</td><td>0.42977</td></tr><tr><td>trainer/global_step</td><td>909</td></tr><tr><td>val_acc</td><td>0.81628</td></tr><tr><td>val_auc</td><td>0.89147</td></tr><tr><td>val_f1</td><td>0.81839</td></tr><tr><td>val_loss_epoch</td><td>0.48924</td></tr><tr><td>val_loss_step</td><td>0.48774</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GAT_3_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/94qpkatg' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/94qpkatg</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240124_085408-94qpkatg\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f35f9db0a6684d9188893bee21d44bc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333332902596, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240124_095137-e97gpxom</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/e97gpxom' target=\"_blank\">GINConv_3_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/e97gpxom' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/e97gpxom</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model2D     | GIN              | 1.7 K \n",
      "2  | model3D     | GIN              | 1.7 K \n",
      "3  | head        | BilinearFusion   | 19.6 K\n",
      "4  | pred        | Sequential       | 34    \n",
      "5  | loss_module | CrossEntropyLoss | 0     \n",
      "6  | train_acc   | BinaryAccuracy   | 0     \n",
      "7  | train_auroc | BinaryAUROC      | 0     \n",
      "8  | train_f1    | BinaryF1Score    | 0     \n",
      "9  | valid_acc   | BinaryAccuracy   | 0     \n",
      "10 | valid_auroc | BinaryAUROC      | 0     \n",
      "11 | valid_f1    | BinaryF1Score    | 0     \n",
      "--------------------------------------------------\n",
      "23.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "23.2 K    Total params\n",
      "0.093     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=65` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "995357524ce140f5a79238b93a973cef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇█▇██▇▇█▇███▇▇▇████████</td></tr><tr><td>train_auc</td><td>▁▆▆▇▇▇▇█▇▇▇▇█▇▇▇▇▇█████▇█▇████▇▇████████</td></tr><tr><td>train_f1</td><td>▁▆▇▇▇▇▇█▇▇▇▇▇▇▇████████▇█████▇██████████</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▃▂▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▂▂▁▁▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▂▇▄▄▄▄▃▄▄▄▃▄▃▃▄▃▄▄▄▂▅▃▂▃▃▄▃▃▁▃▂▂▄▄▅▄▂▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▁▁▃▃▃▃▃▄▂▂▂▂▂▂▅▅▅▅▆▆▂▂▂▂▃▃▇▇▇███▃</td></tr><tr><td>val_acc</td><td>▁▁▄▅▅▆▅▆▆▆▇█▆▆▇▇▇▇▆▅▆▆█▄▆▅▆▅▆▆▆▆▆▇▇▅▅█▆▆</td></tr><tr><td>val_auc</td><td>▁▁▆▅▇▇▇▆▇▇▇██▇▇▇▆█▇▇█▇█▅▆▇▇▇█▇▆▇▆▇▇▆▇▇▇▆</td></tr><tr><td>val_f1</td><td>▁▅▄▅▅▇▆▆▆▆▇█▇▆▇▇▇▇▆▅▆▇█▅▇▅▆▅▆▆▅▆▇▇▇▅▆▇▆▆</td></tr><tr><td>val_loss_epoch</td><td>█▄▄▃▃▂▂▂▂▂▂▁▂▂▂▁▂▂▂▃▃▂▁▄▂▃▃▃▃▃▃▃▂▂▁▃▃▂▃▂</td></tr><tr><td>val_loss_step</td><td>█▁▄▃▅▂▃▃▂▂▃▃▃▃▃▂▂▃▂▄▄▂▂▃▂▅▅▅▄▅▅▄▂▃▂▄▄▄▄▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>64</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8491</td></tr><tr><td>train_auc</td><td>0.89476</td></tr><tr><td>train_f1</td><td>0.83607</td></tr><tr><td>train_loss_epoch</td><td>0.46127</td></tr><tr><td>train_loss_step</td><td>0.48403</td></tr><tr><td>trainer/global_step</td><td>909</td></tr><tr><td>val_acc</td><td>0.80233</td></tr><tr><td>val_auc</td><td>0.87216</td></tr><tr><td>val_f1</td><td>0.80549</td></tr><tr><td>val_loss_epoch</td><td>0.49323</td></tr><tr><td>val_loss_step</td><td>0.42615</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/e97gpxom' target=\"_blank\">https://wandb.ai/thoomas/PLA_01122024_13PPI_2D3D_fusion_Kfold/runs/e97gpxom</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240124_095137-e97gpxom\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k_folds = 5\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_ids, valid_ids) in enumerate(kfold.split(dataset_filtered)):\n",
    "    train_subset = dataset_filtered.index_select(train_ids.tolist())\n",
    "    val_subset = dataset_filtered.index_select(valid_ids.tolist())\n",
    "    for NUM_LAYERS, HIDDEN_CHANNELS, pool, model in params:\n",
    "            # Path to the folder where the pretrained models are saved\n",
    "        # CHECKPOINT_PATH = checkpoint_folder / f'GAT_{NUM_LAYERS}_{HIDDEN_CHANNELS}_onehot_{fold}' / pool\n",
    "        CHECKPOINT_PATH = checkpoint_folder / f'{model}_{NUM_LAYERS}_{HIDDEN_CHANNELS}_{fusion}_{fold}' / pool\n",
    "        CHECKPOINT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Skip already trained kfold and pool\n",
    "        checkpoint = CHECKPOINT_PATH / f\"GraphLevel{model}\" / f\"GraphLevel{model}.ckpt\" \n",
    "        if checkpoint.exists():\n",
    "            print(checkpoint)\n",
    "            continue\n",
    "\n",
    "        # Run training\n",
    "        run = wandb.init(project=project_name, name=f'{model}_{NUM_LAYERS}_{HIDDEN_CHANNELS}_onehot_{fold}', \n",
    "                        group=f'{model}_{pool}_{fusion}', \n",
    "                        # mode=\"disabled\"\n",
    "                        )\n",
    "        PPIGraph.train_graph_classifier_kfold_fusion(model, \n",
    "                                                train_subset, \n",
    "                                                val_subset, \n",
    "                                                dataset, \n",
    "                                                CHECKPOINT_PATH, \n",
    "                                                AVAIL_GPUS, \n",
    "                                                in_channels=13,\n",
    "                                                hidden_channels=HIDDEN_CHANNELS, \n",
    "                                                out_channels = HIDDEN_CHANNELS,\n",
    "                                                num_layers=NUM_LAYERS, \n",
    "                                                epochs=epochs,\n",
    "                                                batch_size=128,\n",
    "                                                fusion=fusion,\n",
    "                                                graph_pooling=pool)\n",
    "        run.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snowflake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
