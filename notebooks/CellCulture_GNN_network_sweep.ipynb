{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2e094bf-8350-4dc1-baad-1d2b43506d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.io\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import re\n",
    "import h5py\n",
    "import napari\n",
    "import tifffile as tiff\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80d3988c-196c-4fca-b035-0b1af24e0106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.utils\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25b12c61-09ad-41b2-9a8c-ae50d190fd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90aabf57-0607-48a3-9c05-742269b7cf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_dir = (Path().cwd().parents[0]).absolute()\n",
    "\n",
    "module_path = str(p_dir / \"src\")\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d2a6df8-d5c2-4dee-ba53-119a7c084424",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = (Path().cwd().parents[0] / 'data').absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fff6962-d83d-41f3-9b9a-0c431155704f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning.pytorch as pl\n",
    "import PPIGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc9bd74-4390-4c75-99b3-5750f9bc68c9",
   "metadata": {},
   "source": [
    "# Test custom torch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd4ef3d7-ddbb-4a8f-8836-a97b012d5cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cdc6fcf-bfe0-4ff6-99a9-afc7a241e71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_mapping = {'HCC827Ctrl': 0, 'HCC827Osim': 1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fc72493-4e7b-42f4-adb4-619e7e97be0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_path = data_dir / 'OCT Cell Culture' / 'Whole' / 'graphs' \n",
    "\n",
    "dataset = PPIGraph.GraphDataset(graph_path, 'raw', 'pt', condition_mapping=condition_mapping, n_c=2)\n",
    "train_set, val_set, test_set = PPIGraph.train_test_val_split(dataset)\n",
    "\n",
    "# Create Dataloader\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7001e783-5bd6-4442-af42-7c1fa389fd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: GraphDataset(2059):\n",
      "======================\n",
      "Number of graphs: 2059\n",
      "Number of features: 5\n",
      "Number of classes: 2\n"
     ]
    }
   ],
   "source": [
    "print(f'Dataset: {dataset}:')\n",
    "print('======================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ba2ee90-059c-44f7-b572-29053bc21270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 989, test set: 823, val set: 247\n"
     ]
    }
   ],
   "source": [
    "print(f'Train set: {len(train_set)}, test set: {len(test_set)}, val set: {len(val_set)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92762d01-a537-47f6-8009-6f3d5faf4237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "=======\n",
      "Number of graphs in the current batch: 32\n",
      "DataBatch(edge_index=[2, 12530], pos=[2409, 2], labels=[2409, 5], nuclei=[2409], weight=[12530], condition=[32], fov=[32], id=[32], train_mask=[2409], test_mask=[2409], x=[2409, 5], y=[32], edge_weight=[12530], name=[32], batch=[2409], ptr=[33])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step, data in enumerate(train_loader):\n",
    "    print(f'Step {step + 1}:')\n",
    "    print('=======')\n",
    "    print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "    print(data)\n",
    "    print()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aa852c-4c8c-45b4-b6a2-4622c562ef6a",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76010aee-b2a3-47d6-8e85-2ad695e595a5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Manual train GCN compoenents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2bd37f9-1a54-408c-adc4-0e68e8aaf8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, epochs, criterion, optimizer, device, mlp=True):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for step, data in enumerate(loader):\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            if mlp:\n",
    "                input_data = data.x.to(device)\n",
    "                out = model(input_data)\n",
    "            else:\n",
    "                x, edge_index, edge_weight = data.x, data.edge_index, data.edge_weight\n",
    "                out = model(x, edge_index, edge_weight=edge_weight)\n",
    "            loss = criterion(out, data.nuclei)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if epoch%10==0:\n",
    "            print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "            \n",
    "def test(model, loader, device, mlp=True):\n",
    "    model.eval()\n",
    "    test_accs = [] \n",
    "\n",
    "    for step, data in enumerate(test_loader):\n",
    "        data = data.to(device)\n",
    "        if mlp:\n",
    "            input_data = data.x.to(device)\n",
    "            out = model(input_data)\n",
    "        else:\n",
    "            x, edge_index, edge_weight = data.x, data.edge_index, data.edge_weight\n",
    "            out = model(x, edge_index, edge_weight=edge_weight)\n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        test_correct = pred == data.nuclei  # Check against ground-truth labels.\n",
    "        test_acc = int(test_correct.sum()) / len(pred)\n",
    "        test_accs.append(test_acc)\n",
    "        print(test_acc)\n",
    "        \n",
    "    return test_accs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6535cac1-f491-4b8e-bdaf-a9480612acb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "AVAIL_GPUS = [1]\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd19908d-2b54-4a02-a0a5-8fd348cee0a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %time\n",
    "# # Create model, criterion and optimizer\n",
    "# model_gcn = PPIGraph.GNNModel(\"GCN\", 5, 16, 2).to(device)\n",
    "# criterion = torch.nn.CrossEntropyLoss()  # Define loss criterion.\n",
    "# optimizer = torch.optim.Adam(model_gcn.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "\n",
    "# # Train Loop\n",
    "# train(model_gcn, train_loader, 10, criterion, optimizer, device, mlp=False)\n",
    "# test_accs = test(model_gcn, test_loader, device, mlp=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf68066-a828-4079-bcd8-5921a8dabe1a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Lightning train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ce5c68d-b020-4e7d-b28b-a7f1ae8d9ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from lightning.pytorch.accelerators import find_usable_cuda_devices\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae4853b5-9932-4e59-aa45-9a1331a8f986",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = 'base'\n",
    "checkpoint_folder = (Path().cwd().parents[0]).absolute() / 'data' / \"saved_models\" / f\"Graph_GNNs_{condition}\" \n",
    "project_name = f'PLA_041623_{condition}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7474adc2-b101-49c7-a293-88e2fe1633f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "AVAIL_GPUS = [1]\n",
    "BATCH_SIZE = 64 if AVAIL_GPUS else 32\n",
    "\n",
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "num_layers = [2,3,4]\n",
    "hiddens = [16, 32, 64]\n",
    "pools = ['mean', 'max', 'sum', 'attention', 'attention2']\n",
    "\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3248cbc2-c017-4384-998d-2cd906758c97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for NUM_LAYERS, HIDDEN_CHANNELS, pool in list(itertools.product(*[num_layers, hiddens, pools])):\n",
    "    \n",
    "#     # Path to the folder where the pretrained models are saved\n",
    "#     CHECKPOINT_PATH = checkpoint_folder / f'{NUM_LAYERS}_{HIDDEN_CHANNELS}_onehot' / pool\n",
    "#     CHECKPOINT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#     # Run training\n",
    "#     models = ['GCN']\n",
    "#     for model_name in models:\n",
    "#         run = wandb.init(project=project_name, name=model_name+f'_{NUM_LAYERS}_{HIDDEN_CHANNELS}_onehot')\n",
    "#         model, result, trainer = PPIGraph.train_graph_classifier(model_name, \n",
    "#                                                                  train_set, \n",
    "#                                                                  val_set, \n",
    "#                                                                  test_set, \n",
    "#                                                                  dataset, \n",
    "#                                                                  CHECKPOINT_PATH, \n",
    "#                                                                  AVAIL_GPUS, \n",
    "#                                                                  in_channels=5,\n",
    "#                                                                  hidden_channels=HIDDEN_CHANNELS, \n",
    "#                                                                  out_channels = HIDDEN_CHANNELS,\n",
    "#                                                                  num_layers=NUM_LAYERS, epochs=epochs,\n",
    "#                                                                  embedding=False,\n",
    "#                                                                  graph_pooling=pool)\n",
    "#         run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6499ccee-a900-445f-b2f5-2ab0471430ce",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mthoomas\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e0fd92db01a4fd585b7e69ced48422b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_012329-s4mnzjkb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/s4mnzjkb' target=\"_blank\">GCN_2_16_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/s4mnzjkb' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/s4mnzjkb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "C:\\Users\\thu71\\Anaconda3\\envs\\snowflake\\lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 96    \n",
      "1 | model       | GNNModel         | 576   \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "-------------------------------------------------\n",
      "826       Trainable params\n",
      "0         Non-trainable params\n",
      "826       Total params\n",
      "0.003     Total estimated model params size (MB)\n",
      "C:\\Users\\thu71\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\thu71\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightning\\pytorch\\utilities\\data.py:77: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "C:\\Users\\thu71\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\thu71\\Anaconda3\\envs\\snowflake\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "C:\\Users\\thu71\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁▅▆▆▇▆▅██▆▅▆▇▇▇▄▆▇▆▆▇▆▇▇▆▇▇▇▅▆</td></tr><tr><td>train_acc_step</td><td>▄▇▆▅▅▄▇▄▇▆▅▅▆▃▆▇▇▅▇▇▁█▅▅█▆▅▆▆█▆▅▅▆▇▅▆▇█▃</td></tr><tr><td>train_loss_epoch</td><td>█▅▃▃▁▃▄▁▁▃▂▁▂▂▂▃▂▃▃▃▂▂▂▃▂▂▂▁▃▃</td></tr><tr><td>train_loss_step</td><td>▇▃▄▄▄▃▃▇▂▃▇▃▃▅▂▂▂▄▂▂▇▂▅▄▂▃▃▃▃▁▅▄▃▃▂█▅▂▂▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>█▅▃▁▇▅▂▄▇▇█▇▄▁▆▅▄█▇▇█▄▆▆▆▄▆▂▅▅</td></tr><tr><td>val_auc</td><td>▇▅▃▂▆▅▂▅▆▇▇▆▃▁▆▅▄█▇▆▇▄▆▆▆▄▆▂▅▅</td></tr><tr><td>val_f1</td><td>▇▆▃▂▇▄▃▄▇▇▇▇▃▁▆▅▄█▇▇▇▄▆▆▆▄▅▂▅▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.73977</td></tr><tr><td>test_auc</td><td>0.73018</td></tr><tr><td>test_f1</td><td>0.65982</td></tr><tr><td>train_acc_epoch</td><td>0.6998</td></tr><tr><td>train_acc_step</td><td>0.4</td></tr><tr><td>train_loss_epoch</td><td>0.58114</td></tr><tr><td>train_loss_step</td><td>0.71111</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.73214</td></tr><tr><td>val_auc</td><td>0.71233</td></tr><tr><td>val_f1</td><td>0.70769</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_16_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/s4mnzjkb' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/s4mnzjkb</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_012329-s4mnzjkb\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ffe290ac4c54ee891e2c56c4a8722f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666495924, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_015613-0i63i7e6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/0i63i7e6' target=\"_blank\">GCN_2_16_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/0i63i7e6' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/0i63i7e6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 96    \n",
      "1 | model       | GNNModel         | 576   \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "-------------------------------------------------\n",
      "826       Trainable params\n",
      "0         Non-trainable params\n",
      "826       Total params\n",
      "0.003     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4cac9b5848e442fb3b604e861b16b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▂▁▄▄▄▄▃▅▇▂▅▆▄▆▅▇▇▅▄▆▆▄▆▇▆▇█▇▇▅</td></tr><tr><td>train_acc_step</td><td>▂▅▇▃▅▇▁▅▅▃▂▅▅▂▅▇▇▃▇▅▃█▆▃▅█▂▇▆█▅█▆▆█▆▆▇█▂</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▄▃▄▃▂▃▃▂▂▃▂▃▂▂▃▃▁▂▂▂▂▂▁▂▂▁▂</td></tr><tr><td>train_loss_step</td><td>▃▃▂▃▃▂▄▃▃▃▄▃▃▄▃▃▃▃▂▃▅▂▃▃▃▂▄▂▂▂▃▂▃▂▂▂▃▂▁█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▁▁▁▁▁▁▁▁▂▂█▆▃▁▁▁▁▇▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_auc</td><td>▂▂▂▂▂▂▂▁▂▂█▆▃▂▂▂▂▇▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>val_f1</td><td>▁▁▁▁▁▁▁▁▁▁▅█▃████▆████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.63419</td></tr><tr><td>test_auc</td><td>0.58403</td></tr><tr><td>test_f1</td><td>0.38994</td></tr><tr><td>train_acc_epoch</td><td>0.58226</td></tr><tr><td>train_acc_step</td><td>0.2</td></tr><tr><td>train_loss_epoch</td><td>0.67277</td></tr><tr><td>train_loss_step</td><td>1.33236</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.4977</td></tr><tr><td>val_auc</td><td>0.48387</td></tr><tr><td>val_f1</td><td>0.64286</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_16_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/0i63i7e6' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/0i63i7e6</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_015613-0i63i7e6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f08ce9cc24493797f03f9411fea044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666883975, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_021957-ju5kyrp9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/ju5kyrp9' target=\"_blank\">GCN_2_16_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/ju5kyrp9' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/ju5kyrp9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 96    \n",
      "1 | model       | GNNModel         | 576   \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "-------------------------------------------------\n",
      "826       Trainable params\n",
      "0         Non-trainable params\n",
      "826       Total params\n",
      "0.003     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "018590fa2918402d803e91c7d0c81f65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁▅▇▆▆▆▆▆▆▇▅▆▄▇▇▆█▇▇▆▆▅▅▆▇▆█▆▅▇</td></tr><tr><td>train_acc_step</td><td>▄▅▄▂▄▅▄▄▇▅▁▂▇▁▄▇▅▄▇▅▁▄▅▄▅▅▄▅▅▄▅▄▅▇▅▅▁▅█▄</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▂▂▁▁▁▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▂▄▂▃▂▂▆▃▁▄▃▁▅▂▁▂▃▂▂▆▂▂▃▂▁▃▃▃▃▂▂▂▁▁▃▄▃▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▃▅▄▆▆▅█▆▁▆▇▆▅▆▄▆▆▅█▆▆▆▅▆▄▅▅▅▁▆</td></tr><tr><td>val_auc</td><td>▃▅▅▆▇▅█▆▁▆▇▅▅▆▄▆▆▅█▅▆▆▄▆▅▆▅▄▁▅</td></tr><tr><td>val_f1</td><td>▄▇▄▄▆▄▇█▁▅▇▆▄▆▄▆▆▆█▆█▆▆█▅▅▆█▁▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.76318</td></tr><tr><td>test_auc</td><td>0.74078</td></tr><tr><td>test_f1</td><td>0.65884</td></tr><tr><td>train_acc_epoch</td><td>0.70645</td></tr><tr><td>train_acc_step</td><td>0.6</td></tr><tr><td>train_loss_epoch</td><td>0.57697</td></tr><tr><td>train_loss_step</td><td>0.75095</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.7644</td></tr><tr><td>val_auc</td><td>0.73625</td></tr><tr><td>val_f1</td><td>0.72849</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_16_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/ju5kyrp9' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/ju5kyrp9</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_021957-ju5kyrp9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "461fa71ca43d47978c1cf65477f189e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_023932-k7f7kz42</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/k7f7kz42' target=\"_blank\">GCN_2_16_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/k7f7kz42' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/k7f7kz42</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "C:\\Users\\thu71\\Anaconda3\\envs\\snowflake\\lib\\site-packages\\torch_geometric\\deprecation.py:12: UserWarning: 'nn.glob.GlobalAttention' is deprecated, use 'nn.aggr.AttentionalAggregation' instead\n",
      "  warnings.warn(out)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 96    \n",
      "1 | model       | GNNModel         | 576   \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "6 | pool        | GlobalAttention  | 17    \n",
      "-------------------------------------------------\n",
      "843       Trainable params\n",
      "0         Non-trainable params\n",
      "843       Total params\n",
      "0.003     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fee61b63f54413489ee304a3cae950e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁▄▆▅▆▇▅▇▇▆▆▆▆▆█▇▇▇▆▆▇▇▆▇▇▇▇▆▅█</td></tr><tr><td>train_acc_step</td><td>▁▅▅▅▂▄▇▂▄▅▂▅▅▄▅█▇▄▅█▁▅▂▄▅█▁▂▇▇▄▅▄▄▅▂▄██▆</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▃▄▃▄▂▂▃▂▂▄▂▂▃▂▂▃▃▂▂▂▂▂▂▂▂▃▁</td></tr><tr><td>train_loss_step</td><td>█▄▄▄▄▃▃▆▃▂▇▂▃▄▂▂▁▃▂▂█▃▆▄▂▂▃▃▃▂▅▃▃▅▄▅█▂▁▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▂▆▅▃▁▂▅▅▅█▄▆▆▆▅█▆▆▆▆▆▆▆▅▆▂▆▆▆▇</td></tr><tr><td>val_auc</td><td>▂▆▅▂▁▂▅▅▄▇▄▆▆▅▄█▆▆▇▆▆▆▅▅▆▁▆▅▆▇</td></tr><tr><td>val_f1</td><td>▁▆▄▃▁▃▅▅▅█▄▇▆▆▄█▆▆▇▆▆▆▆▅▆▂▆▆▆▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.73856</td></tr><tr><td>test_auc</td><td>0.73447</td></tr><tr><td>test_f1</td><td>0.67064</td></tr><tr><td>train_acc_epoch</td><td>0.7252</td></tr><tr><td>train_acc_step</td><td>0.8</td></tr><tr><td>train_loss_epoch</td><td>0.55541</td></tr><tr><td>train_loss_step</td><td>0.501</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.74021</td></tr><tr><td>val_auc</td><td>0.71905</td></tr><tr><td>val_f1</td><td>0.72311</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_16_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/k7f7kz42' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/k7f7kz42</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_023932-k7f7kz42\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2306d453e424a23b6d4f2770ccc144a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_025943-bs6kym5s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/bs6kym5s' target=\"_blank\">GCN_2_16_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/bs6kym5s' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/bs6kym5s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 96    \n",
      "1 | model       | GNNModel         | 576   \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "6 | pool        | Attention_module | 281   \n",
      "-------------------------------------------------\n",
      "1.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 K     Total params\n",
      "0.004     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bead214cd3d40ee8db6a72bd985e323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁▅▇▆██▆█▇█▆▆▆▆█▆▇▇█▇▇▇▇▇▇▆▆▇▆▇</td></tr><tr><td>train_acc_step</td><td>▃▇▅▅▆▃▇▂█▆▃▆▇▄▆▇▇▆▆█▁▇▅▅█▇▄▅▆▇▅▃▆▅▆▅▅██▄</td></tr><tr><td>train_loss_epoch</td><td>█▅▂▃▂▂▃▂▂▃▂▂▃▂▂▃▁▂▂▃▂▁▂▂▁▂▂▁▂▂</td></tr><tr><td>train_loss_step</td><td>█▃▄▃▅▃▂▇▂▂▇▂▂▄▂▁▁▂▂▁▇▂▅▄▂▂▃▃▃▁▄▃▃▃▂█▇▂▁▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▂▆█▃▃▅▄▃▄▅▂▅▂▃▂▆▁▃█▂▅▅▄▃▁▁▅▁▅▇</td></tr><tr><td>val_auc</td><td>▂▆█▄▄▅▅▄▄▆▂▆▂▄▃▇▁▄█▃▅▅▅▄▃▂▅▂▅█</td></tr><tr><td>val_f1</td><td>▂▇█▃▃▄▅▄▄▅▂▆▂▃▂▇▁▄█▄▆▅▆▃▃▁▅▂▅▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.75087</td></tr><tr><td>test_auc</td><td>0.73334</td></tr><tr><td>test_f1</td><td>0.65687</td></tr><tr><td>train_acc_epoch</td><td>0.71754</td></tr><tr><td>train_acc_step</td><td>0.6</td></tr><tr><td>train_loss_epoch</td><td>0.56091</td></tr><tr><td>train_loss_step</td><td>0.53883</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.72811</td></tr><tr><td>val_auc</td><td>0.7119</td></tr><tr><td>val_f1</td><td>0.69953</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_16_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/bs6kym5s' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/bs6kym5s</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_025943-bs6kym5s\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d3bce139ed849a4ac355716b003f11a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666883975, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_031812-w234a0y0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/w234a0y0' target=\"_blank\">GCN_2_32_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/w234a0y0' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/w234a0y0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 192   \n",
      "1 | model       | GNNModel         | 2.2 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "-------------------------------------------------\n",
      "2.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.9 K     Total params\n",
      "0.012     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fe659e30deb4110878a0af041b519e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁▄▅▆▆█▅▅▇▅▇▆▄▅▄▅▅▅▆▆▄▇▅▆▅▇▆▅▅▆</td></tr><tr><td>train_acc_step</td><td>▄▇▇▅▇▇▇▄▇▅▄█▇▃▇▇▇▅▇▅▂▅▄▄██▁▅▅▇▅▄▇▅▇▅▄▇▅▁</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▃▄▃▄▄▂▄▃▄▄▄▄▃▃▂▃▄▃▂▄▄▄▁▄▅▄▄</td></tr><tr><td>train_loss_step</td><td>▆▁▂▄▂▃▃▅▂▂▄▂▂▃▂▃▁▃▃▂▅▃█▄▂▂▅▃▃▂▄▄▂▃▂▇▄▂▂▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▇▄▄▄▇▃▇▄▄▆█▇▂▁▃▃▆▄▄▄▅▇▇▇▃▅▁▃▃▂</td></tr><tr><td>val_auc</td><td>▇▅▆▄▇▄▇▅▅▆█▇▃▃▄▄▆▅▆▅▆▇▇▇▄▆▁▄▄▄</td></tr><tr><td>val_f1</td><td>█▅▇▇▇▅▇▅▇▇█▇▆▄▆▆▇▆▇▆█▇▇▇▅▆▁▅▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.75936</td></tr><tr><td>test_auc</td><td>0.75036</td></tr><tr><td>test_f1</td><td>0.69213</td></tr><tr><td>train_acc_epoch</td><td>0.7381</td></tr><tr><td>train_acc_step</td><td>0.4</td></tr><tr><td>train_loss_epoch</td><td>0.55445</td></tr><tr><td>train_loss_step</td><td>0.68189</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.72811</td></tr><tr><td>val_auc</td><td>0.71018</td></tr><tr><td>val_f1</td><td>0.7242</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_32_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/w234a0y0' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/w234a0y0</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_031812-w234a0y0\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79bf2358b05e4dc3bdde5815ca26e7f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_033943-6te1x00q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/6te1x00q' target=\"_blank\">GCN_2_32_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/6te1x00q' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/6te1x00q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 192   \n",
      "1 | model       | GNNModel         | 2.2 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "-------------------------------------------------\n",
      "2.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.9 K     Total params\n",
      "0.012     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "144addc78b344291b8c478fbf551f305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁▃▄▄▄▅▅▄▃▄▄▄▅▆▇▆▇█▅▄▆▆▆▆▇▅▆▇▅▆</td></tr><tr><td>train_acc_step</td><td>▂▇▇▅▄▇▂▃▄▃▂▇▄▃▇▇▅▇▇▄▂█▅▄▇█▁▇▇▅▅▇▄▇▄▄▇▇█▁</td></tr><tr><td>train_loss_epoch</td><td>█▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▁▂▂▂▂▁▂▁▂▂</td></tr><tr><td>train_loss_step</td><td>▇▁▂▂▃▂▇▅▃▃▅▃▃▄▂▃▁▃▂▄▆▂▃▃▃▂▇▂▂▃▃▁▃▂▃▃▂▂▁█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▁▁▁▁▁▁▇█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_auc</td><td>▁▁▁▁▁▁▆█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_f1</td><td>▁▁▁▁▁▁▅▇██████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.6595</td></tr><tr><td>test_auc</td><td>0.63344</td></tr><tr><td>test_f1</td><td>0.52129</td></tr><tr><td>train_acc_epoch</td><td>0.59133</td></tr><tr><td>train_acc_step</td><td>0.2</td></tr><tr><td>train_loss_epoch</td><td>0.67345</td></tr><tr><td>train_loss_step</td><td>1.14741</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.4977</td></tr><tr><td>val_auc</td><td>0.48387</td></tr><tr><td>val_f1</td><td>0.64286</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_32_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/6te1x00q' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/6te1x00q</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_033943-6te1x00q\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "061b9b5aac2c4a3a869b1e0f05e8396f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_035914-gcmszlpf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/gcmszlpf' target=\"_blank\">GCN_2_32_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/gcmszlpf' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/gcmszlpf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 192   \n",
      "1 | model       | GNNModel         | 2.2 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "-------------------------------------------------\n",
      "2.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.9 K     Total params\n",
      "0.012     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecd32f678c61419f8921f0722194cab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁▇▆▅▆▅▄▄▅▆▆▅▇█▆▆▆▅▆▇▆▇▅▇▄▆▆▆▆▆</td></tr><tr><td>train_acc_step</td><td>▅▅▅▅▂▅▄▄█▅▂▅▅▄▇▂▇▄▇▄▁▅▁▂▅▇▄▅▅▇▂▅▅▅▇▅▄▂▅▁</td></tr><tr><td>train_loss_epoch</td><td>█▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▁▂▂▂▂▂▃▁▂▂▂▁▂▂▂▁▂▂▂▃▁▄▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▁▅▅▄▄▅█▆▄▆▆▆▆▆▅▄▅▇▄▅▆█▇▇█▆▆▅▅▄</td></tr><tr><td>val_auc</td><td>▁▅▅▄▄▅█▆▄▅▆▅▆▆▅▄▄▇▃▅▅▇▇▆█▆▆▅▄▄</td></tr><tr><td>val_f1</td><td>▁▆▆▅▆▅█▇▅▆▆▆▄▅▄▄▅▇▄▅▅█▇▆█▇▅▄▆▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.76422</td></tr><tr><td>test_auc</td><td>0.75819</td></tr><tr><td>test_f1</td><td>0.70367</td></tr><tr><td>train_acc_epoch</td><td>0.70181</td></tr><tr><td>train_acc_step</td><td>0.4</td></tr><tr><td>train_loss_epoch</td><td>0.62589</td></tr><tr><td>train_loss_step</td><td>1.11511</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.7644</td></tr><tr><td>val_auc</td><td>0.73921</td></tr><tr><td>val_f1</td><td>0.70405</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_32_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/gcmszlpf' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/gcmszlpf</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_035914-gcmszlpf\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7994cf8ffb5e465c97a04a6572f9cb38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_041811-7qgzfyxa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/7qgzfyxa' target=\"_blank\">GCN_2_32_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/7qgzfyxa' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/7qgzfyxa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 192   \n",
      "1 | model       | GNNModel         | 2.2 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "6 | pool        | GlobalAttention  | 33    \n",
      "-------------------------------------------------\n",
      "3.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.0 K     Total params\n",
      "0.012     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdf09394d9614a40bc86459ac443360e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁▅▅▆▆▇▇▆█▆▄▄▆▆▆█▇█▅▅▇▆▇▆▄█▆▆▇▆</td></tr><tr><td>train_acc_step</td><td>▂▇▅▄▄▄▅▂▇▅▄▅▄▁▇▇▇▅▅▄▁▅▂▂▇█▄▇▅▄▅▅▅▂▅▄▄▇█▁</td></tr><tr><td>train_loss_epoch</td><td>█▃▅▃▃▂▃▃▂▃▃▄▃▃▃▂▂▁▂▄▁▂▃▂▄▁▁▁▂▂</td></tr><tr><td>train_loss_step</td><td>▆▁▄▆▃▄▄▇▃▄▅▄▄▆▂▄▁▃▃▃█▄█▆▃▁▅▃▃▅▅▃▃▅▄▇▆▃▂▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▇▁█▆▇▆▆▆▇▂▃▅▇▅▇▄▁▁▆▅▅▅▅▇▃▄▇▁▄▅</td></tr><tr><td>val_auc</td><td>▇▁█▆▇▇▆▆▇▂▃▅▇▆▇▄▁▁▆▅▅▅▅▇▃▄▇▁▄▆</td></tr><tr><td>val_f1</td><td>▇▂█▇█▇▇▇▇▃▃▅▇▆█▄▁▂▆▆▆▆▆▇▄▅▆▂▄▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.74965</td></tr><tr><td>test_auc</td><td>0.72285</td></tr><tr><td>test_f1</td><td>0.63393</td></tr><tr><td>train_acc_epoch</td><td>0.70685</td></tr><tr><td>train_acc_step</td><td>0.4</td></tr><tr><td>train_loss_epoch</td><td>0.56964</td></tr><tr><td>train_loss_step</td><td>0.62768</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.71198</td></tr><tr><td>val_auc</td><td>0.69428</td></tr><tr><td>val_f1</td><td>0.66332</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_32_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/7qgzfyxa' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/7qgzfyxa</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_041811-7qgzfyxa\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c6f2730808f4913add331f06730673a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666495924, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_043652-r1mv13p8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/r1mv13p8' target=\"_blank\">GCN_2_32_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/r1mv13p8' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/r1mv13p8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 192   \n",
      "1 | model       | GNNModel         | 2.2 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "6 | pool        | Attention_module | 1.1 K \n",
      "-------------------------------------------------\n",
      "4.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.0 K     Total params\n",
      "0.016     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95e2c10aef60451d96284a9eb8eda672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁▄▅▆▆▆▇▅▆▇▇▆▆▇▅█▇▇▄█▆▇▆▇▅▇▆▆▅▇</td></tr><tr><td>train_acc_step</td><td>▃▆▆▅▆▅▆▁▆▅▃█▆▂▅▆▆▆▅▆▁▅▁▃▆█▂▆▆▅▃▃█▃▆▃▅██▂</td></tr><tr><td>train_loss_epoch</td><td>█▄▅▃▄▄▄▄▄▃▃▃▃▂▃▂▃▁▃▃▁▃▅▃▅▃▄▃▄▃</td></tr><tr><td>train_loss_step</td><td>▅▁▃▃▂▃▃▅▂▄▅▂▃▃▂▃▁▂▂▂▅▂█▄▂▁▄▂▂▃▄▃▂▃▂▇▃▂▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▂▄█▄▄▆▄▅▆▅▃▄▄▄▇▅▁▃▃▂▄▇▅▂▂▁▂▁▁▃</td></tr><tr><td>val_auc</td><td>▂▄█▅▄▆▅▅▆▅▃▄▄▃▆▅▂▄▃▃▅▇▅▃▁▂▂▁▂▄</td></tr><tr><td>val_f1</td><td>▂▄█▅▃▆▅▅▇▅▃▆▅▄█▇▂▄▅▄▅▇▅▄▁▃▁▁▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.74359</td></tr><tr><td>test_auc</td><td>0.71609</td></tr><tr><td>test_f1</td><td>0.63499</td></tr><tr><td>train_acc_epoch</td><td>0.73669</td></tr><tr><td>train_acc_step</td><td>0.6</td></tr><tr><td>train_loss_epoch</td><td>0.55507</td></tr><tr><td>train_loss_step</td><td>0.6069</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.71198</td></tr><tr><td>val_auc</td><td>0.69647</td></tr><tr><td>val_f1</td><td>0.66971</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_32_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/r1mv13p8' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/r1mv13p8</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_043652-r1mv13p8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d41ea8681644eb59a21d14d8d2854be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_045709-9kuk3c5n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/9kuk3c5n' target=\"_blank\">GCN_2_64_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/9kuk3c5n' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/9kuk3c5n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 384   \n",
      "1 | model       | GNNModel         | 8.4 K \n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "-------------------------------------------------\n",
      "11.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "11.0 K    Total params\n",
      "0.044     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁▅▅▆█▇█▆▆▇▆▆▆▅▇▅▆▇▆█▆▅▇▆▅▇▇▆▇▆</td></tr><tr><td>train_acc_step</td><td>▅▆▆▆▆▅▅▃▇▆▇▆▇▂▇▇▆▆▃▇▁█▃▃█▇▂▆▇▆▆▅█▆▆▅▅█▇▂</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▅▁▃▄▄▃▄▂▂▅▄▃▄▃▅▄▃▅▄▁▅▃▂▂▂▃▃</td></tr><tr><td>train_loss_step</td><td>▃▂▂▃▂▂▂▄▂▃▅▂▁▂▁▂▂▂▃▂▅▂█▃▂▂▂▂▂▃▄▃▂▂▂▄▂▁▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▆▇▆▇█▇█▇█▇█▇█▇██▇▇█▅█▇█▇▇██▁██</td></tr><tr><td>val_auc</td><td>▆▇▆▇█▇███▇█▇█▇██▇▆█▅█▇█▇▇██▁██</td></tr><tr><td>val_f1</td><td>█▇▆▇█▇███▇█▇█▇█▇▇▆█▅███▇███▁██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.75052</td></tr><tr><td>test_auc</td><td>0.74647</td></tr><tr><td>test_f1</td><td>0.6847</td></tr><tr><td>train_acc_epoch</td><td>0.72198</td></tr><tr><td>train_acc_step</td><td>0.4</td></tr><tr><td>train_loss_epoch</td><td>0.56105</td></tr><tr><td>train_loss_step</td><td>0.63958</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.74827</td></tr><tr><td>val_auc</td><td>0.72738</td></tr><tr><td>val_f1</td><td>0.73477</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_64_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/9kuk3c5n' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/9kuk3c5n</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_045709-9kuk3c5n\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d2d67f68844e2ea6d2a27010a2d6b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_051642-1iemkp2b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/1iemkp2b' target=\"_blank\">GCN_2_64_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/1iemkp2b' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/1iemkp2b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 384   \n",
      "1 | model       | GNNModel         | 8.4 K \n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "-------------------------------------------------\n",
      "11.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "11.0 K    Total params\n",
      "0.044     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "450f6a0b6460425ab511910ff730d1cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▃▁▄▃▃▄▅▄▅▄▇▅▅▆█▆▅▆▅▆▆▆▇▇▆█▅▇▆▆</td></tr><tr><td>train_acc_step</td><td>▅▇▆▆▅█▁▅█▅▂▆▅▂▇█▇▂▇▅▅█▆▂▆▇▂▇▆█▅▆▅▇▅▅▆▇▇▂</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▂▃▂▂▂▂▃▁▂▂▂▁▂▂▂▂▂▂▂▁▁▂▁▂▂▂▂</td></tr><tr><td>train_loss_step</td><td>▄▁▃▃▄▁▆▆▁▃▄▃▃▇▂▂▂▅▁▂▅▁▂▅▃▁▆▂▃▁▃▃▅▁▃▃▃▃▂█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▁▃▂█▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>val_auc</td><td>▁▂▁█▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄</td></tr><tr><td>val_f1</td><td>▁▁▂▃██████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.63055</td></tr><tr><td>test_auc</td><td>0.56091</td></tr><tr><td>test_f1</td><td>0.26637</td></tr><tr><td>train_acc_epoch</td><td>0.59032</td></tr><tr><td>train_acc_step</td><td>0.2</td></tr><tr><td>train_loss_epoch</td><td>0.67253</td></tr><tr><td>train_loss_step</td><td>1.00274</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.4977</td></tr><tr><td>val_auc</td><td>0.48387</td></tr><tr><td>val_f1</td><td>0.64286</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_64_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/1iemkp2b' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/1iemkp2b</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_051642-1iemkp2b\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a62e6d9c3d514232987b931babfe5745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_053620-ndvwhg3y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/ndvwhg3y' target=\"_blank\">GCN_2_64_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/ndvwhg3y' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/ndvwhg3y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 384   \n",
      "1 | model       | GNNModel         | 8.4 K \n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "-------------------------------------------------\n",
      "11.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "11.0 K    Total params\n",
      "0.044     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaa6327d54b74ed2aeb3b7401010e510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁▃▆▅▅▅▅▇▆▆▇▇▇▆▅▅▆▅▇▇▆█▇▆█▅▅▅▅▇</td></tr><tr><td>train_acc_step</td><td>▄▂▂▄▇▅▁▁▅▇▇▅▅▄▅▅▅▅▄▂▅▅▄▄▇▅▁▄▅▅▂▅▇▄█▄▅▄▅▁</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▂▂▂▂▁▂▂▁▁▁▂▂▂▂▂▁▁▁▁▁▁▁▂▂▁▂▁</td></tr><tr><td>train_loss_step</td><td>▄▃▄▂▂▂▅▄▄▁▂▂▂▂▂▃▃▂▂▅▅▂▄▃▂▃▄▃▄▃▃▂▁█▁▄▂▃▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▄▄▂▄▅▆▆▄▅▅▇▄▆▆▃▅▅▆▅▆▇▅▆▆▇▃█▃▇▁</td></tr><tr><td>val_auc</td><td>▄▃▁▅▅▆▅▄▅▅▇▄▅▆▃▅▅▅▄▅▇▅▆▆▇▃█▃▇▁</td></tr><tr><td>val_f1</td><td>▅▇▃▇▆▆▆▄▆▇▆▅▆▆▇▄▆▇▇▇▇▇▆▇█▇█▃▇▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.76179</td></tr><tr><td>test_auc</td><td>0.75192</td></tr><tr><td>test_f1</td><td>0.68778</td></tr><tr><td>train_acc_epoch</td><td>0.69073</td></tr><tr><td>train_acc_step</td><td>0.4</td></tr><tr><td>train_loss_epoch</td><td>0.62641</td></tr><tr><td>train_loss_step</td><td>0.7646</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.70449</td></tr><tr><td>val_auc</td><td>0.68326</td></tr><tr><td>val_f1</td><td>0.56878</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_64_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/ndvwhg3y' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/ndvwhg3y</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_053620-ndvwhg3y\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "368b97e85550443c8235ec18adacf83d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_055446-jo5nge72</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/jo5nge72' target=\"_blank\">GCN_2_64_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/jo5nge72' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/jo5nge72</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 384   \n",
      "1 | model       | GNNModel         | 8.4 K \n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "6 | pool        | GlobalAttention  | 65    \n",
      "-------------------------------------------------\n",
      "11.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "11.0 K    Total params\n",
      "0.044     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e92cfcb33002405ba7352cb0ebbecab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁▄▄▄▅▅▇▅▅█▇▆▆▇▇▆▇▇▆▆▆▆█▇▇▇▇▇█▆</td></tr><tr><td>train_acc_step</td><td>▇▆▆▃▃▆▅▃▅▆▆▆▆▆▅▇▆▅▆▇▁▆▃▁██▂▆▇▇▅▆▅▃▆▃▆██▂</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▅▄▄▄▃▃▃▄▃▃▃▃▂▃▄▃▃▂▃▃▂▂▁▂▃</td></tr><tr><td>train_loss_step</td><td>▃▂▃▃▄▂▃▄▄▂▂▂▂▂▂▂▂▃▂▂▄▂█▄▂▁▃▂▂▂▃▂▂▃▄▄▂▁▁▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▇▆▅▂▁▄▄▇▃▇█▆▃▂▄▄▆▄▆▅▆▅▆▃▆▃▃▆▅▅</td></tr><tr><td>val_auc</td><td>▇▆▆▂▁▄▄▇▃██▆▃▃▄▄▆▄▆▅▆▆▆▃▆▃▃▆▅▅</td></tr><tr><td>val_f1</td><td>█▆▇▂▁▄▅▇▄██▆▄▂▅▅▆▅▇▆▇▆▇▄▇▄▄▇▅▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.74948</td></tr><tr><td>test_auc</td><td>0.7279</td></tr><tr><td>test_f1</td><td>0.65121</td></tr><tr><td>train_acc_epoch</td><td>0.69375</td></tr><tr><td>train_acc_step</td><td>0.4</td></tr><tr><td>train_loss_epoch</td><td>0.57978</td></tr><tr><td>train_loss_step</td><td>0.60914</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.69182</td></tr><tr><td>val_auc</td><td>0.66955</td></tr><tr><td>val_f1</td><td>0.61697</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_64_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/jo5nge72' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/jo5nge72</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_055446-jo5nge72\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bdcb3f6d8294549b73e0a4a2b9685b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_061407-ie57ng67</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/ie57ng67' target=\"_blank\">GCN_2_64_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/ie57ng67' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/ie57ng67</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 384   \n",
      "1 | model       | GNNModel         | 8.4 K \n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "6 | pool        | Attention_module | 4.2 K \n",
      "-------------------------------------------------\n",
      "15.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.2 K    Total params\n",
      "0.061     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad11f4849bf497084373a1c35cd71ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁▆▆▆▆█▇▆▇▆▆▇▅▆▇▅▅▆▅▆▇▆▆▆▇▇▇▆▆▆</td></tr><tr><td>train_acc_step</td><td>▆▆▇▆▇▅▄▂▅▆▆▆▇▃▇▇▆▆▅▅▁▆▅▆▇█▃▆▇▇▅▅█▄▆▅▅▇█▃</td></tr><tr><td>train_loss_epoch</td><td>█▃▂▂▃▁▂▃▁▃▂▂▄▃▃▃▁▃▃▃▂▁▃▃▁▁▁▂▂▁</td></tr><tr><td>train_loss_step</td><td>▃▂▂▂▂▂▃▄▂▂▃▂▂▂▁▂▂▃▂▂▄▂█▃▂▁▂▂▂▂▂▂▁▂▃▃▂▁▁▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▂▁▄▂▃█▅▂▂▆▃▄▅▅▅▁▆▁▄▅▃█▅▂▅▃▄▅▃▄</td></tr><tr><td>val_auc</td><td>▂▁▅▂▃█▅▂▁▆▃▄▆▄▆▁▇▂▅▅▃█▄▂▅▃▄▄▂▃</td></tr><tr><td>val_f1</td><td>▂▁▆▂▄█▅▂▁▆▂▄▆▅▆▁▇▂▅▆▃█▄▃▆▃▄▅▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.7448</td></tr><tr><td>test_auc</td><td>0.71993</td></tr><tr><td>test_f1</td><td>0.63293</td></tr><tr><td>train_acc_epoch</td><td>0.72298</td></tr><tr><td>train_acc_step</td><td>0.4</td></tr><tr><td>train_loss_epoch</td><td>0.55989</td></tr><tr><td>train_loss_step</td><td>0.68809</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.69182</td></tr><tr><td>val_auc</td><td>0.66325</td></tr><tr><td>val_f1</td><td>0.61803</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_2_64_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/ie57ng67' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/ie57ng67</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_061407-ie57ng67\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c84133d605bf4575b0d283ba049c62b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_063239-tn6iw8a6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/tn6iw8a6' target=\"_blank\">GCN_3_16_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/tn6iw8a6' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/tn6iw8a6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 96    \n",
      "1 | model       | GNNModel         | 880   \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "-------------------------------------------------\n",
      "1.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aa002810a284c61aa8475f60baa3764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁▄▅▆▇▇▅▆▇▆▇▇█▆▇▇▇▇▇█▇▆█▇▇▇▇▇▇▇</td></tr><tr><td>train_acc_step</td><td>▂▇▅▅▅▄▄▁▅▅▂█▇▁▅▇▇▇▅▄▄▅▂▄▇█▁▇▇▅▅▅▄▇▅▄▅█▅▁</td></tr><tr><td>train_loss_epoch</td><td>█▇▅▄▄▃▄▃▃▄▂▃▂▄▃▂▂▂▃▁▄▄▁▃▃▃▂▄▂▃</td></tr><tr><td>train_loss_step</td><td>▄▂▄▃▄▃▄▇▃▂▅▁▁▄▁▃▁▁▃▂▅▂▆▃▂▁▄▃▄▃▂▂▃▃▃▇█▁▃▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▃▂█▃▆▇▇█▂▂▃▇▅▅▄▁▂▅▇▃▄▅▃▄▆▃▁▂▆▆</td></tr><tr><td>val_auc</td><td>▃▂█▃▅▆▆▇▂▂▃▆▄▄▄▁▂▄▆▃▄▅▃▄▅▃▁▂▅▆</td></tr><tr><td>val_f1</td><td>▃▂█▃▅▆▆▇▁▂▃▆▄▄▄▁▂▄▆▃▄▆▃▄▆▃▁▂▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.68499</td></tr><tr><td>test_auc</td><td>0.70596</td></tr><tr><td>test_f1</td><td>0.67817</td></tr><tr><td>train_acc_epoch</td><td>0.74718</td></tr><tr><td>train_acc_step</td><td>0.4</td></tr><tr><td>train_loss_epoch</td><td>0.55815</td></tr><tr><td>train_loss_step</td><td>0.63252</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.68836</td></tr><tr><td>val_auc</td><td>0.66866</td></tr><tr><td>val_f1</td><td>0.72981</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_16_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/tn6iw8a6' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/tn6iw8a6</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_063239-tn6iw8a6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "859ae237890749bf997a695ef8579787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_065307-9ai8zd3m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/9ai8zd3m' target=\"_blank\">GCN_3_16_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/9ai8zd3m' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/9ai8zd3m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 96    \n",
      "1 | model       | GNNModel         | 880   \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "-------------------------------------------------\n",
      "1.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c37341511b44d63a2e2d646e88d947b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁▂▄▆▆▇▇▇▇▇▇▇▇█▇▇▆█▇▇▇█▇▇█▇▇▇▇█</td></tr><tr><td>train_acc_step</td><td>▃▆▇▆▅▇▁▅▅▂▃▇▅▂▆▇▆▅▇▃▅▆▇▁▇█▄▇▇▆▆▇▅▆▅▆▇▆▇▂</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▂▂▂▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▂▂▂▃▂▅▄▃▅▅▃▃▅▂▃▃▃▂▄▄▂▂▅▃▁▆▂▃▃▃▂▃▂▃▂▃▃▁▆</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▁▁▂▂▂▂▁▁▂▂▂▂▁▂▁▂▂▄▂▁▁▁▇██▁▁▁▂▄</td></tr><tr><td>val_auc</td><td>▂▂▂▂▂▂▁▁▂▂▂▂▁▂▁▂▂▄▂▂▂▂▇██▁▂▁▂▄</td></tr><tr><td>val_f1</td><td>██▂▁▁▁▂▂▁▁▁▁▂▁▁▁▁▄▂███▅▅▆▁█▂▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.63176</td></tr><tr><td>test_auc</td><td>0.57788</td></tr><tr><td>test_f1</td><td>0.3452</td></tr><tr><td>train_acc_epoch</td><td>0.58831</td></tr><tr><td>train_acc_step</td><td>0.2</td></tr><tr><td>train_loss_epoch</td><td>0.674</td></tr><tr><td>train_loss_step</td><td>0.88097</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.53514</td></tr><tr><td>val_auc</td><td>0.51386</td></tr><tr><td>val_f1</td><td>0.17826</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_16_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/9ai8zd3m' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/9ai8zd3m</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_065307-9ai8zd3m\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "131c4e150d3c4d5dbff8f4ee8227fe7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666495924, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_071314-o15fdmzd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/o15fdmzd' target=\"_blank\">GCN_3_16_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/o15fdmzd' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/o15fdmzd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 96    \n",
      "1 | model       | GNNModel         | 880   \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "-------------------------------------------------\n",
      "1.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁▄▆▆▇▆▇▇▆▅▅▆▆▆▇▇▇█▅▆▅▆█▆▇▇▇▅▅▇</td></tr><tr><td>train_acc_step</td><td>▅▄▃▄▅▇▃▃▇▇▄▅█▃▇▇█▅█▇▃▅▇▇▇█▁█▄██▅▇█▅▅▄█▇▁</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>▄█▄▂▃▂▃▄▁▁▃▃▁▄▁▂▂▃▂▂▄▃▄▂▂▁▄▂▃▁▁▂▂▂▃▃▃▂▂▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▁▅▃▅▅▇▇▆▆▅▆▆▇█▆▆▇▇▇▇▇▇▇▇▇█▅▇█▇</td></tr><tr><td>val_auc</td><td>▁▅▃▅▅▇▆▆▆▅▅▆▇█▆▆▇▇▇▇▇▆▆▇▇▇▅▇█▇</td></tr><tr><td>val_f1</td><td>▁▄▃▄▄▇▆▅▆▅▆▆▆▆▆▆▇▆▆▇▇▆▆▃▇█▅▇█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.76543</td></tr><tr><td>test_auc</td><td>0.74805</td></tr><tr><td>test_f1</td><td>0.67884</td></tr><tr><td>train_acc_epoch</td><td>0.69819</td></tr><tr><td>train_acc_step</td><td>0.2</td></tr><tr><td>train_loss_epoch</td><td>0.6077</td></tr><tr><td>train_loss_step</td><td>0.95533</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.76843</td></tr><tr><td>val_auc</td><td>0.7384</td></tr><tr><td>val_f1</td><td>0.76826</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_16_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/o15fdmzd' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/o15fdmzd</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_071314-o15fdmzd\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c8501d598fb42bdb2d0a30dd637c5fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_073525-b4t6dk9j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/b4t6dk9j' target=\"_blank\">GCN_3_16_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/b4t6dk9j' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/b4t6dk9j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 96    \n",
      "1 | model       | GNNModel         | 880   \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "6 | pool        | GlobalAttention  | 17    \n",
      "-------------------------------------------------\n",
      "1.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae4983d847bd4248a095a21981204706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁▄▆▆▇▆▇▇▆▇▆▇█▇██▇█▇▇██▇▇█▇█▇██</td></tr><tr><td>train_acc_step</td><td>▃▆▆▆▂▃▁▂▆▇▃▅▇▂▆▇▆▆▅▆▅▆▆▅▇█▂▆▇▆▆▅▅▃▆▅▆▇█▄</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▃▄▃▄▂▄▃▂▂▂▃▂▃▃▂▂▁▂▂▂▂▂▃▁▃▂▂</td></tr><tr><td>train_loss_step</td><td>▅▁▄▄▄▄▅█▃▂▅▃▂▆▂▃▂▂▄▁▇▄▆▃▂▁▄▂▄▂▂▃▂▆▃█▄▁▁▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▁▂▆█▇▅▅▃▆▇▇▅▂▇▂▆▇▆▇▆▆▇▆▇▄█▂▆▇█</td></tr><tr><td>val_auc</td><td>▁▂▆▇▆▅▆▃▇▇▇▆▂▇▂▇▇▆▇▇▇▇▆▇▄█▂▆▇█</td></tr><tr><td>val_f1</td><td>▁▂▇▇▅▆▆▃▇▇▇▆▃▇▂▆▇▆▇▇▇▇▆▇▅█▃▆▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.68031</td></tr><tr><td>test_auc</td><td>0.70358</td></tr><tr><td>test_f1</td><td>0.67418</td></tr><tr><td>train_acc_epoch</td><td>0.71956</td></tr><tr><td>train_acc_step</td><td>0.6</td></tr><tr><td>train_loss_epoch</td><td>0.57748</td></tr><tr><td>train_loss_step</td><td>0.62838</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.71601</td></tr><tr><td>val_auc</td><td>0.68571</td></tr><tr><td>val_f1</td><td>0.73574</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_16_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/b4t6dk9j' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/b4t6dk9j</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_073525-b4t6dk9j\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5a1270ef68444e7bc1c803a6fd0de6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666883975, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_080555-q1ub8n1s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/q1ub8n1s' target=\"_blank\">GCN_3_16_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/q1ub8n1s' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/q1ub8n1s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 96    \n",
      "1 | model       | GNNModel         | 880   \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "6 | pool        | Attention_module | 281   \n",
      "-------------------------------------------------\n",
      "1.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.4 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e092f699ba504b32bf1c29d86b3aa37e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁▅▅▅▇▇▇▆▆▇▇█▇▆▇█▆▇▇▇▇▆█▇▇▆▇▇▇█</td></tr><tr><td>train_acc_step</td><td>▂▅▅▅▂▅▂▂▅▅▂▅▇▁▇▅▅▇▄▇▂▅▅▄█▇▁▅▅▅▅▄▇▂▇▅▅█▇▁</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▃▃▂▃▃▂▃▁▁▁▃▂▁▁▁▂▁▂▄▁▃▃▃▁▃▁▂</td></tr><tr><td>train_loss_step</td><td>▄▃▃▃▃▃▄▆▃▂▄▁▂▄▁▃▂▂▃▂▆▁▃▃▂▁▃▃▄▃▂▃▂▄▂▅█▁▂▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▁▇▅▅▇▆▇▇▆▇▆▇▇▇▇▅▆▇▇▇▇█▇███▇▇▇▇</td></tr><tr><td>val_auc</td><td>▁▇▅▅▇▆▆▇▆▆▆▇▆▇▇▅▆▇▇▇▆█▇███▇▇▇▇</td></tr><tr><td>val_f1</td><td>▁▇▅▆▇▆▇█▇▇▇█▆▇▇▅▇█▇█▇█▆▇▇▇▇▇▆▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.7363</td></tr><tr><td>test_auc</td><td>0.73564</td></tr><tr><td>test_f1</td><td>0.67884</td></tr><tr><td>train_acc_epoch</td><td>0.74617</td></tr><tr><td>train_acc_step</td><td>0.4</td></tr><tr><td>train_loss_epoch</td><td>0.55396</td></tr><tr><td>train_loss_step</td><td>0.61141</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.73214</td></tr><tr><td>val_auc</td><td>0.6927</td></tr><tr><td>val_f1</td><td>0.7414</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_16_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/q1ub8n1s' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/q1ub8n1s</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_080555-q1ub8n1s\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e0e3e991324893b928317f58335154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_082813-8n3elt85</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/8n3elt85' target=\"_blank\">GCN_3_32_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/8n3elt85' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/8n3elt85</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 192   \n",
      "1 | model       | GNNModel         | 3.3 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "-------------------------------------------------\n",
      "4.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.0 K     Total params\n",
      "0.016     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dff96a968de045deb4a6e4c7d58b3a19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁▅▅▇▄▆▆▅▆▄▆▇▇▆▇▇▅▇▇▇▇▇▆▆▆▅▆█▇█</td></tr><tr><td>train_acc_step</td><td>▁▅▆▃▆▅▃▁▅▆▃█▆▂▅▆▅▅▃▆▃▆▅▆▆▆▂▅▆▆▅▅█▃▆▅█▆█▂</td></tr><tr><td>train_loss_epoch</td><td>█▇▆▃▆▅▂▄▃▃▃▃▁▄▅▁▃▄▁▃▃▃▂▃▃▃▂▂▂▂</td></tr><tr><td>train_loss_step</td><td>▄▃▃▅▁▃▄▅▃▁▅▂▂▆▁▂▃▃▃▂▅▂█▄▂▂▃▃▃▂▄▄▂▆▂▆▂▃▂▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▅▁▅▆▇▇▇▇▆▇▇█▅███▄▆▅▃▆▆▆▅▆▅▆▄▇▆</td></tr><tr><td>val_auc</td><td>▅▁▆▆▆▇▇▇▆▇▇█▅█▇▇▅▆▅▃▆▆▆▅▆▅▆▅▇▆</td></tr><tr><td>val_f1</td><td>▆▁▆▆▆▇▇▇▆▇▇█▅█▇▇▅▅▅▃▆▆▆▅▆▆▆▅▇▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.7044</td></tr><tr><td>test_auc</td><td>0.72629</td></tr><tr><td>test_f1</td><td>0.69041</td></tr><tr><td>train_acc_epoch</td><td>0.75585</td></tr><tr><td>train_acc_step</td><td>0.6</td></tr><tr><td>train_loss_epoch</td><td>0.54264</td></tr><tr><td>train_loss_step</td><td>0.61548</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.67972</td></tr><tr><td>val_auc</td><td>0.66141</td></tr><tr><td>val_f1</td><td>0.72411</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_32_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/8n3elt85' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/8n3elt85</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_082813-8n3elt85\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab5853499fe1479c8ae091c8ec8f2a49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333330477276, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_084357-f2x9j0pc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/f2x9j0pc' target=\"_blank\">GCN_3_32_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/f2x9j0pc' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/f2x9j0pc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 192   \n",
      "1 | model       | GNNModel         | 3.3 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "-------------------------------------------------\n",
      "4.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.0 K     Total params\n",
      "0.016     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8d857d13b764c92b06b1f751e965580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▂▁▃▁▄▂▄▃▅▅▅▅▆▄█▇▆▆▆▅▆▄▄▅▆▅▅▄▇▆</td></tr><tr><td>train_acc_step</td><td>▆▇▅▆▅▆▂▅▅▃▂▆▅▂▆▇▆▆▆▇▁▆▅▅▆▅▂█▇▃▃▆▅▇▆▅▅▇▇▂</td></tr><tr><td>train_loss_epoch</td><td>█▃▃▃▃▃▂▂▂▂▂▁▂▂▁▂▂▂▁▂▂▃▁▂▂▂▂▂▂▂</td></tr><tr><td>train_loss_step</td><td>▃▁▃▂▃▂▃▃▃▃▄▂▃█▁▂▂▂▁▃▅▃▂▄▂▂▅▂▂▂▃▂▃▂▂▃▂▂▂▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▂▂▂▂▂▂▂▂▁▂▁▂▇▂█▆▂▂▂▁▁▂▂▁▁▁▂▇▁▁</td></tr><tr><td>val_auc</td><td>▂▂▂▂▂▂▂▁▁▁▁▂▇▂█▆▂▂▂▁▂▂▂▂▁▁▂▇▂▂</td></tr><tr><td>val_f1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▅█▆▅█▁▂▁█▁▃█▁▁▁▅██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.65222</td></tr><tr><td>test_auc</td><td>0.61091</td></tr><tr><td>test_f1</td><td>0.43419</td></tr><tr><td>train_acc_epoch</td><td>0.59133</td></tr><tr><td>train_acc_step</td><td>0.2</td></tr><tr><td>train_loss_epoch</td><td>0.67223</td></tr><tr><td>train_loss_step</td><td>0.88273</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.4977</td></tr><tr><td>val_auc</td><td>0.48387</td></tr><tr><td>val_f1</td><td>0.64286</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_32_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/f2x9j0pc' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/f2x9j0pc</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_084357-f2x9j0pc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe360fcf7994b14ad21784b56f1a57b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333330477276, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_090006-1616rwyd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/1616rwyd' target=\"_blank\">GCN_3_32_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/1616rwyd' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/1616rwyd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 192   \n",
      "1 | model       | GNNModel         | 3.3 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "-------------------------------------------------\n",
      "4.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.0 K     Total params\n",
      "0.016     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37387a19b47e4bccbff13a87934d95b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁▂▄▆▆▆▅▇▅▆▆▅▆▆▆▆▅▅▆▆▆▅██▇▇▆▅▆▆</td></tr><tr><td>train_acc_step</td><td>▄▆▄▆▅▇▅▄▆█▃▇▆▁▇▄▅▇▇▆▃▆▅▃▅▅▃▅▅▆▆▅▅▅▇▅▅▆▆▅</td></tr><tr><td>train_loss_epoch</td><td>█▃▂▂▁▁▂▁▁▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>▇▃█▄▆▃▅▆▃▁▆▄▃▆▃▅▅▄▃▄▆▃█▆▄▄▇▄▄▄▄▄▅▆▃▅▄▄▄█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▄▇▄▇▅▆▂▃▁▃▃▄▂▄▅▆▇▇▆▆▅▇▆▆█▆█▆▇▆</td></tr><tr><td>val_auc</td><td>▅▇▄▇▅▆▃▃▁▃▃▄▃▅▅▆▇▇▆▆▅▇▆▆█▇█▇▇▆</td></tr><tr><td>val_f1</td><td>▄▇▄▇▅▆▂▂▁▃▃▄▂▅▅▆▆▇▅▇▅▆▆▆█▇▆▇▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.73752</td></tr><tr><td>test_auc</td><td>0.74917</td></tr><tr><td>test_f1</td><td>0.70423</td></tr><tr><td>train_acc_epoch</td><td>0.68226</td></tr><tr><td>train_acc_step</td><td>0.6</td></tr><tr><td>train_loss_epoch</td><td>0.62983</td></tr><tr><td>train_loss_step</td><td>0.98598</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.70795</td></tr><tr><td>val_auc</td><td>0.67899</td></tr><tr><td>val_f1</td><td>0.73008</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_32_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/1616rwyd' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/1616rwyd</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_090006-1616rwyd\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfb3bb7d8ae741c0a094d521b43b885b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_091541-mxd3zfaq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/mxd3zfaq' target=\"_blank\">GCN_3_32_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/mxd3zfaq' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/mxd3zfaq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 192   \n",
      "1 | model       | GNNModel         | 3.3 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "6 | pool        | GlobalAttention  | 33    \n",
      "-------------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.1 K     Total params\n",
      "0.016     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf4b7000d38d497a98260dd432de72ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁▃▅▅▆▆▅▅▇▆█▆▇▆▆▇▇▆▅▆▆▇▆▆▅▆█▆█▆</td></tr><tr><td>train_acc_step</td><td>▃▆█▅▆▃▃▅▆▇▁▇▇▂▇▇▆▅▆▇▅▇▆▆▅▇▄▇▅▇▅▃▅▂▇▃▇▇▆▂</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▆▄▄▃▃▂▂▂▃▁▃▄▁▄▄▄▃▄▄▃▂▃▃▂▂▂▂</td></tr><tr><td>train_loss_step</td><td>▇▃▃▅▃▄▄▄▃▁▅▂▂█▁▃▃▃▃▂▄▄▅▂▃▂▄▃▄▂▃▃▄▇▂▇▂▂▄▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>█▃▂▇▅▆▄▇█▇▃▅▄▄▇█▆█▇▄▄█▅▆▅▄▅▁▆▇</td></tr><tr><td>val_auc</td><td>█▄▃▆▅▅▄▆█▇▃▅▄▄▆▇▆█▇▄▄█▅▅▄▄▅▁▆▇</td></tr><tr><td>val_f1</td><td>▇▇▇███▇███▇█▇██████▇████▇▇█▁██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.7181</td></tr><tr><td>test_auc</td><td>0.7361</td></tr><tr><td>test_f1</td><td>0.69145</td></tr><tr><td>train_acc_epoch</td><td>0.71492</td></tr><tr><td>train_acc_step</td><td>0.4</td></tr><tr><td>train_loss_epoch</td><td>0.55744</td></tr><tr><td>train_loss_step</td><td>0.63949</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.72408</td></tr><tr><td>val_auc</td><td>0.69835</td></tr><tr><td>val_f1</td><td>0.73689</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_32_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/mxd3zfaq' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/mxd3zfaq</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_091541-mxd3zfaq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "759c0c21d8ef4bf49968197722b9841f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_093135-tdff45xp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/tdff45xp' target=\"_blank\">GCN_3_32_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/tdff45xp' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/tdff45xp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 192   \n",
      "1 | model       | GNNModel         | 3.3 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "6 | pool        | Attention_module | 1.1 K \n",
      "-------------------------------------------------\n",
      "5.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.1 K     Total params\n",
      "0.020     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5c58c20666c441e9d42e12f54dac87b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁▂▆▅▆▆█▆▇▆▇▆▇▆▆▇▇█▅▅▆▇▆▆▅▅▇▅▆▆</td></tr><tr><td>train_acc_step</td><td>▅▅▄▅▇▅▅▁▅▇▅▇▅▄▇▇▅▅▄▅▄▅▅▄▇▇▁▅▇▅▄▄█▂█▄▅█▇▁</td></tr><tr><td>train_loss_epoch</td><td>█▇▆▄▄▄▂▄▃▃▃▄▁▃▄▂▂▃▃▃▄▃▃▂▄▃▁▄▂▃</td></tr><tr><td>train_loss_step</td><td>▆▂▄▅▂▃▄▅▂▁▇▂▃▆▁▃▃▂▄▂▇▂▅▄▂▂▄▃▃▂▅▄▂▇▁█▂▃▂▆</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▄▂▆▂▆▁▄▆▅▅▇▇▅▇▆▇▇█▆▆▇▆▆▆▆▅▅▄▆▅</td></tr><tr><td>val_auc</td><td>▄▂▅▁▅▁▄▅▅▅█▆▅█▆▇██▆▆█▆▅▅▅▅▅▄▆▅</td></tr><tr><td>val_f1</td><td>▄▃▅▂▅▁▅▅▅▅▇▇▅▇▆▆▆█▅▅▇▅▄▄▅▆▅▄▆▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.72521</td></tr><tr><td>test_auc</td><td>0.73805</td></tr><tr><td>test_f1</td><td>0.69638</td></tr><tr><td>train_acc_epoch</td><td>0.74214</td></tr><tr><td>train_acc_step</td><td>0.4</td></tr><tr><td>train_loss_epoch</td><td>0.55465</td></tr><tr><td>train_loss_step</td><td>0.76045</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.69643</td></tr><tr><td>val_auc</td><td>0.67753</td></tr><tr><td>val_f1</td><td>0.73389</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_32_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/tdff45xp' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/tdff45xp</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_093135-tdff45xp\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d08ad962379c4662bf3cd48c256b94e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_094728-kawip3es</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/kawip3es' target=\"_blank\">GCN_3_64_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/kawip3es' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/kawip3es</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 384   \n",
      "1 | model       | GNNModel         | 12.7 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "-------------------------------------------------\n",
      "15.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.3 K    Total params\n",
      "0.061     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ef3afe54ad4ab9b03ee241446d0ca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁▃▇▄▆▅▇▆▆▅▇▇▅▅▆▅▆▅▆▇▆▇▇▆▆▅█▃▄▇</td></tr><tr><td>train_acc_step</td><td>▅▅▅▄▄▅▅▂▇█▄▇▇▁▅▇▅▅▅▇▄▇▅▅██▁▅▇▅▇▄▅▂▅▅▅▇▇▁</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▅▅▄▃▄▅▄▃▂▅▄▂▄▄▂▃▆▁▃▄▇▄▂▄▄▃</td></tr><tr><td>train_loss_step</td><td>▅▄▃▄▃▃▃█▂▁▄▂▄▄▃▂▃▃▂▂▅▁█▆▂▂▄▃▃▂▄▄▂▅▂█▃▂▁▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▂▄▁▆▁▆▄▂▅▄▂▆▆▇▆▇▇▆▄▃▆▅▄▇▇▅▄█▇▆</td></tr><tr><td>val_auc</td><td>▂▄▁▆▁▆▄▂▆▄▂▆▆▇▆▆▇▆▄▃▆▅▄▇▇▆▄█▇▆</td></tr><tr><td>val_f1</td><td>▂▅▁▇▁▆▄▂▆▄▂▆▆▇▆▆▇▇▄▃▆▅▅▇▇▆▄▅█▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.7266</td></tr><tr><td>test_auc</td><td>0.71558</td></tr><tr><td>test_f1</td><td>0.64359</td></tr><tr><td>train_acc_epoch</td><td>0.74516</td></tr><tr><td>train_acc_step</td><td>0.4</td></tr><tr><td>train_loss_epoch</td><td>0.55062</td></tr><tr><td>train_loss_step</td><td>0.69967</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.69182</td></tr><tr><td>val_auc</td><td>0.65038</td></tr><tr><td>val_f1</td><td>0.70932</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_64_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/kawip3es' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/kawip3es</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_094728-kawip3es\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1352cb3ec23406181482d4ea3bf713d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666495924, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_100230-v51accau</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/v51accau' target=\"_blank\">GCN_3_64_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/v51accau' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/v51accau</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 384   \n",
      "1 | model       | GNNModel         | 12.7 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "-------------------------------------------------\n",
      "15.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.3 K    Total params\n",
      "0.061     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb7d86f292e849d597a47b5f3cab8c56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁▂▃▄▃▄▄▅▆▅▅▆▅▇▅▅▆▆▇▇▇▇█▇▇██▇▇▇</td></tr><tr><td>train_acc_step</td><td>▆▆▄▆▅▇▂▅▆▄▃▅▇▁▆▇▅▇▅▅▄█▆▃▇█▃▇▇█▅▇▆▆█▅▆▆█▃</td></tr><tr><td>train_loss_epoch</td><td>█▃▃▂▂▂▂▂▁▂▂▂▂▁▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>▆▄▄▄▄▃▆▆▄▄▅▄▃▆▂▂▃▄▂▄▅▃▃▆▄▃▅▃▃▂▄▃▄▃▂▄▃▃▁█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▁▂▂▁▁█▂▂▆▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_auc</td><td>▂▁▂▁▁█▂▂▇▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>val_f1</td><td>█▂▂▁▁▇█▂▆▁████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.66436</td></tr><tr><td>test_auc</td><td>0.64007</td></tr><tr><td>test_f1</td><td>0.52729</td></tr><tr><td>train_acc_epoch</td><td>0.58427</td></tr><tr><td>train_acc_step</td><td>0.2</td></tr><tr><td>train_loss_epoch</td><td>0.67655</td></tr><tr><td>train_loss_step</td><td>1.11115</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.4977</td></tr><tr><td>val_auc</td><td>0.48387</td></tr><tr><td>val_f1</td><td>0.64286</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_64_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/v51accau' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/v51accau</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_100230-v51accau\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90edf7d37e82447897ce56ae763c3b47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333330477276, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_101715-9gqba0kh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/9gqba0kh' target=\"_blank\">GCN_3_64_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/9gqba0kh' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/9gqba0kh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 384   \n",
      "1 | model       | GNNModel         | 12.7 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "-------------------------------------------------\n",
      "15.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.3 K    Total params\n",
      "0.061     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f2694db1c264c4fadb54cac938fdc25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁▂▃▅▆▅▇▄▆▅▅▇▄▅█▄█▆█▇▆▆▆▅▅▅▄▆▆▄</td></tr><tr><td>train_acc_step</td><td>▆▆▁▅▆▆█▅▅▆▁██▇▆▃█▃▆▃▅▅▅▃▆█▇▅▁▆█▅▆▁▆▅▅▆█▁</td></tr><tr><td>train_loss_epoch</td><td>█▃▂▂▂▂▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>▄▃█▂▂▁▂▃▂▁▃▁▂▁▂▃▂▃▂▂▃▃▃▃▂▂▂▃▃▂▂▂▃▆▄▂▂▂▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▁▁▄▃▁▁▂▁▁▁▄▂▄▄▄▃▂▃▃▃▄▃▃▅▄▆▄▆▅█</td></tr><tr><td>val_auc</td><td>▁▁▄▃▁▁▂▁▁▁▄▂▄▄▄▃▂▃▃▄▄▃▃▅▄▇▄▆▅█</td></tr><tr><td>val_f1</td><td>▁▁▄▃▁▁▂▁▁▁▄▁▄▄▄▃▂▃▃▃▄▃▃▅▃▆▄▆▅█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.7474</td></tr><tr><td>test_auc</td><td>0.735</td></tr><tr><td>test_f1</td><td>0.6721</td></tr><tr><td>train_acc_epoch</td><td>0.66048</td></tr><tr><td>train_acc_step</td><td>0.4</td></tr><tr><td>train_loss_epoch</td><td>0.71253</td></tr><tr><td>train_loss_step</td><td>0.91999</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.78053</td></tr><tr><td>val_auc</td><td>0.74163</td></tr><tr><td>val_f1</td><td>0.7644</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_64_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/9gqba0kh' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/9gqba0kh</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_101715-9gqba0kh\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37ad3c4ba2cd4dd9b8ffc55bc498c363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_103139-nrbullmd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/nrbullmd' target=\"_blank\">GCN_3_64_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/nrbullmd' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/nrbullmd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 384   \n",
      "1 | model       | GNNModel         | 12.7 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "6 | pool        | GlobalAttention  | 65    \n",
      "-------------------------------------------------\n",
      "15.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.3 K    Total params\n",
      "0.061     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "365c50dd9a7b4eeabf301a956d141463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁▃▃▅▄▅▅▅▇▆▅▆▇▆▇▆▇▆▆▇▆▆█▅▆▆▇▆▇█</td></tr><tr><td>train_acc_step</td><td>▇▅▄▂▅▄▂▄▄▇▂▅▄▁▄▅▇▅▄▇▄▅▄▂▇▇▃▅▅▅▇▂▇▂▄▂▇██▁</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▅▅▄▄▄▃▃▃▃▁▃▂▂▃▃▂▂▂▂▂▃▃▃▁▂▂▁</td></tr><tr><td>train_loss_step</td><td>▅▆▅▅▅▄▄█▅▂▆▃▅▇▅▄▃▅▃▃▆▃▆▇▃▂▆▄▅▃▄▅▂▆▅▇▄▂▁▆</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▁▂▁▁▂▁▁▁▂▁▂▃▂▄▃▂▆▆▄▃▄▅█▅▄▄▄▅▄▄</td></tr><tr><td>val_auc</td><td>▂▂▁▁▂▂▁▂▂▁▂▃▂▄▃▃▆▇▅▃▄▅█▅▅▅▄▅▄▄</td></tr><tr><td>val_f1</td><td>▂▂▁▁▂▁▁▂▂▁▁▄▂▄▃▂▆▇▅▃▄▅█▅▅▅▄▅▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.67649</td></tr><tr><td>test_auc</td><td>0.69842</td></tr><tr><td>test_f1</td><td>0.66725</td></tr><tr><td>train_acc_epoch</td><td>0.73407</td></tr><tr><td>train_acc_step</td><td>0.4</td></tr><tr><td>train_loss_epoch</td><td>0.55246</td></tr><tr><td>train_loss_step</td><td>0.74168</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.58295</td></tr><tr><td>val_auc</td><td>0.57285</td></tr><tr><td>val_f1</td><td>0.67895</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_64_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/nrbullmd' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/nrbullmd</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_103139-nrbullmd\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "914b10f030ad45ffbee876f6e5027df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666883975, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_104635-z8oe34ls</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/z8oe34ls' target=\"_blank\">GCN_3_64_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/z8oe34ls' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/z8oe34ls</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 384   \n",
      "1 | model       | GNNModel         | 12.7 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "6 | pool        | Attention_module | 4.2 K \n",
      "-------------------------------------------------\n",
      "19.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "19.5 K    Total params\n",
      "0.078     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd73226fcb84499cae00ba63a61ef188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁▂▄▃▅▂▅▆█▆▇▇▇█▄▆▆▇█▅▄▅█▆▇▅▇▆█▅</td></tr><tr><td>train_acc_step</td><td>▆▆▆▂▆▅█▁▆█▆█▇▂▅▇▇▇▃▇▃▇▅▅▇▆▄▅▇▆▇▅█▂▆▅▅█▇▂</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▄▅▆▄▄▄▄▃▃▂▃▄▃▄▂▂▃▅▂▄▃▅▅▁▂▃▃</td></tr><tr><td>train_loss_step</td><td>▄▂▄▄▃▂▂▇▃▁▄▂▃▆▂▂▂▂▃▃▅▂█▄▂▂▃▃▂▂▃▃▂▅▂▅▂▂▁▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▆▄▇▃▇▃▂▄▅▅▇▅▁▃▆▇▇▄▅▆█▇█▆▅▇▅▅▇▅</td></tr><tr><td>val_auc</td><td>▆▃▆▃▆▃▂▄▅▅▇▅▁▃▆▆▆▄▅▆█▇▇▅▅▆▅▅▇▅</td></tr><tr><td>val_f1</td><td>▆▄▇▃█▄▂▅▅▅█▅▁▃▆▅▇▅▆▆██▇▆▆▇▆▆▇▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.74237</td></tr><tr><td>test_auc</td><td>0.7479</td></tr><tr><td>test_f1</td><td>0.69414</td></tr><tr><td>train_acc_epoch</td><td>0.73004</td></tr><tr><td>train_acc_step</td><td>0.4</td></tr><tr><td>train_loss_epoch</td><td>0.55865</td></tr><tr><td>train_loss_step</td><td>0.70424</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.63594</td></tr><tr><td>val_auc</td><td>0.6235</td></tr><tr><td>val_f1</td><td>0.69889</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_3_64_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/z8oe34ls' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/z8oe34ls</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_104635-z8oe34ls\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d23ba0853414ed6982a730400f88b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_110434-121xnnam</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/121xnnam' target=\"_blank\">GCN_4_16_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/121xnnam' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/121xnnam</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 96    \n",
      "1 | model       | GNNModel         | 1.2 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "-------------------------------------------------\n",
      "1.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.4 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffde56b759a94bbb9f3ef856f162ebc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁▄▅▇▇▇▇▆▇▇▇▇▇▇▆▆▇▆▇▇▇▆▇▇▇▆▇█▇▇</td></tr><tr><td>train_acc_step</td><td>▁▅▅▅█▄▇▄▇▄▂▅▅▄▅▅▅█▅▅▄▅▅▄█▇▁▅▅▅▇▄▄▅█▇▇█▇▁</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▃▃▃▄▃▃▂▃▃▄▃▂▃▃▂▂▃▃▃▃▃▃▃▁▃▁</td></tr><tr><td>train_loss_step</td><td>▅▇▄▅▁▃▃▄▃▃▄▂▃▅▂▃▁▁▂▂▄▂▄▅▁▂▄▃▄▃▅▃▂▅▂█▁▂▂▆</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▁█▃▄█▆▆▅█▆▇▆▇▅█▃▆▅▄▆▃▇█▅▄█▇▇█▆</td></tr><tr><td>val_auc</td><td>▁█▃▄▇▆▆▅▇▆▇▆▇▅█▃▆▅▄▆▃▇█▅▄▇▇▇▇▆</td></tr><tr><td>val_f1</td><td>▁█▃▄▇▆▆▆▇▆▇▆▇▅▇▃▆▅▄▆▃▇█▆▄▇▇▇█▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.66071</td></tr><tr><td>test_auc</td><td>0.69116</td></tr><tr><td>test_f1</td><td>0.66617</td></tr><tr><td>train_acc_epoch</td><td>0.73911</td></tr><tr><td>train_acc_step</td><td>0.4</td></tr><tr><td>train_loss_epoch</td><td>0.53178</td></tr><tr><td>train_loss_step</td><td>0.80073</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.66417</td></tr><tr><td>val_auc</td><td>0.64919</td></tr><tr><td>val_f1</td><td>0.72075</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_16_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/121xnnam' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/121xnnam</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_110434-121xnnam\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82145f35028844b0b5051b7cfaedf19d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_113118-k0rs5unn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/k0rs5unn' target=\"_blank\">GCN_4_16_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/k0rs5unn' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/k0rs5unn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 96    \n",
      "1 | model       | GNNModel         | 1.2 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "-------------------------------------------------\n",
      "1.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.4 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c10092569b674548b36240e4a7b0a473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁▁▄▃▅▆▅▆▆▆▅▅▇▇▅▇▅▇▇█▆▆▆▆▅▅▆▆▆▆</td></tr><tr><td>train_acc_step</td><td>▆▆█▅▅▇▂▅▅▃▂▇▃▂▆▇▆▃▇▅▅▃▅▁▇▇▂▇▆▆▅▇▅▆▅▆▇▆▇▂</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▂▂▂▂▂▂▁▂▂</td></tr><tr><td>train_loss_step</td><td>▂▃▁▃▃▁▄▂▃▄▄▂▃█▂▂▁▂▁▃▃▃▃▄▂▁▆▂▂▂▃▂▃▂▃▂▂▂▁▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▁▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▂█▂▁▁▁▁▁▁▁▁▄▁▁</td></tr><tr><td>val_auc</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▄▁▁</td></tr><tr><td>val_f1</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▇▁█▁▁▁▁▁▁▁▄▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.6647</td></tr><tr><td>test_auc</td><td>0.62997</td></tr><tr><td>test_f1</td><td>0.49636</td></tr><tr><td>train_acc_epoch</td><td>0.57823</td></tr><tr><td>train_acc_step</td><td>0.2</td></tr><tr><td>train_loss_epoch</td><td>0.67738</td></tr><tr><td>train_loss_step</td><td>0.88931</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.5023</td></tr><tr><td>val_auc</td><td>0.48387</td></tr><tr><td>val_f1</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_16_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/k0rs5unn' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/k0rs5unn</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_113118-k0rs5unn\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7a022e440a94b1fa93a41ccfbe043fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_115531-hpd2rlmh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/hpd2rlmh' target=\"_blank\">GCN_4_16_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/hpd2rlmh' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/hpd2rlmh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 96    \n",
      "1 | model       | GNNModel         | 1.2 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "-------------------------------------------------\n",
      "1.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.4 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63eb4df4631149abbbcee27f3cf9d838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁▄▅▆▆▆▆█▇▇▇▇▇▇▇█▇▇▇████▇█▇▇█▆▇</td></tr><tr><td>train_acc_step</td><td>▄▂▄▃▅▄▂▂▅▅▂█▅▅▇▅███▇▄▅▇▄▅▅▅▇▇█▇▅▅▅█▅▅█▇▁</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▃▄▃▃▄▄▄▃▄▂▂▃▂▂▁▂▂▂▄▂▂▃▃▂▃▂▂▂▃▂▂▃▁▅▂▂▂▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▁▂▇▃▆▅▆█▅▄▃▅▇▇▇▇█▇▇▆▆▄█▆███▆▇▅</td></tr><tr><td>val_auc</td><td>▁▂▇▃▆▅▆█▅▄▃▅▇▇▇▇█▇▇▆▆▄▇▆█▇█▆▇▅</td></tr><tr><td>val_f1</td><td>▁▃▆▃▆▆▇▇▆▅▄▅▇▇▇▇█▇▇▆▆▅▇▇███▆▇▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.73041</td></tr><tr><td>test_auc</td><td>0.72399</td></tr><tr><td>test_f1</td><td>0.66618</td></tr><tr><td>train_acc_epoch</td><td>0.67298</td></tr><tr><td>train_acc_step</td><td>0.2</td></tr><tr><td>train_loss_epoch</td><td>0.60594</td></tr><tr><td>train_loss_step</td><td>1.06304</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.68779</td></tr><tr><td>val_auc</td><td>0.66286</td></tr><tr><td>val_f1</td><td>0.71349</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_16_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/hpd2rlmh' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/hpd2rlmh</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_115531-hpd2rlmh\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "381e33b31ad54cf19ea8f378075db484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333330477276, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_122020-r45fcenp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/r45fcenp' target=\"_blank\">GCN_4_16_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/r45fcenp' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/r45fcenp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 96    \n",
      "1 | model       | GNNModel         | 1.2 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "6 | pool        | GlobalAttention  | 17    \n",
      "-------------------------------------------------\n",
      "1.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.5 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "783bdd05c317420296ece00574766c6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁▅▆▇▇▇▇▇▇▇▇▇▇█▇█▇██▇█▇███▇▇█▇█</td></tr><tr><td>train_acc_step</td><td>▁▅▂▁▅▄▂▁▅▇▂▅▄▆▅▇▅▅█▄▄▄▇▂▇▅▁▅▇▅▄▄▄▄▇▄▇██▁</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▃▃▃▄▃▄▂▃▃▃▃▃▃▂▃▃▃▃▃▃▃▂▃▂▃▁</td></tr><tr><td>train_loss_step</td><td>▄▅▃▅▂▃▃▄▂▂▅▂▃▃▂▂▁▂▁▃▄▄▃▄▁▂▄▂▂▂▃▃▂▅▂█▁▁▁▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▅▁▃▅▄▆▃▆▅▇▆█▆▇▇▅▅▄▆▆▄▄▇▇▅▇▆▅▇▃</td></tr><tr><td>val_auc</td><td>▅▁▃▅▄▆▃▆▅▇▆█▆▇▇▅▄▄▆▆▄▄▇▇▅▇▆▅▇▄</td></tr><tr><td>val_f1</td><td>▄▁▃▆▄▆▃▆▅▇▆█▆▆▇▅▅▄▆▆▄▄▇▆▅▇▆▆▇▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.72053</td></tr><tr><td>test_auc</td><td>0.73285</td></tr><tr><td>test_f1</td><td>0.68928</td></tr><tr><td>train_acc_epoch</td><td>0.72903</td></tr><tr><td>train_acc_step</td><td>0.4</td></tr><tr><td>train_loss_epoch</td><td>0.53885</td></tr><tr><td>train_loss_step</td><td>0.68514</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.61982</td></tr><tr><td>val_auc</td><td>0.60833</td></tr><tr><td>val_f1</td><td>0.69689</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_16_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/r45fcenp' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/r45fcenp</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_122020-r45fcenp\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f457404e7a854cd18a0f2977d99dff7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_131923-a8kxnyiv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/a8kxnyiv' target=\"_blank\">GCN_4_16_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/a8kxnyiv' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/a8kxnyiv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 96    \n",
      "1 | model       | GNNModel         | 1.2 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "6 | pool        | Attention_module | 281   \n",
      "-------------------------------------------------\n",
      "1.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.7 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "470be85eee734d51acbee5534c317e78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁▅▆▆▅▆▇▇▇▆▇█▆▇▆▆▇▆▇▆▆▆▇▇▇▇▆▇▇█</td></tr><tr><td>train_acc_step</td><td>▂▅▄▄▇▅▅▂▇▅▄▇▇▃▅▇▅▅▅▅▂▇▅▇▇▅▁▅▇▅▂▅▅▅▅▅▇█▅▁</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▃▃▄▃▄▃▃▂▂▃▃▃▃▃▃▂▃▃▃▃▃▃▂▃▂▃▁</td></tr><tr><td>train_loss_step</td><td>▅█▄▄▄▃▃▅▂▃▆▂▃▄▂▂▁▂▃▂▅▂▃▄▁▂▅▃▃▃▇▂▂▄▃▇▁▂▃▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▁▅▇▆▆▆▇▇▆▇▇▆▇▅▇▇▇██▇▇▆▆▇█▆▇█▇█</td></tr><tr><td>val_auc</td><td>▁▅▆▆▆▆▇█▆▆▇▆▆▅▇▆▇██▇▆▆▆▆█▆▇█▇█</td></tr><tr><td>val_f1</td><td>▃▆▇▇▇▇▇█▇▇█▆▇▇▇▇▆██▄▇▁▄▇█▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.7422</td></tr><tr><td>test_auc</td><td>0.7476</td></tr><tr><td>test_f1</td><td>0.69893</td></tr><tr><td>train_acc_epoch</td><td>0.75222</td></tr><tr><td>train_acc_step</td><td>0.4</td></tr><tr><td>train_loss_epoch</td><td>0.53161</td></tr><tr><td>train_loss_step</td><td>0.70811</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.7523</td></tr><tr><td>val_auc</td><td>0.72577</td></tr><tr><td>val_f1</td><td>0.75281</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_16_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/a8kxnyiv' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/a8kxnyiv</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_131923-a8kxnyiv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac8a1efebec549a68fde2066a5974a81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_133457-xt227jhq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/xt227jhq' target=\"_blank\">GCN_4_32_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/xt227jhq' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/xt227jhq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 192   \n",
      "1 | model       | GNNModel         | 4.4 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "-------------------------------------------------\n",
      "5.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.2 K     Total params\n",
      "0.021     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e5e8b11a6f943a2a055712d0c42bb2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁▄▄▇▄▅▆▄▆▆▅▅▅▆▅▅▆▇▆▅▅▇▅▇█▆▆▆▆▅</td></tr><tr><td>train_acc_step</td><td>▄▇▇▅▄▇▁▁▇█▅█▇▄▇▅▅█▄▄▄▅▄▄██▁▄▇▅▇▄▇▅▇▄▅▇▇▁</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▅▅▃▃▂▂▃▄▂▃▃▂▃▂▄▂▃▃▃▃▁▃▂▃▁▂</td></tr><tr><td>train_loss_step</td><td>▆▂▅▅▅▅▆▇▃▁▆▂▃▅▂▃▂▂▃▃▆▃█▆▃▃▅▄▄▃▅▇▃█▂▇▂▃▃▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▄▃▁▅▄▅▆▁▆▄▂▆▃▆▇▇▅▇▅▆▇█▄▆▇▇▆▇▆▇</td></tr><tr><td>val_auc</td><td>▄▃▁▅▄▅▆▁▆▄▃▆▃▆▇▇▅▇▅▆▇█▄▆▆█▇▇▆▇</td></tr><tr><td>val_f1</td><td>▇▆▅▇▇▇▇▅█▆▆▇▆███▇█▇▁█▆▆███████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.7363</td></tr><tr><td>test_auc</td><td>0.72501</td></tr><tr><td>test_f1</td><td>0.65818</td></tr><tr><td>train_acc_epoch</td><td>0.73206</td></tr><tr><td>train_acc_step</td><td>0.4</td></tr><tr><td>train_loss_epoch</td><td>0.54474</td></tr><tr><td>train_loss_step</td><td>0.59419</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.70449</td></tr><tr><td>val_auc</td><td>0.68168</td></tr><tr><td>val_f1</td><td>0.73881</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_32_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/xt227jhq' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/xt227jhq</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_133457-xt227jhq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61cf0173e6504969814d2f86afde8987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333330477276, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_134937-b00290rl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/b00290rl' target=\"_blank\">GCN_4_32_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/b00290rl' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/b00290rl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 192   \n",
      "1 | model       | GNNModel         | 4.4 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "-------------------------------------------------\n",
      "5.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.2 K     Total params\n",
      "0.021     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ba0d3ab8b41472ba3d4b822d9c75310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▂▁▃▄▄▅▄▅▆▇█▅▆█▆▇▇▇▆▇▇▆▆█▇▇▆▆▆▅</td></tr><tr><td>train_acc_step</td><td>▅▅▅▅▂▇▁▅▅▅▂▆▆▂█▆▇▅▇▅▅▇▆▃█▇▄▇▇▅▂█▂▇▆▆▆▆▇▅</td></tr><tr><td>train_loss_epoch</td><td>█▃▃▂▃▂▂▂▂▂▂▂▂▁▂▂▁▂▂▂▂▂▂▂▂▁▂▂▁▂</td></tr><tr><td>train_loss_step</td><td>▄▅▄▂▄▂▇▃▄▅▄▃▃█▂▂▂▄▂▄▄▂▃▄▂▂▄▂▂▃▃▂▃▁▃▃▃▃▃▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▂▂▂▂▂▄▂▂▂▃▁▃▂▁▅▄▅▂▁▂█▂▂▅▄▃▂▃▆▁</td></tr><tr><td>val_auc</td><td>▁▂▂▂▂▃▁▂▃▃▂▃▂▂▅▄▅▂▁▂█▂▁▅▄▃▂▂▆▁</td></tr><tr><td>val_f1</td><td>▁▁▁▁▁▄▁▁█▃██▁█▅▃▅▁▂▁▇▁▁▅█▃▁▃▅▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.67545</td></tr><tr><td>test_auc</td><td>0.63769</td></tr><tr><td>test_f1</td><td>0.49313</td></tr><tr><td>train_acc_epoch</td><td>0.57036</td></tr><tr><td>train_acc_step</td><td>0.6</td></tr><tr><td>train_loss_epoch</td><td>0.67568</td></tr><tr><td>train_loss_step</td><td>0.81126</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.49021</td></tr><tr><td>val_auc</td><td>0.46935</td></tr><tr><td>val_f1</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_32_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/b00290rl' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/b00290rl</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_134937-b00290rl\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d93f0ae7b543b582fa23fb5b6cfcae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_140418-5j195mcw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/5j195mcw' target=\"_blank\">GCN_4_32_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/5j195mcw' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/5j195mcw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 192   \n",
      "1 | model       | GNNModel         | 4.4 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "-------------------------------------------------\n",
      "5.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.2 K     Total params\n",
      "0.021     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4558d5fc855f480f936b26cdb6509002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁▂▂▆▅▄▇▄▆▄▆▅▄▅█▇▆▆▆▅▆▆▄▅▆▇▅▅█▆</td></tr><tr><td>train_acc_step</td><td>▃█▅▆▁▅▃▅██▃▅▆▁▆▅██▆▅▃▅▆▃▆█▁▅▆▃▅▅▅▆█▃▃▆█▇</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▂▂▂▁▂▁▂▁▂▂▁▁▁▁▁▂▁▁▂▂▂▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>▃▁▂▂█▂▄▃▁▁▃▂▄▄▂▂▂▂▂▂▃▂▂▃▂▂▂▃▂▃▂▂▂▁▁▃▂▂▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▁▂▂▂▃▂▄▃▅▇▇▆▆█▇▇▄▆▆▆▅▆▆█▇█▇▇▇▆</td></tr><tr><td>val_auc</td><td>▁▂▂▂▃▂▄▃▅▇▇▇▆█▇▇▄▇▇▆▅▆▆█▇█▇▇▇▆</td></tr><tr><td>val_f1</td><td>▁▂▁▂▃▁▃▃▄▆▆▇▆█▆▇▃▇▇▆▅▆▆█▇█▇▇▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.72417</td></tr><tr><td>test_auc</td><td>0.73759</td></tr><tr><td>test_f1</td><td>0.6916</td></tr><tr><td>train_acc_epoch</td><td>0.69194</td></tr><tr><td>train_acc_step</td><td>0.8</td></tr><tr><td>train_loss_epoch</td><td>0.63617</td></tr><tr><td>train_loss_step</td><td>0.53913</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.67972</td></tr><tr><td>val_auc</td><td>0.66609</td></tr><tr><td>val_f1</td><td>0.72363</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_32_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/5j195mcw' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/5j195mcw</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_140418-5j195mcw\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "244ef124cbc54335a2d6d526af293df3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_141909-2t22szk9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/2t22szk9' target=\"_blank\">GCN_4_32_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/2t22szk9' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/2t22szk9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 192   \n",
      "1 | model       | GNNModel         | 4.4 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "6 | pool        | GlobalAttention  | 33    \n",
      "-------------------------------------------------\n",
      "5.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.2 K     Total params\n",
      "0.021     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b373eebd7654a3591f7294c150e46b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁▄▆▇▄▆▅▆▇▆▆▆▆▆█▇▇▅▇█▇▇▇▆█▆▇▇▇▇</td></tr><tr><td>train_acc_step</td><td>▂▅▅▄▅▄▂▂▅█▁▇▅▁▇▇▇▅▄▅▅▄▄▅█▇▁▄▇▇▅▂▇▂▇▄▇▇▇▄</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▂▂▄▃▂▂▂▂▃▂▂▂▃▂▂▃▂▂▂▁▂▂▃▂▂▂▁</td></tr><tr><td>train_loss_step</td><td>▃▃▃▃▂▃▃▃▂▁▃▂▃▂▁▂▁▂▂▂▃▂▃▃▂▂▃▂▂▁▂▄▂█▁▃▂▂▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▇▆▆▅█▂█▅▃▆▁▃▄▂▄▂▂█▅▆▄█▃▅▄▆▁▆▅▆</td></tr><tr><td>val_auc</td><td>▇▅▆▅█▂▇▅▃▆▁▃▄▂▄▂▂▇▅▆▄▇▃▅▄▆▂▇▅▆</td></tr><tr><td>val_f1</td><td>█▆▇▅▇▂█▆▃▆▁▃▅▂▅▁▃▇▆▆▅█▃▅▄▇▁▇▆▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.70683</td></tr><tr><td>test_auc</td><td>0.7251</td></tr><tr><td>test_f1</td><td>0.68542</td></tr><tr><td>train_acc_epoch</td><td>0.71956</td></tr><tr><td>train_acc_step</td><td>0.6</td></tr><tr><td>train_loss_epoch</td><td>0.55369</td></tr><tr><td>train_loss_step</td><td>0.56337</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.6803</td></tr><tr><td>val_auc</td><td>0.66678</td></tr><tr><td>val_f1</td><td>0.72938</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_32_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/2t22szk9' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/2t22szk9</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_141909-2t22szk9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cdd5598e1dc447995fbdd11cd1a1bdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_143409-0uqqrvks</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/0uqqrvks' target=\"_blank\">GCN_4_32_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/0uqqrvks' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/0uqqrvks</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 192   \n",
      "1 | model       | GNNModel         | 4.4 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "6 | pool        | Attention_module | 1.1 K \n",
      "-------------------------------------------------\n",
      "6.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.2 K     Total params\n",
      "0.025     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4912b5a821740caa87d03af7d87c2ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁▅▆▆▅▇▆▅▆▆▆▇▇▆▆▆▇▆▆▆▇▇▆▆█▇▅▇▆▇</td></tr><tr><td>train_acc_step</td><td>▂▅▇▅▄▇▁▂▇▇▁▇▇▁▇█▇▇▂▇▂▅▅▄▇▇▁▅▇▇▅▄▇▅▇▂▅▇█▁</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▃▄▃▃▂▁▃▂▂▁▃▂▂▂▃▁▁▂▂▂▁▂▂▃▁▁</td></tr><tr><td>train_loss_step</td><td>▅▁▄▃▅▂▄▄▂▁▄▂▂▃▁▂▁▁▂▂▄▂▇▄▂▂▄▃▂▂▃▄▂█▂▅▃▃▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▃▅▄▅▂▅▆▁▄▇▆▂▅▇▆▆▆▇▃▄▅█▁█▄▅▃▃▂▅</td></tr><tr><td>val_auc</td><td>▃▅▄▆▂▅▆▁▄▇▆▂▅▆▆▆▆▆▄▅▄█▁█▄▅▃▃▃▅</td></tr><tr><td>val_f1</td><td>▄▆▅▇▂▇▇▂▅█▇▃▆▇▇▇▇▇▄▅▅█▁█▅▆▃▄▃▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.73249</td></tr><tr><td>test_auc</td><td>0.74396</td></tr><tr><td>test_f1</td><td>0.69871</td></tr><tr><td>train_acc_epoch</td><td>0.74415</td></tr><tr><td>train_acc_step</td><td>0.4</td></tr><tr><td>train_loss_epoch</td><td>0.54011</td></tr><tr><td>train_loss_step</td><td>0.50616</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.67224</td></tr><tr><td>val_auc</td><td>0.65791</td></tr><tr><td>val_f1</td><td>0.72613</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_32_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/0uqqrvks' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/0uqqrvks</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_143409-0uqqrvks\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c78e825255904a85a431a66bd218215b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333330477276, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_144921-v0jstrvl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/v0jstrvl' target=\"_blank\">GCN_4_64_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/v0jstrvl' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/v0jstrvl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 384   \n",
      "1 | model       | GNNModel         | 17.0 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "-------------------------------------------------\n",
      "19.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "19.6 K    Total params\n",
      "0.078     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba8a279ebb004a2e9486b825268a0f9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▃▅▇▆█▁▅▂▇▃██▇▆▆▆▆▅▄▆▆▅▅▄▄▃▆▆▁█</td></tr><tr><td>train_acc_step</td><td>▄▅▇▄▄▇▄▁▇▅▂█▇▁▇▇▇▇▄▇▅▇▅▅█▇▄▇▅▇▅▅▅▂▇▄▇▇▅▄</td></tr><tr><td>train_loss_epoch</td><td>▇▇▄▅▆▆▃▆▄▅▃▃█▅▆▄▃▅▇▂▂▁▄▃▅▆▄▃█▇</td></tr><tr><td>train_loss_step</td><td>▂▁▂▃▂▂▃▃▂▃▃▁▂▃▁▂▂▂▂▂▃▂█▃▁▁▂▂▂▂▃▃▂▄▁▄▂▂▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▅▁▁▃▂▇▄▄▄▇▄▇▅▆█▃▆▃▄▂▁▂▂▂▃▂▄▃▅▇</td></tr><tr><td>val_auc</td><td>▅▁▁▃▂▇▄▄▄▆▄▆▅▆█▃▆▃▄▂▁▃▂▂▃▂▄▃▅▇</td></tr><tr><td>val_f1</td><td>▆▂▁▃▂█▄▅▅█▅█▆▇█▃▇▃▄▂▁▃▃▃▄▂▅▃▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.74844</td></tr><tr><td>test_auc</td><td>0.74556</td></tr><tr><td>test_f1</td><td>0.68495</td></tr><tr><td>train_acc_epoch</td><td>0.74274</td></tr><tr><td>train_acc_step</td><td>0.6</td></tr><tr><td>train_loss_epoch</td><td>0.57058</td></tr><tr><td>train_loss_step</td><td>0.59607</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.69988</td></tr><tr><td>val_auc</td><td>0.67039</td></tr><tr><td>val_f1</td><td>0.7262</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_64_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/v0jstrvl' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/v0jstrvl</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_144921-v0jstrvl\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c693351b9641a3a670e2e08841ff01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333330477276, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_150555-l4rz899f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/l4rz899f' target=\"_blank\">GCN_4_64_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/l4rz899f' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/l4rz899f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 384   \n",
      "1 | model       | GNNModel         | 17.0 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "-------------------------------------------------\n",
      "19.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "19.6 K    Total params\n",
      "0.078     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9652f7dcc2714d128878fefbe47b2226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁▁▁▂▃▄▄▄▄▄▅▄▆▅▄▆▆▆▆▇▅▇▇▇▇████▆</td></tr><tr><td>train_acc_step</td><td>▆▇▆▃▇▅▁▅▇▂▂▆▃▄▆▇█▆▇▅▅▆█▅▅▇▅▇▇▇▆█▅▂█▇▆▇█▄</td></tr><tr><td>train_loss_epoch</td><td>█▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▂▁▁▁▁▁▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>▄▆▆▆▅▄█▆▅▇▇▅▆▅▄▆▇▆▅▆▆▆▃▇▅▃▇▄▄▄▃▄▅▇▁▅▆▆▄▇</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▂▂▂▂▅▂▃▂▂▆▃▂▁▂▂▂▆▁▄▂▁█▅▆▃▁█▄▄▂</td></tr><tr><td>val_auc</td><td>▂▂▂▂▅▁▂▂▂▆▃▂▂▂▂▂▆▂▄▂▁█▅▆▃▂█▄▅▂</td></tr><tr><td>val_f1</td><td>▁▁▁▁▆▂▃██▇▃▁█▁▁▂███▁▁████████▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.67164</td></tr><tr><td>test_auc</td><td>0.67598</td></tr><tr><td>test_f1</td><td>0.61333</td></tr><tr><td>train_acc_epoch</td><td>0.60706</td></tr><tr><td>train_acc_step</td><td>0.4</td></tr><tr><td>train_loss_epoch</td><td>0.66735</td></tr><tr><td>train_loss_step</td><td>0.76813</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.5023</td></tr><tr><td>val_auc</td><td>0.48871</td></tr><tr><td>val_f1</td><td>0.02151</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_64_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/l4rz899f' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/l4rz899f</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_150555-l4rz899f\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "383cc651b0e644c4a09a09d3246df1f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_152113-vndfo4hz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/vndfo4hz' target=\"_blank\">GCN_4_64_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/vndfo4hz' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/vndfo4hz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 384   \n",
      "1 | model       | GNNModel         | 17.0 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "-------------------------------------------------\n",
      "19.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "19.6 K    Total params\n",
      "0.078     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1745035ca92c4ff9beffe945ee49e063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁▁▁▃█▅▂▅▆▅▅▅▇▇█▆█▇▆▃▆█▇▅▆▃▅▇▆▆</td></tr><tr><td>train_acc_step</td><td>██▃▂▇▅▃▅▅▅▄▇▇▁▇▅▄▅█▅▄▇▅▅▅▇▅▄█▇█▇▇▇▅▄▇█▃▅</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▂▁▂▃▂▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>▁▂▆█▃▆▄▅▄▅▆▂▂▅▃▄▄▇▂▃▅▃▆▄▃▃▄▅▇▃▂▃▃▃▃▆▂▂▅▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▁▁▁▂▁▁▃▁▄▂▁▃▂▅▅▅▄▅▂▃▅▇▇▅▇▆█▅▄▆</td></tr><tr><td>val_auc</td><td>▁▁▁▂▁▁▃▁▄▂▁▃▂▅▅▅▄▆▃▃▅▇▇▅▇▆█▅▄▇</td></tr><tr><td>val_f1</td><td>▁▁▁▂▁▁▃▁▄▂▁▂▂▅▅▅▄▅▂▃▄▇▇▅▇▆█▅▄▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.69001</td></tr><tr><td>test_auc</td><td>0.70802</td></tr><tr><td>test_f1</td><td>0.67913</td></tr><tr><td>train_acc_epoch</td><td>0.66915</td></tr><tr><td>train_acc_step</td><td>0.6</td></tr><tr><td>train_loss_epoch</td><td>0.74308</td></tr><tr><td>train_loss_step</td><td>0.99115</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.68433</td></tr><tr><td>val_auc</td><td>0.66705</td></tr><tr><td>val_f1</td><td>0.73086</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_64_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/vndfo4hz' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/vndfo4hz</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_152113-vndfo4hz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33858ca769064508a96c08da5772a8a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666883975, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_153623-17ok31n4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/17ok31n4' target=\"_blank\">GCN_4_64_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/17ok31n4' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/17ok31n4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 384   \n",
      "1 | model       | GNNModel         | 17.0 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "6 | pool        | GlobalAttention  | 65    \n",
      "-------------------------------------------------\n",
      "19.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "19.6 K    Total params\n",
      "0.078     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5043805b053a47c6aa4cd022347e8c3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▁▁▄▄▄▂▅▅▃▄▄▃▅▆▆▆▆▇▆▆█▆▆▆▇▆▇▇▇█</td></tr><tr><td>train_acc_step</td><td>▄▅▇▂▄▅▇▁▅▅█▅▁▆▇▇▄▇▅▁▄▅▅▄▅▇▁▂▅▇▅▄█▂▅▄▄▇▅▁</td></tr><tr><td>train_loss_epoch</td><td>█▇▆▅▄▇▃▄▅▆▄▅▅▃▃▃▃▃▂▂▁▂▂▂▂▃▂▂▃▂</td></tr><tr><td>train_loss_step</td><td>▄▃▃▄▄▃▃▅▃▁▃▄▄▄▁▃▃▂▃▃▅▄█▄▂▂▄▄▃▁▃▃▂▅▂▃▃▂▂▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▆▁▂▁▁▂▂▂▁▃▂▆▂▄▃▅▅▃▄▆▅▆▅▇▇▇█▇▆▇</td></tr><tr><td>val_auc</td><td>▆▁▁▁▁▁▂▂▁▃▂▆▂▄▃▅▅▃▄▆▅▆▅▆▇▇█▇▆▇</td></tr><tr><td>val_f1</td><td>▆▁▂▁▁▂▂▂▁▃▂▇▂▄▃▅▆▃▅▇▅▇▆▇▇██▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.75451</td></tr><tr><td>test_auc</td><td>0.75787</td></tr><tr><td>test_f1</td><td>0.70445</td></tr><tr><td>train_acc_epoch</td><td>0.74113</td></tr><tr><td>train_acc_step</td><td>0.4</td></tr><tr><td>train_loss_epoch</td><td>0.55788</td></tr><tr><td>train_loss_step</td><td>0.7302</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.72465</td></tr><tr><td>val_auc</td><td>0.68894</td></tr><tr><td>val_f1</td><td>0.74327</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_64_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/17ok31n4' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/17ok31n4</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_153623-17ok31n4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b0d991fe5f041a5a2a778c0f6613aa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333330477276, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230422_155216-avhx8g29</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_041623_base/runs/avhx8g29' target=\"_blank\">GCN_4_64_emb</a></strong> to <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_041623_base' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/avhx8g29' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/avhx8g29</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Linear           | 384   \n",
      "1 | model       | GNNModel         | 17.0 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | metricf1    | BinaryF1Score    | 0     \n",
      "5 | metricauc   | BinaryAUROC      | 0     \n",
      "6 | pool        | Attention_module | 4.2 K \n",
      "-------------------------------------------------\n",
      "23.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "23.7 K    Total params\n",
      "0.095     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42ad2cde83bc4272a87f8018353a0788",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_acc</td><td>▁</td></tr><tr><td>test_auc</td><td>▁</td></tr><tr><td>test_f1</td><td>▁</td></tr><tr><td>train_acc_epoch</td><td>▃▃▄▅▇▁▅▆▄▃▇▇▆▇▆▇▇▇▅▆▆▅▆▇▇▃█▇▅█</td></tr><tr><td>train_acc_step</td><td>▂▅▇▁▅▅▅▁▅▇▁█▇▁▅▅▇█▄▅▄▇▅▅▅▇▁▅▇▇▅▂▅▁▇▅▅▇▇▁</td></tr><tr><td>train_loss_epoch</td><td>█▇▅▅▄▇▃▄▄▆▅▃▅▄▃▂▁▂▆▄▁▃▄▃▃▄▂▂▄▃</td></tr><tr><td>train_loss_step</td><td>▃▁▂▄▃▂▃▄▃▂▅▂▂▃▁▂▁▁▃▂▃▂█▅▃▁▃▂▂▁▃▃▁▅▁▅▄▂▁▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val_acc</td><td>▂▁▄▆▂▄▃▆█▆▄▆▇██▆▆▇▇▆▅▇▆▅▆█▇▇▇▆</td></tr><tr><td>val_auc</td><td>▂▁▄▆▂▄▃▆▇▆▄▆▇▇▇▆▆▆▇▆▅▇▆▅▆█▇▆▆▆</td></tr><tr><td>val_f1</td><td>▂▁▄▇▂▅▃▇█▆▄▇▇██▇▆▇█▇▅██▆▇██▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>test_acc</td><td>0.75832</td></tr><tr><td>test_auc</td><td>0.75171</td></tr><tr><td>test_f1</td><td>0.69246</td></tr><tr><td>train_acc_epoch</td><td>0.74214</td></tr><tr><td>train_acc_step</td><td>0.4</td></tr><tr><td>train_loss_epoch</td><td>0.55311</td></tr><tr><td>train_loss_step</td><td>0.55359</td></tr><tr><td>trainer/global_step</td><td>3720</td></tr><tr><td>val_acc</td><td>0.6924</td></tr><tr><td>val_auc</td><td>0.67001</td></tr><tr><td>val_f1</td><td>0.7334</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GCN_4_64_emb</strong> at: <a href='https://wandb.ai/thoomas/PLA_041623_base/runs/avhx8g29' target=\"_blank\">https://wandb.ai/thoomas/PLA_041623_base/runs/avhx8g29</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230422_155216-avhx8g29\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for NUM_LAYERS, HIDDEN_CHANNELS, pool in list(itertools.product(*[num_layers, hiddens, pools])):\n",
    "    \n",
    "    # Path to the folder where the pretrained models are saved\n",
    "    CHECKPOINT_PATH = checkpoint_folder / f'{NUM_LAYERS}_{HIDDEN_CHANNELS}_emb' / pool\n",
    "    CHECKPOINT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Run training\n",
    "    models = ['GCN']\n",
    "    for model_name in models:\n",
    "        run = wandb.init(project=project_name, name=model_name+f'_{NUM_LAYERS}_{HIDDEN_CHANNELS}_emb')\n",
    "        model, result, trainer = PPIGraph.train_graph_classifier(model_name, \n",
    "                                                                 train_set, \n",
    "                                                                 val_set, \n",
    "                                                                 test_set, \n",
    "                                                                 dataset, \n",
    "                                                                 CHECKPOINT_PATH, \n",
    "                                                                 AVAIL_GPUS, \n",
    "                                                                 in_channels=HIDDEN_CHANNELS,\n",
    "                                                                 hidden_channels=HIDDEN_CHANNELS, \n",
    "                                                                 out_channels = HIDDEN_CHANNELS,\n",
    "                                                                 num_layers=NUM_LAYERS, epochs=epochs,\n",
    "                                                                 embedding=True,\n",
    "                                                                 graph_pooling=pool)\n",
    "        run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06556c6e-af60-4b45-9467-f01dc2f7896b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86dd364-b7cb-4910-9961-b288741c5cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:snowflake]",
   "language": "python",
   "name": "conda-env-snowflake-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
