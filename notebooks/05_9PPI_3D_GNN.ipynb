{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bb1094b-3ac6-49ae-9c51-9952c8987127",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.io\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import re\n",
    "import h5py\n",
    "import napari\n",
    "import tifffile as tiff\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c2dc746-ef6a-4289-b0ea-38adf6a33bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.utils\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94f7e35b-e960-4fab-84fa-bced8761b99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1549ea57-9b54-4965-8735-107d08afff41",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_dir = (Path().cwd().parents[0]).absolute()\n",
    "\n",
    "module_path = str(p_dir / \"src\")\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c9bcfbd-bd6d-448b-abc7-e49f91ca3b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = (Path().cwd().parents[0] / 'data').absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce8d51c1-7532-430e-969e-43a7318225e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning.pytorch as pl\n",
    "import PPIGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e1ef59-fba4-424d-801f-4ca6bcafc417",
   "metadata": {},
   "source": [
    "# Test custom torch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a303e43-e680-42e3-9827-c610578ed813",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62377297-c838-46d3-af70-729f049e1c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_mapping = {'HCC827Ctrl': 0, 'HCC827Osim': 1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be1bfa6f-ca26-43dc-aaea-e90f4931bea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_path = data_dir / '9PPI Cell Culture' / '3D_Whole' / 'graphs' \n",
    "\n",
    "dataset = PPIGraph.GraphDataset(graph_path, 'raw', 'pt', condition_mapping=condition_mapping, n_c=2)\n",
    "train_set, val_set, test_set = PPIGraph.train_test_val_split(dataset)\n",
    "\n",
    "# Create Dataloader\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64f3773a-dd67-40ea-8f43-217aa19c21b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: GraphDataset(1451):\n",
      "======================\n",
      "Number of graphs: 1451\n",
      "Number of features: 9\n",
      "Number of classes: 2\n"
     ]
    }
   ],
   "source": [
    "print(f'Dataset: {dataset}:')\n",
    "print('======================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c7beaf5-75c9-4d49-abc6-153fce500148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 697, test set: 580, val set: 174\n"
     ]
    }
   ],
   "source": [
    "print(f'Train set: {len(train_set)}, test set: {len(test_set)}, val set: {len(val_set)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cac6d207-a878-4acb-b6a9-3caf98cb5577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1:\n",
      "=======\n",
      "Number of graphs in the current batch: 32\n",
      "DataBatch(edge_index=[2, 91576], pos=[6862, 3], labels=[6862, 9], nuclei=[6862], weight=[91576], condition=[32], fov=[32], id=[32], train_mask=[6862], test_mask=[6862], x=[6862, 9], y=[32], edge_weight=[91576], name=[32], batch=[6862], ptr=[33])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step, data in enumerate(train_loader):\n",
    "    print(f'Step {step + 1}:')\n",
    "    print('=======')\n",
    "    print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "    print(data)\n",
    "    print()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c288bf21-b281-49de-a8f0-946e9a3d8d13",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33c736d8-0f3a-4cf0-b9a3-46b3785b68dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from lightning.pytorch.accelerators import find_usable_cuda_devices\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2721e73a-6503-49b6-880b-671c722230fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AVAIL_GPUS = [1]\n",
    "# BATCH_SIZE = 64 if AVAIL_GPUS else 32\n",
    "\n",
    "# # Setting the seed\n",
    "# pl.seed_everything(42)\n",
    "\n",
    "# NUM_LAYERS = 2\n",
    "# HIDDEN_CHANNELS = 16\n",
    "# pools = ['mean', 'max', 'sum', 'attention', 'attention2']\n",
    "\n",
    "# epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d330a4f-82b0-428f-a7ae-c07dee9147c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pool in pools:\n",
    "#     # Path to the folder where the pretrained models are saved\n",
    "#     CHECKPOINT_PATH = checkpoint_folder / f'3D_{NUM_LAYERS}_{HIDDEN_CHANNELS}_onehot' / pool\n",
    "#     CHECKPOINT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#     # Run training\n",
    "#     models = ['GCN']\n",
    "#     for model_name in models:\n",
    "#         run = wandb.init(project=project_name, name=model_name+f'_{NUM_LAYERS}_{HIDDEN_CHANNELS}_onehot')\n",
    "#         model, result, trainer = PPIGraph.train_graph_classifier(model_name, \n",
    "#                                                                  train_set, \n",
    "#                                                                  val_set, \n",
    "#                                                                  test_set, \n",
    "#                                                                  dataset, \n",
    "#                                                                  CHECKPOINT_PATH, \n",
    "#                                                                  AVAIL_GPUS, \n",
    "#                                                                  in_channels=5,\n",
    "#                                                                  hidden_channels=HIDDEN_CHANNELS, \n",
    "#                                                                  out_channels = HIDDEN_CHANNELS,\n",
    "#                                                                  num_layers=NUM_LAYERS, \n",
    "#                                                                  epochs=epochs,\n",
    "#                                                                  embedding=False,\n",
    "#                                                                  graph_pooling=pool)\n",
    "#         run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac541be-7224-48e5-9b48-8b1ecb31f1ef",
   "metadata": {},
   "source": [
    "# K Fold filter datasaet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4438738f-5b7a-4a18-b43a-52be8a9cb070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from lightning.pytorch.accelerators import find_usable_cuda_devices\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a332036c-f465-4414-9bf2-87fb676ee181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "895cb707-2209-46b1-80cd-1bd1799f43d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out by maximum number of counts per cell\n",
    "min_count = 100\n",
    "max_count = 400\n",
    "\n",
    "graph_path = data_dir / '9PPI Cell Culture' / '3D_Whole' / 'graphs' \n",
    "\n",
    "dataset = PPIGraph.GraphDataset(graph_path, 'raw', 'pt', condition_mapping=condition_mapping, n_c=2)\n",
    "\n",
    "# Create Dataloader\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Get Indices\n",
    "indices = []\n",
    "for step, data in enumerate(loader):\n",
    "    if len(data.x) <= min_count:\n",
    "        continue \n",
    "    \n",
    "    if (data.x.sum(axis=0) >= max_count).any():\n",
    "        continue\n",
    "    indices.append(step)\n",
    "    \n",
    "# Get subset dataset\n",
    "dataset_filtered = dataset.index_select(indices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5940dd43-9fd1-4a1a-8284-4b7348d46872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1298"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "246afbfb-031f-4731-a594-cbf0372c27de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = '9PPI_v2'\n",
    "condition = 'Kfold'\n",
    "checkpoint_folder = (Path().cwd().parents[0]).absolute() / 'data' / \"saved_models\" / dataset_name / f\"Graph_GNNs_{condition}\" \n",
    "\n",
    "project_name = f'PLA_070323_{dataset_name}_{condition}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de172714-fbb1-4ecd-aacf-a3b72761833d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "AVAIL_GPUS = [0]\n",
    "\n",
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "NUM_LAYERS = 2\n",
    "HIDDEN_CHANNELS = 32\n",
    "pools = ['mean', 'max', 'sum', 'attention', 'attention2']\n",
    "\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de9c6338-3ea7-4d18-8a33-0cc660701c79",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mthoomas\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "599a8e3c5a594e14aef4e70e77ed3f9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230704_123805-1equuymu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/1equuymu' target=\"_blank\">3D_GCN_2_32_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/1equuymu' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/1equuymu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "C:\\Users\\thu71\\Anaconda3\\envs\\snowflake\\lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 1.4 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n",
      "C:\\Users\\thu71\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:478: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\thu71\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\thu71\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightning\\pytorch\\utilities\\data.py:77: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "C:\\Users\\thu71\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\thu71\\Anaconda3\\envs\\snowflake\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\thu71\\Anaconda3\\envs\\snowflake\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▆▆▇▇▇▇█▆▆▆▇▇▇▆█▇██▇▇▇▇█▇▇▇▇██▇▇▇▇▇▇█▇</td></tr><tr><td>train_auc</td><td>▁▆▇▆▆▇▇▇▆▇▆▆▆▇▇▇▆▇▇██▆▆▆▇▇▆▇▇▆█▇▇▇▇▇▆▇█▇</td></tr><tr><td>train_f1</td><td>▁▆▇▆▆▇▇▆▆▇▆▅▆▇▇▇▆▇▇██▆▆▆▇▇▆▇▇▆█▇▇▇▇▇▆▇█▆</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▄▂▂▂▂▁▃▄▃▂▁▂▂▂▃▂▂▃▃▂▂▂▃▂▁▂▂▂▃▂▄▂▂▁▃▂</td></tr><tr><td>train_loss_step</td><td>▇█▅▆▄▂▄▃▆▃▃▄▆▄▄▃▅▆▆▇▄▅▆▄▃▅▄▄▄▃▄▃▆▆▆▆▅▃▅▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▁▂▁▃▁▃▂▃▂▂▄▂▄▂▅▂▅▂▆▂▆▆▃▇▃▇▃▇▃█▃█▃▃</td></tr><tr><td>val_acc</td><td>▁▆▆▆▇▇▇▇▇▆▆▆▇██▆██▇▇▅█▆▇▇█▇▆█▇▅▅██▂▇▆▇▇▆</td></tr><tr><td>val_auc</td><td>▁▆▆▅█▇▇▇▇▆▆▇▇██▆███▇▇█▆▇▆█▇▆▇█▇▅██▆█▇█▇▆</td></tr><tr><td>val_f1</td><td>▁▇▇▆██▇▇▇▇▇█▇██▇███▇██▆█▇█▇▇███▆██▇███▇▇</td></tr><tr><td>val_loss_epoch</td><td>▆▃▂▄▃▃▅▆▂▃▁▆▂▂▃▂▂▄▃▄▄▁▄▂▆▃▂▃▂▃▆▃▃▇█▄▃▃▂▃</td></tr><tr><td>val_loss_step</td><td>▃▂▃▄▂▂▅▃▃▃▃▅▃▂▃▃▃▄▃▂▃▂▄▂▂▂▂▃▁▃▄▃▃█▃▂▁▃▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.79191</td></tr><tr><td>train_auc</td><td>0.77035</td></tr><tr><td>train_f1</td><td>0.71948</td></tr><tr><td>train_loss_epoch</td><td>0.45214</td></tr><tr><td>train_loss_step</td><td>0.27504</td></tr><tr><td>trainer/global_step</td><td>1699</td></tr><tr><td>val_acc</td><td>0.76923</td></tr><tr><td>val_auc</td><td>0.73419</td></tr><tr><td>val_f1</td><td>0.65909</td></tr><tr><td>val_loss_epoch</td><td>0.52112</td></tr><tr><td>val_loss_step</td><td>0.6445</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_GCN_2_32_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/1equuymu' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/1equuymu</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230704_123805-1equuymu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f62215069fc04960920cc125f9e9bfff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230704_130420-syd1wjrs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/syd1wjrs' target=\"_blank\">3D_GCN_2_32_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/syd1wjrs' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/syd1wjrs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 1.4 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▄▅▅▅▆▅▇▆▅▇▇█▇▆▇▇▇█▇▇▇▇▇█▇▇▇███▇██▇▇██</td></tr><tr><td>train_auc</td><td>▁▃▃▃▄▄▄▅▄▆▅▄▆▆█▆▆▇▇▇█▆▇█▆▇█▆▇▆██▇▇██▇▇█▇</td></tr><tr><td>train_f1</td><td>▃▃▂▁▂▂▃▄▃▅▄▂▆▅█▆▅▇▆▇█▅▆█▆▇▇▆▇▆██▇▇▇█▆▇█▇</td></tr><tr><td>train_loss_epoch</td><td>█▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▂▁▁▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▄▅▆▃▆▄▃▃▃▄▄▃▃▄▄▁▃▅▃▂▄▄▃▆▃▄▄▃▄▃▃▄▄▃▃▄▄▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▁▂▁▃▁▃▂▃▂▂▄▂▄▂▅▂▅▂▆▂▆▆▃▇▃▇▃▇▃█▃█▃▃</td></tr><tr><td>val_acc</td><td>▁▁▂▂▄▄▄▅▃▅▅▆▄▂▃▄▄▂▆▄▂▂▂▂▄▂▄▂▇▄▃▄▆▃▃▂█▂▂▅</td></tr><tr><td>val_auc</td><td>▁▁▃▃▄▅▅▆▄█▅█▄▃▃▃▄▂▆▄▂▂▂▂▄▂▄▁▇▄▂▄▆▃▃▂█▂▂▅</td></tr><tr><td>val_f1</td><td>▁▁▅▄▅▆▆▇▅█▆█▅▄▃▄▄▂▆▄▂▂▂▂▄▂▅▂▆▄▃▄▆▃▄▂█▃▂▅</td></tr><tr><td>val_loss_epoch</td><td>▆▆▅▆▅▅▅▄▄▄▃▃▃▇▅▃▄█▃▇▆▄▄▄▆▇▂▆▁▄▆▂▄▃▄▂▂▃▃▃</td></tr><tr><td>val_loss_step</td><td>▄▄▄▅▄▃▄▄▄▃▃▃▄▄▄▄▃█▄▃▃▄▃▄▄▆▃▄▁▄▃▄▃▂▃▃▂▃▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.71098</td></tr><tr><td>train_auc</td><td>0.67833</td></tr><tr><td>train_f1</td><td>0.58449</td></tr><tr><td>train_loss_epoch</td><td>0.5547</td></tr><tr><td>train_loss_step</td><td>0.44695</td></tr><tr><td>trainer/global_step</td><td>1699</td></tr><tr><td>val_acc</td><td>0.67692</td></tr><tr><td>val_auc</td><td>0.58352</td></tr><tr><td>val_f1</td><td>0.32258</td></tr><tr><td>val_loss_epoch</td><td>0.58077</td></tr><tr><td>val_loss_step</td><td>0.5885</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_GCN_2_32_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/syd1wjrs' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/syd1wjrs</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230704_130420-syd1wjrs\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "197ba40d6a1a484895ad1c1623c6b28f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230704_133430-0bsvmesj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/0bsvmesj' target=\"_blank\">3D_GCN_2_32_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/0bsvmesj' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/0bsvmesj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 1.4 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f85d1fdac64c4e9683b9494c05443df0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▄▅▆▆▆▆▆▆▆▆▇▆▆▆▇▆▇▇▆▇▇▇▇▇▇▇▇██▇▇▇▇▇█▇▇</td></tr><tr><td>train_auc</td><td>▁▃▃▃▅▅▆▆▅▅▆▅▆▇▆▆▆▇▆▇▇▆▇▆▆▇▆▆▇▇█▇▆▆▆▇▆█▇▇</td></tr><tr><td>train_f1</td><td>▁▃▃▂▄▅▆▆▅▄▆▅▅▆▅▆▅▇▆▇▇▆▇▆▅▇▅▆▇▆█▇▅▆▆▆▅▇▇▆</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▁▂▁▃▁▃▂▃▂▂▄▂▄▂▅▂▅▂▆▂▆▆▃▇▃▇▃▇▃█▃█▃▃</td></tr><tr><td>val_acc</td><td>▁▇▇▇██████████▇██▇█████████▇██▇█████████</td></tr><tr><td>val_auc</td><td>▁▇▆▆▇▇▇▇███▇▆▇▆▇▇▆▇▇█▇▇▇█▇▇▇▇▇▆█▇▇▇▇▇█▇█</td></tr><tr><td>val_f1</td><td>▁▆▅▄▇▇▆▆▇▇▇▇▅▆▅▇▆▄▆▇█▆▇▇▇▇▆▅▇▇▅▇▆▇▆▆▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▁▂▃▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▂▂▂▂▃▂▂▁▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.78324</td></tr><tr><td>train_auc</td><td>0.76051</td></tr><tr><td>train_f1</td><td>0.70588</td></tr><tr><td>train_loss_epoch</td><td>0.47775</td></tr><tr><td>train_loss_step</td><td>0.31564</td></tr><tr><td>trainer/global_step</td><td>1699</td></tr><tr><td>val_acc</td><td>0.80385</td></tr><tr><td>val_auc</td><td>0.7922</td></tr><tr><td>val_f1</td><td>0.74112</td></tr><tr><td>val_loss_epoch</td><td>0.50453</td></tr><tr><td>val_loss_step</td><td>0.61465</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_GCN_2_32_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/0bsvmesj' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/0bsvmesj</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230704_133430-0bsvmesj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f657d971a1b7439aae005df1bd292f21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230704_140030-xnegxovl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/xnegxovl' target=\"_blank\">3D_GCN_2_32_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/xnegxovl' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/xnegxovl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "C:\\Users\\thu71\\Anaconda3\\envs\\snowflake\\lib\\site-packages\\torch_geometric\\deprecation.py:12: UserWarning: 'nn.glob.GlobalAttention' is deprecated, use 'nn.aggr.AttentionalAggregation' instead\n",
      "  warnings.warn(out)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 1.4 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2fc0da4d6814ed0bb672fb1e2902bf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▇▆▆▇▆▆▆▇▇▆▇█▆▇▆▇▇▇▇▆▇▇▆▇▇▇▇█▇██▇▇▇▆▇</td></tr><tr><td>train_auc</td><td>▁▅▅▆▇▆▅▇▆▅▅▇▇▆▇█▆▇▆▇▆▇▆▆▇▇▆▇▇▇▇█▇▇█▇▇▇▆▇</td></tr><tr><td>train_f1</td><td>▁▅▅▆▇▆▅▇▆▅▅▇▇▆▇█▆▇▆▇▆▇▆▆▇▇▆▇▇▇▇█▇▇█▇▇▇▆▇</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▃▃▃▄▂▃▃▄▃▃▂▂▂▃▂▂▃▂▁▂▃▂▂▂▂▁▁▂▂▂▁▁▂▂▂▃▂</td></tr><tr><td>train_loss_step</td><td>▄▅▄▄▃▆▇▁▃▅▅▁█▃▆▁▄▃▃▃▄▃▁▂▃▅▅▅▅▆▂▅▂▃▆▁▁▂▂▆</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▁▂▁▃▁▃▂▃▂▂▄▂▄▂▅▂▅▂▆▂▆▆▃▇▃▇▃▇▃█▃█▃▃</td></tr><tr><td>val_acc</td><td>▁▃▇▆▇▇▇▇▆▆▇▄▅██▄▇▇▆█▇▇▇▇▅▇▇▇▆▇▇▇▆▇▇▇▇▇▇▆</td></tr><tr><td>val_auc</td><td>▁▃▇▆▇▇▇▇▆▆▇▇▅██▄█▇▇█▇██▇▅▇█▇▇▇▆▆▇██▇▇▇▇▆</td></tr><tr><td>val_f1</td><td>▁▄▇▇████▇▇█▇▆██▅████████▆████▇▇▇███▇███▇</td></tr><tr><td>val_loss_epoch</td><td>▅▃▄▂▂▄▂▂▂▃▃▆▂▁▂█▃▄▂▂▅▃▄▂▂▃▂▁▃▁▁▂▃▂▄▂▁▁▂▁</td></tr><tr><td>val_loss_step</td><td>▅▄▃▃▃▃▁▄▄▃▃▇▃▃▁▄▃█▂▂▅▃▇▃▃▆▂▃▂▃▄▂▃▂▃▃▁▂▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.79383</td></tr><tr><td>train_auc</td><td>0.77304</td></tr><tr><td>train_f1</td><td>0.72351</td></tr><tr><td>train_loss_epoch</td><td>0.46566</td></tr><tr><td>train_loss_step</td><td>0.57391</td></tr><tr><td>trainer/global_step</td><td>1699</td></tr><tr><td>val_acc</td><td>0.77308</td></tr><tr><td>val_auc</td><td>0.73325</td></tr><tr><td>val_f1</td><td>0.65497</td></tr><tr><td>val_loss_epoch</td><td>0.41521</td></tr><tr><td>val_loss_step</td><td>0.14275</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_GCN_2_32_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/xnegxovl' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/xnegxovl</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230704_140030-xnegxovl\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbf349a14bc04ac993d74da7839c9d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230704_142500-37o3gtbq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/37o3gtbq' target=\"_blank\">3D_GCN_2_32_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/37o3gtbq' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/37o3gtbq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 1.4 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "3.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 K     Total params\n",
      "0.012     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c01bd8bddf6f4cc0b9238087649ec93a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇█▇▇▇▇▇███▇███▇▇▇▇██▇▇█▇▇▇▇▇▇▇▇█▇█▇</td></tr><tr><td>train_auc</td><td>▁▆▆▇▇▇▇▇▇▆▇▆███▇██▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇█▇</td></tr><tr><td>train_f1</td><td>▁▆▆▇▇▇▇▇▇▆▇▆███▇██▇▇▇▇▇▇▇▆▇█▇▇▇▇▇▇▇▇▇▇█▇</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▄▂▂▂▄▂▂▂▂▂▂▂▃▁▂▂▃▂▂▃▂▂▁▂▂▂▂▂▁▂▂▂▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>▇▄▄▂▇▅█▄▄▅▄▄▆▄▅▆▅▄▄▄▆▅▃▂█▅▄▆▅▄▅▂▇▄▃▃▄▁▄▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▁▂▁▃▁▃▂▃▂▂▄▂▄▂▅▂▅▂▆▂▆▆▃▇▃▇▃▇▃█▃█▃▃</td></tr><tr><td>val_acc</td><td>▄▅█▇████▅███▇▇▇█▇█▇███▇█▁██▇█▇█▇█▇███▇██</td></tr><tr><td>val_auc</td><td>▁▂▇▅██▇▇▆███▆▆▆█▅█████▆█▃██▆███▅█▇███▆█▇</td></tr><tr><td>val_f1</td><td>▁▃█▆████▇███▇▇▇█▆█████▇█▆██▇███▆█████▇██</td></tr><tr><td>val_loss_epoch</td><td>▆▄▄▄▄▂▂▂▅▂▃▅▄▅▂▂▄▁█▂▃▂▂▂█▃▄▂▂▄▂▅▃▄▃▂▁▃▃▁</td></tr><tr><td>val_loss_step</td><td>▄▃▃▆▂▄▂▄▄▃▃█▃▃▂▄▄▁▃▃▄▄▂▃▄▄▃▃▂▃▄▅▃▅▂▄▁▃▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.79094</td></tr><tr><td>train_auc</td><td>0.77023</td></tr><tr><td>train_f1</td><td>0.72</td></tr><tr><td>train_loss_epoch</td><td>0.45553</td></tr><tr><td>train_loss_step</td><td>0.37635</td></tr><tr><td>trainer/global_step</td><td>1699</td></tr><tr><td>val_acc</td><td>0.79615</td></tr><tr><td>val_auc</td><td>0.7699</td></tr><tr><td>val_f1</td><td>0.71038</td></tr><tr><td>val_loss_epoch</td><td>0.41605</td></tr><tr><td>val_loss_step</td><td>0.08421</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_GCN_2_32_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/37o3gtbq' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/37o3gtbq</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230704_142500-37o3gtbq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa1be25bc4574ba480ad9c4773923e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230704_144920-e1nh2e6c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/e1nh2e6c' target=\"_blank\">3D_GCN_2_32_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/e1nh2e6c' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/e1nh2e6c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 1.4 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6022c8c15d7430988ad8c1231cd9121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇▇▇█▇▇██▇█▇█▇▇█▇█▇███▇█▇▇██▇█▇██▆█▇</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇▇▇▇▇▇█▇█▇▇█▇█▇█▇█▇█▇█▇▇██▇█▇█▇▆█▇</td></tr><tr><td>train_f1</td><td>▁▆▇▆▇▆▆▇▇▇▇▇▇▆▇▇▇█▇█▇█▇█▇█▇█▇▆██▇█▆█▇▆█▆</td></tr><tr><td>train_loss_epoch</td><td>█▃▄▄▃▂▂▂▂▃▂▂▂▂▁▂▂▂▃▁▃▂▂▂▂▁▂▁▂▃▁▁▂▂▂▁▁▂▂▁</td></tr><tr><td>train_loss_step</td><td>▅▅█▅▃▃▅▄▅▄▅▄▅▄▄▃▃▃▆▅▂▅▆▇▃▅▆▆▆▄▅▃▆▄▆▃▄▃▅▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▁▂▁▃▁▃▂▃▂▂▄▂▄▂▅▂▅▂▆▂▆▆▃▇▃▇▃▇▃█▃█▃▃</td></tr><tr><td>val_acc</td><td>▁▆▇▆▇▆██▆▆▇▅▆▅▆█▇▇▆▇▆▇▇▇▇▆▇███▇▆▇▇▇▇▇▇▆▇</td></tr><tr><td>val_auc</td><td>▁▆▇▆▆▆█▇▇▆▇▆▆▆▅█▇█▅▇▆▇▆▇▇▆▇████▆█▇▆▇▇▇▆▇</td></tr><tr><td>val_f1</td><td>▁▆▇▇▇▇███▆▇▇▇▇▆█▇█▆▇▇█▇██▆▇████▆█▇▇█▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▅▂▃▃▂▃▁▆▆▁▄▅▇▄▃▂▄▃▃▃▃▃▃▃▆▇▂▁▁▂▄▂▁▁▄▁▂▄▂</td></tr><tr><td>val_loss_step</td><td>▆▄▅▃▄▅▅▅▅▅▄▃▅▆▆▄▅▇▄▅▃▆▅▅▅█▃▄▁▅▆▅▄▁▅▅▁▄▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.79094</td></tr><tr><td>train_auc</td><td>0.76108</td></tr><tr><td>train_f1</td><td>0.70069</td></tr><tr><td>train_loss_epoch</td><td>0.45482</td></tr><tr><td>train_loss_step</td><td>0.27464</td></tr><tr><td>trainer/global_step</td><td>1699</td></tr><tr><td>val_acc</td><td>0.76154</td></tr><tr><td>val_auc</td><td>0.73441</td></tr><tr><td>val_f1</td><td>0.66667</td></tr><tr><td>val_loss_epoch</td><td>0.45997</td></tr><tr><td>val_loss_step</td><td>0.36086</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_GCN_2_32_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/e1nh2e6c' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/e1nh2e6c</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230704_144920-e1nh2e6c\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3e510ce3a944f1e89e84aa2b622d1ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230704_151533-gilxil2j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/gilxil2j' target=\"_blank\">3D_GCN_2_32_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/gilxil2j' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/gilxil2j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 1.4 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b21c9dbe9569411487360370cf2b4ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▅▆▅▅▅▆▆▇▆▆▆▅█▇▇█▇▇▇▇▇▇▇▇▇█▇██▇▇▇█▇▇▇▆</td></tr><tr><td>train_auc</td><td>▁▃▃▄▅▄▃▄▅▅▆▅▅▅▄█▆▆▇▇▇▇▇▇▆▇▇▇█▇██▇▇▆█▇▆▇▅</td></tr><tr><td>train_f1</td><td>▄▄▃▃▄▃▁▃▅▅▆▄▅▆▂█▆▆▇▇▇▇▇▇▆▇▇▇█▇██▇▇▅█▇▆▇▅</td></tr><tr><td>train_loss_epoch</td><td>█▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▆▅▆▄▆▅▄▄▄▆▃▃▄▃▃▃▄▆▃▅▄▆▅▆▅▄▄▄▄▄▅▁▂▂▃▂▆▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▁▂▁▃▁▃▂▃▂▂▄▂▄▂▅▂▅▂▆▂▆▆▃▇▃▇▃▇▃█▃█▃▃</td></tr><tr><td>val_acc</td><td>▁▁▂▂▄▄▃▄▄▅▄▆▄▄▁▂▄▃▅▄▁▂▁▂▂▁▁▁▂▁▂▁▁▁▂▄█▄▁▃</td></tr><tr><td>val_auc</td><td>▁▁▂▂▄▄▃▅▄▅▄▆▄▄▁▂▅▃▅▄▁▂▁▂▂▁▁▁▂▁▂▁▁▁▂▄█▄▁▃</td></tr><tr><td>val_f1</td><td>▁▁▂▂▅▅▄▆▅▆▅▇▅▄▁▂▅▃▆▄▁▃▁▂▂▁▁▁▂▁▂▁▁▁▂▅█▅▁▄</td></tr><tr><td>val_loss_epoch</td><td>▅▅▄▅▄▄▄▃▄▄▂▃▃▅▅▇▄▆▃█▆▆▅▅▅▇▃▅▂▅▆▅▇▂▄▃▁▃▄▃</td></tr><tr><td>val_loss_step</td><td>▅▅▅▅▄▅▅▅▅▄▅▄▅▄▅▄▅█▅▅▄▅▆▅▅█▅▅▁▅▄▆▄▂▅▄▂▅▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.67534</td></tr><tr><td>train_auc</td><td>0.61719</td></tr><tr><td>train_f1</td><td>0.44298</td></tr><tr><td>train_loss_epoch</td><td>0.58724</td></tr><tr><td>train_loss_step</td><td>0.46177</td></tr><tr><td>trainer/global_step</td><td>1699</td></tr><tr><td>val_acc</td><td>0.63077</td></tr><tr><td>val_auc</td><td>0.55556</td></tr><tr><td>val_f1</td><td>0.2</td></tr><tr><td>val_loss_epoch</td><td>0.60105</td></tr><tr><td>val_loss_step</td><td>0.49574</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_GCN_2_32_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/gilxil2j' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/gilxil2j</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230704_151533-gilxil2j\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "890bcd9b751a42698c378d4f5f03e4ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230704_154012-kf5vm9r9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/kf5vm9r9' target=\"_blank\">3D_GCN_2_32_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/kf5vm9r9' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/kf5vm9r9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 1.4 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23c83d066f5f4aa2bbb1e05d6ed68d8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▅▆▆▆▇█▆▇█▇▆█▇▇▇▇▇▇▇▇▆▇█▇██▇████▇██▇█▇</td></tr><tr><td>train_auc</td><td>▁▃▄▅▅▅▆▇█▆▇█▆▆█▇▇▇▇▇▇▇▇▅▆█▇▇▇▇████▇▇▇▆█▇</td></tr><tr><td>train_f1</td><td>▁▃▃▄▄▅▅▆█▆▆█▆▆█▇▆▇▇▇▇▇▆▅▆█▇▇▇▆████▆▇▇▆▇▆</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▂▂▂▂▂▂▂▂▁▂▁▂▂▂▁▂▁▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▁▂▁▃▁▃▂▃▂▂▄▂▄▂▅▂▅▂▆▂▆▆▃▇▃▇▃▇▃█▃█▃▃</td></tr><tr><td>val_acc</td><td>▁▇▇▇▇█▇▇▇▇▇▇▇▇▇██▇██▇▇▇▇▇████▃▇███▇█████</td></tr><tr><td>val_auc</td><td>▁▇▆▆▆▇▇▆▇▇▇▆▇▇▆█▇▇▇▇▆▆▆▇▇▇▇▇█▃▇▇▇█▆▇█▇▇█</td></tr><tr><td>val_f1</td><td>▁▆▃▃▄▅▅▄▅▅▅▄▅▅▄█▅▅▅▅▄▃▂▄▅▆▆▆▇▃▄▅▆█▄▅█▅▆▇</td></tr><tr><td>val_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▃▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▁▂▂▂▂▁▂▁▂▂▁▂▂▂▂▂▃▂▂▁▂▂▂▂▂▁▂▁▂▂▂▂▁▂▁▁▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77746</td></tr><tr><td>train_auc</td><td>0.74469</td></tr><tr><td>train_f1</td><td>0.67602</td></tr><tr><td>train_loss_epoch</td><td>0.47473</td></tr><tr><td>train_loss_step</td><td>0.19399</td></tr><tr><td>trainer/global_step</td><td>1699</td></tr><tr><td>val_acc</td><td>0.78462</td></tr><tr><td>val_auc</td><td>0.76888</td></tr><tr><td>val_f1</td><td>0.72277</td></tr><tr><td>val_loss_epoch</td><td>0.4393</td></tr><tr><td>val_loss_step</td><td>0.2715</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_GCN_2_32_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/kf5vm9r9' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/kf5vm9r9</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230704_154012-kf5vm9r9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee487d5ff2e145a1a7c76a0f119f8966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230704_160454-ds2qeapg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/ds2qeapg' target=\"_blank\">3D_GCN_2_32_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/ds2qeapg' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/ds2qeapg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 1.4 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f138cd83eaae4a97b6e70e65854de0cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇█▇█▇█▇███▇▇███▇█</td></tr><tr><td>train_auc</td><td>▁▆▆▆▆▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇▇█▇▇▇▇▇▇▇▇</td></tr><tr><td>train_f1</td><td>▁▇▆▇▆▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇▇█▇▇▇██▇▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▂▃▃▃▃▂▃▂▃▃▂▂▂▃▂▂▂▁▁▂▂▂▂▁▂▁▂▂▂▂▁▂▂▂▂▂▂</td></tr><tr><td>train_loss_step</td><td>▇▅▂▆▇▃▅▅▃▄▇▅▅▃▅▄▄▆▃▃▃▅▃▂▃▃▆▆▇▇▅▄▃▄▂▂▁▅▃█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▁▂▁▃▁▃▂▃▂▂▄▂▄▂▅▂▅▂▆▂▆▆▃▇▃▇▃▇▃█▃█▃▃</td></tr><tr><td>val_acc</td><td>▁▆▆▇▆▆▆▇▇██▆▇▇▇▅▇▇█▇█▇▇▆▆▅▇▇▇▇▇▇▇▇▇▇█▇▇▇</td></tr><tr><td>val_auc</td><td>▁▅▆▇▅▆▆▇▇██▇█▆▇▅▇▇█▇█▇▇▅▆▅▇▇█▇▇▇▇▇▇▇▇▇█▇</td></tr><tr><td>val_f1</td><td>▁▆▇█▆▆▇▇█████▇▇▆▇▇███▇█▆▆▆█▇█▇█████▇▇██▇</td></tr><tr><td>val_loss_epoch</td><td>▆▄▆▂▄▄▄▂▂▅▂█▆▆▁▆▂▂▂▂▄▁▂▄▂▃▁▂▆▃▁▃▁▃▃▂▄▂▁▁</td></tr><tr><td>val_loss_step</td><td>▄▃▃▂▃▃▃▄▃▃▃█▃▃▁▃▃▃▃▄▃▃▃▃▃▂▃▃▆▃▃▃▃▂▃▃▅▃▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.79865</td></tr><tr><td>train_auc</td><td>0.77618</td></tr><tr><td>train_f1</td><td>0.72536</td></tr><tr><td>train_loss_epoch</td><td>0.47465</td></tr><tr><td>train_loss_step</td><td>0.65534</td></tr><tr><td>trainer/global_step</td><td>1699</td></tr><tr><td>val_acc</td><td>0.76538</td></tr><tr><td>val_auc</td><td>0.74038</td></tr><tr><td>val_f1</td><td>0.67725</td></tr><tr><td>val_loss_epoch</td><td>0.40503</td></tr><tr><td>val_loss_step</td><td>0.082</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_GCN_2_32_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/ds2qeapg' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/ds2qeapg</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230704_160454-ds2qeapg\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d202da8cd774bb39a720893ee48195e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230704_163038-26rn4unk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/26rn4unk' target=\"_blank\">3D_GCN_2_32_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/26rn4unk' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/26rn4unk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 1.4 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "3.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 K     Total params\n",
      "0.012     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "315f3d9220ed4886a0c77c3fa5a2762d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▇▆▆▆▇▆▆▇▆▇▇▇▆▇▇▇▇▇▇▇▆▇▇█▇▇▆▇▆▇▆▇▇▆▇▇▇</td></tr><tr><td>train_auc</td><td>▁▆▆▇▆▆▆▇▆▆▇▆▇▇▇▆▇▇▇▇▇▇▇▆▇▇█▇▇▆▇▆▇▆▇▇▅▇▇▇</td></tr><tr><td>train_f1</td><td>▁▆▆▇▇▆▆▇▆▅▇▆▇▇▇▆▇▇▇▇▇▇▇▆▇▇█▇▇▇▇▆▇▆▇▇▅▇▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▂▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▃▃▂▂▂▁▂▂▃▂▃▂▂▃▁▃▁▁▃</td></tr><tr><td>train_loss_step</td><td>▄▁▂▄▃█▄▂▅▃▃▃▅▅▂▅▃▃▃▅▂▄▆▃▄▃▃▄▅▄▄▄▁▂▅▂▅▂▂█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▁▂▁▃▁▃▂▃▂▂▄▂▄▂▅▂▅▂▆▂▆▆▃▇▃▇▃▇▃█▃█▃▃</td></tr><tr><td>val_acc</td><td>▁▃▇▅▇▅▇▇▇█▅▇▇▇▆▇▇▇▇▆▇▆▇█▇▅█▇▇▇▇██▇▇█▆▇▇▇</td></tr><tr><td>val_auc</td><td>▁▃▇▅▇▅▇▆▇█▇▇▆▆▆▇▇▇█▅▇▆██▇▄█▆▇▇▇██▆▆█▆▇▇▇</td></tr><tr><td>val_f1</td><td>▁▄▇▆█▆█▇▇██▇▇▇▇▇▇▇█▆█▇██▇▅█▇█▇▇██▇▇█▇▇▇█</td></tr><tr><td>val_loss_epoch</td><td>█▅▂▂▅▄▄▂▁▅▅▂▂▂▂▃▂▁▂▅▂▄█▃▁▆▁▂▁▂▂▃▂▃▃▃▁▄▂▅</td></tr><tr><td>val_loss_step</td><td>▄▃▃▁▃▃▄▃▃▂▄▂▃▃▁▂▃▂▃▂▃▃█▃▃▅▂▃▁▃▂▃▃▃▃▃▁▃▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.79769</td></tr><tr><td>train_auc</td><td>0.77341</td></tr><tr><td>train_f1</td><td>0.72074</td></tr><tr><td>train_loss_epoch</td><td>0.48228</td></tr><tr><td>train_loss_step</td><td>0.70159</td></tr><tr><td>trainer/global_step</td><td>1699</td></tr><tr><td>val_acc</td><td>0.76538</td></tr><tr><td>val_auc</td><td>0.7779</td></tr><tr><td>val_f1</td><td>0.75102</td></tr><tr><td>val_loss_epoch</td><td>0.59001</td></tr><tr><td>val_loss_step</td><td>0.92725</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_GCN_2_32_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/26rn4unk' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/26rn4unk</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230704_163038-26rn4unk\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b8ffa506f748deb0653a746e5cbea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666592937, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230704_165607-ttn36wtp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/ttn36wtp' target=\"_blank\">3D_GCN_2_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/ttn36wtp' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/ttn36wtp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 1.4 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb3c284b0b014bc8a6444f162ffef803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▇▇▇▆▆█▇▇▇▇▇▇▇▇█▇█▇▇▇███▇▇▇███▇█▇███▇▇</td></tr><tr><td>train_auc</td><td>▁▆▆▆▆▇▆▆▇▇▇▆▇▇▇▇▆█▇█▇▇▇█▇█▇▇▇▇██▇█▆█▇▇▇▇</td></tr><tr><td>train_f1</td><td>▁▆▆▆▆▆▆▅▇▇▆▆▇▇▇▇▆▇▇█▇▇▇█▇█▇▇▇▇██▆█▆▇▇▇▇▆</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▃▃▃▃▃▂▃▃▂▂▃▂▂▂▂▂▁▂▃▃▃▂▂▂▂▂▂▂▂▂▃▂▂▁▂▂▂</td></tr><tr><td>train_loss_step</td><td>█▄▅▅▅▄▄▃▆▆▆▄▅▄▃▄▄▄▆▄▅▄▅▂▄▄▆█▆▇▂▇▅▂▆▁▂▅▅▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▁▂▁▃▁▃▂▃▂▂▄▂▄▂▅▂▅▂▆▂▆▆▃▇▃▇▃▇▃█▃█▃▃</td></tr><tr><td>val_acc</td><td>▁▄▆▇█▆▇▇▇▆██▇██▇█▇▇▇▇▇▇█▇▆▇▆▇▆█▆█▇█████▇</td></tr><tr><td>val_auc</td><td>▁▄▆▆▇▅▆█▇▆██▆██▆▇▇▇▇▆▆▇█▆▅▇▅█▆█▅█▆███▇█▇</td></tr><tr><td>val_f1</td><td>▁▅▇▇█▆▇█▇▇██▇██▇█▇▇▇▇▇▇█▇▆▇▆█▇█▆█▇██████</td></tr><tr><td>val_loss_epoch</td><td>▇▅▂▃▆▃▂▄▃▅▃▄▁▃▂▂▅▅▄▆▅▄▂▄▄█▁▄▃▂▄▃▃▂▃▃▂▁▆▃</td></tr><tr><td>val_loss_step</td><td>▄▃▄▃▄▃▁▅▃▃▃▄▃▄▁▄▃█▂▅▂▃▂▃▂█▃▃▁▂▄▄▂▂▄▄▂▃▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.7948</td></tr><tr><td>train_auc</td><td>0.77104</td></tr><tr><td>train_f1</td><td>0.71863</td></tr><tr><td>train_loss_epoch</td><td>0.46165</td></tr><tr><td>train_loss_step</td><td>0.3243</td></tr><tr><td>trainer/global_step</td><td>1699</td></tr><tr><td>val_acc</td><td>0.79231</td></tr><tr><td>val_auc</td><td>0.77085</td></tr><tr><td>val_f1</td><td>0.71277</td></tr><tr><td>val_loss_epoch</td><td>0.47255</td></tr><tr><td>val_loss_step</td><td>0.48552</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_GCN_2_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/ttn36wtp' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/ttn36wtp</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230704_165607-ttn36wtp\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f1ac0b45b98468f91b936ad28674813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230704_172242-gaw3teyh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/gaw3teyh' target=\"_blank\">3D_GCN_2_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/gaw3teyh' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/gaw3teyh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 1.4 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3bda6553338422a9b4c3e94342d5349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▄▄▅▅▅▆▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▆█▇▇██▇▇█▇█</td></tr><tr><td>train_auc</td><td>▁▃▃▂▃▄▄▅▅▄▅▅▆▅▅▆▆▇▆▇▇▇▆▇▆▇▇▇▇▆█▇▇█▇▇▇█▇█</td></tr><tr><td>train_f1</td><td>▄▄▂▁▃▃▃▅▅▅▅▄▅▅▅▇▆▇▇▇▇▇▆▇▆▇▇▇█▅█▇▇█▇▇▇█▇█</td></tr><tr><td>train_loss_epoch</td><td>█▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▆▅▅▄▆▅▄▄▅▅▇▃▅▃▃▃▃▂▄▃▄▄▄▄▅▆▅▅▂▃▄▂▅▁▂▂▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▁▂▁▃▁▃▂▃▂▂▄▂▄▂▅▂▅▂▆▂▆▆▃▇▃▇▃▇▃█▃█▃▃</td></tr><tr><td>val_acc</td><td>▁▁▄▄▃▃▄▅▄▆▂▅▄▅▄▂▃▄▂▂▄▄▁▃▄▂▃▃▅▄▄▅▅▆▆▆▇█▅▆</td></tr><tr><td>val_auc</td><td>▁▁▄▄▃▄▄▅▄▇▁▄▄▄▃▂▂▃▁▂▃▃▁▂▃▁▃▃▅▄▄▄▄▅▆▅▇█▄▆</td></tr><tr><td>val_f1</td><td>▁▁▅▄▄▆▆▆▅▇▁▅▄▄▄▃▃▄▁▂▃▃▁▃▃▁▃▃▆▅▄▅▄▅▇▆██▅▇</td></tr><tr><td>val_loss_epoch</td><td>▅▄▄▄▃▃▃▂▃▃▂▂▂▃▂▃▅▄▃█▄▃▃▄▃▅▁▃▁▃▃▂▃▂▂▁▂▂▃▂</td></tr><tr><td>val_loss_step</td><td>▅▅▅▅▄▄▅▅▄▃▄▁▅▄▂▅▄▇▅▅▄▄▃▅▅█▄▄▁▄▄▅▃▂▄▃▄▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.73121</td></tr><tr><td>train_auc</td><td>0.70292</td></tr><tr><td>train_f1</td><td>0.6245</td></tr><tr><td>train_loss_epoch</td><td>0.55519</td></tr><tr><td>train_loss_step</td><td>0.43949</td></tr><tr><td>trainer/global_step</td><td>1699</td></tr><tr><td>val_acc</td><td>0.69231</td></tr><tr><td>val_auc</td><td>0.62812</td></tr><tr><td>val_f1</td><td>0.47368</td></tr><tr><td>val_loss_epoch</td><td>0.57349</td></tr><tr><td>val_loss_step</td><td>0.56144</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_GCN_2_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/gaw3teyh' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/gaw3teyh</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230704_172242-gaw3teyh\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ba84f33a204122a890cb0a0caab27c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230704_175142-ptc5jis9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/ptc5jis9' target=\"_blank\">3D_GCN_2_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/ptc5jis9' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/ptc5jis9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 1.4 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98a7cbf295e54d5c812f307567da6abe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▅▅▆▆▆▆▆▇▆▆▇▆▆▇▇█▇▇▇▇█▇▇▇▇█▇█████▇██▇▇</td></tr><tr><td>train_auc</td><td>▁▄▄▅▅▆▆▅▆▆▇▅▆▇▆▆▇▇█▇▇▇▇█▇▇▇▇█▇▇███▇▇▇█▇▇</td></tr><tr><td>train_f1</td><td>▁▄▃▅▅▅▆▅▆▅▇▄▅▇▅▆▆▇██▇▇▇▇▇▇▇▇█▇▇███▇▇▇▇█▇</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▁▂▁▃▁▃▂▃▂▂▄▂▄▂▅▂▅▂▆▂▆▆▃▇▃▇▃▇▃█▃█▃▃</td></tr><tr><td>val_acc</td><td>▁▇▇███████▇███▇█▇█▇▇█▇▄▇█▇██▇▇██▇▇█▇▆▇▆▇</td></tr><tr><td>val_auc</td><td>▁█▅▆▇▇▇▇█▇▆▆▇▇▆▇▆▇▆▆▇▆▅▆█▅▆▇▇▆▇▇▆▄█▆▄▅▄▆</td></tr><tr><td>val_f1</td><td>▂█▃▆▆▇▇▇█▆▆▆▇▆▄▇▆▇▅▅▇▆▅▆▇▄▆▇▆▅▇▇▅▁█▅▂▄▁▅</td></tr><tr><td>val_loss_epoch</td><td>█▄▂▂▃▂▂▂▂▂▂▂▂▂▁▂▃▃▇▃▂▂▄▂▂▄▁▂▁▁▂▂▂▂▂▁▃▁▃▂</td></tr><tr><td>val_loss_step</td><td>▆▃▄▃▄▃▃▄▃▃▄▂▃▄▁▅▃▆▃▆▃▃▄▃▂█▄▃▁▃▃▄▂▂▄▃▂▃▅▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77746</td></tr><tr><td>train_auc</td><td>0.7549</td></tr><tr><td>train_f1</td><td>0.69883</td></tr><tr><td>train_loss_epoch</td><td>0.48999</td></tr><tr><td>train_loss_step</td><td>0.36512</td></tr><tr><td>trainer/global_step</td><td>1699</td></tr><tr><td>val_acc</td><td>0.78077</td></tr><tr><td>val_auc</td><td>0.74748</td></tr><tr><td>val_f1</td><td>0.67797</td></tr><tr><td>val_loss_epoch</td><td>0.48396</td></tr><tr><td>val_loss_step</td><td>0.54537</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_GCN_2_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/ptc5jis9' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/ptc5jis9</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230704_175142-ptc5jis9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60f9c582abb544d5b97759bba84ca995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230704_182045-jzrzkjgo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/jzrzkjgo' target=\"_blank\">3D_GCN_2_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/jzrzkjgo' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/jzrzkjgo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 1.4 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "315d2a6e6dad4d43840c18062a21fb9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▇▆▆▇▆▆▇▇▆▆▇▇▇▇█▇█▇▇▇▇█▇▇▇▇▇█▇█▇▇▇█▇██▇▇</td></tr><tr><td>train_auc</td><td>▁▇▆▆▆▆▆▇▇▆▆▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇█▇██▇▇</td></tr><tr><td>train_f1</td><td>▁▇▆▆▆▆▆▇▇▆▆▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇█▇███▇</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▄▃▄▄▂▂▃▃▂▃▃▃▂▂▂▃▃▂▂▁▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▂▂</td></tr><tr><td>train_loss_step</td><td>▆▅▃▄▃▃▅▂▂▃▄▂▄▄▄▂▂▂▃▃▃▂▂▂▃▄▃▃▃▃▄▅▂▃▅▁▂▂▁█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▁▂▁▃▁▃▂▃▂▂▄▂▄▂▅▂▅▂▆▂▆▆▃▇▃▇▃▇▃█▃█▃▃</td></tr><tr><td>val_acc</td><td>▁▄▇▇▇▇▇▆▆▇██▆▇▂▆▇▇█▆▇▅▇▅▇▇▇▆█▇▇▇▅▇▇▇▆▇▇▇</td></tr><tr><td>val_auc</td><td>▁▄▇▇▆▇▇▇▆███▆▆▅▆▆▇█▆█▇█▅▇▇▆▆▇▇▆▇▅▇▇▆▅▆▇█</td></tr><tr><td>val_f1</td><td>▁▅▇█▇█▇█▇███▇▇▇▇▇▇█▇█▇█▆▇▇▇▇██▇█▆█▇▇▆▇██</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▄▃▃▂▂▂▄▃█▁▂▇▄▁▁▃▅▅▄▃▂▁▃▁▃▁▁▂▅▂▂▂▂▄▁▄▃</td></tr><tr><td>val_loss_step</td><td>▄▄▃▄▃▃▂▃▃█▃█▂▃▂▃▃▁▂▃▃▃▁▃▄▃▃▃▁▃▃▃▃▂▄▃▃▃▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8025</td></tr><tr><td>train_auc</td><td>0.78428</td></tr><tr><td>train_f1</td><td>0.73952</td></tr><tr><td>train_loss_epoch</td><td>0.47656</td></tr><tr><td>train_loss_step</td><td>0.80373</td></tr><tr><td>trainer/global_step</td><td>1699</td></tr><tr><td>val_acc</td><td>0.80385</td></tr><tr><td>val_auc</td><td>0.79623</td></tr><tr><td>val_f1</td><td>0.74627</td></tr><tr><td>val_loss_epoch</td><td>0.50004</td></tr><tr><td>val_loss_step</td><td>0.54555</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_GCN_2_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/jzrzkjgo' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/jzrzkjgo</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230704_182045-jzrzkjgo\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71dfde8bad6d416ea75662820f83c252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230704_184951-r61w53ns</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/r61w53ns' target=\"_blank\">3D_GCN_2_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/r61w53ns' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/r61w53ns</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 1.4 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "3.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 K     Total params\n",
      "0.012     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52d67dc810294c0ab3419cce078afabf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▇▇▇█▇▇▆▇██▇█▇▇█████▇█▇▇▇▇▇██▇▇▇▇▇███</td></tr><tr><td>train_auc</td><td>▁▆▆▆▇▇▇█▇▆▆▇██▇█▇▇████▇▇█▇▇▇▇▇██▇▇▇▇▆██▇</td></tr><tr><td>train_f1</td><td>▁▆▅▆▇▇▇█▇▆▆▇███▇▇▇▇███▇▇█▇▇▇▇▇██▇▇▇▇▆██▇</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▄▂▂▂▃▂▃▂▃▂▂▁▂▂▁▂▂▂▂▃▁▂▂▃▂▂▂▁▃▂▂▂▂▂▁▂</td></tr><tr><td>train_loss_step</td><td>▆▅▄▄▅█▅▂▄▂▆▅▃▅▃▅█▄▂▆▄▃▃▆▃▇▅▁▅▄▆▄▄▂▅▄▃▃▄▆</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▁▂▁▃▁▃▂▃▂▂▄▂▄▂▅▂▅▂▆▂▆▆▃▇▃▇▃▇▃█▃█▃▃</td></tr><tr><td>val_acc</td><td>▁▃██▇▇█▆▇▇▇▇▇▆█▆▆▇█▇▇▇▇▆███▆█▇▆▇▆▆█▇▇▆▇▇</td></tr><tr><td>val_auc</td><td>▁▃▇█▇▆█▆█▇▇▇▆▆▇▅▅▇▇▆▇▇▆▆███▅█▇▆▆▆▆█▇▇▆█▆</td></tr><tr><td>val_f1</td><td>▁▄███▇█▇██▇▇▇▇█▆▆██▇▇▇▇▇███▆█▇▆▇▇▇██▇▇█▇</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▂▃▂▃▁▃▄▄▂▁▂▂▆▅▂▄▅▂▃▅▃▁▃▁▃▃▄▂▇▃▄▃▅▁▂▃▄</td></tr><tr><td>val_loss_step</td><td>▅▃▃▁▃▄▄▃▄▃▄▃▄▃▂▅▄▂▃▃▃▃█▃▅▄▃▄▂▃▄▃▃▆▃▂▁▃▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.80154</td></tr><tr><td>train_auc</td><td>0.7817</td></tr><tr><td>train_f1</td><td>0.73522</td></tr><tr><td>train_loss_epoch</td><td>0.46474</td></tr><tr><td>train_loss_step</td><td>0.55648</td></tr><tr><td>trainer/global_step</td><td>1699</td></tr><tr><td>val_acc</td><td>0.77692</td></tr><tr><td>val_auc</td><td>0.73432</td></tr><tr><td>val_f1</td><td>0.65476</td></tr><tr><td>val_loss_epoch</td><td>0.52218</td></tr><tr><td>val_loss_step</td><td>0.73332</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_GCN_2_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/r61w53ns' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/r61w53ns</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230704_184951-r61w53ns\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3192340b4304a40ba198d414becd373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230704_191849-flpy7k2w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/flpy7k2w' target=\"_blank\">3D_GCN_2_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/flpy7k2w' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/flpy7k2w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 1.4 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c600f6777529438cb55cb5c86c6256c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▅▆▇▅▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▆█▇▇▇▆██▇▆██▇█▇██▇</td></tr><tr><td>train_auc</td><td>▁▅▅▅▆▅▇▆▆▇▆▆▆▇▇█▆▇▇▆▇▆▆▇▆▇▆▆▇▇▇▆█▇▆▇▆█▇▆</td></tr><tr><td>train_f1</td><td>▁▅▄▅▆▄▇▆▆▇▆▆▅▇▇▇▆▇▇▆▇▆▆▇▆▇▆▆▇▇▇▆█▇▆▇▆█▇▅</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▂▃▂▂▂▂▂▂▃▃▂▂▂▂▃▂▁▁▃▂▂▂▁▂▁▂▂▂▂▁▂▂▁▂▁▂</td></tr><tr><td>train_loss_step</td><td>▅▆█▃▃▄▃▃▃▂▃▄▅▇▂▃█▂▄▅▅▂▄▅▃▃▂▄▆▁▇▇▂▅▄▂▅▃▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▁▂▁▃▁▃▂▃▂▂▄▂▄▂▅▂▅▂▆▂▆▆▃▇▃▇▃▇▃█▃█▃▃</td></tr><tr><td>val_acc</td><td>▁▆▅▇▇▇▇▇███▇█▅█▇▇▇▆█▇▇▇▆▆▇▆▆▇█▇▇▆█▆▆▇▇▇▇</td></tr><tr><td>val_auc</td><td>▁▆▅▇▇▇█▇████▇▅█▇▇▇▆█▇█▇▆▆▇▇▆▇█▇▆▅▇▇▇▇█▇▆</td></tr><tr><td>val_f1</td><td>▁▇▆▇▇▇███████▆█▇█▇▇█▇█▇▇▇▇█▇▇██▇▆██▇▇██▇</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▂▃▄▂▃▃▁▂▄▁▄▂▂▃▁▃▂▆▁▂▇▂▁▄▂▁▂▁▃█▁▅▃▂▃▄▂</td></tr><tr><td>val_loss_step</td><td>█▄▅▄▄▅▃▄▄▅▅█▇▆▅▄▅▂▅▅▅▅▃▅▅▁▅▄▁▆▇▆▆▂▅▅▄▅▆▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.78152</td></tr><tr><td>train_auc</td><td>0.74919</td></tr><tr><td>train_f1</td><td>0.68252</td></tr><tr><td>train_loss_epoch</td><td>0.4721</td></tr><tr><td>train_loss_step</td><td>0.34201</td></tr><tr><td>trainer/global_step</td><td>1699</td></tr><tr><td>val_acc</td><td>0.77992</td></tr><tr><td>val_auc</td><td>0.74471</td></tr><tr><td>val_f1</td><td>0.67052</td></tr><tr><td>val_loss_epoch</td><td>0.41855</td></tr><tr><td>val_loss_step</td><td>0.20539</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_GCN_2_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/flpy7k2w' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/flpy7k2w</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230704_191849-flpy7k2w\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c7274d4f27945e88ed1257d7f762cfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230704_194917-p2kcmeu8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/p2kcmeu8' target=\"_blank\">3D_GCN_2_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/p2kcmeu8' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/p2kcmeu8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 1.4 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf6525f9c6c14e85a2c7d26affb429ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▅▆▆▅▆▆▇▆▇▆▇▇▇▇▇▇▇█▇█▇█▇▇▇█▇▇█▇██▇▇██▇</td></tr><tr><td>train_auc</td><td>▁▂▂▃▅▄▄▅▆▆▅▆▄▇▇▇▇▇▆▇█▇▇▇▇▇▇▇█▇▇█▇▇▇▇▇██▇</td></tr><tr><td>train_f1</td><td>▅▃▁▄▅▄▅▆▆▆▅▇▄▇▇▇▇▇▇▇█▇█▇█▇▇▇█▇▇█▇▇▇█▇██▇</td></tr><tr><td>train_loss_epoch</td><td>█▃▂▂▂▂▂▂▂▂▂▁▂▂▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▅▄▅▄▃▃▃▃▃▅▅▄▂▂▅▁▂▄▄▂▂▄▂▂▁▃▂▂▃▄▃▄▃▁▂▁▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▁▂▁▃▁▃▂▃▂▂▄▂▄▂▅▂▅▂▆▂▆▆▃▇▃▇▃▇▃█▃█▃▃</td></tr><tr><td>val_acc</td><td>▁▁▁▃▆▆▂██▃█▃▁▄▃▁▄▃▁▅▃▃▂▇▂▃▂▁▂▃▂▃▁▂▃▃▄▁▂█</td></tr><tr><td>val_auc</td><td>▁▁▁▃▆▇▂██▃█▄▁▄▃▁▄▃▁▅▄▂▂▇▂▃▂▁▂▃▂▂▁▂▃▃▄▁▂█</td></tr><tr><td>val_f1</td><td>▁▁▁▃▇█▂██▃█▅▂▅▃▂▄▃▂▅▄▃▂▇▂▃▂▁▂▃▂▂▁▂▃▃▄▁▂█</td></tr><tr><td>val_loss_epoch</td><td>▆▅▅▅▄▄▆▄▂▂▅▄▃▃▂▂▆▃▅▂█▄▂▃▃▁▁▃▁▁█▄▅▃▂▃▃▂▆▂</td></tr><tr><td>val_loss_step</td><td>▅▅▅▆▅▅█▅▅▄▄▅▅▅▂▄▅▄▅▄▅▅▂▅▄▁▅▅▁▅▅▅▅▄▅▅▄▅▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.69779</td></tr><tr><td>train_auc</td><td>0.65295</td></tr><tr><td>train_f1</td><td>0.52994</td></tr><tr><td>train_loss_epoch</td><td>0.58375</td></tr><tr><td>train_loss_step</td><td>0.54725</td></tr><tr><td>trainer/global_step</td><td>1699</td></tr><tr><td>val_acc</td><td>0.67568</td></tr><tr><td>val_auc</td><td>0.61578</td></tr><tr><td>val_f1</td><td>0.40845</td></tr><tr><td>val_loss_epoch</td><td>0.56594</td></tr><tr><td>val_loss_step</td><td>0.44529</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_GCN_2_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/p2kcmeu8' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/p2kcmeu8</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230704_194917-p2kcmeu8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "330d6ce26ded4cf3bb228a8248b3ede0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230704_201930-vkpksdxz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/vkpksdxz' target=\"_blank\">3D_GCN_2_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/vkpksdxz' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/vkpksdxz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 1.4 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04d3e39679e842e690d33f4514d866a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▃▆▆▅▆▆▇▆▆▆▆▆▆▆▆▇▇▇▆▇▇█▇▇▇▇▇█▇▆▇▇▆█▇█▆▆</td></tr><tr><td>train_auc</td><td>▁▂▂▅▆▅▆▅▇▆▆▆▅▆▆▆▆▇▇▆▆▆▇█▇▆▇▇▇█▇▆▇▇▆█▇█▆▆</td></tr><tr><td>train_f1</td><td>▂▂▁▄▆▄▅▅▆▆▅▆▅▆▆▅▆▇▇▆▆▆▇█▇▆▇▇▇█▆▆▇▇▅▇▇█▅▅</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▂▂▁▁▁▁▁▁▁▁▁▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▁▂▁▃▁▃▂▃▂▂▄▂▄▂▅▂▅▂▆▂▆▆▃▇▃▇▃▇▃█▃█▃▃</td></tr><tr><td>val_acc</td><td>▁▇▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇█▇█▇██▇▇▇█▇██▆▇▇██▇█▇▇▆</td></tr><tr><td>val_auc</td><td>▁▆▅▆▇▆▆▅▇▆▆▆▆▆▆▆▆▇▆█▆▇█▆▆▆█▆██▇▇▆█▇▇█▆▇▄</td></tr><tr><td>val_f1</td><td>▃▅▄▅▆▆▅▄▆▅▆▅▅▅▅▅▅▇▅█▅▇█▆▅▅█▆█▇▇▆▅█▇▇█▅▇▁</td></tr><tr><td>val_loss_epoch</td><td>█▂▂▂▂▃▂▃▂▂▂▃▂▂▂▁▂▁▂▂▃▁▁▄▂▁▁▂▁▁▂▂▂▁▂▂▁▁▂▂</td></tr><tr><td>val_loss_step</td><td>▇▄▅▅▄▅▅▄▄▅▄█▅▅▃▄▅▃▅▅▄▅▃▅▄▁▄▄▁▆▆▅▄▂▄▅▂▄▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.75746</td></tr><tr><td>train_auc</td><td>0.72242</td></tr><tr><td>train_f1</td><td>0.64306</td></tr><tr><td>train_loss_epoch</td><td>0.48938</td></tr><tr><td>train_loss_step</td><td>0.37038</td></tr><tr><td>trainer/global_step</td><td>1699</td></tr><tr><td>val_acc</td><td>0.74903</td></tr><tr><td>val_auc</td><td>0.7018</td></tr><tr><td>val_f1</td><td>0.58599</td></tr><tr><td>val_loss_epoch</td><td>0.47036</td></tr><tr><td>val_loss_step</td><td>0.09841</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_GCN_2_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/vkpksdxz' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/vkpksdxz</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230704_201930-vkpksdxz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9cd25c0ef0b48f390348553868ddbf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230704_204705-pqwyl7zz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/pqwyl7zz' target=\"_blank\">3D_GCN_2_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/pqwyl7zz' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/pqwyl7zz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 1.4 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6202cffe4885411a95412ec6f96eeec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇▇▇▇█▇██▇▇▇▇██▇█▇██▇███▇▇█▇██▇█████</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇▇▇▇▇██▇▇▇▇██▇▇▇█▇▇███▇▇▇▇██▇██▇██</td></tr><tr><td>train_f1</td><td>▁▇▇▇▇▇▇▇▇█▇██▇▇▇▇████▇██▇███▇▇▇▇██▇██▇██</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▃▃▂▃▃▂▃▂▂▂▂▂▃▁▂▂▂▂▂▁▂▂▁▁▂▂▁▂▂▂▂▂▂▁▂▂</td></tr><tr><td>train_loss_step</td><td>▇▅▃▆▃▄█▄▄▁▄▂▂▆▆▇▄▃▅▅▄▄▇▂▃▁▄▅▂▃▃▂▄▃▄▆▃▂▂▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▁▂▁▃▁▃▂▃▂▂▄▂▄▂▅▂▅▂▆▂▆▆▃▇▃▇▃▇▃█▃█▃▃</td></tr><tr><td>val_acc</td><td>▁▅▇▇▆▇▆▆▇▇▇▇▇▆▇▇▇▆▆███▇▆▆█▇██▆▇█▇▇▇██▇▆█</td></tr><tr><td>val_auc</td><td>▁▅▇▆▆▇▆▆▇▇▇▇▇▅▇▇▆▆▇██▇▇▆▆████▆▆█▆▇▇▇▇█▅█</td></tr><tr><td>val_f1</td><td>▁▆▇▇▇▇▇▆████▇▆█▇▇▇████▇▇▇████▇▇█▇▇████▆█</td></tr><tr><td>val_loss_epoch</td><td>█▅█▃▃▃▂▃▃▄▅▄▁▂▆█▂▄▄▆▁▂▁▅▃▂▂▄▂▂▃▂▄▂▃▁▂▄▃▂</td></tr><tr><td>val_loss_step</td><td>▅▄▄▃▃▄▁▄▄▄▄▅▄▅█▄▃▄▅▃▄▃▁▃▃▂▃▃▂▄▄▃▃▃▃▃▂▄▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.80173</td></tr><tr><td>train_auc</td><td>0.78135</td></tr><tr><td>train_f1</td><td>0.73316</td></tr><tr><td>train_loss_epoch</td><td>0.48112</td></tr><tr><td>train_loss_step</td><td>0.52944</td></tr><tr><td>trainer/global_step</td><td>1699</td></tr><tr><td>val_acc</td><td>0.81081</td></tr><tr><td>val_auc</td><td>0.81115</td></tr><tr><td>val_f1</td><td>0.78027</td></tr><tr><td>val_loss_epoch</td><td>0.4364</td></tr><tr><td>val_loss_step</td><td>0.29601</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_GCN_2_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/pqwyl7zz' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/pqwyl7zz</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230704_204705-pqwyl7zz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df8a6235f0774b1783466559e1f2c907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666592937, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230704_211347-pqehvki7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/pqehvki7' target=\"_blank\">3D_GCN_2_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/pqehvki7' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/pqehvki7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 1.4 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "3.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 K     Total params\n",
      "0.012     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b80e4a6372504e71a9683c490f90127a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▇█▇▇▆▇▇▇▇▇▇▇███▇▇▇▇█▇█▇▇▇▇▇▇▇██▇█▇▇▇</td></tr><tr><td>train_auc</td><td>▁▃▆▆▇█▆▆▅▇▇▆▇▇▇▇███▆▇▇▇█▇▇▇▇▇▇▇▇▇██▇█▇▆▇</td></tr><tr><td>train_f1</td><td>▁▂▆▆▇█▆▆▅▇▆▆▇▆▆▇███▆▇▆▇█▇▇▆▆▇▇▇▇▆██▆█▇▆▇</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▂▃▁▃▂▂▃▂▂▂▂▁▁▁▂▂▂▁▂▁▁▂▁▂▂▂▁▁▁▂▂▁▂▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>▄▇▃▂▂▃▅▅▆▂▄▃▅█▄▂▂▇▄▅▁▄▅▂▅▃▂▂▃▂▄▁▅▃▅▄█▂▅▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▁▂▁▃▁▃▂▃▂▂▄▂▄▂▅▂▅▂▆▂▆▆▃▇▃▇▃▇▃█▃█▃▃</td></tr><tr><td>val_acc</td><td>▁▄▇▇▆██▇▇▆██▆▇▇▇▆▇▆██▇█▆████▇█▇█▇█▇▆▇▇▇▇</td></tr><tr><td>val_auc</td><td>▁▄▇▇▆██▇▇▆██▇▆▇▇▆▇▆██▇▇▆█▇██▆█▆█▆█▆▇██▇▇</td></tr><tr><td>val_f1</td><td>▁▅▇█▆███▇▇███▇▇▇▆█▇██▇█▆████▇█▇█▇█▇███▇▇</td></tr><tr><td>val_loss_epoch</td><td>██▃▂▂▂▃▃▂▄▁▃▃▂▅▁▄▁▃▄▄▁▁▅▆▁▂▃▄▂▅▃▄▂▂▅▄▃▁▁</td></tr><tr><td>val_loss_step</td><td>▇▄▅▂▅▄▅▅▄▄▄▅▅▅█▃▅▂▄▄▅▆▁▄▄▁▄▄▇▄▄▄▄▂▄▃▆▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.79403</td></tr><tr><td>train_auc</td><td>0.77295</td></tr><tr><td>train_f1</td><td>0.72208</td></tr><tr><td>train_loss_epoch</td><td>0.46096</td></tr><tr><td>train_loss_step</td><td>0.36934</td></tr><tr><td>trainer/global_step</td><td>1699</td></tr><tr><td>val_acc</td><td>0.77992</td></tr><tr><td>val_auc</td><td>0.75163</td></tr><tr><td>val_f1</td><td>0.68852</td></tr><tr><td>val_loss_epoch</td><td>0.38101</td></tr><tr><td>val_loss_step</td><td>0.08552</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_GCN_2_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/pqehvki7' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/pqehvki7</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230704_211347-pqehvki7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5f67aa0d03b43ce870279b2a83f64d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230704_214148-s611bvqt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/s611bvqt' target=\"_blank\">3D_GCN_2_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/s611bvqt' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/s611bvqt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 1.4 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99856577577747bca234143fbb0b7a80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▇▆▆▇▇▇▇▇▇▆▆▇▇▇▇▇▇█▇▇█▇▇███▇▇▇▇▇▇▇▇██▇</td></tr><tr><td>train_auc</td><td>▁▅▅▆▆▆▇▆▆▇▆▆▅▆▇▇▇▇▇▇█▇▇▇▇▇▇▇█▇▆▇▇▇▆▇▇██▆</td></tr><tr><td>train_f1</td><td>▁▅▅▆▆▆▇▆▆▇▆▆▅▆▇▇▇▆▇▇█▇▇▇▇▇▇▇█▇▆▇▇▇▆▇▇██▆</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▃▃▃▂▂▃▃▂▂▃▃▂▂▃▂▁▂▂▁▂▂▂▂▂▃▂▁▃▁▁▁▁▂▂▁▂▂</td></tr><tr><td>train_loss_step</td><td>▄▅▆▅█▂▄▂▄▅▂▄▄▆▄▃█▁▅▃▃▄▄▃▆▂▂▃▄▃▄▆▂▄▅▆▄▃▇▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▁▂▁▃▁▃▂▃▂▂▄▂▄▂▅▂▅▂▆▂▆▆▃▇▃▇▃▇▃█▃█▃▃</td></tr><tr><td>val_acc</td><td>▁▅▇▇▇▇█▇█▆▁▇█▆█▇▇▇▆▇▆███▇█▇▇▆██▆▆▇███▇██</td></tr><tr><td>val_auc</td><td>▁▅▇▆▇▇█▇█▆▄▇█▆█▇▇▇▆█▆██▇██▇▆▆▇▇▅▅▇███▇▇▇</td></tr><tr><td>val_f1</td><td>▁▆▇▇▇▇█▇█▆▇▇█▇█▇▇▇▇█▆█████▇▇▇██▆▆▇███▇██</td></tr><tr><td>val_loss_epoch</td><td>▆▃▂▃▁▃▁▂▂▂▆▂▂▂▁▁▃▃▂▂▃▂▂▂▂▁▁▂▁▂▂▄▆▂▂▂█▁▃▁</td></tr><tr><td>val_loss_step</td><td>▃▂▂▃▂▂▁▂▂▂▃▂▂▂▁▂▂▃▂▂▂▂▂▂▂▁▂▂▁▂▂▂▂▂▂▂█▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.78152</td></tr><tr><td>train_auc</td><td>0.74654</td></tr><tr><td>train_f1</td><td>0.6771</td></tr><tr><td>train_loss_epoch</td><td>0.45774</td></tr><tr><td>train_loss_step</td><td>0.48396</td></tr><tr><td>trainer/global_step</td><td>1699</td></tr><tr><td>val_acc</td><td>0.79923</td></tr><tr><td>val_auc</td><td>0.78787</td></tr><tr><td>val_f1</td><td>0.75238</td></tr><tr><td>val_loss_epoch</td><td>0.39768</td></tr><tr><td>val_loss_step</td><td>0.17507</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_GCN_2_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/s611bvqt' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/s611bvqt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230704_214148-s611bvqt\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdfb8b28fe1b400f80744e39ffd74de1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230704_220713-z8jm7mwk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/z8jm7mwk' target=\"_blank\">3D_GCN_2_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/z8jm7mwk' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/z8jm7mwk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 1.4 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d33ac7ffc2c945ffb622e7cfc94e1189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▅▆▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇▇█▇██▇</td></tr><tr><td>train_auc</td><td>▁▂▂▃▄▃▄▄▅▅▅▆▅▇▆▆▆▇▇▆▇▇▇▇▆▆▆▇█▇▆▇▇▆▇▇▇██▅</td></tr><tr><td>train_f1</td><td>▅▃▁▃▄▃▅▄▆▆▆▆▅▇▇▆▇▇▇▇█▇▇▇▇▆▆▇█▇▆▇█▆▇▇███▅</td></tr><tr><td>train_loss_epoch</td><td>█▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▅▄▇▃▄▂▃▄▄▅▅▆▄▂▄▂▄▄▃▃▄▃▅▂▁▂▃▁▃▃▂▂▂▃▂▃▄▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▁▂▁▃▁▃▂▃▂▂▄▂▄▂▅▂▅▂▆▂▆▆▃▇▃▇▃▇▃█▃█▃▃</td></tr><tr><td>val_acc</td><td>▁▁▁▄▇▆▆▅▆▃▇▃█▆▄▇▇▅▂▁▁▁▂▁▆▆▂▂▃▅▂▁▁▂▄▂▂▁▂▆</td></tr><tr><td>val_auc</td><td>▁▁▁▄▇▇▆▅▆▃▇▃█▅▄▇▇▅▂▁▁▁▂▁▆▆▂▂▃▅▂▁▁▂▄▂▂▁▂▆</td></tr><tr><td>val_f1</td><td>▁▁▁▄█▇▇▆▆▃▇▃█▅▄▇▇▅▂▁▁▁▂▁▆▆▂▂▃▅▂▁▁▂▄▂▂▁▃▆</td></tr><tr><td>val_loss_epoch</td><td>▄▄▄▄▃▄▅▄▃▂▄▃▁▃▂▂▃▂▆▄█▆▄▄▂▂▂▃▂▂▆▆▆▆▅▄▅▂▄▂</td></tr><tr><td>val_loss_step</td><td>▅▅▅▅▄▄█▅▄▄▄▄▅▅▁▄▅▂▅▅▄▆▅▆▄▁▅▅▂▅▅▅▅▆▆▆▅▅▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.67469</td></tr><tr><td>train_auc</td><td>0.60688</td></tr><tr><td>train_f1</td><td>0.40702</td></tr><tr><td>train_loss_epoch</td><td>0.58518</td></tr><tr><td>train_loss_step</td><td>0.55379</td></tr><tr><td>trainer/global_step</td><td>1699</td></tr><tr><td>val_acc</td><td>0.62162</td></tr><tr><td>val_auc</td><td>0.57111</td></tr><tr><td>val_f1</td><td>0.25758</td></tr><tr><td>val_loss_epoch</td><td>0.58917</td></tr><tr><td>val_loss_step</td><td>0.2424</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_GCN_2_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/z8jm7mwk' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/z8jm7mwk</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230704_220713-z8jm7mwk\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e21836aa2e844493a231d132e5bb0319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230704_223200-3b8lhnti</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/3b8lhnti' target=\"_blank\">3D_GCN_2_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/3b8lhnti' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/3b8lhnti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GNNModel         | 1.4 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1af37814f7734ae1902c976703b0ef85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▃▅▃▅▆▅▆▇▅▅▆▆▇▇▇▇▆▇▇▆▇█▇▇▇▇█▇▆▇▇█▆▇▇▇▇█</td></tr><tr><td>train_auc</td><td>▁▁▂▃▂▄▆▄▆▆▅▄▅▆▇▆▇▇▆▆▆▅▇█▆▇▇▇█▆▄▇▇█▅▇▇▇▇▇</td></tr><tr><td>train_f1</td><td>▂▁▁▂▂▃▆▃▅▆▄▄▅▆▆▆▇▇▅▆▆▄▇█▆▇▇▆█▆▃▇▇█▄▇▇▇▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▁▂▁▃▁▃▂▃▂▂▄▂▄▂▅▂▅▂▆▂▆▆▃▇▃▇▃▇▃█▃█▃▃</td></tr><tr><td>val_acc</td><td>▁▆▇▇▇▇▇█▇▇██▇▇▇▇█▇▇█▇▇██▇▇█▇████▆▇▇▇████</td></tr><tr><td>val_auc</td><td>▁▇▇▇▆▇▆▇▇▆██▇▇▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▅▇▇▆████</td></tr><tr><td>val_f1</td><td>▃█▅▅▅▆▅▇▆▅▇▇▆▆▆▅▇▆▅▇▆▆▆▇▆▆▆▅▇▆▆▆▁▆▆▄█▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▂▂▂▁▂▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▂▁▂▂▄▁▂▁</td></tr><tr><td>val_loss_step</td><td>▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▁▂▂▁▂▂▂▂▂▂▂▂▂▂█▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77863</td></tr><tr><td>train_auc</td><td>0.74458</td></tr><tr><td>train_f1</td><td>0.67514</td></tr><tr><td>train_loss_epoch</td><td>0.46972</td></tr><tr><td>train_loss_step</td><td>0.34181</td></tr><tr><td>trainer/global_step</td><td>1699</td></tr><tr><td>val_acc</td><td>0.80695</td></tr><tr><td>val_auc</td><td>0.79383</td></tr><tr><td>val_f1</td><td>0.75728</td></tr><tr><td>val_loss_epoch</td><td>0.38372</td></tr><tr><td>val_loss_step</td><td>0.11684</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_GCN_2_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/3b8lhnti' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/3b8lhnti</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230704_223200-3b8lhnti\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b68789f622642c589b939a08e1cd388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230704_225642-0e7jccnu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/0e7jccnu' target=\"_blank\">3D_GCN_2_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/0e7jccnu' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/0e7jccnu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 1.4 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "407fc99d92614e1bb3502572218ba5fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▇▇▇▇▇▇▇▆▇▇▇▇▇▆▇█▇▇▇▇▇█▇▇▇▇▇█▇▇▇▇▇▇▇▇▇</td></tr><tr><td>train_auc</td><td>▁▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇▆▇█▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>train_f1</td><td>▁▆▆█▇▇▇▇▇▇▇▇▇▇▇▇▆▇█▇▇▇▇▇▇▇▇▇▇███▇▇▇▇▇▇█▇</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▂▃▃▂▃▂▂▃▂▃▂▁▂▃▂▂▃▂▂▂▁▁▂▂▁▂▁▂▃▂▁▁▂▂▂▁▂</td></tr><tr><td>train_loss_step</td><td>█▅▄▆▃▂▃▄▆▅▅▃▅▆▆▅▄▂▃▆▄▂▆▂▃▃▇▂▃▃▅▃▅▄▂▇▃▁▄█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▁▂▁▃▁▃▂▃▂▂▄▂▄▂▅▂▅▂▆▂▆▆▃▇▃▇▃▇▃█▃█▃▃</td></tr><tr><td>val_acc</td><td>▁▄▇▄▆▇▆▇█▄▇▆▇▇▇▇▆▇▇▇▇█▆▇▆▅█▇▇█▇▆██▇▇█▇▇▇</td></tr><tr><td>val_auc</td><td>▁▄▇▄▆▇▆▇▇▄▇▆▇▇▇▇▆▇▇▇▇█▆▆▆▆▇▇▇▇▇▇█▇▇▆██▆▇</td></tr><tr><td>val_f1</td><td>▁▅▇▅▇▇▇██▅▇▆███▇▆▇████▇▇▇██▇██▇███▇▇██▇█</td></tr><tr><td>val_loss_epoch</td><td>█▅▄▄▅▂▃▃▄▄▂▄▂▃▃▃▃▃▁▃▃▂▄▄▄▄▂▃▃▁▅▃▃▁▂▂▁▃▆▃</td></tr><tr><td>val_loss_step</td><td>█▆▆▁▇▅▃▆▇▆▆▆▅▅▇▆▅▅█▅▆▆█▃▅▄▆▄▆▄▅▄▄▂▆▇▁▆▅▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.78826</td></tr><tr><td>train_auc</td><td>0.76431</td></tr><tr><td>train_f1</td><td>0.70822</td></tr><tr><td>train_loss_epoch</td><td>0.47789</td></tr><tr><td>train_loss_step</td><td>0.62484</td></tr><tr><td>trainer/global_step</td><td>1699</td></tr><tr><td>val_acc</td><td>0.80309</td></tr><tr><td>val_auc</td><td>0.79694</td></tr><tr><td>val_f1</td><td>0.76923</td></tr><tr><td>val_loss_epoch</td><td>0.47139</td></tr><tr><td>val_loss_step</td><td>0.51823</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_GCN_2_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/0e7jccnu' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/0e7jccnu</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230704_225642-0e7jccnu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a9d536377e84b059782ae28a9e76eae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230704_232132-ptlgbg0f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/ptlgbg0f' target=\"_blank\">3D_GCN_2_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/ptlgbg0f' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/ptlgbg0f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GNNModel         | 1.4 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "3.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.1 K     Total params\n",
      "0.012     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48781bca80c644cdb05ccd239692d9d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇▇▇▇▇█▇▆▇▇▇███▇█▇█▇▇▇▇█▇█▇▇▇▇▆▇▇██▇</td></tr><tr><td>train_auc</td><td>▁▅▆▇▇▇▇▇▆▇█▇▆▇▇▇███▇▇▆▇▆▇▇▇█▇█▆▆▇▇▆▇▇▇▇▆</td></tr><tr><td>train_f1</td><td>▁▅▆▇▇▇▇▇▆▇█▇▅▆█▇███▇▇▆▇▆▆▇▇▇▇▇▆▆▇▇▆▇▇▇▇▆</td></tr><tr><td>train_loss_epoch</td><td>█▅▃▂▂▄▂▂▂▄▁▂▂▄▂▂▂▂▁▂▂▂▂▁▂▂▂▂▂▂▂▁▂▂▂▂▂▁▂▁</td></tr><tr><td>train_loss_step</td><td>▄▇▆▃█▄▃▄▇▃▄▄▃▆▃▃▃▄▂▃▄▆▃▃▃▃█▁▄▂▆▃▄▄▄▅▄▂▄▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▁▂▁▃▁▃▂▃▂▂▄▂▄▂▅▂▅▂▆▂▆▆▃▇▃▇▃▇▃█▃█▃▃</td></tr><tr><td>val_acc</td><td>▁▃▇▆▇▇▇▇▇▇██▇▇▅▇▆▇▇▇▇█▇▇▇▇▇▇▇▇█▇██▇▇▆▇▆█</td></tr><tr><td>val_auc</td><td>▁▃▇▆▇▇▇▇▇▇██▇▇▅▇▆▆▇▇▇█▆▇▇▇▇▇█▇█▇▇█▇▇▆▇▆█</td></tr><tr><td>val_f1</td><td>▁▄▇▆▇▇█▇█████▇▆▇▇▇▇█▇█▇████▇█▇████▇▇▇█▇█</td></tr><tr><td>val_loss_epoch</td><td>█▆▂▄▂▇▁▃▃▂▁▃▂▂▆▂▅▃▂▂▃▁▂▁▂▂▂▁▂▂▂▁▃▁▂▂▃▁▂▃</td></tr><tr><td>val_loss_step</td><td>▇▆▄▆▅▄▁▆▅▅▄▇▆▆█▅▆▄▄▄▄▅▂▄▅▂▄▅▃▄▄▅▄▁▄▅▃▇▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77767</td></tr><tr><td>train_auc</td><td>0.75429</td></tr><tr><td>train_f1</td><td>0.69565</td></tr><tr><td>train_loss_epoch</td><td>0.45717</td></tr><tr><td>train_loss_step</td><td>0.35773</td></tr><tr><td>trainer/global_step</td><td>1699</td></tr><tr><td>val_acc</td><td>0.80695</td></tr><tr><td>val_auc</td><td>0.7957</td></tr><tr><td>val_f1</td><td>0.7619</td></tr><tr><td>val_loss_epoch</td><td>0.46481</td></tr><tr><td>val_loss_step</td><td>0.53569</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_GCN_2_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/ptlgbg0f' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/ptlgbg0f</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230704_232132-ptlgbg0f\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k_folds = 5\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_ids, valid_ids) in enumerate(kfold.split(dataset_filtered)):\n",
    "    train_subset = dataset_filtered.index_select(train_ids.tolist())\n",
    "    val_subset = dataset_filtered.index_select(valid_ids.tolist())\n",
    "    \n",
    "    for pool in pools:\n",
    "        # Path to the folder where the pretrained models are saved\n",
    "        CHECKPOINT_PATH = checkpoint_folder / f'3D_{NUM_LAYERS}_{HIDDEN_CHANNELS}_onehot_{fold}' / pool\n",
    "        CHECKPOINT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Skip already trained kfold and pool\n",
    "        checkpoint = CHECKPOINT_PATH / \"GraphLevelGCN\" / \"GraphLevelGCN.ckpt\" \n",
    "        if checkpoint.exists():\n",
    "            print(checkpoint)\n",
    "            continue\n",
    "        \n",
    "        # Run training\n",
    "        run = wandb.init(project=project_name, name=f'3D_GCN_{NUM_LAYERS}_{HIDDEN_CHANNELS}_onehot_{fold}', \n",
    "                        group=f'3D_GCN_{pool}')\n",
    "        PPIGraph.train_graph_classifier_kfold('GCN', \n",
    "                                             train_subset, \n",
    "                                             val_subset, \n",
    "                                             dataset, \n",
    "                                             CHECKPOINT_PATH, \n",
    "                                             AVAIL_GPUS, \n",
    "                                             in_channels=9,\n",
    "                                             hidden_channels=HIDDEN_CHANNELS, \n",
    "                                             out_channels = HIDDEN_CHANNELS,\n",
    "                                             num_layers=NUM_LAYERS, \n",
    "                                             epochs=epochs,\n",
    "                                             embedding=False,\n",
    "                                             graph_pooling=pool)\n",
    "        run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a71ba203-c955-440c-841d-e37c60826e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_folder = (Path().cwd().parents[0]).absolute() / 'data' / \"saved_models\" / dataset_name /  f\"MLP_{condition}\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de6d38e1-408f-4f2f-b753-b475beb5fa05",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cd00380442741c6b28448a25c52b59e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230704_234620-dbh6giek</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/dbh6giek' target=\"_blank\">3D_MLP_2_32_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/dbh6giek' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/dbh6giek</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | MLPModel         | 1.4 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thu71\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:280: PossibleUserWarning: The number of training batches (9) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3de7c30ae827454d815cc25bff1fa2bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▁▃▅▅▅▆▇▆▅▇▆▆▆▇▆▆▇▇▇▇▆▆▆▇▆▆▇█▇▆▇▇▆▆▇▆▆▆</td></tr><tr><td>train_auc</td><td>▁▁▁▃▆▅▅▅▇▆▇▇▆▆▆█▆▆▇▇▇▇▆▆▆▇▇▆██▇▆▇▇▇▇▇▇▆▇</td></tr><tr><td>train_f1</td><td>▁▁▁▄▇▆▅▆▇▇█▇▇▇▇█▇▇██▇▇▇▇▇▇▇▆██▇▇████▇▇▇▇</td></tr><tr><td>train_loss_epoch</td><td>███▆▄▄▃▃▃▂▄▂▂▂▃▁▂▂▃▂▂▃▄▃▃▁▄▂▂▁▂▂▂▂▃▂▃▃▂▃</td></tr><tr><td>train_loss_step</td><td>▅▆▅▅▆▃▄▃▄▃▄▃▂▂▂▁▃▃▂▃▂▃▃▃▄▃▄▃▄▃▂▅▃▃▃▂▃▅▁█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▂▁▂▃▂▃▂▂▄▄▂▄▂▂▅▂▂▅▂▆▆▃▆▆▃▇▇▃▇█▃██▃</td></tr><tr><td>val_acc</td><td>▁▁▁▁▆▅▆▇▇▇▅▆▆████▅▇▇▆▆████▇▆▆▇█▇█▇▆███▇▇</td></tr><tr><td>val_auc</td><td>▁▁▁▁▆▇▆▇▇▇▅▆█▇███▅█████████▆▇▇█▇▇█▆███▇█</td></tr><tr><td>val_f1</td><td>▁▁▁▁▆▇▇▇▇▇▆▇█████▆█████████▇██████▇███▇█</td></tr><tr><td>val_loss_epoch</td><td>▅▆▆▅▂▅▄▃▂▅▅▄▄▆▃▃▄▁▃▇▃▃▃█▄▂▁▁▃▅▃▁█▃▂▅▄▅▄▅</td></tr><tr><td>val_loss_step</td><td>▆▇▆▇▅▅▆▅▄▂▄▆▅▅▅▅▅▁▄▅▄▅▄▄▅▄▅▄▅▅▆▅▅▅▅▅▇▅▄█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.69653</td></tr><tr><td>train_auc</td><td>0.66324</td></tr><tr><td>train_f1</td><td>0.56311</td></tr><tr><td>train_loss_epoch</td><td>0.605</td></tr><tr><td>train_loss_step</td><td>0.7437</td></tr><tr><td>trainer/global_step</td><td>899</td></tr><tr><td>val_acc</td><td>0.72692</td></tr><tr><td>val_auc</td><td>0.69218</td></tr><tr><td>val_f1</td><td>0.60335</td></tr><tr><td>val_loss_epoch</td><td>0.63679</td></tr><tr><td>val_loss_step</td><td>0.76212</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_MLP_2_32_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/dbh6giek' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/dbh6giek</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230704_234620-dbh6giek\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76795a5b18f84dfd97a4619acb0f630a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230705_000758-g29bjrq7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/g29bjrq7' target=\"_blank\">3D_MLP_2_32_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/g29bjrq7' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/g29bjrq7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | MLPModel         | 1.4 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1faaf88c06014acfa6a8cab073c41da6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▅▅▅▅▄▅▅▇▅▅▅▆▆▆▇▇▅█▇▇▆▆▆▇▆██▆▇█▅▇██▆██</td></tr><tr><td>train_auc</td><td>▁▁▁▂▂▂▃▂▂▃▇▄▄▄▅▆▄▆▆▄▇▅▅▄▅▅▆▄█▇▆▅█▅▇█▇▅▆▇</td></tr><tr><td>train_f1</td><td>▅▂▂▂▂▁▃▁▂▄▇▅▅▅▅▆▅▆▇▅▆▆▆▃▆▆▇▅█▇▇▅█▇▇█▇▆▆▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▄▅▄▄▅▄▄▃▄▄▄▄▂▄▂▄▄▃▂▃▃▁▁▃▂▄▁▃▂▁▃▃▂▃▅▁▃</td></tr><tr><td>train_loss_step</td><td>▅▆▅▄▇▅▄▅▄▅▄▆▄▄▄▃▃▄▅▅▂▄▄▆▆▁▅▅▄▃▆▅▂▅▅▅▃▅▆█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▂▁▂▃▂▃▂▂▄▄▂▄▂▂▅▂▂▅▂▆▆▃▆▆▃▇▇▃▇█▃██▃</td></tr><tr><td>val_acc</td><td>██████████████▆▁▅▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_auc</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁██▁▆▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_f1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▇██████████████████████████</td></tr><tr><td>val_loss_epoch</td><td>▁▂▂▂▁▃▁▃▁▁▁▂▂▂▂▂▂▃▄▃▄▃▅▄▄▃▆▅▄▅▆▇▃▄▆▆▅▄▃█</td></tr><tr><td>val_loss_step</td><td>▂▂▂▃▂▂▂▂▂▂▂▃▂▂▃▃▂▃▃▃▃▃▄▃▃▁▄▄▁▄█▄▅▂▅▄▃▄▅▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.63006</td></tr><tr><td>train_auc</td><td>0.58174</td></tr><tr><td>train_f1</td><td>0.40741</td></tr><tr><td>train_loss_epoch</td><td>0.65436</td></tr><tr><td>train_loss_step</td><td>0.72819</td></tr><tr><td>trainer/global_step</td><td>899</td></tr><tr><td>val_acc</td><td>0.37692</td></tr><tr><td>val_auc</td><td>0.5</td></tr><tr><td>val_f1</td><td>0.54749</td></tr><tr><td>val_loss_epoch</td><td>0.89767</td></tr><tr><td>val_loss_step</td><td>0.96576</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_MLP_2_32_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/g29bjrq7' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/g29bjrq7</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230705_000758-g29bjrq7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d622e3236e47ad86cf209f5ef77f9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230705_002950-5h5rtlw9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/5h5rtlw9' target=\"_blank\">3D_MLP_2_32_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/5h5rtlw9' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/5h5rtlw9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | MLPModel         | 1.4 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aebc6c4b90224ba991b0fe09bb630312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▃▄▄▅▅▆▆▄▆▇▇▇▇▇▇▇▇██▇▇▇█▇▆▇█▇▇▇▇▇▇█▇▇▇</td></tr><tr><td>train_auc</td><td>▁▃▃▂▃▂▄▄▅▆▄▆▇▆▇▇▇▆▇▇██▇▆▇█▇▅▇██▇▇▇▇███▆▇</td></tr><tr><td>train_f1</td><td>▄▅▄▁▄▂▂▃▄▆▅▆▇▆▇▇▇▅▇▇██▇▇▇██▄█▇█▇██▇███▆▇</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▂▂▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▂▁▂▃▂▃▂▂▄▄▂▄▂▂▅▂▂▅▂▆▆▃▆▆▃▇▇▃▇█▃██▃</td></tr><tr><td>val_acc</td><td>▁▅▄▄▂▂▇▅▆▇▄▇▇█▇▇▇▆▇▇▇▆▇▇▇█▆▇█▇▆▇▇▇█▇▆▇▇█</td></tr><tr><td>val_auc</td><td>▁▄▃▄▂▂▆▄▆▇▄▆▇▇█▇▇▆█▇██▇▇▇██▆█▇▆▇▆▇█▇▆▆▇▇</td></tr><tr><td>val_f1</td><td>▁▅▄▄▂▂▆▅▆▇▄▆▇▇█▇▇▆█████▇▇▇█▆▇█▆▇▇▇▇▇▆▆▇▇</td></tr><tr><td>val_loss_epoch</td><td>▅▄▄▅▄▆▅▅▃▅▅▄▄▆▄▃▅▂▃▇▄▃▃▆▄▂▂▂▃▅▄▁█▂▃▄▄▆▄▅</td></tr><tr><td>val_loss_step</td><td>▇▆▅▇▆▆▆▅▃▅▄▇▄▅▅▄▄▁▃▄▃▅▃▄▄▂▄▄▄▃▆▄▄▂▄▄▇▅▃█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.67823</td></tr><tr><td>train_auc</td><td>0.6431</td></tr><tr><td>train_f1</td><td>0.53221</td></tr><tr><td>train_loss_epoch</td><td>0.62203</td></tr><tr><td>train_loss_step</td><td>0.66274</td></tr><tr><td>trainer/global_step</td><td>899</td></tr><tr><td>val_acc</td><td>0.72692</td></tr><tr><td>val_auc</td><td>0.67404</td></tr><tr><td>val_f1</td><td>0.55901</td></tr><tr><td>val_loss_epoch</td><td>0.62531</td></tr><tr><td>val_loss_step</td><td>0.70371</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_MLP_2_32_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/5h5rtlw9' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/5h5rtlw9</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230705_002950-5h5rtlw9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c5ca4d2c23d4af0b639fc8cd09e0f4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230705_005143-t4b3bapc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/t4b3bapc' target=\"_blank\">3D_MLP_2_32_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/t4b3bapc' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/t4b3bapc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | MLPModel         | 1.4 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a581cc4117274861a0a3076b10956e23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▁▂▄▅▅▆▆▆▅▆▅▆▆▇▆▆▅▇▇▇▇█▇▇▆▇▆▇▆▇▇▆▆▇▇▇▇▆</td></tr><tr><td>train_auc</td><td>▁▁▂▂▅▆▅▇▇▇▅▆▆▆▇▇█▆▆█▇▇▇█▇▇▇█▇█▇▇▇▇▇▇▇█▇▇</td></tr><tr><td>train_f1</td><td>▂▁▂▃▇▇▇█▇▇▅▇▇▇▇▇█▇▇█▇█▇██▇██▇█▇▇▇▇▇▇████</td></tr><tr><td>train_loss_epoch</td><td>███▇▃▅▃▅▃▄▄▃▃▃▂▃▄▃▃▁▃▃▂▁▂▂▃▃▂▂▃▃▃▃▄▃▂▂▄▂</td></tr><tr><td>train_loss_step</td><td>▆▆▇▄█▄▄▃▃▅▃▅▄▃▃▅▃▇▄▁▄▃▂▂▁▄▃▃▃▆▃▆▃▅▄▄▄▄▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▂▁▂▃▂▃▂▂▄▄▂▄▂▂▅▂▂▅▂▆▆▃▆▆▃▇▇▃▇█▃██▃</td></tr><tr><td>val_acc</td><td>▁▁▁▂▂▃▄▃▄▇▇▇▇▇▅▆▆▆▆▅▆▇█▇▇▆▅▄▇▆▆▇██▇█▆▆▆▆</td></tr><tr><td>val_auc</td><td>▁▁▁▂▁▂▄▃▃▇▆▆▆▇▅▆▅▆▅▄▆▇█▇▆▆▄▄▇▆▆▇▇▇▇█▆▅▆▆</td></tr><tr><td>val_f1</td><td>▁▁▁▂▁▃▄▃▄▇▇▆▆▇▅▆▆▆▆▅▆▇█▇▆▆▅▄█▆▆▇▇▇▇█▆▆▆▆</td></tr><tr><td>val_loss_epoch</td><td>▅▇▆▅▄▆▂▂▄▃▄▄▅▃▂▆▅▇▃▃█▃▅▁▂▄▃▆▄▃▂▂▃▅▂▆▂█▄▃</td></tr><tr><td>val_loss_step</td><td>▄▄▄▄▄▄▁▄▄▄▄▃▄▃▁▄▄█▃▄▄▃▆▃▃▄▄▃▄▃▂▃▃▆▄▃▂▃▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.68015</td></tr><tr><td>train_auc</td><td>0.66026</td></tr><tr><td>train_f1</td><td>0.585</td></tr><tr><td>train_loss_epoch</td><td>0.59525</td></tr><tr><td>train_loss_step</td><td>0.55407</td></tr><tr><td>trainer/global_step</td><td>899</td></tr><tr><td>val_acc</td><td>0.70385</td></tr><tr><td>val_auc</td><td>0.6273</td></tr><tr><td>val_f1</td><td>0.44604</td></tr><tr><td>val_loss_epoch</td><td>0.5424</td></tr><tr><td>val_loss_step</td><td>0.46313</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_MLP_2_32_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/t4b3bapc' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/t4b3bapc</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230705_005143-t4b3bapc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c145b0aedb7c410eaa4e7113b3ec8928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230705_011453-q7aq9t40</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/q7aq9t40' target=\"_blank\">3D_MLP_2_32_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/q7aq9t40' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/q7aq9t40</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | MLPModel         | 1.4 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "3.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.0 K     Total params\n",
      "0.012     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e94a1de62b5475d9e695686da1b162c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▁▃▅▇▆▇▇▇▆▇▇▇▇▆█▇▆▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇█▇▇█</td></tr><tr><td>train_auc</td><td>▁▁▁▃▅█▇▇▇█▆█▇▇█▆██▆█▇▇▇█▇█▇▆█▆▇██▇████▇█</td></tr><tr><td>train_f1</td><td>▂▁▁▃▆█▇▇▇█▇██▇█▇██▆██▇██▇█▇▇█▇▇██▇████▇█</td></tr><tr><td>train_loss_epoch</td><td>███▇▄▃▃▃▃▄▄▂▃▃▂▃▂▂▄▂▄▂▃▃▁▃▃▃▃▄▂▂▃▂▂▃▂▃▂▂</td></tr><tr><td>train_loss_step</td><td>████▅▄▅▅█▄▄▆▄▂▃▅▄▂▂▄▁▂▇▄▄▄▄▄▆▂▄▃▄▂▃▆▁▆▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▂▁▂▃▂▃▂▂▄▄▂▄▂▂▅▂▂▅▂▆▆▃▆▆▃▇▇▃▇█▃██▃</td></tr><tr><td>val_acc</td><td>▁▁▁▁▆▆▆▆▇▆▇▆▆▇▆▇▇▆▆▆▇▆▆▆█▆▇█▇▇▆▇▇█▇▇▇█▆▇</td></tr><tr><td>val_auc</td><td>▁▁▁▁▇▅▆▆▇▆▇▇▆█▇▇█▇▆▆█▆▇▆█▆██▇█▆▇▇█▇▇██▆█</td></tr><tr><td>val_f1</td><td>▁▁▁▁▇▆▆▆█▇▇▇▇█▇███▇▇█▇█▇█▇██▇█▇▇▇█▇▇██▇█</td></tr><tr><td>val_loss_epoch</td><td>▇██▇▇▁▄▄▅▃▂▄▄▁█▄▅▅▄▅▆▃▂▄▆▄▄▄▅▅▃▄▅▅▇▄▃▇▃▃</td></tr><tr><td>val_loss_step</td><td>▄▄▄▅▃▃▃▃▃▃▄▃▃▃█▃▃▅▃▃▃▄▁▄▄▃▃▃▄▃▁▄▃▄▃▃▂▄▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.71773</td></tr><tr><td>train_auc</td><td>0.68582</td></tr><tr><td>train_f1</td><td>0.59586</td></tr><tr><td>train_loss_epoch</td><td>0.58144</td></tr><tr><td>train_loss_step</td><td>0.58341</td></tr><tr><td>trainer/global_step</td><td>899</td></tr><tr><td>val_acc</td><td>0.71923</td></tr><tr><td>val_auc</td><td>0.67996</td></tr><tr><td>val_f1</td><td>0.58286</td></tr><tr><td>val_loss_epoch</td><td>0.51567</td></tr><tr><td>val_loss_step</td><td>0.39884</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_MLP_2_32_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/q7aq9t40' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/q7aq9t40</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230705_011453-q7aq9t40\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "983c2827e92043069b033e949852546b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230705_013737-zzwbygek</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/zzwbygek' target=\"_blank\">3D_MLP_2_32_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/zzwbygek' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/zzwbygek</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | MLPModel         | 1.4 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d9538d302ef41a7b3949df0e8707de0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▁▂▄▅▅▆▆▆▆▇▇▇▇▇▇▆▆▇▇▆▇▆▇▇▇▅██▇▇▇▇▆▇▇▇▇▇</td></tr><tr><td>train_auc</td><td>▁▁▁▂▄▅▄▆▆▆▇▇▇▆▆▇▇▆▇▇▇▆▆▆▆▇▆▅██▇▇▇▇▇▇▇▆▇▇</td></tr><tr><td>train_f1</td><td>▁▁▁▄▅▇▅▆▇▇█▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▅██▇▇▇▇▇██▇▇▇</td></tr><tr><td>train_loss_epoch</td><td>███▆▄▃▃▂▃▃▃▂▂▂▃▂▃▁▂▁▃▃▃▃▂▁▃▂▁▂▂▃▂▁▃▂▃▂▁▃</td></tr><tr><td>train_loss_step</td><td>▆▆▆▆▆▂▃▄▁▄▅▂▂▃▃▃▅▂▅▅▄▂▁▃▃▂█▄▂▂▃▃▁▄▃▃▃▃▅▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▂▁▂▃▂▃▂▂▄▄▂▄▂▂▅▂▂▅▂▆▆▃▆▆▃▇▇▃▇█▃██▃</td></tr><tr><td>val_acc</td><td>▁▁▁▁▇▇▇▆▇▆▆▆▆▆█▇▇▆▆▇▇▆▆▇▆▆█▇█▇█▇▆▇▆▆▇▇▆▇</td></tr><tr><td>val_auc</td><td>▁▁▁▁▇▇▇▆▇▆▆▆▆▆█▇▇▆▆▇▇▆▇█▆▆█▆█▇▇▇▆▇▆▆▇▇▆▇</td></tr><tr><td>val_f1</td><td>▁▁▁▂▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇█▇▇█▆█▇██▇▇▇▇▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▇▇▆▄▆▅▃▂▄▂▆▃▃▃▅▅▅▃▆▇▅▅▄▆▇▆▄▅▅▄▅█▆▁█▅▇▅▄</td></tr><tr><td>val_loss_step</td><td>▅▅▅▅▄▄▅▄▄▅▄▇▄▄▃▅▄▅▄▅▄▄▅▄▅█▄▅▆▄▁▅▄▆▄▄▅▄▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.70135</td></tr><tr><td>train_auc</td><td>0.66178</td></tr><tr><td>train_f1</td><td>0.55331</td></tr><tr><td>train_loss_epoch</td><td>0.59533</td></tr><tr><td>train_loss_step</td><td>0.65103</td></tr><tr><td>trainer/global_step</td><td>899</td></tr><tr><td>val_acc</td><td>0.69231</td></tr><tr><td>val_auc</td><td>0.66313</td></tr><tr><td>val_f1</td><td>0.56989</td></tr><tr><td>val_loss_epoch</td><td>0.59765</td></tr><tr><td>val_loss_step</td><td>0.62338</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_MLP_2_32_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/zzwbygek' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/zzwbygek</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230705_013737-zzwbygek\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eed22eeb1d7d4dd795dc8b32c0ce757d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230705_015756-9bhgn8a3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/9bhgn8a3' target=\"_blank\">3D_MLP_2_32_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/9bhgn8a3' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/9bhgn8a3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | MLPModel         | 1.4 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ee2ed71ce2b446c80662a2109a4d50b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▄▄▄▄▅▄▄▅▅▄▅▇▇▇▅▆▇▆▆▅█▇▆▇▇▆▆▆▇▅▇▇▇▆█▅█▆</td></tr><tr><td>train_auc</td><td>▂▁▂▂▂▂▃▃▃▄▅▃▅▅▇▆▆▅█▆▅▄▇▆▆▇▆▅▅▆▇▅▇▇▆▆█▄▇▅</td></tr><tr><td>train_f1</td><td>▅▂▂▁▂▁▃▃▃▅▆▄▆▅▇▆▇▅█▆▆▅▇▅▇▇▆▅▆▇▇▆▇▇▆▇█▅▇▆</td></tr><tr><td>train_loss_epoch</td><td>█▇▆▅▅▅▄▅▄▅▄▃▆▃▄▄▄▃▄▃▅▃▂▃▁▂▄▂▄▃▃▄▁▄▃▂▃▅▁▄</td></tr><tr><td>train_loss_step</td><td>▅▆▆▄▇▅▄▅▄▄▅▅▆▄▂▄▄▄▆▅▃▃▃▄▂▃▅▅▃▁█▄▄▁▄▁▂▅▅▇</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▂▁▂▃▂▃▂▂▄▄▂▄▂▂▅▂▂▅▂▆▆▃▆▆▃▇▇▃▇█▃██▃</td></tr><tr><td>val_acc</td><td>▇▇▇▇▇▇▇▇▇▇▇▇▆█▇▆▆▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_auc</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▆██▆▆▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_f1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁████████████████████████████</td></tr><tr><td>val_loss_epoch</td><td>▄▂▂▂▂▄▂▃▁▂▂▂▃▂▂▂▂▃▅▃▄▂▅▄▃▃▆▅▃▆▆█▂▅▇▄▅▃▂▄</td></tr><tr><td>val_loss_step</td><td>▂▃▃▃▃▃▂▂▂▃▂▂▃▂▃▃▃▃▃▃▃▃▃▃▄▂▄▃▂▄█▄▅▁▄▄▃▄▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.61368</td></tr><tr><td>train_auc</td><td>0.54715</td></tr><tr><td>train_f1</td><td>0.30261</td></tr><tr><td>train_loss_epoch</td><td>0.65415</td></tr><tr><td>train_loss_step</td><td>0.70754</td></tr><tr><td>trainer/global_step</td><td>899</td></tr><tr><td>val_acc</td><td>0.41538</td></tr><tr><td>val_auc</td><td>0.5</td></tr><tr><td>val_f1</td><td>0.58696</td></tr><tr><td>val_loss_epoch</td><td>0.73998</td></tr><tr><td>val_loss_step</td><td>0.70182</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_MLP_2_32_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/9bhgn8a3' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/9bhgn8a3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230705_015756-9bhgn8a3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5eae425eaed4cb58cd6ee30dccbe000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230705_022052-qd60q4fx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/qd60q4fx' target=\"_blank\">3D_MLP_2_32_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/qd60q4fx' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/qd60q4fx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | MLPModel         | 1.4 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9a39d246b454afc9472ca26f040a2aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▄▃▅▄▅▆▆▆▆▆▇▇▇▇▇▆▇▇▇▇▇▇▇▇▆▇▇▇███▇▇▇███▇</td></tr><tr><td>train_auc</td><td>▁▂▃▂▄▃▄▄▅▅▇▆▇▆▇▇▇▅▇▆▆▆▇▇▆▆▅▆▇▇█▇█▇▇▇█▇█▇</td></tr><tr><td>train_f1</td><td>▂▃▂▁▂▁▁▂▄▅▇▆▇▅▆▆▆▃▇▆▄▄▆▆▄▅▃▄▇▆▇▆█▇▆▅█▇█▆</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▂▁▂▃▂▃▂▂▄▄▂▄▂▂▅▂▂▅▂▆▆▃▆▆▃▇▇▃▇█▃██▃</td></tr><tr><td>val_acc</td><td>▁▃▅▅▃▅▆▆▆▅▆▇▇▆▆█▇▆▆▆▇▅▇▄▇▆▆▆▅▇█▆▇▇▇▆▆█▆█</td></tr><tr><td>val_auc</td><td>▁▃▅▄▃▅▅▅▆▅▆▆▆▆▆▇▆▆▆▆▇▆█▇▆▆▇▆▆▇█▆▆▆▆▆▆█▆█</td></tr><tr><td>val_f1</td><td>▁▃▆▅▃▅▆▆▆▅▆▆▆▇▇▇▆▇▆▇▇▆██▆▆▇▆▆▇▇▇▆▆▆▆▆█▆█</td></tr><tr><td>val_loss_epoch</td><td>▆▄▃▄▃▄▃▃▁▃▂▃▂▂▂▃▃▂▂▄▄▄▃▃▄▄▄▂▄▃▃▃█▄▁▅▃▆▃▄</td></tr><tr><td>val_loss_step</td><td>▅▆▅▆▅▅▅▅▅▅▅▆▅▅▄▅▅▄▅▅▅▅▅▅▅▇▅▅▇▅▁▅▅█▅▄▅▄▅▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.68497</td></tr><tr><td>train_auc</td><td>0.63785</td></tr><tr><td>train_f1</td><td>0.50379</td></tr><tr><td>train_loss_epoch</td><td>0.60553</td></tr><tr><td>train_loss_step</td><td>0.58488</td></tr><tr><td>trainer/global_step</td><td>899</td></tr><tr><td>val_acc</td><td>0.71154</td></tr><tr><td>val_auc</td><td>0.69164</td></tr><tr><td>val_f1</td><td>0.62312</td></tr><tr><td>val_loss_epoch</td><td>0.65166</td></tr><tr><td>val_loss_step</td><td>0.76816</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_MLP_2_32_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/qd60q4fx' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/qd60q4fx</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230705_022052-qd60q4fx\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a39eac7498ea4fb78c8738ae84f0539a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230705_024031-moegtt13</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/moegtt13' target=\"_blank\">3D_MLP_2_32_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/moegtt13' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/moegtt13</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | MLPModel         | 1.4 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90748cdddaf94edfa3e4fac2644b5b0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▁▁▄▅▅▆▆▆▅▇▅▆▇▅▇▇▇▇▇▇▅▇▆▆▅▇▇▇▇▇▆▇▇▇▆▇█▇</td></tr><tr><td>train_auc</td><td>▁▁▁▁▅▆▅▇▆▇▅█▅▆▇▆▇▇▇▇▇▇▅▇▇▆▆▇▇█▇▆▆▇▇▆▇██▇</td></tr><tr><td>train_f1</td><td>▂▁▁▂▆▇▇█▇▇▆█▆▇▇▇█▇██▇▇▆▇▇▇▇▇███▇▆█▇▆▇███</td></tr><tr><td>train_loss_epoch</td><td>███▇▄▄▃▅▃▄▂▄▅▃▂▄▃▂▃▃▃▃▃▁▂▂▅▃▅▃▃▃▂▆▃▃▂▂▁▂</td></tr><tr><td>train_loss_step</td><td>▇▆█▅▇▅▅▅▇▂▃▂▄▂▄▃▂▄▄▂▄▆▅▃▃▅▁▅▄█▄▃▇▇▂▃▄▄▄▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▂▁▂▃▂▃▂▂▄▄▂▄▂▂▅▂▂▅▂▆▆▃▆▆▃▇▇▃▇█▃██▃</td></tr><tr><td>val_acc</td><td>▁▁▁▁▂▄▅▅▆▇█▅▇▇▇█▇█▇▇▇▇▇▇█▇▆▆▇▇█▇▇█▇▇█▇█▇</td></tr><tr><td>val_auc</td><td>▁▁▁▁▂▄▅▅▆▇█▅▇█▇█▆█▆▆▇██▇█▇▆▆▇▇██▇█▇█▇▆█▇</td></tr><tr><td>val_f1</td><td>▁▁▁▁▂▅▅▅▆▇▇▅▆▇▇▇▆▇▆▆▇██▇▇▇▆▆▇▇▇█▇▇▇█▇▆▇▇</td></tr><tr><td>val_loss_epoch</td><td>▅▆▆▆▄▇▄▄▃▄▅█▆▅▄▄▆▄▅▅▄▃▅█▄▃▄▇▃▃▂▅▆▆▇▄▄▆▃▁</td></tr><tr><td>val_loss_step</td><td>▅▅▅▆▅▅▃▅▅▇▅█▅▄▄▅▄▄▄▅▅▅▅▅▄▃▅▄▃▅▃▅▄▇▅▅▄▄▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.7052</td></tr><tr><td>train_auc</td><td>0.67721</td></tr><tr><td>train_f1</td><td>0.59309</td></tr><tr><td>train_loss_epoch</td><td>0.59285</td></tr><tr><td>train_loss_step</td><td>0.62694</td></tr><tr><td>trainer/global_step</td><td>899</td></tr><tr><td>val_acc</td><td>0.68462</td></tr><tr><td>val_auc</td><td>0.63377</td></tr><tr><td>val_f1</td><td>0.46753</td></tr><tr><td>val_loss_epoch</td><td>0.48161</td></tr><tr><td>val_loss_step</td><td>0.22208</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_MLP_2_32_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/moegtt13' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/moegtt13</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230705_024031-moegtt13\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "352e21b1a27b41e2a60ac33e4cc4f901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230705_025953-txaleng7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/txaleng7' target=\"_blank\">3D_MLP_2_32_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/txaleng7' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/txaleng7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | MLPModel         | 1.4 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "3.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.0 K     Total params\n",
      "0.012     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ebb5e5873b3416ea7c272742824037b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▁▂▄▆▆▇▇▆▇▇▇▇▆▇▇▇▆▆▆▇▇█▇█▇▇█▆▆▇▇▇█▇█▇▆█</td></tr><tr><td>train_auc</td><td>▁▁▁▂▄▆▆▇▇▇▇▇▇█▇▇█▆▆▇▆▇▇█▇█▆▆█▆▆█▇▇█▇▇▇▅▇</td></tr><tr><td>train_f1</td><td>▁▁▁▂▅▇▇▇▇▇▇█▇█▇▇█▇▆▇▇▇▇█▇█▇▇▇▆▆█▇▇█▇▇▇▆▇</td></tr><tr><td>train_loss_epoch</td><td>███▇▄▄▄▂▃▂▂▃▁▃▂▂▄▃▂▂▃▁▂▄▁▃▂▂▂▄▂▂▂▃▂▅▂▂▂▂</td></tr><tr><td>train_loss_step</td><td>▇▅▆▇▂▄▄▅▆▄▃▃▃▄▄▂▃▂▃▃▄▂▄▂▂▅▃▃▄▃▄▁▂▂▁▃▃▃▂█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▂▁▂▃▂▃▂▂▄▄▂▄▂▂▅▂▂▅▂▆▆▃▆▆▃▇▇▃▇█▃██▃</td></tr><tr><td>val_acc</td><td>▁▁▁▁▆▆▆▆▇▇▇▆▇▆▇█▆▇▇▇▇▆▆▇▇▇▇▇▇▇▆▇▅▆▅▅▇▆▇█</td></tr><tr><td>val_auc</td><td>▁▁▁▁▆▆▆▆▆▆▇▆▆▆▆█▆▇▆▆▇▆▆▇▆▆▇█▆▇▆▆▆▆▆▆▇▇▆█</td></tr><tr><td>val_f1</td><td>▁▁▁▁▇▇▆▇▇▇▇▇▇▆▇█▇▇▇▇▇▇▇▇▇▇██▇▇▇▇▇▇▇▇▇▇▇█</td></tr><tr><td>val_loss_epoch</td><td>▆▇▇▆▄▃▂▃▃▅▃▄▄▁▂▃▂▄▅▅▅▃▂▁▅▂▃▄█▆▄█▄▄▄▂▃▂▄▄</td></tr><tr><td>val_loss_step</td><td>▄▄▄▅▃▃▁▃▃▁▃▄▃▃▂▃▃▄▄▄▃▃▁▄▃▁▃▄█▃▂▃▃▃▃▃▃▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.71676</td></tr><tr><td>train_auc</td><td>0.67821</td></tr><tr><td>train_f1</td><td>0.57759</td></tr><tr><td>train_loss_epoch</td><td>0.58804</td></tr><tr><td>train_loss_step</td><td>0.71347</td></tr><tr><td>trainer/global_step</td><td>899</td></tr><tr><td>val_acc</td><td>0.70769</td></tr><tr><td>val_auc</td><td>0.68433</td></tr><tr><td>val_f1</td><td>0.60825</td></tr><tr><td>val_loss_epoch</td><td>0.58113</td></tr><tr><td>val_loss_step</td><td>0.57048</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_MLP_2_32_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/txaleng7' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/txaleng7</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230705_025953-txaleng7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2b90fc23403480e98587f50a02dc24a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230705_032000-zdxoqooq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/zdxoqooq' target=\"_blank\">3D_MLP_2_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/zdxoqooq' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/zdxoqooq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | MLPModel         | 1.4 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "651df0b77f454790ac76a265f6fdb5e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▁▃▅▆▆▇▇▇▆▇▇▇▇▇▇█▇▇▇▇▇▇█▇▆▇▇█▇▇▇▇▇███▇▇</td></tr><tr><td>train_auc</td><td>▁▁▁▃▅▆▇▇▇▆▇▇▇▇█▇▇█▇▇▇▇▇▇▇▇▆▇▇██▇▇█▇███▇▇</td></tr><tr><td>train_f1</td><td>▁▁▁▄▆▇▇▇█▇█▇█▇█▇▇█▇██▇▇█▇█▆▇███▇██████▇▇</td></tr><tr><td>train_loss_epoch</td><td>██▇▆▅▄▄▃▃▄▄▂▄▃▃▂▂▃▃▃▃▂▃▂▂▂▂▂▃▂▃▃▂▂▃▃▁▃▂▂</td></tr><tr><td>train_loss_step</td><td>███▇▇▃▅▆▅▃▇▂▃▅▁▂▄▄▂▅▅▇▅▂▆▂▇▃▂▅▅▅▃▆▃▂▅▂▃▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▂▁▂▃▂▃▂▂▄▄▂▄▂▂▅▂▂▅▂▆▆▃▆▆▃▇▇▃▇█▃██▃</td></tr><tr><td>val_acc</td><td>▁▁▁▂▆▆▆▆▆▇▇▆▇▇▇▇▇▇█████▇█▇▇███▇▇▇▇█▇▇▇██</td></tr><tr><td>val_auc</td><td>▁▁▁▂▆▆▆▆▇▇▆▆▇▇█▇▇▇█▇██▇██▇▇██▇▆▆▇▇▇▇▇▇▇▇</td></tr><tr><td>val_f1</td><td>▁▁▁▂▇▇▇▇▇▇▇▇█▇███▇███████▇▇███▇▇▇▇█▇▇▇██</td></tr><tr><td>val_loss_epoch</td><td>▅▆▆▅▃▃▃▃▁▃▅█▄▆▃▃▂▂▁▄▂▅▆▆▅▄▂▅▃▇▄▂█▅▅▅▄▂▆▃</td></tr><tr><td>val_loss_step</td><td>▄▄▄▄▃▃▂▃▂▃▃█▃▃▂▃▃▁▃▃▃▃▅▃▃▃▃▃▂▃▂▃▃▅▃▃▄▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.70135</td></tr><tr><td>train_auc</td><td>0.66345</td></tr><tr><td>train_f1</td><td>0.55331</td></tr><tr><td>train_loss_epoch</td><td>0.58136</td></tr><tr><td>train_loss_step</td><td>0.60728</td></tr><tr><td>trainer/global_step</td><td>899</td></tr><tr><td>val_acc</td><td>0.73462</td></tr><tr><td>val_auc</td><td>0.69835</td></tr><tr><td>val_f1</td><td>0.61017</td></tr><tr><td>val_loss_epoch</td><td>0.56286</td></tr><tr><td>val_loss_step</td><td>0.53572</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_MLP_2_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/zdxoqooq' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/zdxoqooq</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230705_032000-zdxoqooq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3da87f1f43ac4422a3a456eb824d8acd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230705_034212-gwqdj2bp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/gwqdj2bp' target=\"_blank\">3D_MLP_2_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/gwqdj2bp' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/gwqdj2bp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | MLPModel         | 1.4 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b38acd72ccb5465a912dac38d316dd6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▅▄█▅▄▇▅▅▅▇▅▆▆▇▇▅▇▆▇▆▅█▆▆▆▇▆▆▆▇█▇▆▇▇▇</td></tr><tr><td>train_auc</td><td>▁▂▃▂▄▂▇▃▃▇▅▃▄▆▄▄▅▆▇▄▇▅▆▆▅█▅▆▆▆▅▅▆▇██▆▇▇▇</td></tr><tr><td>train_f1</td><td>▅▂▁▁▃▂▇▃▂▆▆▂▅▅▄▄▅▆▇▅▇▅▆▅▅▇▅▆▆▆▄▅▆▆▇█▆▆▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▄▃▃▂▃▃▃▂▃▃▃▃▂▃▂▄▃▅▂▁▃▁▂▃▁▃▃▃▄▂▂▁▂▂▄▂▂</td></tr><tr><td>train_loss_step</td><td>▅▆▆▅▆▆▄▅▄▆▄▆▄▃▂▄▆▅▇▆▄▄▄▇▃▂▅▄▃▄▄█▁▆▄▃▅▃▄▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▂▁▂▃▂▃▂▂▄▄▂▄▂▂▅▂▂▅▂▆▆▃▆▆▃▇▇▃▇█▃██▃</td></tr><tr><td>val_acc</td><td>██████████████▅▁▁▅▁▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_auc</td><td>▁▁▁▁▁▁▁▁▁▁▁▁██▆▁▁▆▁▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_f1</td><td>▁▁▁▁▁▁▁▁▁▁▃▁████████████████████████████</td></tr><tr><td>val_loss_epoch</td><td>▁▃▃▃▁▅▂▄▁▂▂▃▄▃▄▃▄▄▆▄▇▄▆▆▅▃█▅▃▅▆▇▃▅▇▆█▅▃▇</td></tr><tr><td>val_loss_step</td><td>▃▄▄▅▄▄▃▄▄▅▄▄▄▅▅▅▅▄▅▅▆▅▆▆▅▁▆▅▂▆█▆▆▂▆▆▆▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.62331</td></tr><tr><td>train_auc</td><td>0.57072</td></tr><tr><td>train_f1</td><td>0.3744</td></tr><tr><td>train_loss_epoch</td><td>0.6553</td></tr><tr><td>train_loss_step</td><td>0.67455</td></tr><tr><td>trainer/global_step</td><td>899</td></tr><tr><td>val_acc</td><td>0.37692</td></tr><tr><td>val_auc</td><td>0.5</td></tr><tr><td>val_f1</td><td>0.54749</td></tr><tr><td>val_loss_epoch</td><td>0.7566</td></tr><tr><td>val_loss_step</td><td>0.77074</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_MLP_2_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/gwqdj2bp' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/gwqdj2bp</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230705_034212-gwqdj2bp\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29360317640c4a14b7dabddd65fa6f88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230705_040258-2cnhnwsb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/2cnhnwsb' target=\"_blank\">3D_MLP_2_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/2cnhnwsb' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/2cnhnwsb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | MLPModel         | 1.4 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9505c3b8a33c4b9ca29052cc59bc7258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▃▃▅▄▆▆▆▅▅▆▇▇█▇▇▇▆▇▇█▇▇▇██▇███▇▇▇▇██▇██</td></tr><tr><td>train_auc</td><td>▁▂▃▃▄▂▄▅▅▄▅▆▇▆▇▇▆▆▅▇▇▇▆▇▇▇▇▇▇██▆▇▇▇███▇█</td></tr><tr><td>train_f1</td><td>▃▃▃▄▃▁▃▄▅▃▆▅▇▆▇▆▆▆▅▇▆▆▅▆▆▆▇▆▇▇█▆▇▇▇███▇█</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▂▂▂▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▂▁▂▃▂▃▂▂▄▄▂▄▂▂▅▂▂▅▂▆▆▃▆▆▃▇▇▃▇█▃██▃</td></tr><tr><td>val_acc</td><td>▁▂▄▄▂▃▅▆▄▄▄▅▇▆▆▇▇▇█▆█▇▇█▇▇▆██▆▆▇▆█▆▇▇▇▇█</td></tr><tr><td>val_auc</td><td>▁▃▅▃▂▃▅▆▄▃▃▄▆▆▆▇▆▆█▆▇▇▇▇▆▇▇█▇▆▅▇▆▇▆▆▆▆█▇</td></tr><tr><td>val_f1</td><td>▁▅▆▄▃▄▆▇▅▄▄▅▆▇▇▇▇▇█▆████▇▇███▇▆█▇█▆▇▇▇██</td></tr><tr><td>val_loss_epoch</td><td>█▂▂▂▁▂▂▂▁▁▂▂▂▂▁▂▂▁▁▂▁▂▂▂▂▂▁▂▁▂▂▁▃▂▂▂▁▁▂▂</td></tr><tr><td>val_loss_step</td><td>▅▅▅▅▅▅▄▅▄▄▅█▄▅▃▅▅▂▄▅▄▅▇▅▅▅▅▅▄▅▁▅▅█▅▅▄▄▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.70039</td></tr><tr><td>train_auc</td><td>0.67321</td></tr><tr><td>train_f1</td><td>0.58808</td></tr><tr><td>train_loss_epoch</td><td>0.60433</td></tr><tr><td>train_loss_step</td><td>0.61271</td></tr><tr><td>trainer/global_step</td><td>899</td></tr><tr><td>val_acc</td><td>0.75</td></tr><tr><td>val_auc</td><td>0.72077</td></tr><tr><td>val_f1</td><td>0.64481</td></tr><tr><td>val_loss_epoch</td><td>0.58087</td></tr><tr><td>val_loss_step</td><td>0.58466</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_MLP_2_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/2cnhnwsb' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/2cnhnwsb</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230705_040258-2cnhnwsb\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaa852c614f24e01b3fbda77790ed262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230705_042355-n9jqgzmu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/n9jqgzmu' target=\"_blank\">3D_MLP_2_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/n9jqgzmu' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/n9jqgzmu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | MLPModel         | 1.4 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7b6c89e112e437d8d55af03abc08af6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▂▂▆▅▆▆▆▇▆▇▆▆▆▇▇▇▇▇▆▇▆▇▇▇▅▆▇█▇▇▇▇▆▇▇▇▆▇</td></tr><tr><td>train_auc</td><td>▁▁▂▂▆▅▆▆▇▇▅▇▆▆▇▇▇▇▇▇▇▆▆▇█▇▇█▆█▇▆▇▇▆▇▇▇▇▇</td></tr><tr><td>train_f1</td><td>▂▁▂▃▇▆▇▇▇▇▆█▇▆▇▇█▇██▇▇▇▇█▇██▇█▇▇▇█▇▇▇▇▇█</td></tr><tr><td>train_loss_epoch</td><td>███▇▃▅▃▄▃▅▄▃▄▄▃▂▂▄▄▃▃▃▂▂▁▂▄▄▂▂▄▅▃▃▃▂▄▃▄▄</td></tr><tr><td>train_loss_step</td><td>▅▅▆▄█▃▂▃▄▄▂▃▃▃▂▂▂▄▃▁▄▁▄▁▂▄▅▃▃▇▃▂▆▄▄▄▂▄▃▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▂▁▂▃▂▃▂▂▄▄▂▄▂▂▅▂▂▅▂▆▆▃▆▆▃▇▇▃▇█▃██▃</td></tr><tr><td>val_acc</td><td>▁▁▁▂▃▃▃▅▂▆▆▅▆▆▅▆▆▅▅▅▆██▆▆▆▄▅█▆▆▆▇▆▇▇▆▆▆▆</td></tr><tr><td>val_auc</td><td>▁▁▁▂▂▃▃▅▂▅▅▄▅▅▄▅▅▄▄▄▅█▇▅▅▅▃▄▇▅▅▆▆▆▇▇▅▅▅▆</td></tr><tr><td>val_f1</td><td>▁▁▁▂▂▃▄▅▃▆▆▅▆▆▅▆▆▅▅▅▆█▇▆▆▆▄▅▇▆▆▆▇▆▇▇▆▆▆▆</td></tr><tr><td>val_loss_epoch</td><td>▅▅▅▅▃▅▄▁▄▃▃▃▃▃▃▂▄█▆▂▆▄▃▃▁▃▄▅▃▃▃▅▅▆▃▅▃▅▃▂</td></tr><tr><td>val_loss_step</td><td>▃▃▃▄▃▃▃▃▃▂▃▂▃▃▃▄▃█▃▃▃▃▂▃▃▂▃▃▂▃▁▃▃▆▃▃▂▃▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.68979</td></tr><tr><td>train_auc</td><td>0.67091</td></tr><tr><td>train_f1</td><td>0.5995</td></tr><tr><td>train_loss_epoch</td><td>0.60831</td></tr><tr><td>train_loss_step</td><td>0.6522</td></tr><tr><td>trainer/global_step</td><td>899</td></tr><tr><td>val_acc</td><td>0.70385</td></tr><tr><td>val_auc</td><td>0.63536</td></tr><tr><td>val_f1</td><td>0.47619</td></tr><tr><td>val_loss_epoch</td><td>0.51033</td></tr><tr><td>val_loss_step</td><td>0.36929</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_MLP_2_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/n9jqgzmu' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/n9jqgzmu</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230705_042355-n9jqgzmu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe3c742a1664ebd8093c3e4c60a339c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230705_044458-fxxesur1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/fxxesur1' target=\"_blank\">3D_MLP_2_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/fxxesur1' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/fxxesur1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | MLPModel         | 1.4 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "3.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.0 K     Total params\n",
      "0.012     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f468f4176894ea79bb4dca1e0b14a56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▁▂▄▄▆▇▆▇▇█▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇▇▇▇▇▇█▇▇▇▇</td></tr><tr><td>train_auc</td><td>▁▁▁▂▄▄▇█▆▇▇█▇▇█▇▇▆▆█▇▇▇█▇▇▇▇█▇▇█▇▇▇█▇▇▇▇</td></tr><tr><td>train_f1</td><td>▂▁▁▃▅▄▇█▇█▇██▇█▇█▇▆█▇▇▇█▇▇▇▇█▇▇█▇▇▇███▇█</td></tr><tr><td>train_loss_epoch</td><td>███▇▅▅▃▂▄▄▃▃▃▂▁▃▃▃▂▂▃▁▃▄▁▂▂▂▃▁▂▁▂▃▁▃▂▁▁▃</td></tr><tr><td>train_loss_step</td><td>████▆▅▄▇▅▆█▆▃▃▄▂▅▆▄▁▆▂▃▁▃▇▅▅▄▅▅▂▃▃▄▂▅▇▅▇</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▂▁▂▃▂▃▂▂▄▄▂▄▂▂▅▂▂▅▂▆▆▃▆▆▃▇▇▃▇█▃██▃</td></tr><tr><td>val_acc</td><td>▁▁▁▂▅▅▅▅▆▆▇█▆▇▆▇█▇▇▇█▇████▇█▆█▇█████████</td></tr><tr><td>val_auc</td><td>▁▁▁▂▄▅▅▅▆▆█▇▆▇▆█▇▇▆▆█▇▇▇█▇▇█▆█▆▇██████▇▇</td></tr><tr><td>val_f1</td><td>▁▁▁▂▅▆▆▆▇▆██▆█▇███▇▇█▇██████▇█▇▇████████</td></tr><tr><td>val_loss_epoch</td><td>▇█▇▆▄▂▃▃▃▇▂▇▂▂▂▃▆▂█▄▆▃▂▃▅▁█▄▃▆▁▇▃▃▅▂▂▅▁▇</td></tr><tr><td>val_loss_step</td><td>▄▄▄▅▄▃▃▄▄▁▄█▄▃▂▄▃▂▄▃▄▄▂▃▄▁▃▃▃▃█▃▃▃▃▃▂▃▄▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.6946</td></tr><tr><td>train_auc</td><td>0.66795</td></tr><tr><td>train_f1</td><td>0.58235</td></tr><tr><td>train_loss_epoch</td><td>0.59651</td></tr><tr><td>train_loss_step</td><td>0.65242</td></tr><tr><td>trainer/global_step</td><td>899</td></tr><tr><td>val_acc</td><td>0.73077</td></tr><tr><td>val_auc</td><td>0.69325</td></tr><tr><td>val_f1</td><td>0.60227</td></tr><tr><td>val_loss_epoch</td><td>0.67637</td></tr><tr><td>val_loss_step</td><td>0.88675</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_MLP_2_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/fxxesur1' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/fxxesur1</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230705_044458-fxxesur1\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d37dd050c84afd8e6225759616dc91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230705_050425-1kktu347</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/1kktu347' target=\"_blank\">3D_MLP_2_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/1kktu347' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/1kktu347</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | MLPModel         | 1.4 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b7f9781f5e47dca057120449bcd0ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▁▁▅▆▆▆▆▇▇▆▇▇▆▇▆▇▇▇▇▇▇▇█▇▇▇█▇▇▇▇▇▇▆▇▇▇▇</td></tr><tr><td>train_auc</td><td>▁▁▁▁▅▆▆▆▆▆▇▆▇▆▆▇▇▇▆▇▇▇▇▇█▇▇▇█▇▇▇█▇▆▅▆▆▆▆</td></tr><tr><td>train_f1</td><td>▁▁▁▁▆▇▇▇▇▇▇▇▇▇▆▇█▇▇▇█▇▇▇█▇▇▇█▇█▇█▇▇▅▆▆▇▆</td></tr><tr><td>train_loss_epoch</td><td>██▇▆▅▄▅▃▃▄▃▃▃▃▄▂▄▂▃▃▃▃▄▂▃▂▃▃▁▄▂▃▃▃▃▆▃▃▃▃</td></tr><tr><td>train_loss_step</td><td>▇▇▆▆▃▂█▄▃▅▃▅▅▁▁▂▂▃▃▃▄▃▁▁▄▅▃▅▁▄▄▁▄▄▄▂▃▃▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▂▁▂▃▂▃▂▂▄▄▂▄▂▂▅▂▂▅▂▆▆▃▆▆▃▇▇▃▇█▃██▃</td></tr><tr><td>val_acc</td><td>▁▁▁▁▇▆▇▆▇▆▆▇▆▇▇▆▆▇█▇▆▆▇▇▇▆▇▇▇█▇██▇▇▅▇▆▆▆</td></tr><tr><td>val_auc</td><td>▁▁▁▁▇▆▇▆▆▆▆▆▆▇▇▅▆▇█▆▆▆▇▆▇▆▆▆▆█▆██▆▆▅▆▆▆▆</td></tr><tr><td>val_f1</td><td>▁▁▁▁█▇▇▇▇▆▆▇▆█▇▆▇██▇▇▇▇▇▇▇▇▇▇█▇██▇▇▆▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>▅▅▅▄▄▂▃▄▁▆▃▃▃▂▂█▄▃▃▄▂▃▆▃▃▂▃▆▄▃▅▁▅▄▂▂▃▂▆█</td></tr><tr><td>val_loss_step</td><td>▃▃▃▂▃▃▂▃▃▃▃▃▃▃▁▃▃▂▃▃▃▃▅▃▃▁▂▃▃▃▃▃▃▄▃▃▃▃▃█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.69201</td></tr><tr><td>train_auc</td><td>0.63482</td></tr><tr><td>train_f1</td><td>0.47195</td></tr><tr><td>train_loss_epoch</td><td>0.58627</td></tr><tr><td>train_loss_step</td><td>0.56778</td></tr><tr><td>trainer/global_step</td><td>899</td></tr><tr><td>val_acc</td><td>0.71429</td></tr><tr><td>val_auc</td><td>0.66942</td></tr><tr><td>val_f1</td><td>0.54321</td></tr><tr><td>val_loss_epoch</td><td>0.85458</td></tr><tr><td>val_loss_step</td><td>1.42028</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_MLP_2_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/1kktu347' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/1kktu347</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230705_050425-1kktu347\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98382a1a6716485f9c6b28c407003b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230705_052500-9kjyfq6e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/9kjyfq6e' target=\"_blank\">3D_MLP_2_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/9kjyfq6e' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/9kjyfq6e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | MLPModel         | 1.4 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb44328495f249a9843d6220bc9fc42a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▅▄▅▅▄▄▄█▄▆▅▅▇▇▆▆▇▇▆▇▇█▇▇▇▇▇▆█▆█▆██▆█</td></tr><tr><td>train_auc</td><td>▃▁▂▂▂▂▄▄▄▃▃▇▅▆▅▆▇▇▅▅▇▇▄▇▇█▇▇▅▆▇▆█▇▇▅▇▇▅▆</td></tr><tr><td>train_f1</td><td>▇▂▂▁▁▂▄▄▅▄▅▇▇▇▆██▇▅▅██▅▇██▇▇▅▇▇▆█▇▇▅▇▇▅▆</td></tr><tr><td>train_loss_epoch</td><td>██▅▅▆▆▅▄▅▅▄▃▅▄▄▃▄▄▄▄▃▄▄▂▃▁▄▂▃▄▄▄▃▃▃▅▃▄▃▂</td></tr><tr><td>train_loss_step</td><td>█▆▆▇▆▆▇▅▅▅▅█▅▃▇▄▅▄▆▅▃▃▄▃▃▆▅▇▃▅▅▃▃▄▅▂▅▇▄▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▂▁▂▃▂▃▂▂▄▄▂▄▂▂▅▂▂▅▂▆▆▃▆▆▃▇▇▃▇█▃██▃</td></tr><tr><td>val_acc</td><td>████████████████████████▁▁▅▅▁▁▁▁▁▁▁▁▁▅▅█</td></tr><tr><td>val_auc</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁█████▁█████▁▁▆▆▁▁▁▁▁▁▁▁▁▆▆█</td></tr><tr><td>val_f1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁█████▁█████████████████████</td></tr><tr><td>val_loss_epoch</td><td>▆▃▃▁▃▃▃▄▂▅▃▄▃▄▄▄▄▂▄▄▄▄▄▄▅▅▄▃▄▄▄▅█▆▃▅▅▅▄▄</td></tr><tr><td>val_loss_step</td><td>▆▅▆▁▆▆▆▅▆▅▆█▆▆▇▅▆▄▆▆▆▆▇▆▇█▇▇▅▇▇▇▇▇▇▇▇▆▇▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.63138</td></tr><tr><td>train_auc</td><td>0.5536</td></tr><tr><td>train_f1</td><td>0.25341</td></tr><tr><td>train_loss_epoch</td><td>0.63786</td></tr><tr><td>train_loss_step</td><td>0.59082</td></tr><tr><td>trainer/global_step</td><td>899</td></tr><tr><td>val_acc</td><td>0.59459</td></tr><tr><td>val_auc</td><td>0.6214</td></tr><tr><td>val_f1</td><td>0.61255</td></tr><tr><td>val_loss_epoch</td><td>0.68706</td></tr><tr><td>val_loss_step</td><td>0.68556</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_MLP_2_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/9kjyfq6e' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/9kjyfq6e</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230705_052500-9kjyfq6e\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "327f0120676441a7a112bb186456995f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666592937, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230705_054614-tn3l2dun</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/tn3l2dun' target=\"_blank\">3D_MLP_2_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/tn3l2dun' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/tn3l2dun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | MLPModel         | 1.4 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c2d6b0d5c442b59d2ef85fad4c6373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▃▄▄▅▄▅▆▆▆▅▆▇▇▇▆▇▇▇▆▇▇▇█▇▇▇█▇█▇▆▇▆▆█▆█▇</td></tr><tr><td>train_auc</td><td>▁▁▃▃▃▄▄▄▅▅▆▅▇▇▇▇▇▆▇▇▆▇▇▇██▇▆█▇█▇▆▆▅▅█▅█▇</td></tr><tr><td>train_f1</td><td>▃▃▄▁▂▄▃▃▅▄▅▅▇▇▇▇█▆▆▇▇▆▆█▇██▅▇▇▇▆▇▅▃▂▇▂█▅</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▂▁▂▃▂▃▂▂▄▄▂▄▂▂▅▂▂▅▂▆▆▃▆▆▃▇▇▃▇█▃██▃</td></tr><tr><td>val_acc</td><td>▁▂▂▅▃▆▄▄▅▅▅▅▅▇▇▆▅█▇█▇▆█▆▇▅▇▇██▇█▇▇▇▆▇▇▇▆</td></tr><tr><td>val_auc</td><td>▁▂▂▅▃▆▃▄▅▄▄▅▅▆▇▅▅▇▇▇▆▆█▆▇▅▇▆▇▇▇█▆▇▆▆▇▇▆▆</td></tr><tr><td>val_f1</td><td>▁▂▂▆▄▇▄▅▅▅▅▅▅▇▇▆▅███▇▆█▆▇▅▇▇█▇▇█▇▇▇▆▇█▇▆</td></tr><tr><td>val_loss_epoch</td><td>▄▂▃▃▂▂▂▄▁▅▃▃▂▂▁█▄▂▂▂▁▂▄▂▂▁▂▅▃▃▃▁▃▃▂▃▂▂▅▆</td></tr><tr><td>val_loss_step</td><td>▄▃▃▃▃▃▂▃▃▃▃▄▃▃▁▃▃▂▃▃▃▃▄▃▃▁▃▃▃▃▄▃▃▃▃▃▃▃▃█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.69105</td></tr><tr><td>train_auc</td><td>0.63519</td></tr><tr><td>train_f1</td><td>0.47635</td></tr><tr><td>train_loss_epoch</td><td>0.60384</td></tr><tr><td>train_loss_step</td><td>0.57594</td></tr><tr><td>trainer/global_step</td><td>899</td></tr><tr><td>val_acc</td><td>0.7027</td></tr><tr><td>val_auc</td><td>0.65402</td></tr><tr><td>val_f1</td><td>0.50955</td></tr><tr><td>val_loss_epoch</td><td>0.86778</td></tr><tr><td>val_loss_step</td><td>1.46035</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_MLP_2_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/tn3l2dun' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/tn3l2dun</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230705_054614-tn3l2dun\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "989445f6fe2f4a5e9e43f5419541ddad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230705_060707-z520i2bz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/z520i2bz' target=\"_blank\">3D_MLP_2_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/z520i2bz' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/z520i2bz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | MLPModel         | 1.4 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a739f570a25f411cb51d7a713d5162f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▁▁▄▆▅▆▅▆▆▇▇▇▆▇▆▆▆▇▅█▇█▇▇▇▆▇█▇▇▆▆▆▆▇▆▇▇</td></tr><tr><td>train_auc</td><td>▁▁▁▁▄▆▆▇▅▅▇▇▇▇▆█▆▇▇▇▅█▆█▇▇▇▇███▇▇▇▆▇▇▆█▇</td></tr><tr><td>train_f1</td><td>▁▁▁▁▅▇▆▇▇▆▇▇▇█▆█▆▇▇▇▅█▇█▇▇▇▇█████▇▇▇▇▆█▇</td></tr><tr><td>train_loss_epoch</td><td>████▅▅▄▂▄▄▄▂▃▄▄▂▄▃▂▄▃▅▃▂▃▃▃▂▃▃▄▁▃▂▂▃▃▃▁▂</td></tr><tr><td>train_loss_step</td><td>▇▇█▅▅▅▅▅▆▄▆▆▃▁▄▇▆▃▄▄▄▃▄▃▃▃▃▅▄▃▄▇▃▃██▆▄▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▂▁▂▃▂▃▂▂▄▄▂▄▂▂▅▂▂▅▂▆▆▃▆▆▃▇▇▃▇█▃██▃</td></tr><tr><td>val_acc</td><td>▁▁▁▁▃▅▅▅▆▆▅▆▇▆▆▄█▄▆▆▆▆▇▇▇▆▇▇▄▆▅▄▅▇▇▇▇█▇█</td></tr><tr><td>val_auc</td><td>▁▁▁▁▃▅▅▅▆▆▅▆▇▆▆▄█▄▆▆▆▆▆▇▇▆▆▆▄▅▅▄▅▇▇▇▆█▆█</td></tr><tr><td>val_f1</td><td>▁▁▁▁▄▅▆▅▆▇▅▆▇▆▇▅█▅▇▇▆▇▇▇▇▆▇▇▅▆▅▅▅▇▇▇▇█▇█</td></tr><tr><td>val_loss_epoch</td><td>█▅▅▇▄▂▃▅▃▆▅▄▂▃▃▂▁▂▃▂▃█▃▄▂▃▄▄▅▂▄▂▂▁▂▂▄▃▂▁</td></tr><tr><td>val_loss_step</td><td>▆▆▆█▆▅▅▆▆▁▆▅▆▆▄▇▆▂▆▆▆▅▄▅▅▄▆▅▆▅▆▇▆▁▅▅▆▅▆▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.6949</td></tr><tr><td>train_auc</td><td>0.65249</td></tr><tr><td>train_f1</td><td>0.53451</td></tr><tr><td>train_loss_epoch</td><td>0.58405</td></tr><tr><td>train_loss_step</td><td>0.52347</td></tr><tr><td>trainer/global_step</td><td>899</td></tr><tr><td>val_acc</td><td>0.71429</td></tr><tr><td>val_auc</td><td>0.67634</td></tr><tr><td>val_f1</td><td>0.56977</td></tr><tr><td>val_loss_epoch</td><td>0.47172</td></tr><tr><td>val_loss_step</td><td>0.25232</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_MLP_2_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/z520i2bz' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/z520i2bz</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230705_060707-z520i2bz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1702bb496694cbf8dd56923b5e0b53a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230705_062724-n9uufl09</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/n9uufl09' target=\"_blank\">3D_MLP_2_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/n9uufl09' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/n9uufl09</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | MLPModel         | 1.4 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "3.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.0 K     Total params\n",
      "0.012     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c25696bc614440a4759c477b2cc55c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▁▂▇▆▇▆▆▆▇▇█▆▇▇▇▆▇▇█▇▇▇▆▆▇██▇█▇▇▇█▆▇█▇▇</td></tr><tr><td>train_auc</td><td>▁▁▁▂▆▆▆▆▆▆▆▇▇▆▆▆▇▆▇▇▇▇▆▇▅▆▇▇▇▇▇▆█▇▇▆▇▇▇▇</td></tr><tr><td>train_f1</td><td>▁▁▁▂▇▇▇▇▇▆▇▇▇▆▇▇▇▇▇▇▇▇▇█▆▆▇▇▇▇█▇█▇▇▆▇▇▇▇</td></tr><tr><td>train_loss_epoch</td><td>██▇▇▃▃▃▃▅▅▃▁▃▃▁▂▂▂▂▃▁▁▃▄▃▂▄▂▂▂▁▃▄▂▂▅▃▂▂▂</td></tr><tr><td>train_loss_step</td><td>▆▇▆█▆▇▅▃▃▃▃▁▂▄▂▃▄▄▂▄▄▂▃▃▅▃▃▃▂▆▇▂▃▄▁▅▄▂▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▂▁▂▃▂▃▂▂▄▄▂▄▂▂▅▂▂▅▂▆▆▃▆▆▃▇▇▃▇█▃██▃</td></tr><tr><td>val_acc</td><td>▁▁▁▁▄▄▅▆▆▆▅▆▆▆▆▆▆▆▆▆▆▅▆▆▇▅▅▆█▆▅█▆██▇█▇▇█</td></tr><tr><td>val_auc</td><td>▁▁▁▁▄▄▅▆▆▆▅▆▆▆▆▆▆▆▆▆▆▅▆▆█▅▅▆█▆▅█▆██▇█▇▇█</td></tr><tr><td>val_f1</td><td>▁▁▁▁▅▅▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▆▇▇█▆▆▇█▇▆█▇████▇▇█</td></tr><tr><td>val_loss_epoch</td><td>▄▅▅▅▂▆▃▂▄▃▂▁▂▃▂▂▄▂▁▃▄▁▃▂▄▄▆▂▃▂█▄▆▁▂▄▄▅▄▂</td></tr><tr><td>val_loss_step</td><td>▇▇▇█▆▆▅▅▆▆▆▁▅▅▄▆▅▄▅▆▆▆▄▆▅█▆▅▄▅▆▆▅▁▆▅█▆▅▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.7026</td></tr><tr><td>train_auc</td><td>0.65775</td></tr><tr><td>train_f1</td><td>0.53673</td></tr><tr><td>train_loss_epoch</td><td>0.58734</td></tr><tr><td>train_loss_step</td><td>0.58017</td></tr><tr><td>trainer/global_step</td><td>899</td></tr><tr><td>val_acc</td><td>0.74131</td></tr><tr><td>val_auc</td><td>0.72288</td></tr><tr><td>val_f1</td><td>0.66332</td></tr><tr><td>val_loss_epoch</td><td>0.52222</td></tr><tr><td>val_loss_step</td><td>0.40846</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_MLP_2_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/n9uufl09' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/n9uufl09</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230705_062724-n9uufl09\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c9b91c9063640ecaeb17803b4e13c9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230705_064720-zeatg92b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/zeatg92b' target=\"_blank\">3D_MLP_2_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/zeatg92b' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/zeatg92b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | MLPModel         | 1.4 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c3fcdb3eb9043b789559d633e4f1224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▁▁▄▆▄▆▇▆▇▇▇▆▆▇▇▆▅▇▇▆▇▇▇▇▇▆█▇▇▆▇▇▇▆▆▆▇▆</td></tr><tr><td>train_auc</td><td>▁▁▁▁▃▆▅▆▇▇▇▇█▆▆██▇▅▆▇▇▆█▇▇▇▆█▇▇▇█▇▇▅▆▆▇▆</td></tr><tr><td>train_f1</td><td>▁▁▁▁▄▇▇▇▇▇▇▇█▆▇██▇▆▇█▇▇█▇█▇▆█▇▇▇█▇▇▆▇▇▇▇</td></tr><tr><td>train_loss_epoch</td><td>██▇▆▅▄▅▂▂▃▃▃▃▃▃▂▃▃▃▂▂▂▃▂▂▁▄▂▂▃▂▂▂▃▂▄▃▃▁▂</td></tr><tr><td>train_loss_step</td><td>██▇▇▅▅▆▅▇▄▃▃▅▁▃▂▁▃▄▄▃▇▅▅▃▆▃▆▁▃▅▃█▆▃▃▃▆▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▂▁▂▃▂▃▂▂▄▄▂▄▂▂▅▂▂▅▂▆▆▃▆▆▃▇▇▃▇█▃██▃</td></tr><tr><td>val_acc</td><td>▁▁▁▁▇▆▅▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇█▇▇█▇▇▇▇▇▇▇▇▇▇█▇█</td></tr><tr><td>val_auc</td><td>▁▁▁▁▇▇▅▇█▇▇▇▇█▇▇██▇█▇▇█████▇██▇█████████</td></tr><tr><td>val_f1</td><td>▁▁▁▁▇▇▅▇█▇▇▇▇█▇▇▇█▇█▇██████▇██▇████████▇</td></tr><tr><td>val_loss_epoch</td><td>█▆▆▄▄▅▄▄▅▆▃▄▂▂▄▇▅▃▂▅▃▄▄▅▃▃▃█▅▅▃▂▂▄▃▄▅▁▂▆</td></tr><tr><td>val_loss_step</td><td>▅▅▅▁▄▄▄▃▃▂▃▄▃▃▄▂▃▂▃▃▂▂▅▃▃▃▃▃█▃▂▃▃▄▃▃▆▄▃█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.69105</td></tr><tr><td>train_auc</td><td>0.63471</td></tr><tr><td>train_f1</td><td>0.48309</td></tr><tr><td>train_loss_epoch</td><td>0.58205</td></tr><tr><td>train_loss_step</td><td>0.52266</td></tr><tr><td>trainer/global_step</td><td>899</td></tr><tr><td>val_acc</td><td>0.71042</td></tr><tr><td>val_auc</td><td>0.68043</td></tr><tr><td>val_f1</td><td>0.56647</td></tr><tr><td>val_loss_epoch</td><td>0.66377</td></tr><tr><td>val_loss_step</td><td>0.84111</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_MLP_2_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/zeatg92b' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/zeatg92b</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230705_064720-zeatg92b\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a383bd5262944ee9f4384c1fa401e74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230705_070653-lwv0uhan</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/lwv0uhan' target=\"_blank\">3D_MLP_2_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/lwv0uhan' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/lwv0uhan</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | MLPModel         | 1.4 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44d5508b5a1d4e4780c10b8ad2d47873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▆▅▅▅▅▅▅▅▅▅▆▆▆▆▅▆▅▆▇▆▆▇▆▆▇▆█▆▄▆▅▆▇▆▆▆█▆</td></tr><tr><td>train_auc</td><td>▂▁▃▂▂▂▂▂▂▃▃▃▅▄▄▄▃▄▃▄▇▅▃▆▄▅▆▄▇▄▃▄▅▄▆▃▂▄█▄</td></tr><tr><td>train_f1</td><td>█▂▂▁▁▁▁▁▂▂▃▄▅▅▄▅▄▅▃▄▇▇▂▆▅▅▆▄▆▄▅▄▇▅▇▃▁▃█▄</td></tr><tr><td>train_loss_epoch</td><td>█▇▄▅▅▆▅▄▅▄▅▅▄▄▃▃▅▄▃▄▃▃▄▃▅▂▄▂▃▃▄▃▄▃▄▅▅▄▁▃</td></tr><tr><td>train_loss_step</td><td>▆▅▄▅▄▅▅▄▄▄▄▅▄▂▄▄▃▄▅▅▄▄▄▃▄▆▄█▃▄▅▃▄▄▄▁▃▄▂▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▂▁▂▃▂▃▂▂▄▄▂▄▂▂▅▂▂▅▂▆▆▃▆▆▃▇▇▃▇█▃██▃</td></tr><tr><td>val_acc</td><td>▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▅▆▇▇▆▁▁▁▁▅▁▁▁▁▁▁▇▆▁▁</td></tr><tr><td>val_auc</td><td>▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▇▂▇▆▇▂▇▇▁▂▂▂▆▂▂▂▂▂▂▂█▂▂</td></tr><tr><td>val_f1</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▆▁▇██▁▇████████████▁███</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▁▃▃▃▄▂▄▃▄▃▃▃▄▃▃▃▄▄▃▃▃▃▄▃▃▃▃▃▃▅▅▂▄▃▄▄▃</td></tr><tr><td>val_loss_step</td><td>▆▅▆▁▆▆▅▆▆▅▆▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▆▅▆▇▆▆██▆▆▆▆▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.61213</td></tr><tr><td>train_auc</td><td>0.52192</td></tr><tr><td>train_f1</td><td>0.15514</td></tr><tr><td>train_loss_epoch</td><td>0.65529</td></tr><tr><td>train_loss_step</td><td>0.6781</td></tr><tr><td>trainer/global_step</td><td>899</td></tr><tr><td>val_acc</td><td>0.44015</td></tr><tr><td>val_auc</td><td>0.5</td></tr><tr><td>val_f1</td><td>0.61126</td></tr><tr><td>val_loss_epoch</td><td>0.67212</td></tr><tr><td>val_loss_step</td><td>0.61448</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_MLP_2_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/lwv0uhan' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/lwv0uhan</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230705_070653-lwv0uhan\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c701b7d318404f9187bd5d0786eaf94e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230705_073056-5ogvtj1f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/5ogvtj1f' target=\"_blank\">3D_MLP_2_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/5ogvtj1f' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/5ogvtj1f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | MLPModel         | 1.4 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b31a1567ee3e48ec96ddfd865a1a1018",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▂▄▄▄▅▅▆▆▆▇▆▆▇▇▇▆▇▇▇▇▇▇██▇█▇▇▇▇▇▆▇▇▇▇▇▇</td></tr><tr><td>train_auc</td><td>▁▃▂▃▃▂▄▃▅▅▅▆▇▆▆█▇▆▇▆▇▇▆▇██▇█▇▆▇▇█▆▆▆▇▇█▇</td></tr><tr><td>train_f1</td><td>▃▅▄▃▁▁▃▁▅▅▄▆▇▆▆▇▇▆▇▄▇▇▆▇██▆▇▇▅▇▆█▅▆▄▇▆█▆</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▂▂▂▂▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▂▁▁▁▁▁▁▂▂▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▂▁▂▃▂▃▂▂▄▄▂▄▂▂▅▂▂▅▂▆▆▃▆▆▃▇▇▃▇█▃██▃</td></tr><tr><td>val_acc</td><td>▂▂▁▁▁▃▂▂▅▅▅▆▆▆▇▅▆▇▇█▇▇█▇▇▆▇▇▇▇▇▇█▇▇▇▇▇▇█</td></tr><tr><td>val_auc</td><td>▂▂▁▁▁▃▂▂▅▄▅▆▅▆▆▅▅▇▇█▇▇█▆▇▅▇▇▇▇▇█▇▆█▇▇▇▇█</td></tr><tr><td>val_f1</td><td>▃▂▁▂▁▄▂▂▅▄▅▆▆▆▆▅▆▇▇█▇▇█▇▇▆▇█▇▇▇█▇▆█▇▇▇▇█</td></tr><tr><td>val_loss_epoch</td><td>█▅▄▄▄▅▄▅▃▇▃▅▃▄▄▆▄▄▂▅▄▄▄▅▃▄▃▅▆▆▃▂▂▄▃▅▅▁▂▄</td></tr><tr><td>val_loss_step</td><td>█▃▃▁▃▃▂▃▃▂▂▄▃▂▂▂▃▂▂▂▂▂▄▂▂▃▂▃▇▂▂▃▃▂▃▂▅▃▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.68912</td></tr><tr><td>train_auc</td><td>0.6306</td></tr><tr><td>train_f1</td><td>0.47136</td></tr><tr><td>train_loss_epoch</td><td>0.59308</td></tr><tr><td>train_loss_step</td><td>0.47113</td></tr><tr><td>trainer/global_step</td><td>899</td></tr><tr><td>val_acc</td><td>0.7027</td></tr><tr><td>val_auc</td><td>0.68666</td></tr><tr><td>val_f1</td><td>0.62069</td></tr><tr><td>val_loss_epoch</td><td>0.62036</td></tr><tr><td>val_loss_step</td><td>0.68616</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_MLP_2_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/5ogvtj1f' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/5ogvtj1f</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230705_073056-5ogvtj1f\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af7eaea42db143a3af802aee0d885e29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230705_075331-nk3oabqc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/nk3oabqc' target=\"_blank\">3D_MLP_2_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/nk3oabqc' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/nk3oabqc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | MLPModel         | 1.4 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "2.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.0 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60e49fa92fab4cf6908aae2cdbb608d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▁▁▄▆▅▆▄▄▆▇▆▆▆▇▆▇▇▆▇▇▇▇▇█▇▆▇▇█▇▇▇▇██▇▇▇</td></tr><tr><td>train_auc</td><td>▁▁▁▁▄▆▅▆▄▄▆▇▆▇▅█▇▇▇▇▇▇▇▇▇█▇▆▇▇███▇▇█▇▆▇▇</td></tr><tr><td>train_f1</td><td>▁▁▁▁▅▆▆▆▄▅▇█▇▇▆█▇▇▇▇▇▇▇▇██▇▇▇█████▇█▇▇▇█</td></tr><tr><td>train_loss_epoch</td><td>████▄▄▅▃▄▄▄▃▃▄▃▃▄▂▃▄▃▄▃▁▄▃▃▃▃▃▃▁▁▂▂▂▂▂▃▃</td></tr><tr><td>train_loss_step</td><td>▇▇█▅▅▅▄▄▆▃▄▂▃▄▄▅▄▂▄▃▅▁▄▃▃▃▃▃█▄▆▄▄▂▆▆▇▅▅▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▂▁▂▃▂▃▂▂▄▄▂▄▂▂▅▂▂▅▂▆▆▃▆▆▃▇▇▃▇█▃██▃</td></tr><tr><td>val_acc</td><td>▁▁▁▁▄▅▆▅▅▄▅▅▇▆▆▅▇▆▇▆▇▇▆▇▆▆▆▇▇▇▆▅▆▆█▆▇█▅▇</td></tr><tr><td>val_auc</td><td>▁▁▁▁▄▅▆▅▄▄▅▅█▆▆▄▇▆▇▆▇▇▆▇▆▆▇▇▇▇▆▅▆▆█▆▇█▅▇</td></tr><tr><td>val_f1</td><td>▁▁▁▁▅▆▆▆▅▄▅▅█▆▇▅▇▆█▆▇▇▇▇▇▆█▇▇▇▇▅▇▆█▇▇█▆▇</td></tr><tr><td>val_loss_epoch</td><td>█▅▅▇▃▃▅▄▄▅▄▃▅▃▄▂▃▂▄▄▃▄▅▄▁▆▄▂▅▁▁▁▁▃▂▆▁▆▃▁</td></tr><tr><td>val_loss_step</td><td>▅▄▄▅▄▄▅▄▄▂▄▂▄▄▄▄▄▂▄▄▄▄▅▃▄▆▃▄▅▄█▄▄▃▄▄▁▄▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.70452</td></tr><tr><td>train_auc</td><td>0.65973</td></tr><tr><td>train_f1</td><td>0.54383</td></tr><tr><td>train_loss_epoch</td><td>0.59584</td></tr><tr><td>train_loss_step</td><td>0.61107</td></tr><tr><td>trainer/global_step</td><td>899</td></tr><tr><td>val_acc</td><td>0.69884</td></tr><tr><td>val_auc</td><td>0.66633</td></tr><tr><td>val_f1</td><td>0.53571</td></tr><tr><td>val_loss_epoch</td><td>0.47791</td></tr><tr><td>val_loss_step</td><td>0.25399</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_MLP_2_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/nk3oabqc' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/nk3oabqc</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230705_075331-nk3oabqc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aecd49d878d49d4983df3fcfcc53c6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>Y:\\coskun-lab\\Thomas\\15_PLA\\notebooks\\wandb\\run-20230705_081633-zfv63y4k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/zfv63y4k' target=\"_blank\">3D_MLP_2_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/zfv63y4k' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/zfv63y4k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | MLPModel         | 1.4 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "3.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.0 K     Total params\n",
      "0.012     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1db3ebb2e0234ec2ad419cf77b3356d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▁▂▅▇█▆▆▆▇▇▆▆▇▇▆▇▆▇▇▇▇█▆▆█▇▆▇▆▇▇▇▇▆▇▇▇▆</td></tr><tr><td>train_auc</td><td>▁▁▁▂▆▇█▆▆▆▇█▇▆▆▇▆█▇▇▇▇▇█▅▇█▇▆▇█▇█▇▇▆▇█▇▆</td></tr><tr><td>train_f1</td><td>▁▁▁▃▇▇█▆▇▇▇█▇▆▇▇▇█▇▇▇▇▇█▆▇█▇▆▇█▇█▇▇▇▇█▇▇</td></tr><tr><td>train_loss_epoch</td><td>██▇▆▂▁▃▃▄▂▂▂▃▂▂▃▂▃▃▁▂▂▁▂▃▁▁▁▂▂▂▃▃▁▃▃▂▂▂▁</td></tr><tr><td>train_loss_step</td><td>▇█▇█▆▅▇▃▅▃▅▃▁▆█▆▄▇▆▁▁▆▄▅▄█▄▄▂▄▆▅▄▇▂▃▇▅▆▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▁▂▂▁▂▃▂▃▂▂▄▄▂▄▂▂▅▂▂▅▂▆▆▃▆▆▃▇▇▃▇█▃██▃</td></tr><tr><td>val_acc</td><td>▁▁▁▃▅▅▆▇▆▇▇▇▇█▇▇▇▆▇█▇▇▇█████▇▇█▇▇▆▇▇▇▇▇▇</td></tr><tr><td>val_auc</td><td>▁▁▁▃▅▅▆█▇█▇█▇████▆▇█▇▇██████▇██▇█▇▇▇█▇██</td></tr><tr><td>val_f1</td><td>▁▁▁▃▅▆▆███▇▇▇▇███▆▇█▇▇█▇██▇▇██▇▇██▇▇█▇██</td></tr><tr><td>val_loss_epoch</td><td>▅▆▆▆▅▅▂▃▃▄▃█▄▃▃▄▄▄▁▅▄▃▃▂▅▅▆▁▄▃▅▃▆▄▆▄▃▆▄▄</td></tr><tr><td>val_loss_step</td><td>▅▅▅▅▄▄▁▄▄▃▄█▃▄▃▃▄▄▄▄▄▃▃▄▃▅▄▃▃▃▁▄▄▄▄▃▃▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.69586</td></tr><tr><td>train_auc</td><td>0.64205</td></tr><tr><td>train_f1</td><td>0.5</td></tr><tr><td>train_loss_epoch</td><td>0.58055</td></tr><tr><td>train_loss_step</td><td>0.55448</td></tr><tr><td>trainer/global_step</td><td>899</td></tr><tr><td>val_acc</td><td>0.70656</td></tr><tr><td>val_auc</td><td>0.68542</td></tr><tr><td>val_f1</td><td>0.60417</td></tr><tr><td>val_loss_epoch</td><td>0.58124</td></tr><tr><td>val_loss_step</td><td>0.59627</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">3D_MLP_2_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/zfv63y4k' target=\"_blank\">https://wandb.ai/thoomas/PLA_070323_9PPI_v2_Kfold/runs/zfv63y4k</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230705_081633-zfv63y4k\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### MLP\n",
    "\n",
    "k_folds = 5\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_ids, valid_ids) in enumerate(kfold.split(dataset_filtered)):\n",
    "    train_subset = dataset_filtered.index_select(train_ids.tolist())\n",
    "    val_subset = dataset_filtered.index_select(valid_ids.tolist())\n",
    "    \n",
    "    for pool in pools:\n",
    "        # Path to the folder where the pretrained models are saved\n",
    "        CHECKPOINT_PATH = checkpoint_folder / f'3D_{NUM_LAYERS}_{HIDDEN_CHANNELS}_onehot_{fold}' / pool\n",
    "        CHECKPOINT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Skip already trained kfold and pool\n",
    "        checkpoint = CHECKPOINT_PATH / \"GraphLevelMLP\" / \"GraphLevelMLP.ckpt\" \n",
    "        if checkpoint.exists():\n",
    "            print(checkpoint)\n",
    "            continue\n",
    "        \n",
    "        # Run training\n",
    "        run = wandb.init(project=project_name, name=f'3D_MLP_{NUM_LAYERS}_{HIDDEN_CHANNELS}_onehot_{fold}', \n",
    "                        group=f'3D_MLP_{pool}')\n",
    "        PPIGraph.train_graph_classifier_kfold('MLP', \n",
    "                                             train_subset, \n",
    "                                             val_subset, \n",
    "                                             dataset, \n",
    "                                             CHECKPOINT_PATH, \n",
    "                                             AVAIL_GPUS, \n",
    "                                             in_channels=9,\n",
    "                                             hidden_channels=HIDDEN_CHANNELS, \n",
    "                                             out_channels = HIDDEN_CHANNELS,\n",
    "                                             num_layers=NUM_LAYERS, \n",
    "                                             epochs=epochs,\n",
    "                                             batch_size=128,\n",
    "                                             embedding=False,\n",
    "                                             graph_pooling=pool)\n",
    "        run.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732e858c-05a3-4b76-9236-25731b15d198",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:snowflake]",
   "language": "python",
   "name": "conda-env-snowflake-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
