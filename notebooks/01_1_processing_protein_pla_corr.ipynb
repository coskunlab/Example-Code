{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "570bba47-b9b6-424a-822e-4267faf7973e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.io\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import trange, tqdm, tqdm_notebook\n",
    "from joblib import Parallel, delayed\n",
    "import re\n",
    "import h5py\n",
    "import tifffile as tiff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cb8afe3-2a25-434c-81b4-633c54715da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13e38472-13de-4396-be3b-b105259cec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = (Path().cwd().parents[0] / 'data').absolute()\n",
    "data_processed = data_dir / 'processed'\n",
    "data_raw = r'Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\Protein baseline vs PLA'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e858677-cb7e-47bb-a6b6-034b28f0776a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Get info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0750f57d-e961-432e-936a-f6179fd51103",
   "metadata": {},
   "outputs": [],
   "source": [
    "markers_map = {\n",
    "    '2': {\n",
    "        1: 'DNA', \n",
    "        3: 'Cyclin D1',\n",
    "    },\n",
    "    '3': {\n",
    "        1: 'DNA', \n",
    "        3: 'CDK4',\n",
    "    },\n",
    "    '4': {\n",
    "        1: 'DNA', \n",
    "        3: 'SOX2',\n",
    "    },\n",
    "    '5': {\n",
    "        1: 'DNA', \n",
    "        3: 'Oct4',\n",
    "    },\n",
    "    '6': {\n",
    "        1: 'DNA', \n",
    "        3: 'CycD1/CDK4',\n",
    "    },\n",
    "    '7': {\n",
    "        1: 'DNA', \n",
    "        3: 'Sox2/Oct4',\n",
    "    },\n",
    "    '8': {\n",
    "        1: 'DNA', \n",
    "        3: 'Wnt1/Tead',\n",
    "    },\n",
    "    'cycle2': {\n",
    "        1: 'DNA', \n",
    "        2: 'Concanavalin A',\n",
    "        3: 'Phalloidin',\n",
    "        4: 'WGA'\n",
    "    },\n",
    "    'cycle2_sec': {\n",
    "        1: 'DNA', \n",
    "        3: 'Wnt1',\n",
    "        4: 'Tead'\n",
    "    }\n",
    "}\n",
    "\n",
    "def get_info(data_raw, marker_dict):\n",
    "    conditions = []\n",
    "    fovs = []\n",
    "    cycles = []\n",
    "    channels = []\n",
    "    markers = []\n",
    "    paths = [] \n",
    "    \n",
    "    # Loop through image folder\n",
    "    for (dirpath, dirnames, filenames) in os.walk(data_raw):\n",
    "        if 'Dont use' in dirpath:\n",
    "            continue\n",
    "            \n",
    "        for name in sorted(filenames):\n",
    "            if \"tif\" in name and \"sti\" in name \\\n",
    "            and 'overlay' not in name \\\n",
    "            and 'Composite' not in name:\n",
    "                # Get information from image name\n",
    "                condition = 'Control' if filenames[-1][1] == 'B' else 'Treated'\n",
    "                well = filenames[-1][-1]\n",
    "                n_split = name.split('_')\n",
    "                \n",
    "                ch = int(n_split[-1][-5])\n",
    "                if 'Seg' in dirpath:\n",
    "                    cycle = 'cycle2'\n",
    "                    try: marker = marker_dict[cycle][ch] \n",
    "                    except: continue\n",
    "                    cycle = '2'\n",
    "                elif 'Second' in dirpath:\n",
    "                    cycle = 'cycle2_sec'\n",
    "                    try: marker = marker_dict[cycle][ch] \n",
    "                    except: continue\n",
    "                    cycle = '2'\n",
    "                else:\n",
    "                    cycle = well\n",
    "                    try: marker = marker_dict[cycle][ch] \n",
    "                    except: continue\n",
    "                    cycle = '1'\n",
    "        \n",
    "                conditions.append(condition)\n",
    "                fovs.append(well)\n",
    "                cycles.append(cycle)\n",
    "                channels.append(ch)\n",
    "                markers.append(marker)\n",
    "                paths.append(os.path.join(dirpath, name))\n",
    "                \n",
    "    info = {\n",
    "            \"Condition\": conditions,\n",
    "            \"FOV\": fovs,\n",
    "            \"Cycle\": cycles,\n",
    "            \"Channels\": channels,\n",
    "            \"Markers\": markers,\n",
    "            \"Path\": paths\n",
    "        }\n",
    "\n",
    "    df = pd.DataFrame(info)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "264d55c2-b405-4dfd-91b9-85fc2b4963e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created df\n"
     ]
    }
   ],
   "source": [
    "df_meta_path = data_dir / 'basline' / 'metadata' / 'info.csv'\n",
    "df_meta_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "df_exist = df_meta_path.is_file()\n",
    "\n",
    "if not df_exist:\n",
    "    print('Created df')\n",
    "    df = get_info(data_raw, markers_map)\n",
    "    df.to_csv(df_meta_path, index=False)\n",
    "else:\n",
    "    print('Loaded df')\n",
    "    df = pd.read_csv(df_meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "99f581a1-9e61-4642-85a2-9d35c4bc0a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loop through image folder\n",
    "# for (dirpath, dirnames, filenames) in os.walk(data_raw):\n",
    "#     for name in sorted(filenames):\n",
    "#         if \"tif\" in name and \"sti\" in name \\\n",
    "#         and 'overlay' not in name \\\n",
    "#         and 'Composite' not in name:\n",
    "#             print(name, filenames[-1])\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4e06062f-4f3f-4d4d-92e8-62b47311610f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Condition</th>\n",
       "      <th>FOV</th>\n",
       "      <th>Cycle</th>\n",
       "      <th>Channels</th>\n",
       "      <th>Markers</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Control</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>DNA</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Control</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Cyclin D1</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Control</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>DNA</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Control</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>CDK4</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Control</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>DNA</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Control</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Wnt1</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Control</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Tead</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Treated</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>DNA</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Treated</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Wnt1</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Treated</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Tead</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Condition FOV Cycle  Channels    Markers  \\\n",
       "0    Control   2     1         1        DNA   \n",
       "1    Control   2     1         3  Cyclin D1   \n",
       "2    Control   3     1         1        DNA   \n",
       "3    Control   3     1         3       CDK4   \n",
       "4    Control   4     1         1        DNA   \n",
       "..       ...  ..   ...       ...        ...   \n",
       "77   Control   8     2         3       Wnt1   \n",
       "78   Control   8     2         4       Tead   \n",
       "79   Treated   8     2         1        DNA   \n",
       "80   Treated   8     2         3       Wnt1   \n",
       "81   Treated   8     2         4       Tead   \n",
       "\n",
       "                                                 Path  \n",
       "0   Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  \n",
       "1   Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  \n",
       "2   Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  \n",
       "3   Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  \n",
       "4   Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  \n",
       "..                                                ...  \n",
       "77  Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  \n",
       "78  Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  \n",
       "79  Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  \n",
       "80  Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  \n",
       "81  Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  \n",
       "\n",
       "[82 rows x 6 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa481f6-c72b-433e-b57d-6e31ada632a9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Save HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3079f80f-1c6d-4d7f-9292-5960b1c44cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "def save_hdf5(\n",
    "    path: str, name: str, data: np.ndarray, attr_dict=None, mode: str = \"a\"\n",
    ") -> None:\n",
    "    # Read h5 file\n",
    "    hf = h5py.File(path, mode)\n",
    "    # Create z_stack_dataset\n",
    "    if hf.get(name) is None:\n",
    "        data_shape = data.shape\n",
    "        data_type = data.dtype\n",
    "        max_shape = (data_shape[0],) + data_shape[1:]\n",
    "        dset = hf.create_dataset(\n",
    "            name,\n",
    "            shape=data_shape,\n",
    "            maxshape=max_shape,\n",
    "            chunks=True,\n",
    "            dtype=data_type,\n",
    "            compression=\"gzip\",\n",
    "        )\n",
    "        dset[:] = data\n",
    "        if attr_dict is not None:\n",
    "            for attr_key, attr_val in attr_dict.items():\n",
    "                dset.attrs[attr_key] = attr_val\n",
    "    else:\n",
    "        print(f\"Dataset {name} exists\")\n",
    "\n",
    "    hf.close()\n",
    "\n",
    "def read_img(path):\n",
    "    return skimage.io.imread(path, as_gray=True)\n",
    "\n",
    "def joblib_loop(task, pics):\n",
    "    return Parallel(n_jobs=20)(delayed(task)(i) for i in pics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "efe7037c-29d7-402f-b1d5-c2f99846107a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created df\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c110209b4e47c2ae2972ad92273f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_imgs_path = data_dir / 'basline' / 'metadata' / 'imgs.csv'\n",
    "df_imgs_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "temp_path = data_dir  /'basline' /  'hdf5' / 'raw'\n",
    "temp_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_exist = df_imgs_path.is_file()\n",
    "\n",
    "\n",
    "if not df_exist:\n",
    "    print('Created df')\n",
    "    \n",
    "    group = df.groupby(['Condition', 'FOV'])\n",
    "    rows = []\n",
    "\n",
    "    for name, df_group in tqdm(group, total=len(group)):\n",
    "        file_name = '_'.join(np.array(name).astype(str)) + '.hdf5'\n",
    "        file_path = temp_path / file_name\n",
    "        rows.append(list(name)+[file_path])\n",
    "        \n",
    "        group_cycle = df_group.groupby('Cycle')\n",
    "        for cycle, df_cycle in group_cycle:\n",
    "            channels = df_cycle.Channels.to_list()\n",
    "            markers = df_cycle.Markers.to_list()\n",
    "            paths = df_cycle.Path.to_numpy()\n",
    "    \n",
    "            imgs = joblib_loop(read_img, paths)\n",
    "            imgs = np.array(imgs)\n",
    "            info = {\"Channels\": channels, \"Markers\": markers}\n",
    "            \n",
    "            # hdf5 as Channel -> Z mapping\n",
    "            save_hdf5(file_path, cycle, imgs, info)\n",
    "    df_imgs = pd.DataFrame(rows, columns=['Condition', 'FOV', 'Path'])        \n",
    "    df_imgs.to_csv(df_imgs_path, index=False)\n",
    "else:\n",
    "    print('Loaded df')\n",
    "    df_imgs = pd.read_csv(df_imgs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2c114af9-f37d-47c5-af6f-f7051d0e8af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Condition</th>\n",
       "      <th>FOV</th>\n",
       "      <th>Cycle</th>\n",
       "      <th>Channels</th>\n",
       "      <th>Markers</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Treated</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>DNA</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Treated</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Wnt1</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Treated</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Tead</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Condition FOV Cycle  Channels Markers  \\\n",
       "79   Treated   8     2         1     DNA   \n",
       "80   Treated   8     2         3    Wnt1   \n",
       "81   Treated   8     2         4    Tead   \n",
       "\n",
       "                                                 Path  \n",
       "79  Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  \n",
       "80  Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  \n",
       "81  Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f55ad0-2dcc-44df-888d-997ec925f2bd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Save Tiffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "17745c44-7d45-4ac7-8330-f7cf22eb7387",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure, util\n",
    "\n",
    "def contrast_str(img, n_min=0.1, n_max=100):\n",
    "    p2, p98 = np.percentile(img, (n_min, n_max))\n",
    "    img_rescale = exposure.rescale_intensity(img, in_range=(p2, p98))\n",
    "    return img_rescale\n",
    "\n",
    "def make_imgs_same_dim(imgs):\n",
    "    # Get max dimensions\n",
    "    shapes = np.array([img.shape[1:] for img in imgs])\n",
    "    min_x, min_y = shapes.min(axis=0)\n",
    "    imgs_cropped = [img[:, :min_x, :min_y] for img in imgs]\n",
    "    # imgs_cropped[0] = contrast_str(imgs_cropped[0])\n",
    "    return imgs_cropped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b42e20d8-1c30-403a-97c3-bcf1d130b044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_path = data_dir /  'basline' /'imgs' / 'raw'\n",
    "save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "group = df_imgs.groupby(['Condition', 'FOV'])\n",
    "for name, df_group in group:\n",
    "    path = df_group.iloc[0].Path\n",
    "             \n",
    "    # Read images\n",
    "    cycles = []\n",
    "    imgs_all = []\n",
    "    channels = []\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        for k in tqdm(f.keys(), total=len(f.keys()), leave=False):\n",
    "            cycle = k.split('_')[0]\n",
    "            channel = f[k].attrs['Channels']\n",
    "\n",
    "            imgs = f[k][:]\n",
    "            cycles.append(cycle)\n",
    "            channels.append(channel)\n",
    "            imgs[0] = contrast_str(imgs[0])\n",
    "            imgs_all.append(imgs)\n",
    "    \n",
    "    imgs_same_shape = make_imgs_same_dim(imgs_all)\n",
    "    \n",
    "    for i, imgs in enumerate(imgs_same_shape):\n",
    "        temp_path = save_path / '_'.join(np.array(name).astype(str))\n",
    "        temp_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        file_name = f'001_{cycles[i]}.tif'\n",
    "        file_path = temp_path / file_name\n",
    "\n",
    "        # Write image\n",
    "        tiff.imwrite(file_path, imgs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deab5b15-744b-4176-9dd5-be4eb841e52d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Registration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "944547e1-f5f5-42af-9f76-82400fd61bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ashlar import fileseries, thumbnail,reg\n",
    "import matplotlib.pyplot as plt\n",
    "from ashlar.scripts.ashlar import process_axis_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3c4e9786-b5c3-41b8-9d76-2ea38ab7daf0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ad7e40ef55544dc8f58d179f19ff7b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    assembling thumbnail 1/1\n",
      "    assembling thumbnail 1/1\n",
      "    estimated cycle offset [y x] = [-1.  2.]\n",
      "    assembling thumbnail 1/1\n",
      "    assembling thumbnail 1/1\n",
      "    estimated cycle offset [y x] = [4. 1.]\n",
      "    assembling thumbnail 1/1\n",
      "    assembling thumbnail 1/1\n",
      "    estimated cycle offset [y x] = [20.  6.]\n",
      "    assembling thumbnail 1/1\n",
      "    assembling thumbnail 1/1\n",
      "    estimated cycle offset [y x] = [14.  0.]\n",
      "    assembling thumbnail 1/1\n",
      "    assembling thumbnail 1/1\n",
      "    estimated cycle offset [y x] = [11. 14.]\n",
      "    assembling thumbnail 1/1\n",
      "    assembling thumbnail 1/1\n",
      "    estimated cycle offset [y x] = [14.  3.]\n",
      "    assembling thumbnail 1/1\n",
      "    assembling thumbnail 1/1\n",
      "    estimated cycle offset [y x] = [ 0. -1.]\n",
      "    assembling thumbnail 1/1\n",
      "    assembling thumbnail 1/1\n",
      "    estimated cycle offset [y x] = [16.  0.]\n",
      "    assembling thumbnail 1/1\n",
      "    assembling thumbnail 1/1\n",
      "    estimated cycle offset [y x] = [  0. -16.]\n",
      "    assembling thumbnail 1/1\n",
      "    assembling thumbnail 1/1\n",
      "    estimated cycle offset [y x] = [11.  2.]\n",
      "    assembling thumbnail 1/1\n",
      "    assembling thumbnail 1/1\n",
      "    estimated cycle offset [y x] = [15. 15.]\n",
      "    assembling thumbnail 1/1\n",
      "    assembling thumbnail 1/1\n",
      "    estimated cycle offset [y x] = [1. 3.]\n",
      "    assembling thumbnail 1/1\n",
      "    assembling thumbnail 1/1\n",
      "    estimated cycle offset [y x] = [ 2. 24.]\n",
      "    assembling thumbnail 1/1\n",
      "    assembling thumbnail 1/1\n",
      "    estimated cycle offset [y x] = [ 6. 15.]\n"
     ]
    }
   ],
   "source": [
    "# Loop all images\n",
    "imgs_dir = data_dir / 'basline' /'imgs' / 'raw'\n",
    "save_dir = data_dir / 'basline' /'imgs' / 'registered'\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "imgs_dir_list = os.listdir(imgs_dir)\n",
    "\n",
    "for dir_path in tqdm(imgs_dir_list):\n",
    "    \n",
    "    # Create reader for each cycle\n",
    "    readers = []\n",
    "    for i in range(1, 3):\n",
    "        reader = fileseries.FileSeriesReader(\n",
    "            str(imgs_dir / dir_path),\n",
    "            pattern='{series}_'+f'{i}.tif',\n",
    "            overlap=0.29,\n",
    "            width=1,\n",
    "            height=1,\n",
    "            layout='snake',\n",
    "            direction='horizontal',\n",
    "            pixel_size=0.18872, \n",
    "        )\n",
    "        readers.append(reader)\n",
    "    reader_1 = readers[0]\n",
    "    \n",
    "    # Run stitching\n",
    "    aligner0 = reg.EdgeAligner(reader_1, channel=0, filter_sigma=2, verbose=False,)\n",
    "    aligner0.run()\n",
    "    \n",
    "    # Generate merge image for 1 cycle\n",
    "    # Parramter\n",
    "    mosaic_args = {}\n",
    "    mosaic_args['verbose'] = False\n",
    "\n",
    "    mosaic = reg.Mosaic(\n",
    "            aligner0,aligner0.mosaic_shape,**mosaic_args\n",
    "        )\n",
    "    writer_class = reg.TiffListWriter\n",
    "    writer = writer_class(\n",
    "            [mosaic], str(save_dir / (dir_path + '_cycle1_ch{channel}.ome.tif'))\n",
    "    )\n",
    "    writer.run()\n",
    "    \n",
    "    # Loop through rest of cycles\n",
    "    aligners = list()\n",
    "    aligners.append(aligner0)\n",
    "\n",
    "    for j in range(1, 2):\n",
    "        aligners.append(\n",
    "            reg.LayerAligner(readers[j], aligners[0], channel=0, filter_sigma=2, verbose=False)\n",
    "        )\n",
    "        aligners[j].run()\n",
    "        mosaic = reg.Mosaic(\n",
    "            aligners[j], aligners[0].mosaic_shape,**mosaic_args\n",
    "        )\n",
    "        writer = writer_class(\n",
    "                [mosaic], str(save_dir / (dir_path +'_cycle'+str(j+1)+'_ch{channel}.ome.tif'))\n",
    "        )\n",
    "        writer.run()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c960b0de-5b37-4ef5-886a-4cd1764af38e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90c742c2-1fb5-4a05-a660-e29d442f305d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(data_raw, marker_dict):\n",
    "    conditions = []\n",
    "    fovs = []\n",
    "    cycles = []\n",
    "    channels = []\n",
    "    markers = []\n",
    "    paths = [] \n",
    "\n",
    "    # Loop through image folder\n",
    "    for (dirpath, dirnames, filenames) in os.walk(data_raw):\n",
    "        for name in sorted(filenames):\n",
    "            if \"tif\" in name:\n",
    "                # Get information from image name\n",
    "                n_split = name.split('_')\n",
    "                                \n",
    "                cond=n_split[0]\n",
    "                fov=n_split[1]\n",
    "                cycle=n_split[2]\n",
    "                ch = n_split[3][:3]\n",
    "                try:\n",
    "                    marker = marker_dict[fov][cycle][ch]\n",
    "                except:\n",
    "                    continue \n",
    "                    \n",
    "                conditions.append(cond)\n",
    "                fovs.append(fov)\n",
    "                cycles.append(cycle)\n",
    "                channels.append(ch)\n",
    "                markers.append(marker)\n",
    "                paths.append(os.path.join(dirpath, name))\n",
    "                \n",
    "    info = {\n",
    "            \"Condition\": conditions,\n",
    "            \"FOV\": fovs,\n",
    "            \"Cycle\": cycles,\n",
    "            \"Channels\": channels,\n",
    "            \"Markers\": markers,\n",
    "            \"Path\": paths\n",
    "        }\n",
    "\n",
    "    df = pd.DataFrame(info)\n",
    "    return df\n",
    "\n",
    "def joblib_loop(task, pics):\n",
    "    return Parallel(n_jobs=20)(delayed(task)(i) for i in pics)\n",
    "\n",
    "def read_img(path):\n",
    "    return skimage.io.imread(path, as_gray=True)\n",
    "\n",
    "def get_min(imgs):\n",
    "    shapes = np.array([np.array(img.shape) for img in imgs])\n",
    "    return np.min(shapes, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d322e9cf-6ac3-4b85-a47f-f5a9319ba77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "\n",
    "# markers_map_new = defaultdict(dict)\n",
    "# for k in markers_map.keys():\n",
    "#     markers_map_new[k]['cycle1'] = dict()\n",
    "#     markers_map_new[k]['cycle2'] = dict()\n",
    "#     if 'cycle' in k:\n",
    "#         continue\n",
    "#     for i, (ch, marker) in enumerate(markers_map[k].items()):\n",
    "#         markers_map_new[k]['cycle1'][f'ch{i}'] = marker\n",
    "#     if k != '8':\n",
    "#         for i, (ch, marker) in enumerate(markers_map['cycle2'].items()):\n",
    "#             markers_map_new[k]['cycle2'][f'ch{i}'] = marker\n",
    "#     else:\n",
    "#         for i, (ch, marker) in enumerate(markers_map['cycle2_sec'].items()):\n",
    "#             markers_map_new[k]['cycle2'][f'ch{i}'] = marker        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e64da6f3-9005-48a0-9206-52b0245cf1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder is already there\n",
      "Loaded df\n"
     ]
    }
   ],
   "source": [
    "data_raw = data_dir  /  'basline' /'imgs' / 'registered'\n",
    "df_meta_path = data_dir /  'basline' / 'metadata' / 'info_sti.csv'\n",
    "\n",
    "try:\n",
    "    df_meta_path.parent.mkdir(parents=True, exist_ok=False)\n",
    "except FileExistsError:\n",
    "    print(\"Folder is already there\")\n",
    "\n",
    "df_exist = df_meta_path.is_file()\n",
    "\n",
    "if not df_exist:\n",
    "    print('Created df')\n",
    "    df = get_info(data_raw, markers_map_new)\n",
    "    df.to_csv(df_meta_path, index=False)\n",
    "else:\n",
    "    print('Loaded df')\n",
    "    df = pd.read_csv(df_meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6d1c788-2ae5-4836-b81f-5687464f799d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder is already there\n",
      "Loaded df\n"
     ]
    }
   ],
   "source": [
    "df_imgs_path = data_dir / 'basline' /'metadata' / 'imgs_reg.csv'\n",
    "\n",
    "temp_path =data_dir /  'basline' /'hdf5' / 'registered'\n",
    "try:\n",
    "    temp_path.mkdir(parents=True, exist_ok=False)\n",
    "except FileExistsError:\n",
    "    print(\"Folder is already there\")\n",
    "\n",
    "df_exist = df_imgs_path.is_file()\n",
    "\n",
    "if not df_exist:\n",
    "    print('Created df')\n",
    "    group = df.groupby(['Condition','FOV'])\n",
    "    rows = []\n",
    "\n",
    "    for name, df_group in tqdm(group, total=len(group)):\n",
    "        file_name = '_'.join(np.array(name).astype(str)) + '.hdf5'\n",
    "        file_path = temp_path / file_name\n",
    "        rows.append(list(name)+[file_path])\n",
    "        \n",
    "        # if file_path.exists():\n",
    "        #     continue\n",
    "        \n",
    "        channels = df_group.Channels.to_list()\n",
    "        cycles = df_group.Cycle.to_list()\n",
    "        markers = df_group.Markers.to_list()\n",
    "        paths = df_group.Path.to_numpy()\n",
    "            \n",
    "        imgs = joblib_loop(read_img, paths)\n",
    "        min_shape = get_min(imgs)\n",
    "        imgs_cropped = np.array([img[:min_shape[0], :min_shape[1]] for img in imgs])\n",
    "        info = {\"Cycle\": cycles, \"Channel\": channels, \"Marker\": markers}\n",
    "            \n",
    "            # hdf5 as Channel -> Z mapping\n",
    "        save_hdf5(file_path, 'imgs', imgs_cropped, info)\n",
    "    df_imgs = pd.DataFrame(rows, columns=['Condition', 'FOV', 'Path'])        \n",
    "    df_imgs.to_csv(df_imgs_path, index=False)\n",
    "else:\n",
    "    print('Loaded df')\n",
    "    df_imgs = pd.read_csv(df_imgs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2b63b2-99cc-4484-bdeb-226e9f30e283",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b60e2933-5f3e-46ab-8318-b1928e25ef2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.exposure import match_histograms, rescale_intensity\n",
    "import cv2\n",
    "from skimage import img_as_ubyte\n",
    "from skimage import exposure, util, filters, restoration\n",
    "\n",
    "def random_crop(image, NEW_IMG_HEIGHT, NEW_IMG_WIDTH):\n",
    "    cropped_image = tf.image.random_crop(\n",
    "      image, size=[3, NEW_IMG_HEIGHT, NEW_IMG_WIDTH])\n",
    "\n",
    "    return cropped_image\n",
    "\n",
    "def make_color_overlay(input_data):\n",
    "    \"\"\"Create a color overlay from 2 channel image data\n",
    "    \n",
    "    Args:\n",
    "        input_data: stack of input images\n",
    "    \n",
    "    Returns:\n",
    "        numpy.array: color-adjusted stack of overlays in RGB mode\n",
    "    \"\"\"\n",
    "    RGB_data = np.zeros(input_data.shape[:3] + (3, ), dtype='float32')\n",
    "    \n",
    "    # rescale channels to aid plotting\n",
    "    for img in range(input_data.shape[0]):\n",
    "        for channel in range(input_data.shape[-1]):\n",
    "            # get histogram for non-zero pixels\n",
    "            percentiles = np.percentile(input_data[img, :, :, channel][input_data[img, :, :, channel] > 0],\n",
    "                                            [0, 100])\n",
    "            rescaled_intensity = rescale_intensity(input_data[img, :, :, channel],\n",
    "                                                       in_range=(percentiles[0], percentiles[1]),\n",
    "                                                       out_range='float32')\n",
    "            RGB_data[img, :, :, channel + 1] = rescaled_intensity\n",
    "        \n",
    "    # create a blank array for red channel\n",
    "    return RGB_data\n",
    "\n",
    "def contrast_str(img, n_min=10, n_max=100):\n",
    "    p2, p98 = np.percentile(img, (n_min, n_max))\n",
    "    img_rescale = rescale_intensity(img, in_range=(p2, p98))\n",
    "    img_rescale = util.img_as_ubyte(img_rescale)\n",
    "    return img_rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "543a4076-1f66-4d3a-8fd1-bb6ffc59d2f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abfc18f258834db7b93ca944b21cf3b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for row in tqdm(df_imgs.iloc[4:].itertuples(), total=len(df_imgs)):\n",
    "    path = row.Path\n",
    "    \n",
    "    # Read images\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        \n",
    "        markers = f['imgs'].attrs['Marker']\n",
    "        imgs = f['imgs'][:]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af994d1e-d961-4302-b226-c7abc5ee89c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Viewer(camera=Camera(center=(0.0, 1737.5, 2327.0), zoom=0.14726133472400008, angles=(0.0, 0.0, 90.0), perspective=0.0, mouse_pan=True, mouse_zoom=True), cursor=Cursor(position=(1.0, 1.0), scaled=True, size=1, style=<CursorStyle.STANDARD: 'standard'>), dims=Dims(ndim=2, ndisplay=2, last_used=0, range=((0.0, 3476.0, 1.0), (0.0, 4655.0, 1.0)), current_step=(1737, 2327), order=(0, 1), axis_labels=('0', '1')), grid=GridCanvas(stride=1, shape=(-1, -1), enabled=False), layers=[<Image layer 'DNA' at 0x207e30fe430>, <Image layer 'CycD1/CDK4' at 0x20777ed0940>, <Image layer 'DNA [1]' at 0x20777ef6970>, <Image layer 'Concanavalin A' at 0x20777f2c880>, <Image layer 'Phalloidin' at 0x20777f5d820>, <Image layer 'WGA' at 0x20777f8cf40>], help='use <2> for transform', status='Ready', tooltip=Tooltip(visible=False, text=''), theme='dark', title='napari', mouse_over_canvas=False, mouse_move_callbacks=[], mouse_drag_callbacks=[], mouse_double_click_callbacks=[], mouse_wheel_callbacks=[<function dims_scroll at 0x00000207A8CCA310>], _persisted_mouse_event={}, _mouse_drag_gen={}, _mouse_wheel_gen={}, keymap={})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import napari \n",
    "\n",
    "napari.view_image(np.stack(imgs), name=markers, channel_axis=0, contrast_limits=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76c1c87a-7fac-4fb8-a5d3-5e61554e8214",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imgs['FOV'] = df_imgs['FOV'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67ceeab2-3178-42bb-aad5-6a4dde3bf0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define markers to use for cytosolic segmentation\n",
    "cyto_markers = ['Phalloidin', 'WGA']\n",
    "\n",
    "# Define folder and create if don't exsit\n",
    "whole_seg_path = data_dir / 'basline'/ 'imgs' / 'segmentation'\n",
    "whole_seg_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save combined images\n",
    "for row in df_imgs.itertuples():\n",
    "    # Read image\n",
    "    path = row.Path\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        imgs = f['imgs'][:]\n",
    "        markers = f['imgs'].attrs['Marker']\n",
    "\n",
    "    # Get dapi and cyto imgaes\n",
    "    indices = np.isin(markers, cyto_markers)\n",
    "    img_dapi = imgs[2]\n",
    "    imgs_cyto = imgs[indices,:]\n",
    "    \n",
    "    # Contrast streching and combine to rgb image\n",
    "    img_dapi = contrast_str(img_dapi, n_max=99.9)\n",
    "        \n",
    "    if row.FOV == '8':\n",
    "        img_cyto = np.zeros(img_dapi.shape)\n",
    "    else:\n",
    "        imgs_cyto_scaled = [contrast_str(imgs_cyto[0], n_max=99.9), contrast_str(imgs_cyto[1], n_max=99.9)]\n",
    "        img_cyto = np.max(np.array(imgs_cyto_scaled), axis=0)\n",
    "    img_rgb = np.stack([np.zeros(img_dapi.shape),img_cyto, img_dapi], axis=0).astype(np.uint8)\n",
    "    \n",
    "    # Crop and save\n",
    "    file_name = f'{\"_\".join(row[1:3])}.tif'\n",
    "    file_path = whole_seg_path / file_name\n",
    "    tiff.imwrite(file_path, img_rgb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f741be-0346-439c-b6b9-435b773a56c0",
   "metadata": {},
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15e64c05-83f5-4a1e-a730-5e39a8042709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> GPU activated? YES\n"
     ]
    }
   ],
   "source": [
    "from skimage import exposure, util\n",
    "from cellpose import core, utils, io, models, metrics\n",
    "\n",
    "use_GPU = core.use_gpu()\n",
    "yn = ['NO', 'YES']\n",
    "print(f'>>> GPU activated? {yn[use_GPU]}')\n",
    "\n",
    "def contrast_str(img, n_min=0.01, n_max=99.95):\n",
    "    p2, p98 = np.percentile(img, (n_min, n_max))\n",
    "    img_rescale = exposure.rescale_intensity(img, in_range=(p2, p98))\n",
    "    img_rescale = util.img_as_ubyte(img_rescale)\n",
    "    return img_rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dca0b6f9-998d-4fb6-97a7-3f76da88d797",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_seg_path = data_dir / 'basline'/ 'imgs' / 'segmentation'\n",
    "mask_path = data_dir  / 'basline'/ 'imgs' / 'masks'\n",
    "\n",
    "mask_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a90e23e-4554-4e2f-b03a-0d4495aecf2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\cellpose\\lib\\site-packages\\cellpose\\transforms.py:363: UserWarning: chan to seg' has value range of ZERO\n",
      "  warnings.warn(\"chan to seg' has value range of ZERO\")\n"
     ]
    }
   ],
   "source": [
    "# Cyto segmentaion\n",
    "masks = []\n",
    "for p in os.listdir(whole_seg_path):\n",
    "    if 'tif' not in p:\n",
    "        continue\n",
    "    img = skimage.io.imread(whole_seg_path / p).transpose((2,0,1))\n",
    "    \n",
    "    # Cyto segmentation\n",
    "    model = models.CellposeModel(gpu=True, model_type='cyto2')\n",
    "    mask_cyto, flows, styles = model.eval(img, \n",
    "                                  channels=[2,3],\n",
    "                                  diameter=300,\n",
    "                                  flow_threshold=0.8,\n",
    "                                  cellprob_threshold=-3\n",
    "                                  )\n",
    "    \n",
    "    file_path = mask_path / p\n",
    "    tiff.imwrite(file_path, mask_cyto)\n",
    "    \n",
    "    # # Nuclei segemtnation\n",
    "    # model = models.CellposeModel(gpu=True, model_type='nuclei')\n",
    "    # mask_nuclei, flows, styles = model.eval(img, \n",
    "    #                               channels=[3,0],\n",
    "    #                               diameter=100,\n",
    "    #                               flow_threshold=0.6,\n",
    "    #                               )\n",
    "    \n",
    "        \n",
    "    # file_path = mask_path / f'Nuclei_{p}'\n",
    "    # tiff.imwrite(file_path, mask_nuclei)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ad6d48-5591-4445-84bf-cba23e48ef6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
