{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.io\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import re\n",
    "import h5py\n",
    "import napari\n",
    "import tifffile as tiff\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.utils\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_dir = (Path().cwd().parents[0]).absolute()\n",
    "\n",
    "module_path = str(p_dir / \"src\")\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = (Path().cwd().parents[0] / 'data').absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning.pytorch as pl\n",
    "import PPIGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Define condition mapping\n",
    "condition_mapping = {'control': 0, '100nM': 1}\n",
    "\n",
    "# Load graph dataset and process if neede\n",
    "graph_path = data_dir / '13cyc' / 'graphs' \n",
    "\n",
    "dataset = PPIGraph.GraphDataset(graph_path, 'raw', 'pt', condition_mapping=condition_mapping, n_c=2)\n",
    "train_set, val_set, test_set = PPIGraph.train_test_val_split(dataset)\n",
    "\n",
    "# Create Dataloader\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: GraphDataset(2230):\n",
      "======================\n",
      "Number of graphs: 2230\n",
      "Number of features: 13\n",
      "Number of classes: 2\n",
      "Train set: 1071, test set: 892, val set: 267\n",
      "Step 1:\n",
      "=======\n",
      "Number of graphs in the current batch: 32\n",
      "DataBatch(edge_index=[2, 16106], pos=[2827, 2], labels=[2827, 13], nuclei=[2827], weight=[16106], condition=[32], fov=[32], id=[32], train_mask=[2827], test_mask=[2827], edge_attr=[16106, 2], x=[2827, 13], y=[32], edge_weight=[16106], name=[32], batch=[2827], ptr=[33])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print some information on the dataset\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('======================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "print(f'Train set: {len(train_set)}, test set: {len(test_set)}, val set: {len(val_set)}')\n",
    "for step, data in enumerate(train_loader):\n",
    "\n",
    "    print(f'Step {step + 1}:')\n",
    "    print('=======')\n",
    "    print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "    print(data)\n",
    "    print()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: GraphDataset(2230):\n",
      "======================\n",
      "Number of graphs: 2230\n",
      "Number of features: 13\n",
      "Number of classes: 2\n",
      "Train set: 1071, test set: 892, val set: 267\n",
      "Step 1:\n",
      "=======\n",
      "Number of graphs in the current batch: 32\n",
      "DataBatch(edge_index=[2, 18032], pos=[3150, 2], labels=[3150, 13], nuclei=[3150], weight=[18032], condition=[32], fov=[32], id=[32], train_mask=[3150], test_mask=[3150], edge_attr=[18032, 2], x=[3150, 13], y=[32], edge_weight=[18032], name=[32], batch=[3150], ptr=[33])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print some information on the dataset\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('======================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "print(f'Train set: {len(train_set)}, test set: {len(test_set)}, val set: {len(val_set)}')\n",
    "for step, data in enumerate(train_loader):\n",
    "\n",
    "    print(f'Step {step + 1}:')\n",
    "    print('=======')\n",
    "    print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "    print(data)\n",
    "    print()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-fold on filter dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from lightning.pytorch.accelerators import find_usable_cuda_devices\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from torch.utils.data import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out by maximum number of counts per cell\n",
    "min_count = 20\n",
    "max_count = 70\n",
    "\n",
    "graph_path = data_dir / '13cyc' / 'graphs' \n",
    "dataset = PPIGraph.GraphDataset(graph_path, 'raw', 'pt', condition_mapping=condition_mapping, n_c=2)\n",
    "\n",
    "# Create Dataloader\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Get Indices\n",
    "indices = []\n",
    "for step, data in enumerate(loader):\n",
    "    if len(data.x) <= min_count:\n",
    "        continue \n",
    "    \n",
    "    if (data.x.sum(axis=0) >= max_count).any():\n",
    "        continue\n",
    "    indices.append(step)\n",
    "    \n",
    "# Get subset dataset\n",
    "dataset_filtered = dataset.index_select(indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2117"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = '13PPI'\n",
    "condition = 'Kfold'\n",
    "checkpoint_folder = (Path().cwd().parents[0]).absolute() / 'data' / '13PPI' /\"saved_models\" / dataset_name / f\"Graph_GNNs_{condition}\" \n",
    "project_name = f'PLA_10152023_{dataset_name}_{condition}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "AVAIL_GPUS = [1]\n",
    "\n",
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "NUM_LAYERS = 2\n",
    "HIDDEN_CHANNELS = 16\n",
    "pools = ['mean', 'max', 'sum', 'attention', 'attention2']\n",
    "num_layers = [2,3,4]\n",
    "hiddens = [16, 32, 64]\n",
    "\n",
    "\n",
    "epochs = 80\n",
    "# model = 'GAT'\n",
    "model = 'GINConv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mthoomas\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78597dcece894e6aafffb821a87ffe2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231226_232307-1nsoq6rp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1nsoq6rp' target=\"_blank\">GINConv_2_16_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1nsoq6rp' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1nsoq6rp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\Anaconda3\\envs\\snowflake\\lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n",
      "C:\\Users\\thu71\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:478: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\thu71\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\thu71\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightning\\pytorch\\utilities\\data.py:77: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "C:\\Users\\thu71\\AppData\\Roaming\\Python\\Python39\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇████████████▇██████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████▇██████</td></tr><tr><td>train_f1</td><td>▁▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇████████████▇▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▄▃▃▃▃▂▃▃▃▂▃▂▂▃▃▂▂▂▂▂▂▂▂▁▂▁▁▁▂▂▂▂▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▇▆▆▅▅▅▇▅▄▅▅▆▅▄▄▆▅▆▄▆▄▂▅▅▃▄▃▃▄▅▅▆▃▄▅▄▃▄▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▄▃▂▄▄▆█▆▇▂▄▆▆▄▇▅▆▆▆▇▅▅▆▅▅▆▅▅▄▆█▅▆▅▆▆▅▅</td></tr><tr><td>val_auc</td><td>▁▄▅▆▆▆▆▇█▇█▅▇▇▇▇█▅██▇█▇▇██▆▇▇▇▅▇▇▇▇▇▆▇▇▆</td></tr><tr><td>val_f1</td><td>▁▃▄▂▂▃▅▆█▇▆▃▄▆▇▃▇▇▆▆▆▇▆▅▆▇▆▇▅▅▆▇▇▅▆▆▆▆▅▆</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▃▃▃▃▂▂▂▂▃▃▂▂▄▂▃▂▂▂▃▂▂▂▁▂▃▁▂▃▂▂▃▂▂▂▁▄▂</td></tr><tr><td>val_loss_step</td><td>▇▅▄▄▅▄▄▂▅▆▄▅▆▅▅▆▅▅▄▄▆▇▄▄▆▂▃▆▁▄▃▅▃▆▄▄▄▃█▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84347</td></tr><tr><td>train_auc</td><td>0.917</td></tr><tr><td>train_f1</td><td>0.8431</td></tr><tr><td>train_loss_epoch</td><td>0.35819</td></tr><tr><td>train_loss_step</td><td>0.19526</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80896</td></tr><tr><td>val_auc</td><td>0.90261</td></tr><tr><td>val_f1</td><td>0.81119</td></tr><tr><td>val_loss_epoch</td><td>0.39459</td></tr><tr><td>val_loss_step</td><td>0.36489</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1nsoq6rp' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1nsoq6rp</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231226_232307-1nsoq6rp\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cc5b77376f449e1a26cc35570df3abc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231226_235955-gy8wezec</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gy8wezec' target=\"_blank\">GINConv_2_16_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gy8wezec' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gy8wezec</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇██▇██</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇██████████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇██▇██</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▄▄▄▃▃▃▂▃▂▃▃▂▂▂▂▃▂▂▂▂▁▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▅▆▇▄▃▆▃▂▅▃▄▃▂▂▃▂▆▂▃▂▂▅▁▁▂▁▃▂▂▃▃▁▄▃▃▁▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▂▁▅▅▄▄▆▃▅▆▆▆▆▆▅▆█▆▇▆▇▇▆▇▇▇▇▅█▇▆▇▆▇▅▆▇▆▇▇</td></tr><tr><td>val_auc</td><td>▁▄▅▆▆▇▇▇▇▇▇▇▇▇▇███▇███▇▇███▇████▇▇▇▇▇▇▇▇</td></tr><tr><td>val_f1</td><td>▃▁▆▆▄▃▇▃▇▇▆▇▆▇▅▆█▇█▇█▇▇▇▇▇▇▇█▇▇▇▇▇▆▇▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▁▁▂▁▁▁▂▁▂▂▂▂▂▂▂</td></tr><tr><td>val_loss_step</td><td>█▆▄▃▅▃▄▃▅▅▃▄▂▂▂▃▄▄▃▂▅▄▄▂▅▁▁▅▁▂▂▅▁▃▂▃▃▂▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.81807</td></tr><tr><td>train_auc</td><td>0.90024</td></tr><tr><td>train_f1</td><td>0.8203</td></tr><tr><td>train_loss_epoch</td><td>0.39389</td></tr><tr><td>train_loss_step</td><td>0.37456</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83726</td></tr><tr><td>val_auc</td><td>0.90739</td></tr><tr><td>val_f1</td><td>0.83991</td></tr><tr><td>val_loss_epoch</td><td>0.38729</td></tr><tr><td>val_loss_step</td><td>0.33424</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gy8wezec' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gy8wezec</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231226_235955-gy8wezec\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b3aa8d46bf6418c8c15f93291843851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_003724-42traflu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/42traflu' target=\"_blank\">GINConv_2_16_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/42traflu' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/42traflu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇█▇▇▇▇██▇▇████</td></tr><tr><td>train_auc</td><td>▁▅▅▅▆▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▆▇█▇▆▇▇</td></tr><tr><td>train_f1</td><td>▁▄▄▅▅▆▆▆▇▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▂▄▃▄▄▄▄▄▅▅▄▂▆▄▄▆▅▇▇█▇▆▄▅▇▆▅▇█▇█▇█▅▃▆▇▇</td></tr><tr><td>val_auc</td><td>▁▂▃▄▅▅▅▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇█▇▇█▇▇▇█▇▇█▇▇▇▇▇▇▇</td></tr><tr><td>val_f1</td><td>▃▄▁▄▂▂▄▃▄▄▅▅▂▁▅▃▂▅▅▇█▇▇▅▂▅▇▆▅▆█▇███▃▁▆▆▆</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▃▄▃▃▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▁▂▃▁▂▃▁▁▁▂▁▂▁▂▂▁▂▂</td></tr><tr><td>val_loss_step</td><td>█▄▃▂▅▂▄▃▄▃▄▅▄▅▄▅▃▃▃▃▃▅▃▃▅▁▃▇▁▃▃▄▂▅▂▃▄▂▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83343</td></tr><tr><td>train_auc</td><td>0.8059</td></tr><tr><td>train_f1</td><td>0.83793</td></tr><tr><td>train_loss_epoch</td><td>0.38881</td></tr><tr><td>train_loss_step</td><td>0.21276</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82311</td></tr><tr><td>val_auc</td><td>0.9031</td></tr><tr><td>val_f1</td><td>0.81572</td></tr><tr><td>val_loss_epoch</td><td>0.41167</td></tr><tr><td>val_loss_step</td><td>0.44308</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/42traflu' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/42traflu</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_003724-42traflu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a0eac773c2413dbcf124cc9b2f1b7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_011238-7yauihty</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7yauihty' target=\"_blank\">GINConv_2_16_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7yauihty' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7yauihty</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\Anaconda3\\envs\\snowflake\\lib\\site-packages\\torch_geometric\\deprecation.py:12: UserWarning: 'nn.glob.GlobalAttention' is deprecated, use 'nn.aggr.AttentionalAggregation' instead\n",
      "  warnings.warn(out)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.1 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▆▇▇▆▇▇▇▇▇▇▇██▇▇▇▇▇██▇▇▇██████████▇█</td></tr><tr><td>train_auc</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇█▇▇██▇███████▇▇████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇█▇█▇██████▇███▇█</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▃▃▃▃▃▃▃▃▃▂▂▃▂▂▂▂▂▂▂▁▁▂▂▂▁▁▂▁▁▁▂▁▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▄▄▄▅▄▂▃▃▅▄▂▇▄▂▂▃▁▂▆▄▇▂▃▂▂▂▂▃▁▄▄▂▂▄▂▄▃▃▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▃▅▆▁▅▆█▅▆▇▆█▇█▇▇▆▇▇▆▇▇▇▇█▇▇▆██▇▇▇▇█▆▇▇█▇</td></tr><tr><td>val_auc</td><td>▁▄▅▅▄▆▇▆▆▆▅▇▅▇▇▆▇▇▆▆▇▇▇▇▇▇█▅█▆▇▇▇██▆▆██▇</td></tr><tr><td>val_f1</td><td>▄▅▆▁▆▆█▅▇▇▆█▇█▇▇▆▇▆▆▇▇▇▇██▆▆██▇▇▇▇█▆▇▇█▇</td></tr><tr><td>val_loss_epoch</td><td>▇▄▃█▃▃▁▃▂▃▃▂▂▂▂▂▃▂▂▃▁▂▃▂▂▁▃▃▁▃▃▁▂▂▂▄▂▁▂▁</td></tr><tr><td>val_loss_step</td><td>▅▃▃█▃▃▁▃▂▄▃▃▃▃▃▃▃▄▂▄▁▃▄▂▂▂▃▄▂▄▄▁▃▃▃▅▃▁▄▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84761</td></tr><tr><td>train_auc</td><td>0.91362</td></tr><tr><td>train_f1</td><td>0.85</td></tr><tr><td>train_loss_epoch</td><td>0.38725</td></tr><tr><td>train_loss_step</td><td>0.49821</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82311</td></tr><tr><td>val_auc</td><td>0.90653</td></tr><tr><td>val_f1</td><td>0.8307</td></tr><tr><td>val_loss_epoch</td><td>0.36649</td></tr><tr><td>val_loss_step</td><td>0.2756</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7yauihty' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7yauihty</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_011238-7yauihty\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed51b0351f4949cd9d8e8c5e0c2ddc15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_014753-a2qhyhll</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/a2qhyhll' target=\"_blank\">GINConv_2_16_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/a2qhyhll' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/a2qhyhll</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.1 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "1.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇███▇▇██▇█████████</td></tr><tr><td>train_auc</td><td>▁▆▆▆▇▆▇▇▇▇▇▇▇▇▇█▇█▇▇▇▇▇███▇▇██▇█████▇█▇█</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇██▇████▇██▇██████▇██</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▄▄▃▃▃▂▃▃▃▂▂▃▂▂▂▂▂▃▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▆▆▃▄▄▅▂▅▃▆▃▂▂▂▃▄▂▃▃▃▃▇▅▄▃▃▂▅▄▂▄▁▂▂▅▂▃▄▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▂▄▅▂▂▆▆▃█▆▇▇████▆▅▄▆▆▇▅██▇▅█▇█▆▆▇▇▆▃▆▇</td></tr><tr><td>val_auc</td><td>▁▄▅▆▆▇▆▆▅▇▇▇▆▇█▇██▇▆▇▆▇█▇▇▆▇▆█▆▆▇▆▇▇▇▃▇▇</td></tr><tr><td>val_f1</td><td>▁▄▂▃▅▁▁▆▇▂█▅▇▇▇▇█▇▅▆▃▇▇▆▅▆█▆▅▇▇█▆▇▆▆▆▄▆▇</td></tr><tr><td>val_loss_epoch</td><td>█▄▄▃▃▄▃▃▂▃▂▂▂▂▂▂▂▂▃▂▃▂▂▁▂▂▂▂▂▁▂▃▁▂▂▂▂▃▁▂</td></tr><tr><td>val_loss_step</td><td>█▅▅▄▄▄▃▇▃▄▃▅▃▄▄▃▆▄▇▃▅▄▄▂▃▅▂▄▃▂▅▆▃▁▄▃▃▁▂▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8417</td></tr><tr><td>train_auc</td><td>0.9194</td></tr><tr><td>train_f1</td><td>0.84179</td></tr><tr><td>train_loss_epoch</td><td>0.35931</td></tr><tr><td>train_loss_step</td><td>0.28484</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82311</td></tr><tr><td>val_auc</td><td>0.90544</td></tr><tr><td>val_f1</td><td>0.8307</td></tr><tr><td>val_loss_epoch</td><td>0.401</td></tr><tr><td>val_loss_step</td><td>0.45894</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/a2qhyhll' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/a2qhyhll</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_014753-a2qhyhll\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "105a7e16a91f4905a7dc007ff8e76844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_022207-mvbvvrgg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/mvbvvrgg' target=\"_blank\">GINConv_2_32_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/mvbvvrgg' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/mvbvvrgg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 3.8 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "417658b117f44701bdd590635c134ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▄▅▅▆▆▆▆▆▇▆▆▆▆▇▇▇▇▇█▇▇▇▇▇▇█▇▇▇███▇████</td></tr><tr><td>train_auc</td><td>▁▅▅▅▅▅▆▅▆▆▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇████▇████</td></tr><tr><td>train_f1</td><td>▁▄▅▅▆▅▆▆▆▆▆▇▆▆▇▇▇▆▇▇▇█▇▇▇▇▇▇▇▇▇▇███▇███▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▅▅▄▄▃▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▃▂▂▁▂▂▂▁▁▁▂▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▅▅▇▅▅▅▄▄▇▃▅▆▃▅▃▅▂▄▄▄▄▂▂▄▄▅▁▄▃▄▃▅▃▂▆▂▄▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▇▅▃▄▅▆▆▆▇▄█▅▁▃▇▄▄██▅▄▅▅▅▆▆▅▅▇▅▅▇▄▆▄▂▆▅▇▅</td></tr><tr><td>val_auc</td><td>▃▆▇▅▆█▆▇█▁▇▇▆▇▇▇▃▇▇▄▃▅▅▇▅▇▆▇▆▆▁▆▅▆▅▅▇▆█▂</td></tr><tr><td>val_f1</td><td>▇▅▂▄▆▇▇▆▇▆▇▅▁▃█▅▆██▅▆▅▅▅▇▇▅▆▇▆▆▇▅▆▃▂▇▅▇▆</td></tr><tr><td>val_loss_epoch</td><td>▅▃▄▆▂▁▁▂▂▆▁▂▇▄▂▂▃▂▃▄▇▅▃▃▆▂▇▄▆▃▇▃▄▄█▆▇▄▁▆</td></tr><tr><td>val_loss_step</td><td>▅▄▃▅▃▃▃▄▄▄▃▃▇▅▄▁▂▄▆▅▇▄▄▃█▄▇▆▇▄▇▄▄▅▆▅█▄▁▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8671</td></tr><tr><td>train_auc</td><td>0.93437</td></tr><tr><td>train_f1</td><td>0.86421</td></tr><tr><td>train_loss_epoch</td><td>0.30727</td></tr><tr><td>train_loss_step</td><td>0.29555</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.79953</td></tr><tr><td>val_auc</td><td>0.87558</td></tr><tr><td>val_f1</td><td>0.8</td></tr><tr><td>val_loss_epoch</td><td>0.46941</td></tr><tr><td>val_loss_step</td><td>0.47564</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/mvbvvrgg' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/mvbvvrgg</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_022207-mvbvvrgg\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af5fbeb21da442668c9842965c5fdcec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_025641-txo62hzi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/txo62hzi' target=\"_blank\">GINConv_2_32_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/txo62hzi' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/txo62hzi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 3.8 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▅▅▆▆▆▆▅▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇█▇█▇█▇</td></tr><tr><td>train_auc</td><td>▁▄▅▆▆▆▆▆▇▇▆▇▇▇▇▇▇█▇█▇█▇█▇██▇████▇██▇████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇█▇█▇█▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▄▄▄▃▃▄▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▂▁▁▂▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▅▆▆▄▃▅▅▅▃▄▆▄▅▃▅▂▄▄▄▃▁▃▃▄▆▅▄▂▄▂▄▁▂▃▄▅▃▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▄▄▅▅▆▇▇▇▇▆▁▇▇▇▅█▆▆█▇▇▆▆▅▅▅▇▇▆▅▇▇█▆▆▆▆▇▆▆</td></tr><tr><td>val_auc</td><td>▁▆▇▇▇▇▇▇▇▇█▇██▇▇▇▆▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆▇▇▇▇</td></tr><tr><td>val_f1</td><td>▆▅▅▅▇▇█▇▇▇▁▇▇▇▆█▇▇█▇█▇▆▅▅▅▇▇▇▅█▇█▆▆▇▇█▆▇</td></tr><tr><td>val_loss_epoch</td><td>█▅▃▃▃▃▂▂▁▃▆▁▂▂▃▁▂▃▂▃▂▂▂▃▃▃▃▂▃▃▃▂▂▄▄▂▄▂▂▂</td></tr><tr><td>val_loss_step</td><td>▆▄▃▄▄▄▂▃▂▆▆▁▅▃▅▂▁▄▃▅▃▄▂▃▄▂▅▅▅▃▅▁▁▅▇▂█▃▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84111</td></tr><tr><td>train_auc</td><td>0.92325</td></tr><tr><td>train_f1</td><td>0.83727</td></tr><tr><td>train_loss_epoch</td><td>0.33989</td></tr><tr><td>train_loss_step</td><td>0.44183</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82075</td></tr><tr><td>val_auc</td><td>0.90748</td></tr><tr><td>val_f1</td><td>0.82407</td></tr><tr><td>val_loss_epoch</td><td>0.3814</td></tr><tr><td>val_loss_step</td><td>0.38989</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/txo62hzi' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/txo62hzi</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_025641-txo62hzi\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e15a1f0929b4dfc83dd1efc33ffef4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333332417533, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_033349-k6nqztrn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/k6nqztrn' target=\"_blank\">GINConv_2_32_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/k6nqztrn' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/k6nqztrn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 3.8 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▆▆▆▆▆▆▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇███▇██▇█</td></tr><tr><td>train_auc</td><td>▅▂▃▄▄▃▃▃▄▄▃▃▃▃▃▄▄▄▁▂▁▁▃▃▃▃▄▄▆▆▆▅▃▅▅▇▇█▄▃</td></tr><tr><td>train_f1</td><td>▁▃▅▅▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇███████████</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▂▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▂▂▂▂▂▂▂▂▃▂▂▁▂▁▂▁▂▂▁▁▂▂▂▂▁▁▂▁▂▁▁▂▁▂▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▆▆▇▆▆▆▇▇▆▆▇▇█▇▆▇█▇█▇█▇▇▇▆▇▆█▆▇▅▇▇▆█▇▇▆</td></tr><tr><td>val_auc</td><td>▂▂▃▃▂▃▃▃▄▄▃▃▂▂▂▃▂▂▁▁▁▂▂▂▇▃▃▃▇█▆▇▂█████▁▁</td></tr><tr><td>val_f1</td><td>▁▄▂▄▅▃▆▃▆▇▄▃▆▄▇▅▅▆▇▆█▇▇▅▇▆▄▇▄▇▅▇▁▆▅▃▇▇▄▅</td></tr><tr><td>val_loss_epoch</td><td>█▂▂▂▂▂▂▂▁▂▂▁▂▂▂▁▁▁▁▂▂▁▁▁▂▁▃▂▂▁▂▂▃▂▂▂▂▂▂▂</td></tr><tr><td>val_loss_step</td><td>█▃▃▃▃▃▂▃▃▃▃▂▃▃▄▁▂▃▄▃▄▂▃▂▄▃▅▄▄▃▃▃▄▄▂▄▄▃▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85351</td></tr><tr><td>train_auc</td><td>0.46799</td></tr><tr><td>train_f1</td><td>0.85006</td></tr><tr><td>train_loss_epoch</td><td>0.356</td></tr><tr><td>train_loss_step</td><td>0.45854</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.8066</td></tr><tr><td>val_auc</td><td>0.13361</td></tr><tr><td>val_f1</td><td>0.81448</td></tr><tr><td>val_loss_epoch</td><td>0.45128</td></tr><tr><td>val_loss_step</td><td>0.53144</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/k6nqztrn' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/k6nqztrn</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_033349-k6nqztrn\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd461424a1dc42e0a9c982c0c7ca301b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_040722-m9x46g0j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/m9x46g0j' target=\"_blank\">GINConv_2_32_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/m9x46g0j' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/m9x46g0j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 3.8 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.018     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▅▅▆▅▆▆▆▆▆▇▆▇▇▇▇▆▇▇▇▇▆▇▇▇▇▇▇▇▇█▇▇▇▇▇▇█</td></tr><tr><td>train_auc</td><td>▁▅▅▅▅▆▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇███▇████</td></tr><tr><td>train_f1</td><td>▁▅▅▅▅▆▆▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇███▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▅▄▄▃▄▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▄▆▆▆▅▆▄▆▅▄▅▃▄▄▄▄▆▃▄▆▄▁▄▆▄▄▅▅▄▅▃▄▅▃▅▄▃▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▄▅▇▇█▆▆▇▅▃▇█▇▇█▆▆▆▇▄▆▇▇▇▅▆▇█▇▇▆▅█▄▇▇▅▂▁▆</td></tr><tr><td>val_auc</td><td>▃▆▇▅██▇█▅▇▇▇████▇▆▇▆▆▇▇▇▇▇▇▇▆▇▇▆▇▂▆▅▁▅▅▅</td></tr><tr><td>val_f1</td><td>▆▆▇▇█▆▆▇▆▄▇█▇▇█▆▆▇█▄▆▇▇▇▄▆▇█▇▇▆▅█▄▇▇▆▂▁▇</td></tr><tr><td>val_loss_epoch</td><td>▆▃▃▂▂▃▂▂▃▄▂▁▃▂▁▂▃▃▁▃▃▂▁▃▅▃▁▃▂▂▃▅▂▇▄▃▅██▄</td></tr><tr><td>val_loss_step</td><td>▅▂▄▃▃▅▂▃▃▄▄▂▇▄▃▃▄▄▂▃▅▃▂▅█▄▁▄▂▄▃▃▃█▄▄▃▄▇▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.88069</td></tr><tr><td>train_auc</td><td>0.94615</td></tr><tr><td>train_f1</td><td>0.87933</td></tr><tr><td>train_loss_epoch</td><td>0.28548</td></tr><tr><td>train_loss_step</td><td>0.1045</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.79245</td></tr><tr><td>val_auc</td><td>0.88327</td></tr><tr><td>val_f1</td><td>0.80786</td></tr><tr><td>val_loss_epoch</td><td>0.48098</td></tr><tr><td>val_loss_step</td><td>0.50704</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/m9x46g0j' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/m9x46g0j</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_040722-m9x46g0j\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a7d9b082c1c4fe4b8295dd5a588f6dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_044047-gxdpgvfn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gxdpgvfn' target=\"_blank\">GINConv_2_32_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gxdpgvfn' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gxdpgvfn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 3.8 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "5.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.4 K     Total params\n",
      "0.022     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▅▅▆▆▆▆▆▆▆▆▆▆▇▆▇▆▇▇▇▇▇▇▇█▇▇▇▇▇▇▇█▇████</td></tr><tr><td>train_auc</td><td>▁▄▄▅▅▆▆▆▆▆▆▆▆▇▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████</td></tr><tr><td>train_f1</td><td>▁▄▄▅▅▆▆▆▆▇▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇█▇▇▇▇▇▇▇█▇████</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▅▄▄▄▄▃▄▄▄▄▃▃▄▄▃▃▃▃▃▃▃▃▃▃▂▃▂▂▃▂▂▂▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▆▆▆▅▅▅▅▄▅▄▅█▄▅▅▄█▄▄▄▄▃▃▅▅▄▇▄▅▄▂▄▃▄▄▄▃▄▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▆▁█▇▆▇▇▇▇▇▇██▆▆█▆▇▅▇▆█▆█▆▆▇█▇▇▇█▇▇▇▆█▅▆▇</td></tr><tr><td>val_auc</td><td>▁▃▆▇▅▇█▇▆███▇▄▅▆▅█▄█▆▆▇▇▃▇▆▆▆▇▆█▄▇▆▄▄▅▅▄</td></tr><tr><td>val_f1</td><td>▆▁▇▇▆▇▇▇▇▇▇▇▇▇▅█▆▇▆▇▆▇▆▇▇▆▇▇▇▇▇█▇▇▇▆█▅▆▇</td></tr><tr><td>val_loss_epoch</td><td>▅▇▃▂▂▂▂▂▂▂▂▂▂▂▃▄▄▁▅▁▂▂▃▃▅▅▃▂▃▆▃▃▄▂▂▄▅▆▆█</td></tr><tr><td>val_loss_step</td><td>▄▄▃▂▂▃▃▂▂▁▃▃▃▁▃▄▃▂▆▁▁▂▂▃▃▃▃▂▂▆▁▄▄▂▁▂▄▅▄█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8795</td></tr><tr><td>train_auc</td><td>0.94977</td></tr><tr><td>train_f1</td><td>0.87696</td></tr><tr><td>train_loss_epoch</td><td>0.27211</td></tr><tr><td>train_loss_step</td><td>0.13245</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80896</td></tr><tr><td>val_auc</td><td>0.89053</td></tr><tr><td>val_f1</td><td>0.80851</td></tr><tr><td>val_loss_epoch</td><td>0.53896</td></tr><tr><td>val_loss_step</td><td>0.86074</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gxdpgvfn' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gxdpgvfn</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_044047-gxdpgvfn\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c63fb0f785948ef8a1f0fbeb869f6f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_051504-jphsjay2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jphsjay2' target=\"_blank\">GINConv_2_64_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jphsjay2' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jphsjay2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 13.8 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.9 K    Total params\n",
      "0.064     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▄▅▅▅▆▆▆▆▆▆▆▆▆▆▆▇▇▆▆▇▇▆▆▇▇▇▇▇▇▇█▇█████</td></tr><tr><td>train_auc</td><td>▁▃▄▅▅▆▆▆▆▆▆▆▆▇▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇███████████</td></tr><tr><td>train_f1</td><td>▁▄▄▅▅▆▅▆▆▆▆▆▆▆▆▆▆▆▇▇▆▇▇▇▆▆▇▇▇▇▇▇▇█▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▅▄▄▄▄▃▄▄▄▃▃▃▃▄▃▃▃▃▂▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>▆█▅▆▅▄▄▃▄▄▅▅█▅▅▃▃▆▃▄▄▅▃▂▃█▄▂▂▃▂▂▂▃▂▂▂▃▁▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▇▆▇▇▇▇▇▆▇▆▄▆▇██▇▇▇█▇█▂█▇▇▇▆▆▇▆▁▇▆▃█▇▆▃▅▆</td></tr><tr><td>val_auc</td><td>▄▆▇▇█▇▇▇█▆▆▅█▇██▆▇▇▆█▆▇▆▇▇▅▅▅▂▂▄▄▂▆▆▄▁▁▂</td></tr><tr><td>val_f1</td><td>▇▆▇▇▇▇▇▇▇▆▄▇▇███▇▇█▇█▂▇▇█▇▇▇▇▆▁█▇▃█▇▇▄▆▇</td></tr><tr><td>val_loss_epoch</td><td>▂▃▁▁▁▁▁▁▁▂▂▂▂▂▁▃▂▂▁▂▂▄▄▂▂▂▃▃▃▃█▄▄▅▄▃▃▇▄▄</td></tr><tr><td>val_loss_step</td><td>▄▄▁▃▃▂▂▂▃▂▃▃▃▃▂▅▃▃▂▃▂▃▆▄▂▃▃▄▅▁█▃▇▅▅▃▂▇▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.89427</td></tr><tr><td>train_auc</td><td>0.95759</td></tr><tr><td>train_f1</td><td>0.89262</td></tr><tr><td>train_loss_epoch</td><td>0.26299</td></tr><tr><td>train_loss_step</td><td>0.27899</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.78302</td></tr><tr><td>val_auc</td><td>0.85918</td></tr><tr><td>val_f1</td><td>0.79736</td></tr><tr><td>val_loss_epoch</td><td>0.53078</td></tr><tr><td>val_loss_step</td><td>0.44633</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jphsjay2' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jphsjay2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_051504-jphsjay2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c786f31dbbc544fa822faa90c09d6bc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_054909-oyiav9kw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/oyiav9kw' target=\"_blank\">GINConv_2_64_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/oyiav9kw' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/oyiav9kw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 13.8 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.9 K    Total params\n",
      "0.064     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a39ba029ce8240e6ac7a2fa1d1b32bfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▆▇▇▇▇▇▇▆▇▇▇█▇█▇▇█████▇█</td></tr><tr><td>train_auc</td><td>▁▅▆▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████▇▇██████████████</td></tr><tr><td>train_f1</td><td>▁▅▅▅▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇█▇█▇▇█████▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▄▄▄▄▃▄▄▃▃▃▃▃▃▂▂▂▂▂▂▃▃▂▂▂▂▂▂▂▂▂▂▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>▇▇▅▅▃▅▄▃▃▃▅▅▅▄▆▂▃█▃▃▄▃▂▂▃▄▄▂▁▂▃▁▃▂▂▂▂▃▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▂▄▄▄▄▃▄▇▃▄▁▆▄▇▄▄▆▆▇▄▆▅▆▇▃▃▅▄▅▇▄█▅▄▄▆▆▅▆█</td></tr><tr><td>val_auc</td><td>▁▄▅▆▇▅▇▇▄█▆▇▆▇▆▆▇▆▆▆▆▇▇▆▆▆▆▄▆▆▆▆▇▄▅▇▆▇▆▆</td></tr><tr><td>val_f1</td><td>▄▅▆▄▄▄▆▇▅▄▁▇▆█▆▆▇▆▇▇█▆▇█▃▅▇▆▆▇▅█▆▅▆▆▇▆▇█</td></tr><tr><td>val_loss_epoch</td><td>█▅▂▂▃▃▃▁▃▃▃▂▂▃▂▅▁▄▂▄▄▁▅▆▄▃▄█▅▁▇▃▆▆▅▄▃▇▄▆</td></tr><tr><td>val_loss_step</td><td>▅▅▁▃▄▄▄▂▃▄▃▄▃▄▂▇▂▄▂▄▅▂▅▆▃▄▄▅▅▁▇▃█▅▅▂▂█▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.9049</td></tr><tr><td>train_auc</td><td>0.96978</td></tr><tr><td>train_f1</td><td>0.90354</td></tr><tr><td>train_loss_epoch</td><td>0.22091</td></tr><tr><td>train_loss_step</td><td>0.20374</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.84906</td></tr><tr><td>val_auc</td><td>0.90997</td></tr><tr><td>val_f1</td><td>0.84906</td></tr><tr><td>val_loss_epoch</td><td>0.4616</td></tr><tr><td>val_loss_step</td><td>0.48695</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/oyiav9kw' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/oyiav9kw</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_054909-oyiav9kw\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44c66c3e0bf84c6b882398444b91168e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_062232-syyn2woa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/syyn2woa' target=\"_blank\">GINConv_2_64_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/syyn2woa' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/syyn2woa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 13.8 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.9 K    Total params\n",
      "0.064     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▅▆▆▆▆▇▆▆▆▇▇▇▇▆▆▆▇▇▇▇▆▆▇▇▇█▇█▇████▇▇█</td></tr><tr><td>train_auc</td><td>▁▂▃▅▅▅▅▆▆▇▆▆▇▇▅▆▆▆▇▇▇▇▇▇▆▅▅▅▆▇▆▇▇▇▆▇▇▇██</td></tr><tr><td>train_f1</td><td>▁▂▅▅▅▆▆▆▆▇▆▆▆▇▇▇▇▆▇▆▇▇▇▇▆▇▇▇▇█▇█▇██▇█▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▁▁▁▁▁▁▁▁▁▁▁▂▂▁▁▂▁▁▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▃▂▄▆▄▅▆▅▇▄▅▆▅▇▇▅▅▇▅▇▅▇▆▇▇▇█▆█▇▄▃▅▇▅▅▁▄▅▇</td></tr><tr><td>val_auc</td><td>▁▄▄▄▅▆▆▆▇▇▇▆█▇█▇▇▇█▇▇▆▇▇█▇▇▄▇▅▆▃▆▇▇▇▆▅▇▆</td></tr><tr><td>val_f1</td><td>▄▃▅▇▄▅▇▆▇▅▆▇▅▇▇▅▆█▅▇▆▇▆█▇▆█▆█▇▄▅▇▇▅▅▁▅▆▇</td></tr><tr><td>val_loss_epoch</td><td>█▂▁▂▂▁▂▁▁▂▁▂▂▂▁▂▁▁▂▁▁▁▂▁▂▁▁▁▁▁▂▂▂▂▃▂▂▂▁▂</td></tr><tr><td>val_loss_step</td><td>█▃▁▂▂▂▂▂▂▃▂▃▃▃▂▃▂▂▂▂▂▂▃▃▂▂▂▂▂▁▃▂▃▃▄▃▁▃▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86119</td></tr><tr><td>train_auc</td><td>0.90433</td></tr><tr><td>train_f1</td><td>0.86037</td></tr><tr><td>train_loss_epoch</td><td>0.34175</td></tr><tr><td>train_loss_step</td><td>0.49555</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82311</td></tr><tr><td>val_auc</td><td>0.89278</td></tr><tr><td>val_f1</td><td>0.8184</td></tr><tr><td>val_loss_epoch</td><td>0.43527</td></tr><tr><td>val_loss_step</td><td>0.42555</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/syyn2woa' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/syyn2woa</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_062232-syyn2woa\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28c535f884024a828d69f28789694477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_065644-39l9qofk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/39l9qofk' target=\"_blank\">GINConv_2_64_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/39l9qofk' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/39l9qofk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 13.8 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "16.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "16.0 K    Total params\n",
      "0.064     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▅▅▆▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▆▆▇▆▆▇▇▇▇▇▇█▇▇▇▇▇█▇</td></tr><tr><td>train_auc</td><td>▁▄▄▅▅▆▅▆▆▅▆▆▆▆▆▆▇▇▆▇▇▇▆▇▇▇▇█▇▇▇▇█▇▇██▇██</td></tr><tr><td>train_f1</td><td>▁▄▄▄▅▆▅▅▅▅▆▅▆▆▆▆▆▆▆▇▇▆▆▇▆▆▇▇▇▇▇▇█▇▇▇▇▇█▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▅▅▅▅▄▅▅▄▅▄▄▄▄▃▃▄▃▃▃▄▃▃▃▃▂▃▂▂▃▂▃▂▂▂▃▁▂</td></tr><tr><td>train_loss_step</td><td>▇▅▇▅▅▄▅▃▆▆▅█▄▄▅▃▃▄▆▄▃▃▅▂▄▄▁▆▃▂▂▂▆▁▂▃▂▄▂▆</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▃▆▆▁▇▆▅▆█▆▇▆▅▅▄▇▆▆▃▃▅▆▄█▆▆▆▇█▇▄▆▄█▆▇▇▄▅▆</td></tr><tr><td>val_auc</td><td>▄▅▆▇▇▇▅▇█▆▆▆▂▆▆▇▇▆▃▅▆▇▃█▆▅▇▆▇▆▃▇▁▇▇▅▇▄▄▇</td></tr><tr><td>val_f1</td><td>▃▇▇▁▇▆▇██▆▇▇▆▅▅█▆▇▅▃▆▆▅█▇▇▆██▇▅▇▅█▇▇▇▆▆▇</td></tr><tr><td>val_loss_epoch</td><td>▄▃▂▆▁▂▄▃▂▂▂▂▃▃▃▃▃▂▅▆▄▂▃▂▂▃▄▃▂▃▅▂█▄▅▅▆▅▆▄</td></tr><tr><td>val_loss_step</td><td>▃▅▃▄▂▂▅▃▄▃▃▄▃▄▅▅▄▂▅▅▅▃▄▂▃▄▅▅▃▄▄▂█▅▇▅▅▅▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.89191</td></tr><tr><td>train_auc</td><td>0.95951</td></tr><tr><td>train_f1</td><td>0.89127</td></tr><tr><td>train_loss_epoch</td><td>0.27112</td></tr><tr><td>train_loss_step</td><td>0.46824</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.79953</td></tr><tr><td>val_auc</td><td>0.90328</td></tr><tr><td>val_f1</td><td>0.8172</td></tr><tr><td>val_loss_epoch</td><td>0.45208</td></tr><tr><td>val_loss_step</td><td>0.1997</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/39l9qofk' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/39l9qofk</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_065644-39l9qofk\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c001c60d148240b9ae99f05135792f7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_073034-xqrmrmzw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/xqrmrmzw' target=\"_blank\">GINConv_2_64_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/xqrmrmzw' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/xqrmrmzw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 13.8 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "20.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.1 K    Total params\n",
      "0.080     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▃▄▄▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▇▆▇▇▇▆▆▇▇▇▇██▇▇▇█▇█</td></tr><tr><td>train_auc</td><td>▁▃▄▅▅▆▆▆▆▆▆▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇█████</td></tr><tr><td>train_f1</td><td>▁▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇██▇▇▇█▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▅▅▄▄▄▄▄▄▃▄▃▃▃▃▃▃▃▃▂▃▃▂▂▃▃▂▂▂▂▁▁▂▁▂▁▂▁</td></tr><tr><td>train_loss_step</td><td>▇▇▆▆▇█▅▆▅▆▄▄▆▃▅▅▄▇▂▂▄▂▇▄▂▃▁▃▃▃▂▄▁▃▂▄▁▂▄▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▆▂▆▇▇▆▆▄█▇▇▅▅▁▆▅█▇█▇▆▆▅█▆▄▆▇▆▆▆▆▄▅▅▇▄▆▆▆</td></tr><tr><td>val_auc</td><td>▄▅▇▇▆▇▅▄██▆▇▄▅█▆▇▇▆▆▅▆▇▇▆▁▅█▄▆▅▅▂▅▅▅▁▄▅▆</td></tr><tr><td>val_f1</td><td>▆▂▅▆▇▇▇▅▇▇▇▇▆▁▆▄▇▇█▇▇▆▅█▆▄▆▇▇▆▆▆▅▅▅▇▅▆▆▆</td></tr><tr><td>val_loss_epoch</td><td>▃▅▃▁▃▂▂▃▁▂▂▆▃▅▂▄▃▁▃▂▃▄▄▃▂▆▄▁▄▃▆▅▇█▄▆▅▅▄▄</td></tr><tr><td>val_loss_step</td><td>▃▄▃▂▃▃▃▃▁▃▂▃▃▄▃▃▅▂▃▃▃▅▄▃▁▄▄▂▄▂█▂▁▄▄▆▂▃▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.90608</td></tr><tr><td>train_auc</td><td>0.96322</td></tr><tr><td>train_f1</td><td>0.90416</td></tr><tr><td>train_loss_epoch</td><td>0.24363</td></tr><tr><td>train_loss_step</td><td>0.22809</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80189</td></tr><tr><td>val_auc</td><td>0.89124</td></tr><tr><td>val_f1</td><td>0.8</td></tr><tr><td>val_loss_epoch</td><td>0.4644</td></tr><tr><td>val_loss_step</td><td>0.35809</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/xqrmrmzw' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/xqrmrmzw</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_073034-xqrmrmzw\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fcd92f4a88b45da9c86dbec9b2ee160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_080409-weoo882q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/weoo882q' target=\"_blank\">GINConv_3_16_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/weoo882q' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/weoo882q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.7 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇▇█▇███▇████████</td></tr><tr><td>train_auc</td><td>▁▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██████▇████████</td></tr><tr><td>train_f1</td><td>▁▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇██▇██▇██████▇████████</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▄▄▃▃▃▃▃▃▃▂▃▃▃▂▃▂▂▂▂▃▂▂▂▂▂▂▁▂▂▁▂▂▂▂▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▅▄▅▆▃▄▃▅▃▅▂▄▂▃▂▃▄▂▂▃▄▇▂▅▅▃▄▃▂▄▄▄▃▁▂▃▂▃▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▃▃▄▃▄▆▇▇▄▆▇▄▇▅▆▅▁▆█▂▇▃█▇▇▄▇▇▆▄▆▆▅▆▄▇▅▅</td></tr><tr><td>val_auc</td><td>▁▅▆▇▇▆▅█▇█▆██▅▇▇▆▇▃▇█▆█▇▇▇▇▆▇▇▇▅▇▇▇▇▇▇▇▇</td></tr><tr><td>val_f1</td><td>▄▅▃▁▃▁▄▅▆▇▃▅▆▄▇▄▆▅▂▆█▁▇▂▇▆▇▃▇▇▅▅▅▆▄▅▄▆▅▄</td></tr><tr><td>val_loss_epoch</td><td>█▂▃▄▂▃▃▃▁▁▃▂▂▂▂▂▂▂▄▂▁▃▁▃▂▁▁▂▂▂▂▃▂▂▃▃▂▂▁▂</td></tr><tr><td>val_loss_step</td><td>█▃▃▆▁▆▄▆▃▃▆▂▆▃▄▃▃▂▄▂▂▆▃▆▅▁▂▄▃▅▄▃▃▆▅▅▄▃▁▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84997</td></tr><tr><td>train_auc</td><td>0.92141</td></tr><tr><td>train_f1</td><td>0.85181</td></tr><tr><td>train_loss_epoch</td><td>0.36848</td></tr><tr><td>train_loss_step</td><td>0.50042</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.8184</td></tr><tr><td>val_auc</td><td>0.91447</td></tr><tr><td>val_f1</td><td>0.80605</td></tr><tr><td>val_loss_epoch</td><td>0.40208</td></tr><tr><td>val_loss_step</td><td>0.41952</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/weoo882q' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/weoo882q</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_080409-weoo882q\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0deeaa9d646409c88f64f532d7ad101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_083910-mvxejiku</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/mvxejiku' target=\"_blank\">GINConv_3_16_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/mvxejiku' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/mvxejiku</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.7 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b8525265b94416d98dea677c3ccd689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▆▇▇▇▇▇▆▇▇▇▇█▇▇▇██▇███████████████▇█</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇███████████████</td></tr><tr><td>train_f1</td><td>▁▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇██▇████▇████████████</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▄▃▃▃▃▃▃▃▂▃▃▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▆▅▅▆▄▇▃▅▃▅▄▄▃▄▃▂▃▅▂▂▄▅▂▃▄▃▅▂▃▅▃▅▄▁▂▃▃▄▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▆▇▇▇▇▆▆▇█▆█▅▇▇▇▇▇▇▇▇▇▇▇▇▇█▇███▇▇█▇▇▇▇█</td></tr><tr><td>val_auc</td><td>▁▄▅▅▆▆▆▆▇▆▇▇▇▆▇▇▇▇▇▆▇▇█▇█▇██▇██████▇▇█▇█</td></tr><tr><td>val_f1</td><td>▁▄▄▆▅▆▇▆▃▆█▆▇▅▇▆█▆▇▇▇▇▇▇██▇█████▇▆█▇▆▇▆█</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁▂▁▂▁▁▂▂▂▂▂▂▁</td></tr><tr><td>val_loss_step</td><td>█▄▃▆▁▅▂▅▃▁▃▂▄▃▃▃▅▁▃▁▃▂▃▅▃▁▂▃▅▁▆▁▂▃▄▅▃▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.82044</td></tr><tr><td>train_auc</td><td>0.90574</td></tr><tr><td>train_f1</td><td>0.82264</td></tr><tr><td>train_loss_epoch</td><td>0.38676</td></tr><tr><td>train_loss_step</td><td>0.39627</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.84434</td></tr><tr><td>val_auc</td><td>0.91685</td></tr><tr><td>val_f1</td><td>0.85135</td></tr><tr><td>val_loss_epoch</td><td>0.37582</td></tr><tr><td>val_loss_step</td><td>0.42472</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/mvxejiku' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/mvxejiku</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_083910-mvxejiku\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b399200beb14c4ea24943799ec02906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_091548-kphnsnfz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kphnsnfz' target=\"_blank\">GINConv_3_16_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kphnsnfz' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kphnsnfz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.7 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█▇▇██▇█▇███</td></tr><tr><td>train_auc</td><td>█▇█▅▃▂▂▂▂▁▁▃▂▁▁▂▂▂▂▂▂▃▃▂▂▂▃▂▂▂▁▂▂▂▃▄▂▃▂▂</td></tr><tr><td>train_f1</td><td>▁▃▄▄▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇██▇█▇▇████████</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▂▂▂▂▂▂▁▂▂▂▁▂▁▂▁▁▁▁▁▁▂▂▁▂▂▂▁▁▁▂▁▁▁▁▁▁▁▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███▇▇████▇▆▇█▇▇▇▇▇▆█▅▇▇</td></tr><tr><td>val_auc</td><td>▆▆█▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▇▁▁▂▁▁</td></tr><tr><td>val_f1</td><td>▂▅▅▅▆▆▅▇▇▆▆▇▇▇▆▇▆▇▇▇▆▆▇▇█▆▇▄▅█▅▇▆▅▆▃▇▁▆▆</td></tr><tr><td>val_loss_epoch</td><td>█▄▄▄▃▃▂▃▂▂▂▂▂▂▁▁▂▂▁▁▂▂▁▂▂▂▁▂▂▂▂▂▁▂▂▂▁▄▂▂</td></tr><tr><td>val_loss_step</td><td>█▅▄▅▂▄▂▄▃▂▃▁▄▃▂▂▃▃▂▂▂▃▃▄▃▃▁▂▃▄▃▃▁▂▄▄▃▅▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.82575</td></tr><tr><td>train_auc</td><td>0.37772</td></tr><tr><td>train_f1</td><td>0.82596</td></tr><tr><td>train_loss_epoch</td><td>0.41427</td></tr><tr><td>train_loss_step</td><td>0.54811</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.8184</td></tr><tr><td>val_auc</td><td>0.1088</td></tr><tr><td>val_f1</td><td>0.80605</td></tr><tr><td>val_loss_epoch</td><td>0.40438</td></tr><tr><td>val_loss_step</td><td>0.39759</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kphnsnfz' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kphnsnfz</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_091548-kphnsnfz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa28fa51601c4a3b94bd360590177865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_095100-b592u4mv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/b592u4mv' target=\"_blank\">GINConv_3_16_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/b592u4mv' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/b592u4mv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.7 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▇▇▇▆▆▇▇▇▇▇▇▇▇█▇▇▇▇▇█▇█▇█▇▇▇▇▇▇█▇▇▇█</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██▇█▇▇██▇█▇████▇███████</td></tr><tr><td>train_f1</td><td>▁▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████▇▇▇█▇█▇█▇███▇▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▂▁▂▁▂▂▁▁▁▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▅▇▄▃▄▃▃▃▄▄▂▃▃▃▂▂▃▆▃▄▂▃▃▄▃▂▃▃▆▃▁▃▂█▃▃▆▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▄▃▇▃▆▅▆▇▆▆▆██▇▇▇▆▅▅█▇▇▆▆▆▆▇▅▅▇▅▆▇▇█▆▄▆</td></tr><tr><td>val_auc</td><td>▁▃▆▆▇▆█▆▅▇▇▇▇▇█▆▇▇▇▇▇█▇▇▇▆▆▇▆▅▇▇▇▆▇▆▇▆▆▇</td></tr><tr><td>val_f1</td><td>▅▆▄▂▇▁▅▄▇▇▆▆▆██▇▇▆▇▅▅█▇▇▆▆▆▆▇▄▄▇▅▅▆▇▇▆▃▅</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▃▂▄▂▂▂▂▂▁▁▁▁▂▂▂▂▁▂▁▁▁▂▂▃▂▂▃▄▂▂▂▂▂▂▂▄▂</td></tr><tr><td>val_loss_step</td><td>█▄▆▄▃▆▄▂▄▄▄▃▃▁▄▅▄▂▆▂▂▄▂▂▆▄▅▄▅▄▆▅▁▃▂▄▄▃▆▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83579</td></tr><tr><td>train_auc</td><td>0.91433</td></tr><tr><td>train_f1</td><td>0.83856</td></tr><tr><td>train_loss_epoch</td><td>0.37502</td></tr><tr><td>train_loss_step</td><td>0.37977</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81132</td></tr><tr><td>val_auc</td><td>0.91222</td></tr><tr><td>val_f1</td><td>0.79592</td></tr><tr><td>val_loss_epoch</td><td>0.40395</td></tr><tr><td>val_loss_step</td><td>0.4149</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/b592u4mv' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/b592u4mv</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_095100-b592u4mv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13352a8f14bb44c8aa0c5d95133a4abd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_102655-1hnu0bld</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1hnu0bld' target=\"_blank\">GINConv_3_16_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1hnu0bld' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1hnu0bld</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.7 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "2.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.2 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇█▇▇▇█▇▇▇▇█▇▇█▇████▇█████▇███</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇███▇▇█████▇███</td></tr><tr><td>train_f1</td><td>▁▇▇▇▇▇▇▇▇▇█▇█▇██████▇█▇█████████████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▃▃▃▃▃▂▂▂▃▃▂▂▃▂▂▂▂▂▂▂▂▁▂▁▂▂▁▂▂▂▁▂▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▅▄▅▇▄▃▄▄▃▂▄▂▅▂▃▄▃▂▂▃▃▃▄▂▁▃▃▂▃▄▃▂▃▂▂▄▁▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▇▅▆▇█▆▇▆▇▆▆▆▆▅▆▇▇▇▆█▇▆▆█▇▆▇▇▇▇▆█▇▇▇▇▇▇▇</td></tr><tr><td>val_auc</td><td>▁▅▅▇▆██▆██▇▆▇█▆▇██▇█▇█▇▆██████▇▆██▇▆█▇▇▇</td></tr><tr><td>val_f1</td><td>▁▆▃▄▆▇▄▆▂▆▄▄▄▅▃▅▅▆▆▅█▆▄▄▇▆▄▆▇▇▇▄█▆▆▆▅▇▆▆</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▃▂▁▃▃▃▂▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▃▂▃▂▃▂▂▂▂</td></tr><tr><td>val_loss_step</td><td>█▅▄▅▃▃▅▄▄▄▅▇▄▅▃▄▄▄▅▅▄▃▄▃▄▅▄▆▁▂▄▄▄▆▅▄▃▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85056</td></tr><tr><td>train_auc</td><td>0.92327</td></tr><tr><td>train_f1</td><td>0.84877</td></tr><tr><td>train_loss_epoch</td><td>0.35921</td></tr><tr><td>train_loss_step</td><td>0.44726</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82311</td></tr><tr><td>val_auc</td><td>0.90766</td></tr><tr><td>val_f1</td><td>0.82517</td></tr><tr><td>val_loss_epoch</td><td>0.38369</td></tr><tr><td>val_loss_step</td><td>0.3755</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1hnu0bld' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1hnu0bld</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_102655-1hnu0bld\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "582c619de40a4859aae96832ab1009ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_110446-0si5gcbd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0si5gcbd' target=\"_blank\">GINConv_3_32_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0si5gcbd' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0si5gcbd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 6.0 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "6.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.6 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▅▆▆▆▆▆▆▇▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███</td></tr><tr><td>train_auc</td><td>▁▅▅▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇██▇███▇▇██▇███</td></tr><tr><td>train_f1</td><td>▁▄▅▆▆▆▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇▇█▇▇███</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▃▃▃▂▂▂▂▂▃▂▂▂▃▂▂▂▂▃▂▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▇▆▆▅▆▄▅▅▃▃▄▄▅▅▄█▆▄▅▅▆▃▄▃▄▂▄▁▃▄▄▄▃▄▂▃▄▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▅▆▆▇█▇▇▆▃▆▇▇███▆▇▇▆▇▇█▇▅██▇▁▇▇▆█▆▇▇▇▇▆</td></tr><tr><td>val_auc</td><td>▁▄▅▆▆▆█▇▇▆▅▇▆▆▆▆▆▄▆▆▅▆▅▆▆▅▆▆▆▅▅▅▅▅▄▅▅▆▄▄</td></tr><tr><td>val_f1</td><td>▁▅▅▆▆▇███▆▄▆█▇█▇█▆▇▇▆▇▇█▇▅███▂▇▇▆█▆▇▇▇▇▆</td></tr><tr><td>val_loss_epoch</td><td>▆▄▄▂▃▂▁▁▃▂▄▃▁▁▁▂▂▃▁▂▃▂▂▂▂▄▃▃▁█▂▃▄▂▄▄▂▄▃▅</td></tr><tr><td>val_loss_step</td><td>▆▅▆▂▄▃▂▂▇▃▄▄▂▁▂▃▄▄▁▂▂▄▄▄▃▅▅▄▂█▂▅▆▂▄▃▁▄▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87537</td></tr><tr><td>train_auc</td><td>0.94286</td></tr><tr><td>train_f1</td><td>0.87015</td></tr><tr><td>train_loss_epoch</td><td>0.30673</td></tr><tr><td>train_loss_step</td><td>0.35818</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.79245</td></tr><tr><td>val_auc</td><td>0.8859</td></tr><tr><td>val_f1</td><td>0.7672</td></tr><tr><td>val_loss_epoch</td><td>0.52869</td></tr><tr><td>val_loss_step</td><td>0.481</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0si5gcbd' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0si5gcbd</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_110446-0si5gcbd\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "943dea3194914439b744fd28cca41de8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_114117-nii57cxf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/nii57cxf' target=\"_blank\">GINConv_3_32_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/nii57cxf' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/nii57cxf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 6.0 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "6.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.6 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇█▇▇███████▇██</td></tr><tr><td>train_auc</td><td>▁▅▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████▇▇█████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇▇▇██▇███████▇██</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▄▄▃▃▃▃▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▁▂▁▂▂▂▁▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▅▅▄▄▅▂▃▃▂▂▃▃▃▃▂▆▃▂▁▂▂▂▃▂▂▁▂▁▁▂▃▁▁▃▁▁▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▇▆▇▇▇▇█▇▇▇███▇███▇▇██▇▇█▇█▇▇▇▇▇▇▇▇▇█▇▇</td></tr><tr><td>val_auc</td><td>▁▆▇▇▇▇█▇▇▇▇▇███▇▇██▇███▇▇▇▇▇▇▇▇▇█▇▇█▇▇▇▇</td></tr><tr><td>val_f1</td><td>▁▆▇▇▇█▇████████████████▇███████████████▇</td></tr><tr><td>val_loss_epoch</td><td>█▅▄▃▃▃▂▂▃▂▂▃▁▁▁▂▂▁▁▂▁▂▂▃▂▂▃▂▂▂▂▃▂▂▂▃▂▂▂▃</td></tr><tr><td>val_loss_step</td><td>█▇▇▃▅▄▄▃▆▃▄▆▂▂▃▄▅▂▁▃▂▃▄▄▂▅▅▄▂▄▂▆▅▃▃▇▂▄▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85588</td></tr><tr><td>train_auc</td><td>0.92771</td></tr><tr><td>train_f1</td><td>0.85647</td></tr><tr><td>train_loss_epoch</td><td>0.33456</td></tr><tr><td>train_loss_step</td><td>0.37236</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81368</td></tr><tr><td>val_auc</td><td>0.90241</td></tr><tr><td>val_f1</td><td>0.80685</td></tr><tr><td>val_loss_epoch</td><td>0.4132</td></tr><tr><td>val_loss_step</td><td>0.37366</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/nii57cxf' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/nii57cxf</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_114117-nii57cxf\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ede5f17206854855bd02ae70a2a911c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_121943-z5uv0n3b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/z5uv0n3b' target=\"_blank\">GINConv_3_32_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/z5uv0n3b' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/z5uv0n3b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 6.0 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "6.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.6 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a44cba1018d4eb585469177764adaa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▅▆▆▆▆▆▆▇▆▇▆▆▇▇▇▇▇▇▇▇▇█▇█▇▇▇█▇█▇█▇█▇▇█</td></tr><tr><td>train_auc</td><td>▂▂▁▃▆▆▅▅▄▅▇▆▇▇▇██▇▆▅▆▅▅▆█▆▇▆▄▆▅▄▆▄▇▇▆█▅▇</td></tr><tr><td>train_f1</td><td>▁▃▃▅▆▆▆▆▇▆▇▆▇▆▆▇▇▇▇▇▇▇▇▇█▇█▇▇▇███▇██▇▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▂▂▂▁▂▂▂▁▃▁▂▂▁▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▂▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▂▄▅▆▇▇▇▇▇▅█▇▆▇▇▇▇█▇██▆▇▅▇▇▆▇▇▆▇▇▆▆▇▅▆▇▅</td></tr><tr><td>val_auc</td><td>▄▁▃▇███████████████████████████▇████████</td></tr><tr><td>val_f1</td><td>▁▂▄▅▆▇▇▇▇▇▅▇█▆▇▇█▇█▇▇█▆▇▅▇▇▇▇▇▆▇█▆▇▇▅▆▇▆</td></tr><tr><td>val_loss_epoch</td><td>█▅▅▃▃▂▃▃▃▂▃▂▂▂▂▂▂▂▁▂▂▂▃▃▄▃▃▄▂▃▃▃▃▃▂▃▃▅▂▆</td></tr><tr><td>val_loss_step</td><td>▆▇█▂▆▃▃▄▆▃▄▄▃▂▃▃▅▃▁▂▁▃▅▅▂▆▆▆▁▄▂▅▆▄▃▂▂▄▁▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85706</td></tr><tr><td>train_auc</td><td>0.67882</td></tr><tr><td>train_f1</td><td>0.8593</td></tr><tr><td>train_loss_epoch</td><td>0.35771</td></tr><tr><td>train_loss_step</td><td>0.39354</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.79245</td></tr><tr><td>val_auc</td><td>0.89487</td></tr><tr><td>val_f1</td><td>0.77202</td></tr><tr><td>val_loss_epoch</td><td>0.5444</td></tr><tr><td>val_loss_step</td><td>0.63075</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/z5uv0n3b' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/z5uv0n3b</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_121943-z5uv0n3b\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7f715c8e48c407f944c1320f0875f70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_125503-cu84cf3m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/cu84cf3m' target=\"_blank\">GINConv_3_32_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/cu84cf3m' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/cu84cf3m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 6.0 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "6.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.6 K     Total params\n",
      "0.027     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▅▅▅▆▆▆▇▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇███████████</td></tr><tr><td>train_auc</td><td>▁▅▅▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇█▇▇▇█▇█████████████</td></tr><tr><td>train_f1</td><td>▁▅▅▅▆▆▆▆▆▇▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇███████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▄▄▄▄▄▃▃▄▃▃▃▂▃▃▂▂▂▂▂▂▂▁▂▁▂▂▂▂▁▂▂▁▁▂▂▁</td></tr><tr><td>train_loss_step</td><td>▇▆█▇▆▅▅▅▄▃▆▅▅▄▃▄▅▃▂▄▃▃█▅▃▂▄▁▂▄▃▃▃▃▂▄▃▁▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▇▇██▆▇▇█▇█▆▇▇█▇█▆█▇▇▇▇██▇▄███▇█▇▇█▇█▇▇</td></tr><tr><td>val_auc</td><td>▁▄▇▅▆▇▃▄▆▇▆█▇▆▂▇▄▆▆▇▇█▅▇▇▆▃▆▇▅▇▆▆▃▆▆▆▇▇▇</td></tr><tr><td>val_f1</td><td>▁▇▇▇██▇▇▇▇▇▇▆▇▇█▇█▆█▇▇▇▇██▇▅███▇█▇▇█▇█▇▇</td></tr><tr><td>val_loss_epoch</td><td>▆▃▃▂▂▁▃▃▃▂▃▂▄▂▃▃▃▂▄▁▂▃▂▃▁▂▃█▂▂▁▃▂▂▂▂▃▁▃▂</td></tr><tr><td>val_loss_step</td><td>▆▃▆▄▄▃▅▅▆▄▇▄▇▄▃▄▇▄▆▃▃▅▃▅▂▂▆█▃▃▂▄▅▄▄▃▅▁▆▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8795</td></tr><tr><td>train_auc</td><td>0.9401</td></tr><tr><td>train_f1</td><td>0.8774</td></tr><tr><td>train_loss_epoch</td><td>0.31138</td></tr><tr><td>train_loss_step</td><td>0.26986</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.79245</td></tr><tr><td>val_auc</td><td>0.90991</td></tr><tr><td>val_f1</td><td>0.78325</td></tr><tr><td>val_loss_epoch</td><td>0.40899</td></tr><tr><td>val_loss_step</td><td>0.42855</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/cu84cf3m' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/cu84cf3m</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_125503-cu84cf3m\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f20f66b7d3b4b7fae926dc197ab402e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_133101-wbfown5p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wbfown5p' target=\"_blank\">GINConv_3_32_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wbfown5p' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wbfown5p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 6.0 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "7.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.7 K     Total params\n",
      "0.031     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▅▅▆▆▆▆▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇█████████</td></tr><tr><td>train_auc</td><td>▁▅▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇███▇▇▇██████████</td></tr><tr><td>train_f1</td><td>▁▆▅▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇██████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▃▃▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂</td></tr><tr><td>train_loss_step</td><td>█▆▆▆▅▅▅▄▄▃▇▅▅▃▅▃▄▆▄▃▂▃▆▄▃▃▃▅▃▃▄▃▃▂▃▄▁▃▂▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▇▇▇▇▇▇█▇█▆▇▇▇▇███▇██▇█▇▇██▇▇▇▆▇█▇▇▆█▇▆▇</td></tr><tr><td>val_auc</td><td>▁▅▇█▇█▇▇▇█▁█▆▇▇▇█▇▇▇▆▅▇▇▇▇▅▇▆▁▇▅▇▆▆▆▇▇▄▆</td></tr><tr><td>val_f1</td><td>▁▇▇▇▇▇██▇█▇▇▇▇▇████████▇█████▇▇██▇█▇█▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▃▂▂▁▂▂▂▃▂▃▂▃▂▁▂▂▂▁▂▂▃▂▂▂▂▂▃▇▂▂▃▂▅▂▄▃▄</td></tr><tr><td>val_loss_step</td><td>█▃▃▃▂▃▁▃▃▃▃▃▂▂▄▄▂▃▄▃▁▃▂▄▃▃▄▃▂▃▆▂▃▂▃▄▃▇▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85883</td></tr><tr><td>train_auc</td><td>0.93121</td></tr><tr><td>train_f1</td><td>0.85799</td></tr><tr><td>train_loss_epoch</td><td>0.33136</td></tr><tr><td>train_loss_step</td><td>0.40995</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.75708</td></tr><tr><td>val_auc</td><td>0.89342</td></tr><tr><td>val_f1</td><td>0.72237</td></tr><tr><td>val_loss_epoch</td><td>0.51806</td></tr><tr><td>val_loss_step</td><td>0.55009</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wbfown5p' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wbfown5p</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_133101-wbfown5p\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c945daff865434cb8bbb62f5dc45209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333332417533, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_141016-1ryc753c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1ryc753c' target=\"_blank\">GINConv_3_64_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1ryc753c' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1ryc753c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 22.3 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "24.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.5 K    Total params\n",
      "0.098     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▅▄▃▅▅▅▅▆▅▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇███████</td></tr><tr><td>train_auc</td><td>▁▄▄▄▅▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇██▇███████</td></tr><tr><td>train_f1</td><td>▁▃▄▅▄▃▄▅▅▅▆▅▆▆▅▆▆▆▆▇▆▇▇▇▆▆▇▇▇▇▇▇▇████▇██</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▅▆▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▃▂▃▃▂▃▂▃▁▁▂▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▆▅▇▅▅▆▄▅▄▄▄▄▄▄▅▆▄▅▅▃▇▄▄▄▄▅▃▃▃▂▄▃▃▄▂▃▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▃▅▃▁▅▇▆▇▂█▅▄▄▇▄█▂▆▄▇▇▃▇▇▇▅█▃▁▃▅▅▇▃▇▄▆▆▄▅</td></tr><tr><td>val_auc</td><td>▄▆▆▁█▇██▂█▄▅▂▇▄█▅▆▇▆▄▄▇▇▇▆▇▃▂▆▄▅▆▆▅▄▆▆▃▃</td></tr><tr><td>val_f1</td><td>▆▄▂▁▅▇▆▆▃▇▆▄▆▆▆▇▂▇▄▇▇▃▇▇▇▆█▃▁▃▆▇▇▂▆▆▆▆▅▅</td></tr><tr><td>val_loss_epoch</td><td>▄▄▃▆▂▂▂▂▄▁▂▃▃▃▅▂▄▃▄▃▅█▂▄▂▄▃▆▆▄▃▆▃█▄▅▃▅▄▆</td></tr><tr><td>val_loss_step</td><td>▅▆▄▅▃▃▃▄▄▂▂▃▄▅▇▃▄▄▃▃▆▅▂▅▃▆▃▅▄▃▁▄▄█▂▂▄▅▃█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.89781</td></tr><tr><td>train_auc</td><td>0.9565</td></tr><tr><td>train_f1</td><td>0.89806</td></tr><tr><td>train_loss_epoch</td><td>0.25626</td></tr><tr><td>train_loss_step</td><td>0.14513</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.78302</td></tr><tr><td>val_auc</td><td>0.86494</td></tr><tr><td>val_f1</td><td>0.78505</td></tr><tr><td>val_loss_epoch</td><td>0.57257</td></tr><tr><td>val_loss_step</td><td>0.78364</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1ryc753c' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1ryc753c</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_141016-1ryc753c\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cb067f364734ddcb050065d4117fad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_144824-qv10jcz2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qv10jcz2' target=\"_blank\">GINConv_3_64_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qv10jcz2' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qv10jcz2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 22.3 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "24.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.5 K    Total params\n",
      "0.098     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▅▅▆▆▅▆▆▆▇▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████▇▇</td></tr><tr><td>train_auc</td><td>▁▄▅▅▆▆▆▅▇▆▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇▇▇██▇███████</td></tr><tr><td>train_f1</td><td>▁▅▅▅▅▆▆▄▆▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█████▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▄▄▅▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▃▂▂▁▂▂▂▁▁▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>▆▇▆▄▅▃▃▅▃▄▃▄▃▃▃▃▂█▄▂▃▂▄▃▄▂▂▅▂▂▂▂▁▃▃▂▃▂▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▆▃▅▇▅▄▆▆▆▆▅▇▅▆█▇▅█▇▇▇▅▅▇▇▆▆▇▅▇▇▆▆▇▆▅▅▆</td></tr><tr><td>val_auc</td><td>▁▄▆▁▇▇█▆▆██▆▆█▆█▇▇▇▇▇█▇▆▆▇▇▅▆▆▅▆▇▇▆▆▆▆▅▆</td></tr><tr><td>val_f1</td><td>▁▄▄▄▃▆▃▁▆▇▇▆▅▆▆▆█▇▂▇▇▇▇▅▆▇▆▆▅▇▅▇▆▆▆▇▅▅▅▅</td></tr><tr><td>val_loss_epoch</td><td>█▆▄▆▄▂▃▄▂▁▁▂▃▄▄▃▂▄▆▂▄▂▄▃▅▆▃▃▃▄▅▆▃▇▃▄▆▇▇▇</td></tr><tr><td>val_loss_step</td><td>▇▇▅▅▄▂▄▅▃▂▂▃▃█▅▄▁▇▃▂▄▄▄▃▄▇▃▃▂▃▁▇▄▇▂▂▆▆██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.88069</td></tr><tr><td>train_auc</td><td>0.94521</td></tr><tr><td>train_f1</td><td>0.88187</td></tr><tr><td>train_loss_epoch</td><td>0.28133</td></tr><tr><td>train_loss_step</td><td>0.18823</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83255</td></tr><tr><td>val_auc</td><td>0.91058</td></tr><tr><td>val_f1</td><td>0.82555</td></tr><tr><td>val_loss_epoch</td><td>0.47623</td></tr><tr><td>val_loss_step</td><td>0.66209</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qv10jcz2' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qv10jcz2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_144824-qv10jcz2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59765c9cba524bd0be02d01cb0bb8310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333332417533, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_152256-7vhmwdnj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7vhmwdnj' target=\"_blank\">GINConv_3_64_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7vhmwdnj' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7vhmwdnj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 22.3 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "24.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.5 K    Total params\n",
      "0.098     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▅▆▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████</td></tr><tr><td>train_auc</td><td>█▄▂▂▁▁▂▁▂▂▂▂▂▂▂▃▂▂▃▄▄▆███▅▂▂▂▃▂▃▃▃▂▃▂▂▄▆</td></tr><tr><td>train_f1</td><td>▁▄▅▅▆▆▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▂▁▂▂▁▁▁▁▂▁▂▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▆▆▆▇▆▇▇▇▅▇▆▇▆▆▄█▇▇▄▇▇▂▇██▇█▄▆▇▆▅▇▅▅▆▇▆▄▁</td></tr><tr><td>val_auc</td><td>▆▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▂▂▃█▅▆▁▁▁▂▁▁▂▂▁▂▁▁▁▁▁</td></tr><tr><td>val_f1</td><td>▇▇▆▇▇▇▇▇▆▇█▇▇▆▆██▇▄▇█▃▇████▅▆▇▇▇█▆▆▇█▆▅▁</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▂▂▁▁▁▂▁▂▁▂▂▂▁▁▁▃▁▂▃▂▂▁▂▁▂▂▁▂▃▂▃▂▂▃▃▃▇</td></tr><tr><td>val_loss_step</td><td>▅▅▃▃▂▂▂▂▃▁▂▂▂▃▃▂▁▃▃▁▃▃▂▃▂▄▂▃▁▂▁▃▁▄▁▁▅▃▃█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.88423</td></tr><tr><td>train_auc</td><td>0.4847</td></tr><tr><td>train_f1</td><td>0.88402</td></tr><tr><td>train_loss_epoch</td><td>0.29379</td></tr><tr><td>train_loss_step</td><td>0.21189</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.70991</td></tr><tr><td>val_auc</td><td>0.11183</td></tr><tr><td>val_f1</td><td>0.6192</td></tr><tr><td>val_loss_epoch</td><td>0.82425</td></tr><tr><td>val_loss_step</td><td>1.05479</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7vhmwdnj' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7vhmwdnj</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_152256-7vhmwdnj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33e9bb0fa2d14ac8860fd2f947e2ce2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_155723-nqc603hc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/nqc603hc' target=\"_blank\">GINConv_3_64_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/nqc603hc' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/nqc603hc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 22.3 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "24.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.5 K    Total params\n",
      "0.098     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c18778e82c6e417e838983a92a8171cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▃▄▅▅▆▅▆▆▆▆▆▆▆▇▆▅▇▇▇▇▆▇▇▇▇▇▇▇▆▇▇▆▇▇█▇██</td></tr><tr><td>train_auc</td><td>▁▄▄▅▆▆▆▆▆▆▆▆▆▆▇▇▇▆▇▇▇▇▇█▇█▇▇██▇██▇██████</td></tr><tr><td>train_f1</td><td>▁▃▃▄▅▅▆▅▅▆▅▆▆▅▆▇▆▆▇▇▇▇▆▇▇▇▇▇▇▇▆▇▇▆▇▇█▇██</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▅▅▄▄▄▄▄▄▄▄▄▃▃▃▄▃▂▃▃▃▂▃▂▂▂▂▂▃▂▁▃▂▁▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>▆▅▄▄▅▄▄▄▄▄▄▄█▄▃▄▃▇▃▃▃▃▃▂▃▃▃▃▃▃▃▃▂▄▃▃▃▂▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▆▇▇▆▁▇▆▇▇▆▆█▇▄▆▆▇▅▅▆▂▇▆▅▆▆▄▇▄▆▆▇▆▃▃▅▆▆▄▆</td></tr><tr><td>val_auc</td><td>▅▇▇▇▇▇█▇█▇▇█▇▆▆▇██▅▆▄▇▇▅▆▇▆▇▂▇▇▆▇▁▁▆▆▅▅▆</td></tr><tr><td>val_f1</td><td>▇▇█▇▁█▇█▇▇▇█▇▇▆▇▇▅▆▇▃▇▇▇▇▆▄█▆█▇▇▇▅▄▆▇▇▆▇</td></tr><tr><td>val_loss_epoch</td><td>▄▂▂▂▅▂▃▃▁▁▁▁▂▄▂▂▁▂▃▃▇▂▃▅▃▃█▄▇▃▄▆▅▆▇▅▄▅█▅</td></tr><tr><td>val_loss_step</td><td>▃▂▃▂▃▄▄▄▂▁▁▂▂▂▁▃▁▁▃▂▃▁▂▃▃▃▇▂▅▂▅▅▃▅▃▃▂▁█▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.90254</td></tr><tr><td>train_auc</td><td>0.96059</td></tr><tr><td>train_f1</td><td>0.90042</td></tr><tr><td>train_loss_epoch</td><td>0.24459</td></tr><tr><td>train_loss_step</td><td>0.08742</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80896</td></tr><tr><td>val_auc</td><td>0.89073</td></tr><tr><td>val_f1</td><td>0.80576</td></tr><tr><td>val_loss_epoch</td><td>0.4866</td></tr><tr><td>val_loss_step</td><td>0.52788</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/nqc603hc' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/nqc603hc</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_155723-nqc603hc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11bc000e70214fab84e30d6627ea8f0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_163151-fx5rjmg1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fx5rjmg1' target=\"_blank\">GINConv_3_64_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fx5rjmg1' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fx5rjmg1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 22.3 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "28.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "28.7 K    Total params\n",
      "0.115     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▅▆▅▆▅▆▅▅▆▆▆▆▇▆▇▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇█▇██</td></tr><tr><td>train_auc</td><td>▁▄▅▅▆▆▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇██▇█▇▇███▇████▇██</td></tr><tr><td>train_f1</td><td>▁▃▅▅▆▅▆▅▆▅▆▆▇▆▆▇▆▇▆▆▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇█▇██</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▄▄▄▄▄▄▃▃▃▄▃▃▃▃▃▂▃▂▂▂▃▁▂▂▂▂▂▂▂▂▂▂▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▆▆█▅▆▄▅▄▅▆▄▅▃▃▆▃▄▃▅▃▃▅▃▄▃▄▄▃▅▂▂▃▃▂▄▃▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▆▂▇▅▁▇▇██▇▇▇▅▇▆▆▇▇▆▇▇▆▇▆█▇▄▆▆▆▇▆▇▇▇▁▇▆▆▆</td></tr><tr><td>val_auc</td><td>▆▇██▁███▇██▇▆▆▆▆▇▆▇▇▇▇█▆▇▆▆▆▇▆▆▆▇▅▇▄▆▆▅▆</td></tr><tr><td>val_f1</td><td>▇▂▇▄▄▇▇███▇█▅▇▇▆▇█▇▇▆▇▇▇█▇▇▆▆▇▇▆▇▇█▁█▆▇▆</td></tr><tr><td>val_loss_epoch</td><td>▃▅▂▃▄▂▁▂▂▃▁▃▃▂▂▃▃▂▃▃▄▃▃▂▂▃▅▃▃▂▃▄▂▃▂█▃▃▄▃</td></tr><tr><td>val_loss_step</td><td>▃▅▄▅▅▄▁▅▄▅▂▇▄▁▂▅▄▄▄▆▃▆▄▁▄▃█▂▄▂▄▁▂▅▂▅▃▄▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.89191</td></tr><tr><td>train_auc</td><td>0.95822</td></tr><tr><td>train_f1</td><td>0.89009</td></tr><tr><td>train_loss_epoch</td><td>0.2518</td></tr><tr><td>train_loss_step</td><td>0.15552</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.79481</td></tr><tr><td>val_auc</td><td>0.89019</td></tr><tr><td>val_f1</td><td>0.79236</td></tr><tr><td>val_loss_epoch</td><td>0.44977</td></tr><tr><td>val_loss_step</td><td>0.4204</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fx5rjmg1' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fx5rjmg1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_163151-fx5rjmg1\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d537d86ad6ab4a00b3a37bdb8d46822e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_170630-jcqfz8ke</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jcqfz8ke' target=\"_blank\">GINConv_4_16_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jcqfz8ke' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jcqfz8ke</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 2.4 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█████▇█▇▇████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▇▇▇▇▇▇▇██▇█▇▇▇▇█▇██████▇████████████</td></tr><tr><td>train_f1</td><td>▁▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇███▇█▇▇████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▂▁▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▅▄▅▅▃▃▄▅▄▃▄▃▄▃▃▃▅▁▃▂▄▃▃▅▂▃▃▂▁▁▁▂▂▂▄▂▁▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▆▆▅▇▆▄▆▇▇▇▄▇▆▇▇█▆▅▅▆█▇▇▇▆█▅█▅█▇▇▇▇▅▅▇▆</td></tr><tr><td>val_auc</td><td>▁▄▅▅▅▇▆▃▆▇▇█▄▇▇▇██▆▆▅▇▇▇▇▇▅▇▆█▇▇▇▇▇▇▅▅▇▅</td></tr><tr><td>val_f1</td><td>▄▇▅▅▃▅▄▃▄▇▆▆▁▇▄▇▇▇▄▃▃▅█▅▆▇▄▇▄▇▃█▇▆▇▆▃▅▆▆</td></tr><tr><td>val_loss_epoch</td><td>█▂▃▃▃▂▃▂▃▁▂▂▃▂▂▁▁▂▂▂▃▂▂▂▁▁▂▁▂▂▃▁▁▂▂▂▃▂▂▃</td></tr><tr><td>val_loss_step</td><td>█▂▅▆▅▄▄▄▆▂▃▅▆▆▅▃▄▅▃▁▇▅▆▆▂▃▄▃▂▆▃▄▃▇▅▅▆▄▅▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83579</td></tr><tr><td>train_auc</td><td>0.89488</td></tr><tr><td>train_f1</td><td>0.83373</td></tr><tr><td>train_loss_epoch</td><td>0.40699</td></tr><tr><td>train_loss_step</td><td>0.42768</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80425</td></tr><tr><td>val_auc</td><td>0.89649</td></tr><tr><td>val_f1</td><td>0.81348</td></tr><tr><td>val_loss_epoch</td><td>0.42541</td></tr><tr><td>val_loss_step</td><td>0.501</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jcqfz8ke' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jcqfz8ke</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_170630-jcqfz8ke\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e17d4879a5461eb2a77a49c3baba92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_174054-avps9erg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/avps9erg' target=\"_blank\">GINConv_4_16_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/avps9erg' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/avps9erg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 2.4 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2abe10d1afce4c62a48a1a5bfc4fb69e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇███▇▇███</td></tr><tr><td>train_auc</td><td>▁▄▅▅▅▆▆▇▇▆▇▇▇▇▇▇▇▇▇██▇██▇▇█▇████████████</td></tr><tr><td>train_f1</td><td>▁▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇▇▇██▇████▇▇██▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▅▄▃▄▃▃▃▃▂▂▃▂▂▂▃▂▂▂▂▂▂▂▂▂▃▁▂▂▂▂▁▁▁▂▂▁▂</td></tr><tr><td>train_loss_step</td><td>█▆▄▅▆▃▄▃▅▃▃▄▂▄▃▂▂▄▂▄▃▄▂▂▄▂▃▃▄▁▂▂▁▁▃▄▃▁▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▇▇▇▇▇▇▇█▇▇▅█▇▇▆█▆▇▇▇▇▆▇▅▆▆▆▇▇▇▇▇▆▇▇▆▇▆</td></tr><tr><td>val_auc</td><td>▁▅▆▆▇▇▇▇▆█▇▇▅▇█▇▆▇▆▇▇██▆▇▅▅▅▇█▇██▇▆██▆▇▆</td></tr><tr><td>val_f1</td><td>▁▄▅▆▆▇▇▇▆█▅▇▅█▇▇▅█▄▇▆▇▇▅▇▅▅▅▆▇▇▇▇▇▆▇▇▆▇▆</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▃▂▂▂▂▂▁▁▂▄▂▁▂▂▂▃▂▂▂▂▂▂▃▂▃▂▂▁▂▁▂▃▁▂▂▂▂</td></tr><tr><td>val_loss_step</td><td>█▂▅▅▄▄▄▃▄▁▂▆▆▅▃▃▂▃▄▁▃▃▄▃▃▃▁▄▃▅▃▄▂▄▆▂▄▃▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.80744</td></tr><tr><td>train_auc</td><td>0.87875</td></tr><tr><td>train_f1</td><td>0.80456</td></tr><tr><td>train_loss_epoch</td><td>0.42956</td></tr><tr><td>train_loss_step</td><td>0.46458</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.79481</td></tr><tr><td>val_auc</td><td>0.89565</td></tr><tr><td>val_f1</td><td>0.81046</td></tr><tr><td>val_loss_epoch</td><td>0.42318</td></tr><tr><td>val_loss_step</td><td>0.44016</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/avps9erg' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/avps9erg</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_174054-avps9erg\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7ed44f62f624ac6a1ad0f4de3fabca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.017183333332650364, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_181619-pu4gk7jz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/pu4gk7jz' target=\"_blank\">GINConv_4_16_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/pu4gk7jz' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/pu4gk7jz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 2.4 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb2a8255b8304ece8f54c6c05c6b6526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇███▇▇████▇█</td></tr><tr><td>train_auc</td><td>▅▄▄▄▅▅▆█▇▆▆▆▅▄▄▄▂▂▃▁▂▂▃▂▂▃▄▃▁▃▃▅▅▄▄▂▄▃▄▆</td></tr><tr><td>train_f1</td><td>▁▂▅▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇██▇███▇▇▇██████▇██████</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇▇▇▆▇█▇▇▇█████▇▇▇█▇█▇█▇██▇▇█</td></tr><tr><td>val_auc</td><td>▅▆▇▇▇▇▇▇█████▇▇▆▆█▇▄▆▃▂▅▃▁▆█▁▇██████████</td></tr><tr><td>val_f1</td><td>▁▄▆▇▆▆▆▆▄▅▅▇▆▆▆▄▆▇▆▆▆██▇▇▇▇▆▆█▆▇▆█▇▇▇▆▆█</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▃▃▂▂▂▂▂▁▁▂▂▂▂▂▂▁▁▂▁▂▂▁▁▂▁▂▂▁▁▁▂▁▁▁▁▂▁</td></tr><tr><td>val_loss_step</td><td>█▄▅▄▄▃▃▃▃▂▂▃▃▃▃▂▃▃▂▁▃▃▃▃▁▂▃▂▂▄▂▂▂▄▄▃▃▂▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83343</td></tr><tr><td>train_auc</td><td>0.6278</td></tr><tr><td>train_f1</td><td>0.83431</td></tr><tr><td>train_loss_epoch</td><td>0.4053</td></tr><tr><td>train_loss_step</td><td>0.53589</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83962</td></tr><tr><td>val_auc</td><td>0.91046</td></tr><tr><td>val_f1</td><td>0.84545</td></tr><tr><td>val_loss_epoch</td><td>0.40076</td></tr><tr><td>val_loss_step</td><td>0.48708</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/pu4gk7jz' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/pu4gk7jz</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_181619-pu4gk7jz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ae094af360543c493e0aa08eb70fe41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333332417533, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_185544-dwyn1gym</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/dwyn1gym' target=\"_blank\">GINConv_4_16_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/dwyn1gym' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/dwyn1gym</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 2.4 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "2.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▇▆▇▆▇▇▇▇▇▇▇█▇█▇▇████▇███▇███████████</td></tr><tr><td>train_auc</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇███▇█████▇███████████████</td></tr><tr><td>train_f1</td><td>▁▇▆▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇████████▇███████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▄▃▃▃▂▃▂▂▃▃▂▂▂▂▂▂▂▂▂▂▁▂▁▂▁▁▁▂▁▁▁▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▄▃▆▄▅▄▆▃▂▃▄▂▃▅▂▃▄▂▂▃▄▁▄▄▆▄▁▂▃▁▃▂▃▃▂▃▃▂▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▇▇█▇▇▇▇▇█▇███▇▇▇███▇▇▇▇█████▇██▇▇█▇▇█▇█</td></tr><tr><td>val_auc</td><td>▁▅▄▆▇▆▆▇▆▇▇▇█▇▇▆▆███▇▆▇▆▇▇██▆▆▇█▅▇▇▇▆▇▆█</td></tr><tr><td>val_f1</td><td>▁▇▇▇▄▄▅▆▆▆▇▆█▇▅▅▅▇▇▇▅▆▆▇▇▆▇██▄▇▇▆▆█▅▅█▆█</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▃▃▃▃▃▂▂▂▂▁▂▂▃▃▁▂▂▃▂▂▂▂▂▂▁▂▃▂▃▃▂▂▃▃▂▂▂</td></tr><tr><td>val_loss_step</td><td>█▄▄▄▃▄▃▄▃▄▃▃▂▅▃▅▅▂▅▅▅▄▃▃▄▅▃▁▄▅▃▅▅▄▂▅▄▄▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84052</td></tr><tr><td>train_auc</td><td>0.90973</td></tr><tr><td>train_f1</td><td>0.83813</td></tr><tr><td>train_loss_epoch</td><td>0.39892</td></tr><tr><td>train_loss_step</td><td>0.51663</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82783</td></tr><tr><td>val_auc</td><td>0.92152</td></tr><tr><td>val_f1</td><td>0.82904</td></tr><tr><td>val_loss_epoch</td><td>0.3615</td></tr><tr><td>val_loss_step</td><td>0.36895</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/dwyn1gym' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/dwyn1gym</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_185544-dwyn1gym\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e74918426f6f46fa936cbfd7245931b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_193156-ahqowq8d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ahqowq8d' target=\"_blank\">GINConv_4_16_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ahqowq8d' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ahqowq8d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 2.4 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "2.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.8 K     Total params\n",
      "0.011     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fde9ea60f8646d0ac23aaefbc31913a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇█▇▇███▇██▇█▇██████</td></tr><tr><td>train_auc</td><td>▁▆▇▆▇▇▇▇▇▇▇▇▇█▇████▇████████████████████</td></tr><tr><td>train_f1</td><td>▁▆▇▆▇▇▇▇▇▇▇▇█▇██▇▇█▇███▇████▇████▇▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▂▁▂▁▂▂▁▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>▅▅▄▃▃▄▃▃▃▃▄▃▃▃▃▂▂▂▃▃▃▃▃▂▂▃▃▁▂▃▂▃▃▃▂▃▃▄▄█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▇▇▇▇▇█▇▇▇████▇▇▇█▇▇▆▇█▇▇▇▇██▇██▆█▇██▇█▇</td></tr><tr><td>val_auc</td><td>▁▆▇▇█▇█▇█▇██████████▇██▇█▇▇█████▇████▇█▇</td></tr><tr><td>val_f1</td><td>▁▇▆▆▆▇▇▄▆▄█▇█▇▇▅▇▇█▆▃▆█▆▆▆▄▇█▆██▂▇▇█▇▄█▆</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▂▂▂▂▂▂▄▂▂▁▁▂▃▁▂▂▃▃▂▁▂▁▃▂▂▂▁▂▂▃▁▂▁▂▂▂▂</td></tr><tr><td>val_loss_step</td><td>█▆▃▅▅▄▅▄▄▇▆▄▂▃▄▅▂▄▄▆▄▅▂▄▃▇▄▄▆▂▅▄▅▂▄▄▅▁▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85115</td></tr><tr><td>train_auc</td><td>0.91161</td></tr><tr><td>train_f1</td><td>0.85349</td></tr><tr><td>train_loss_epoch</td><td>0.40091</td></tr><tr><td>train_loss_step</td><td>0.95663</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80425</td></tr><tr><td>val_auc</td><td>0.90526</td></tr><tr><td>val_f1</td><td>0.79404</td></tr><tr><td>val_loss_epoch</td><td>0.41597</td></tr><tr><td>val_loss_step</td><td>0.46288</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ahqowq8d' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ahqowq8d</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_193156-ahqowq8d\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1954ef80b07e4b0788aa5da8e32e4558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_200646-gkzlyoua</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gkzlyoua' target=\"_blank\">GINConv_4_32_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gkzlyoua' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gkzlyoua</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 8.3 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "8.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.8 K     Total params\n",
      "0.035     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3d274604885491c8a2d65e203a7f40e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▅▅▆▆▆▆▆▇▆▇▆▇▇▆▇▇▇▇▇▇█▇▇██▇█▇▇█████▇██</td></tr><tr><td>train_auc</td><td>▁▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇██████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇████▇████████▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▅▅▄▄▄▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▂▂▁▂▂</td></tr><tr><td>train_loss_step</td><td>█▆▇▇▅▇▆█▅▇▅▆▄▄▃▅▅▁▄▅▄▄▅▅▄▄▅▂▅▃▅▆▅▃▃▄▅▄▅█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▆▇█▇▆█▇▇▇▆█▆▇▇█▇██▇█▇▇▆</td></tr><tr><td>val_auc</td><td>▁▃▄▆▃▇▆▇▆▅▅▆▆▃▅▅▆▃▅▇▇▄▅▆▆▂▆█▃▇▇▇▆▃▇▇▆▄▇▆</td></tr><tr><td>val_f1</td><td>▁▆▇▇▇█▇▇▇█▇█▇█▇▇▇▆▇█▇▇█▇▇▇▇█▆▇▇█▇██▇█▇▇▆</td></tr><tr><td>val_loss_epoch</td><td>█▅▃▂▃▁▂▃▂▁▂▁▃▂▆▃▂▄▄▁▃▃▂▃▂▃▅▂▄▄▂▁▃▃▂▄▃▄▄▅</td></tr><tr><td>val_loss_step</td><td>█▅▄▂▃▁▄▂▂▁▂▁▄▂▆▄▄▄▆▁▄▃▂▃▂▅▂▃▄▃▄▁▄▃▄▃▄▃▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86119</td></tr><tr><td>train_auc</td><td>0.93212</td></tr><tr><td>train_f1</td><td>0.85609</td></tr><tr><td>train_loss_epoch</td><td>0.33841</td></tr><tr><td>train_loss_step</td><td>0.53104</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.75708</td></tr><tr><td>val_auc</td><td>0.90279</td></tr><tr><td>val_f1</td><td>0.70487</td></tr><tr><td>val_loss_epoch</td><td>0.52593</td></tr><tr><td>val_loss_step</td><td>0.55113</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gkzlyoua' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gkzlyoua</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_200646-gkzlyoua\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7caf147dfaf64316817bbe9ba2c2fb56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_204637-k9i1wn28</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/k9i1wn28' target=\"_blank\">GINConv_4_32_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/k9i1wn28' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/k9i1wn28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 8.3 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "8.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.8 K     Total params\n",
      "0.035     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇█▇██████████▇</td></tr><tr><td>train_auc</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇██▇█████▇███████████</td></tr><tr><td>train_f1</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████▇▇▇▇██████████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▄▄▃▃▃▃▃▂▂▃▂▂▁▂▂▂▂▂▂▂▂▂▁▂▂▂▂▁▁▁▁▂▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▆▆▅▄▅▄▆▄▅▄▅▅▄▄▄▄▁▃▄▄▄▃▅▄▃▄▂▅▃▄▄▄▃▃▃▄▃▄▇</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▁▇█▆▆▇▇▆▇▇▇▆▅█▆▇▅▇█▆▇█▇▇█▇▆▇▇█▇▇▇▅█▆▆▆▆</td></tr><tr><td>val_auc</td><td>▁▅▆▇▇▆▇▇▆▇▇█▇▅▇▇▇▆▇▇▇▇▇▇▇▇▆▇▇▇██▇▇▆▇▆▆▆▆</td></tr><tr><td>val_f1</td><td>▁▁▇█▆▇█▇▇██▇▆▆█▆▇▇▇█▆▇█▇██▇▆▇██▇▇▇▇█▆▆▆▇</td></tr><tr><td>val_loss_epoch</td><td>█▅▂▁▂▂▂▁▂▁▂▁▂▂▂▁▂▃▃▁▂▂▁▁▁▂▂▂▁▂▁▁▂▂▂▂▂▃▃▂</td></tr><tr><td>val_loss_step</td><td>█▇▅▃▃▂▄▃▃▃▂▃▆▄▅▃▅▅▆▃▄▆▃▂▄▅▁▄▂▅▃▃▅▅▅▄▅▅▇▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83225</td></tr><tr><td>train_auc</td><td>0.90733</td></tr><tr><td>train_f1</td><td>0.82809</td></tr><tr><td>train_loss_epoch</td><td>0.39394</td></tr><tr><td>train_loss_step</td><td>0.57605</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80425</td></tr><tr><td>val_auc</td><td>0.89898</td></tr><tr><td>val_f1</td><td>0.81596</td></tr><tr><td>val_loss_epoch</td><td>0.40142</td></tr><tr><td>val_loss_step</td><td>0.42376</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/k9i1wn28' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/k9i1wn28</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_204637-k9i1wn28\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f56f4d430ba4e15a9b9c4dea689fd70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_212408-bx3oj7lt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/bx3oj7lt' target=\"_blank\">GINConv_4_32_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/bx3oj7lt' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/bx3oj7lt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 8.3 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "8.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.8 K     Total params\n",
      "0.035     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▆▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇██████</td></tr><tr><td>train_auc</td><td>█▆▄▃▃▃▃▃▃▂▂▃▃▃▃▃▃▃▃▃▃▃▂▃▃▃▃▅▄▄▃▂▂▃▃▂▁▂▂▃</td></tr><tr><td>train_f1</td><td>▁▄▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████▇██████</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▃▂▂▂▂▃▂▂▂▂▂▂▂▂▂▁▁▂▂▂▁▂▂▂▂▁▂▂▁▂▂▂▂▂▂▂▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▅▆▆▆▇▇▇▇▆▇▇▇█▇▇▆▇▆▇▆▇▇█▇▇▇▃▇▇▇▇▇▇▆▃▇▅▇</td></tr><tr><td>val_auc</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_f1</td><td>▁▃▅▆▆▆▇▇█▇▆▇▇▇█▇▆▆▇▆▇▅▇▇█▇▇▇▂▇▇█▇▇▇▆▁▇▄▇</td></tr><tr><td>val_loss_epoch</td><td>▇▅▄▂▃▂▃▂▂▂▂▂▂▁▂▂▂▂▃▂▂▃▁▁▁▂▁▃▅▁▂▁▂▁▂▃█▂▆▁</td></tr><tr><td>val_loss_step</td><td>█▆▅▂▄▂▅▂▃▂▃▃▃▂▅▄▃▃▇▂▄▃▁▂▃▅▁▄▃▂▃▃▃▃▄▄▇▄▇▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84406</td></tr><tr><td>train_auc</td><td>0.23348</td></tr><tr><td>train_f1</td><td>0.84342</td></tr><tr><td>train_loss_epoch</td><td>0.38765</td></tr><tr><td>train_loss_step</td><td>0.56054</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83491</td></tr><tr><td>val_auc</td><td>0.10204</td></tr><tr><td>val_f1</td><td>0.8301</td></tr><tr><td>val_loss_epoch</td><td>0.38808</td></tr><tr><td>val_loss_step</td><td>0.35552</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/bx3oj7lt' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/bx3oj7lt</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_212408-bx3oj7lt\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03ab15c54798413a86523aa46da00977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333332417533, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_215931-3cyk5qei</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/3cyk5qei' target=\"_blank\">GINConv_4_32_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/3cyk5qei' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/3cyk5qei</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 8.3 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "8.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.9 K     Total params\n",
      "0.036     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇██</td></tr><tr><td>train_auc</td><td>▁▄▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████▇██</td></tr><tr><td>train_f1</td><td>▁▄▅▅▆▅▆▆▆▆▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇██</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▄▃▂▃▃▂▂▂▂▂▃▂▂▂▂▂▂▂▂▂▃▁▁</td></tr><tr><td>train_loss_step</td><td>██▇▅▆▆▆▆█▄▃▆▄▆▅▄▅█▇▂▄▅▅▂▄▃▄▅▄▂▄▄▁▄▄▃▂▃▂▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▅█▅▇██▆▅██▆▅██▃▇▆█▇▆▃▇▆█▅▆▇▇▇▇▇▇▇▇▇▆█▅</td></tr><tr><td>val_auc</td><td>▁▆▆▇▇▇▇▇▇▇█▇█▇▇█▆▇███▇▇▇▇█▆▅▇▇▆▇▅▅██▇▇█▅</td></tr><tr><td>val_f1</td><td>▅▂▃▇▃▆▇▇▅▄▇▇▅▃▇█▁▆▅▇▇▅▁▆▄▇▄▇▇▇▆▇▆▆▆▇▆▄▇▅</td></tr><tr><td>val_loss_epoch</td><td>█▆▆▂▄▂▂▂▃▇▁▂▃▄▂▁▆▃▃▂▂▅▇▃▄▂▅▃▃▄▂▃▃▄▃▃▅█▄▆</td></tr><tr><td>val_loss_step</td><td>▅▅▆▃▃▃▄▃▃█▁▂▃▃▄▁▄▃▃▃▃▄▂▃▄▃▅▃▄▆▂▃▂▅▁▅▆▆▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87478</td></tr><tr><td>train_auc</td><td>0.94833</td></tr><tr><td>train_f1</td><td>0.87136</td></tr><tr><td>train_loss_epoch</td><td>0.29882</td></tr><tr><td>train_loss_step</td><td>0.40553</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.77123</td></tr><tr><td>val_auc</td><td>0.87825</td></tr><tr><td>val_f1</td><td>0.75443</td></tr><tr><td>val_loss_epoch</td><td>0.52485</td></tr><tr><td>val_loss_step</td><td>0.52517</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/3cyk5qei' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/3cyk5qei</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_215931-3cyk5qei\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9716521f5fcf4e88bf71e44ca73f8ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_223533-xydnbt7x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/xydnbt7x' target=\"_blank\">GINConv_4_32_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/xydnbt7x' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/xydnbt7x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 8.3 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "9.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "9.9 K     Total params\n",
      "0.040     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██▇██████▇███▇</td></tr><tr><td>train_auc</td><td>▁▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████▇████</td></tr><tr><td>train_f1</td><td>▁▅▅▆▆▆▆▆▆▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██▇███▇████▇█▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▅▄▄▄▄▃▄▃▄▃▃▃▃▂▃▂▂▃▃▂▃▃▂▁▂▁▂▂▂▁▁▂▂▂▁▂</td></tr><tr><td>train_loss_step</td><td>█▆▆▄▅▅▄▄▅▅▄▄▅▅▅▃▅▂▁▃▁▄█▃▄▅▃▁▄▄▄▂▂▃▂▂▁▅▅▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▇▇▇▇█▇▇█▇▇▇▆▆▆▇▇▇▇▇█▇▇▃▆█▄▁▇▆█▆▆▇▇▆▆▆▆</td></tr><tr><td>val_auc</td><td>▁▂▅▅▆▆▇▅▄▅▇▆█▅▃▄▇▇▇▆▅▇▅▃▄▅▆▄▄▆▂▆▄▄▆▅▅▃▆▃</td></tr><tr><td>val_f1</td><td>▁▆▇█▇▇██▇█▇▇█▇▇▇▇▇▇▇▇█▇▇▃▇█▄▁█▇█▆▆█▇▆▆▇▆</td></tr><tr><td>val_loss_epoch</td><td>▅▃▂▁▂▂▂▁▂▁▂▁▁▂▂▂▂▂▂▁▂▃▂▂▄▂▂▅█▂▂▃▄▃▂▃▃▃▂▃</td></tr><tr><td>val_loss_step</td><td>▇▅▃▂▃▃▄▂▂▃▃▃▂▃▂▂▂▄▄▂▃▅▃▂▃▁▄▃█▃▃▃█▄▄▆▄▄▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86119</td></tr><tr><td>train_auc</td><td>0.93344</td></tr><tr><td>train_f1</td><td>0.85801</td></tr><tr><td>train_loss_epoch</td><td>0.32676</td></tr><tr><td>train_loss_step</td><td>0.32012</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.78774</td></tr><tr><td>val_auc</td><td>0.89638</td></tr><tr><td>val_f1</td><td>0.76684</td></tr><tr><td>val_loss_epoch</td><td>0.47628</td></tr><tr><td>val_loss_step</td><td>0.44986</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/xydnbt7x' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/xydnbt7x</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_223533-xydnbt7x\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb54b412aed4076856644e538674378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_231305-lkwxn38p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/lkwxn38p' target=\"_blank\">GINConv_4_64_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/lkwxn38p' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/lkwxn38p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 30.9 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "33.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "33.1 K    Total params\n",
      "0.132     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▅▅▅▅▆▆▆▅▆▆▆▆▆▆▇▇▆▇▆▇▇▇▇▇▇▇█▇▇█▇▇██▇██</td></tr><tr><td>train_auc</td><td>▁▄▅▅▆▆▆▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█████████</td></tr><tr><td>train_f1</td><td>▁▃▄▄▅▅▅▆▆▆▅▅▆▆▆▆▆▇▇▆▆▆▇▇▇▇▇▇▇█▇▇█▇▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▅▄▅▄▄▃▄▄▄▄▃▃▃▃▃▂▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▆▆▅▆▅▅▆▃▄▄▃▄▄▃▃▄▃▄▄▄▄▃▄▅▄▂▂▃▃▂▂▂▂▁▁▁▁▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▅▁▆█▅▆▇▇▆▇▆▅▇▆▇▅▅▆▅▇▆▇▇▇▇▆▇▆▅▇▆▇▇▆▆▅▆▇▇▇</td></tr><tr><td>val_auc</td><td>▄▅▆█▅▆█▇▆▅▆▂▇▆▆▅▄▅▃▆▅▅▄█▆▆▅▂▁▆▆▆▅▄▆▅▅▆▇▆</td></tr><tr><td>val_f1</td><td>▇▁▆█▆▆██▆█▇▆▇▇▇▅▆▇▆▇▇▇▇▇█▇▇▇▆▇▇▇▇▇▆▆▆▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>▅▆▂▁▄▁▁▂█▆▁▅▁▂▂▆▃▃▆▃▃▂▄▅▅▂▄▇▆▅▅▆▃▅▅█▇▄▇▃</td></tr><tr><td>val_loss_step</td><td>▃▄▂▃▃▂▃▄█▅▁▃▂▂▄▅▃▃▃▃▂▃▃▃▄▂▄▃▅▅▄▃▁▄▄▅▅▂▅▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.90254</td></tr><tr><td>train_auc</td><td>0.96516</td></tr><tr><td>train_f1</td><td>0.90018</td></tr><tr><td>train_loss_epoch</td><td>0.24835</td></tr><tr><td>train_loss_step</td><td>0.34877</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81368</td></tr><tr><td>val_auc</td><td>0.89511</td></tr><tr><td>val_f1</td><td>0.81499</td></tr><tr><td>val_loss_epoch</td><td>0.43808</td></tr><tr><td>val_loss_step</td><td>0.32958</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/lkwxn38p' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/lkwxn38p</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_231305-lkwxn38p\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60a3d385447642479f547d3ecda9807a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231227_234847-7899t5xf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7899t5xf' target=\"_blank\">GINConv_4_64_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7899t5xf' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7899t5xf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 30.9 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "33.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "33.1 K    Total params\n",
      "0.132     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▅▆▆▆▆▇▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇█▇█▇▇██████▇████</td></tr><tr><td>train_auc</td><td>▁▅▄▅▅▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇████████████</td></tr><tr><td>train_f1</td><td>▁▅▅▅▆▆▆▆▆▇▆▇▆▆▆▇▇▇▇▇▇▇▇▇█▇█▇▇██████▇███▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▂▁▂▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▅▆█▃▄▅▄▄▃▄▃▅▃▄▃▃▂▃▂▂▄▃▃▃▃▂▂▁▁▂▃▂▃▁▁▁▂▁▆</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▃▁▆▆▅▅▇▇▆▇▅▃▇▇▆▄▇▆▅▇▇▆▆▆█▅▇▄▇▆▆▅▆▇▆▆▅▅▅▅</td></tr><tr><td>val_auc</td><td>▃▁▇▆▆▃▇▇▇▇▆▆▇▇█▇█▇▇█▇▇█▇█▆█▆█▇▇▇▆▇▇▇▆▆▇▆</td></tr><tr><td>val_f1</td><td>▄▁▅▆▆▄▇▇▆▇▅▂▇▆▇▃█▇▅▇▇▆▆▆█▆▇▅▇▅▅▄▆▇▇▆▆▅▅▆</td></tr><tr><td>val_loss_epoch</td><td>█▇▃▃▃▄▂▃▄▃▂▅▂▂▂▄▁▁▂▃▁▂▁▂▃▃▃▄▂▅▇▃▂▃▅▄▃▃▄▅</td></tr><tr><td>val_loss_step</td><td>▆▆▄▃▂▄▄▆▇▆▂▅▃▃▆▆▄▂▄▅▁▂▃▂▆▂▄▅▃▇█▂▁▃██▃▁▅▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86651</td></tr><tr><td>train_auc</td><td>0.93635</td></tr><tr><td>train_f1</td><td>0.86369</td></tr><tr><td>train_loss_epoch</td><td>0.3064</td></tr><tr><td>train_loss_step</td><td>0.48524</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.8184</td></tr><tr><td>val_auc</td><td>0.9023</td></tr><tr><td>val_f1</td><td>0.83002</td></tr><tr><td>val_loss_epoch</td><td>0.43619</td></tr><tr><td>val_loss_step</td><td>0.2605</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7899t5xf' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7899t5xf</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231227_234847-7899t5xf\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "261d2e8014eb45bc9e1310717da211c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333332417533, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_002839-3axet77d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/3axet77d' target=\"_blank\">GINConv_4_64_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/3axet77d' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/3axet77d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 30.9 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "33.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "33.1 K    Total params\n",
      "0.132     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▆▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█▇▇▇████</td></tr><tr><td>train_auc</td><td>▁▂▃▃▃▅▆▆▆▆▆▅▆▆▇▇▇████▇▇▇▇███▇▇▇▇▇▇▆▇▇▇▇▇</td></tr><tr><td>train_f1</td><td>▁▄▅▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█▇▇▇████</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▂▂▂▂▂▂▂▁▂▁▂▁▁▁▁▂▁▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▃▅▅▅▆▄▄▅▅▇▇▃▅▃▅▄▅█▆▇▆▄▆▅▅█▇▄▃▄▇▇▁█▅▆▅▇▇▅</td></tr><tr><td>val_auc</td><td>▁▄▇▆▆▅▇▇▆▇▇▄▇▆▇▇▇█▇██▆▇▇▇██▆▆▇▇▇▄▇▆▇▅▇▇▆</td></tr><tr><td>val_f1</td><td>▄▆▅▆▆▅▅▆▅▇▇▄▅▂▅▄▅█▆▇▆▅▆▅▅█▇▄▄▄▇▇▁█▅▆▆▇▇▅</td></tr><tr><td>val_loss_epoch</td><td>▆▃▃▂▂▂▃▃▅▂▁▃▃▅▃▄▃▁▃▁▂▄▃▃▅▁▂▄▄▆▃▃█▄▄▄▇▃▃▅</td></tr><tr><td>val_loss_step</td><td>▂▄▃▃▂▂▃▅▇▂▁▃▄▂▄▄▃▂▃▁▁▃▃▂▅▂▂▂▃▆▄▅▁▆▂▂█▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.89014</td></tr><tr><td>train_auc</td><td>0.86654</td></tr><tr><td>train_f1</td><td>0.88849</td></tr><tr><td>train_loss_epoch</td><td>0.28064</td></tr><tr><td>train_loss_step</td><td>0.4287</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.7783</td></tr><tr><td>val_auc</td><td>0.86901</td></tr><tr><td>val_f1</td><td>0.75263</td></tr><tr><td>val_loss_epoch</td><td>0.57768</td></tr><tr><td>val_loss_step</td><td>0.47771</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/3axet77d' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/3axet77d</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_002839-3axet77d\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c042dfe2394fffbffe0ec6bba241e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_010521-yldcg3b6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yldcg3b6' target=\"_blank\">GINConv_4_64_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yldcg3b6' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yldcg3b6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 30.9 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "33.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "33.1 K    Total params\n",
      "0.132     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▄▃▅▅▅▅▅▆▅▅▆▆▆▆▅▆▇▆▇▇▆▇▇▆▆▇▇▆▇▇▇██▇███</td></tr><tr><td>train_auc</td><td>▁▄▄▄▄▅▅▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▆▇█▇▇▇███▇███</td></tr><tr><td>train_f1</td><td>▁▄▄▄▃▅▅▅▅▅▆▅▅▆▆▆▆▅▆▇▆▇▇▆▇▇▇▆▇▇▆▇▇▇██▇▇██</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▅▅▅▄▄▅▄▄▄▄▃▄▄▄▃▃▃▃▃▃▂▃▃▃▂▂▃▃▂▂▂▂▂▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▇▅▆▅▆▃▆▄▆▃▇▄▄▃▃▂▅▄▃▃▇▄▂▅▆▂▁▃▅▂▃▃▄▃▁▂▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▄▄▇▇▆▆▆▆██▇▇▆▅▇▇▆█▆▅▇▇▅▄▆▆▅▅▆▇▆▆▆▆▆▆▇▇▆▁</td></tr><tr><td>val_auc</td><td>▆▆▇██▇████▇▇▇▆▇█▆▇▇▇▇▇▆▄▆▇▇▆▇▆▆▆▆▇▆▆▇▇▆▁</td></tr><tr><td>val_f1</td><td>▆▃▇▆▆▅▅▇▇█▆▇▇▄▇▇▆█▇▅▇▇▅▄▆▇▅▅▆▇▇▆▇▇▆▆▇▇▆▁</td></tr><tr><td>val_loss_epoch</td><td>▃▅▂▁▁▂▂▂▁▂▂▁▁▂▂▁▂▂▃▂▁▁▂▃▂▃▃▂▃▅▄▂▂▂▃▃▃▂▄█</td></tr><tr><td>val_loss_step</td><td>▃▇▃▂▂▃▃▃▂▅▄▁▂▂▃▂▄▄▃▃▃▂▃▂▂▅▃▂▅▇█▁▂▁▂▂▆▅▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.90018</td></tr><tr><td>train_auc</td><td>0.96554</td></tr><tr><td>train_f1</td><td>0.8991</td></tr><tr><td>train_loss_epoch</td><td>0.2334</td></tr><tr><td>train_loss_step</td><td>0.19235</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.70755</td></tr><tr><td>val_auc</td><td>0.81141</td></tr><tr><td>val_f1</td><td>0.67021</td></tr><tr><td>val_loss_epoch</td><td>0.73426</td></tr><tr><td>val_loss_step</td><td>0.82524</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yldcg3b6' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yldcg3b6</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_010521-yldcg3b6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e02894bb4ebb4527bca9e125f6cde676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_014216-j751fjba</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/j751fjba' target=\"_blank\">GINConv_4_64_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/j751fjba' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/j751fjba</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 30.9 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "37.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "37.3 K    Total params\n",
      "0.149     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▃▅▅▄▅▅▆▅▆▆▆▆▆▅▆▆▆▅▇▆▆▇▇█▇▇▇▇██▇▇█▇███</td></tr><tr><td>train_auc</td><td>▁▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▆▇▆▇▇▇▇▇▇▇█▇▇██▇██▇███</td></tr><tr><td>train_f1</td><td>▁▃▄▃▄▅▄▅▅▆▅▅▅▆▆▆▅▆▆▆▅▆▆▆▇▇█▇▇▇▇█▇▇▇▇▇█▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▆▅▅▅▅▄▄▄▄▄▄▄▄▄▃▄▃▄▃▃▃▃▂▂▃▂▂▂▂▂▃▂▂▃▁▂▂</td></tr><tr><td>train_loss_step</td><td>▆█▅▆▅▅▅▄▃▄▄▃▇▃▄▄▄▆▃▄▃▂▃▃▁▂▄▅▂▁▃▃▅▂▁▂▃▂▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▅▅▄▇▇▇▇▇█▆█▅▇▅▇▇█▇▁▇▆▆▆▂▇▆▇▆▇▇▄▆▄█▆▅▆▂▇▄</td></tr><tr><td>val_auc</td><td>▄▆▆▇▇▇▇▇██▇▇▆▇▇▇▇▇▅▇▇▆▆▄▇▆▇▆▆▇▅▇▅▇▇▇▆▁▆▆</td></tr><tr><td>val_f1</td><td>▆▅▄▇█▆▇▇▇▆▇▅▇▄▇▇▇▇▁▇▆▅▅▂▆▆▆▆▇▆▅▇▅█▆▄▆▃▆▄</td></tr><tr><td>val_loss_epoch</td><td>▃▂▃▂▁▁▂▂▂▂▂▃▂▂▂▂▂▂▄▁▁▃▃▅▁▂▂▃▃▃▄▄▅▄▄▅▅█▄▅</td></tr><tr><td>val_loss_step</td><td>▄▃▃▄▂▂▄▃▄▄▅▄▄▃▄▃▃▄▅▂▁▄▄▇▁▂▂▂▄▆▅▃▅▅▆▄█▆▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.89841</td></tr><tr><td>train_auc</td><td>0.95962</td></tr><tr><td>train_f1</td><td>0.89461</td></tr><tr><td>train_loss_epoch</td><td>0.25511</td></tr><tr><td>train_loss_step</td><td>0.22532</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.78302</td></tr><tr><td>val_auc</td><td>0.90472</td></tr><tr><td>val_f1</td><td>0.75789</td></tr><tr><td>val_loss_epoch</td><td>0.52275</td></tr><tr><td>val_loss_step</td><td>0.53363</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/j751fjba' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/j751fjba</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_014216-j751fjba\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53c086d7332843e0b625f143702fd34f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_021909-9gfrj5kv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9gfrj5kv' target=\"_blank\">GINConv_2_16_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9gfrj5kv' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9gfrj5kv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d191f9c9d2a5427dab49323842287c08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇█▇████▇█████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▇▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█▇████████████</td></tr><tr><td>train_f1</td><td>▁▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇█▇███▇▇██▇██</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▄▄▃▄▃▃▃▃▃▂▃▂▂▃▂▂▂▂▂▂▂▂▂▁▂▁▂▁▂▂▁▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▆▅▇▆▆▅▅▅▅▄▄▄▅▅▄▄▄▆▃▂▂▃▇▄▅▃▄▄▄▃▃▅▃▅▄▄▃▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▅▅▅▆▅▆▆▇▆▇▇▇▇▇▇▆▆▆▆▇▇▆█▇▅▆▇▆▇▇█▇▆▇▇▇▇▇</td></tr><tr><td>val_auc</td><td>▁▅▅▆▆▆▆▆▇▇▇███████▇▇███▇██▅██▇▇██▇▇▇▇█▇▇</td></tr><tr><td>val_f1</td><td>▁▃▆▅▄▆▄▆▆█▇▇█▆█▇█▇▇▆▅▇▇▇█▇▅▆▇▇▇▆█▇▆▇▇▇▆▇</td></tr><tr><td>val_loss_epoch</td><td>█▅▅▄▄▃▃▄▃▂▃▁▃▃▂▄▂▂▂▃▂▃▁▂▃▂▃▂▃▃▄▂▃▃▄▂▃▂▃▄</td></tr><tr><td>val_loss_step</td><td>▆▃▇▅▃▃▃▆▄▄▅▁▅▄▄█▅▃▂▄▂▇▂▂▆▂▂▅▄▄▆▃▅▆▅▂▄▄▄▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85824</td></tr><tr><td>train_auc</td><td>0.92107</td></tr><tr><td>train_f1</td><td>0.86014</td></tr><tr><td>train_loss_epoch</td><td>0.35553</td></tr><tr><td>train_loss_step</td><td>0.24388</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.8184</td></tr><tr><td>val_auc</td><td>0.89652</td></tr><tr><td>val_f1</td><td>0.8171</td></tr><tr><td>val_loss_epoch</td><td>0.45155</td></tr><tr><td>val_loss_step</td><td>0.59137</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9gfrj5kv' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9gfrj5kv</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_021909-9gfrj5kv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "918d0dd2fc554e15bfcb282c39096c62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_025429-q9a6uxh2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/q9a6uxh2' target=\"_blank\">GINConv_2_16_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/q9a6uxh2' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/q9a6uxh2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▆▆▆▇▇▇▇▇▇▇▆▇▇▇▇▇▇█▇▇▇▇█▇██████▇█████▇█</td></tr><tr><td>train_auc</td><td>▁▄▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇█████████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇▇▇█▇█▇████▇█▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▃▃▃▃▃▃▂▃▂▃▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▂▂▁▁▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>██▆▆▆▇▃▅▅▄▆▃▄▄▄▄▄▂▄▃▃▂▁▅▂▃▃▄▃▃▂▃▄▃▄▄▄▃▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▅▅▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▆▇▇▆▇▇▇█▇▇▆█▆▆▇▇▇▇▇█▇</td></tr><tr><td>val_auc</td><td>▁▃▅▆▆▆▆▇▇▇▇█▇▇▇██▇▇██▇█▇█▇█▇▇▇█▇▇▇▇▇▇█▇▇</td></tr><tr><td>val_f1</td><td>▁▃▅▅▆▆▆▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▆█▇▇▆█▆▇▇▇▇▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▃▂▂▂▂▂▂▂▁▂▂▂▃▁▂▁▂▂▂▂▂▂▂▁▂▂▃▃▂▂▂▁▁▁▂▂▃</td></tr><tr><td>val_loss_step</td><td>█▅▅▆▄▄▅▅▅▆▆▂▅▃▅█▄▅▂▆▆▄▄▅▄▆▁▄▄▆▇▃▅▄▂▁▂▅▄▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.82398</td></tr><tr><td>train_auc</td><td>0.90085</td></tr><tr><td>train_f1</td><td>0.82913</td></tr><tr><td>train_loss_epoch</td><td>0.4018</td></tr><tr><td>train_loss_step</td><td>0.34198</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.79481</td></tr><tr><td>val_auc</td><td>0.87938</td></tr><tr><td>val_f1</td><td>0.8121</td></tr><tr><td>val_loss_epoch</td><td>0.46826</td></tr><tr><td>val_loss_step</td><td>0.55028</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/q9a6uxh2' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/q9a6uxh2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_025429-q9a6uxh2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9668112ac68f4d9ab7af932463b1283c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_032939-r65vsfv9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/r65vsfv9' target=\"_blank\">GINConv_2_16_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/r65vsfv9' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/r65vsfv9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇▇███▇███▇██████</td></tr><tr><td>train_auc</td><td>▆██▄▄▄▂▂▃▂▃▃▃▂▃▂▃▂▂▂▂▃▁▃▄▄▃▃▄▃▁▃▃▂▃▃▃▄▂▄</td></tr><tr><td>train_f1</td><td>▁▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇▇███▇███▇▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▂▂▂▂▁▂▁▁▂▁▁▂▂▁▁▁▁▁▁▁▁▂▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▂▁▂▃▂▃▄▄▄▄▅▅▆▆▆▅▅▆▆▆▇▆▇▆█▇▇█▇▇▅█▄▆▆▅▇▇▇▇</td></tr><tr><td>val_auc</td><td>█▇▇▅▅▃▃▃▂▁▂▂▂▁▃▁▂▁▁▂▁▁▁▅▃█▂▃▁▂▁▆▂█▂▆▃▃▁▄</td></tr><tr><td>val_f1</td><td>▁▁▂▂▁▁▃▃▂▃▅▅▅▅▅▄▅▅▆▆▇▆▇▅█▇▆▇▆▇▆▇▆▄▅▃▇▆▇▆</td></tr><tr><td>val_loss_epoch</td><td>█▅▅▄▄▄▄▄▄▃▄▂▃▄▃▅▃▂▂▃▃▄▂▃▃▁▁▂▂▂▂▂▄▄▃▂▂▂▁▂</td></tr><tr><td>val_loss_step</td><td>▅▄▆▄▃▄▃▄▄▃▅▁▄▄▄█▄▂▂▂▃▅▂▃▄▂▁▄▃▃▄▂▄▅▄▁▃▂▁▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.82162</td></tr><tr><td>train_auc</td><td>0.51767</td></tr><tr><td>train_f1</td><td>0.82584</td></tr><tr><td>train_loss_epoch</td><td>0.41106</td></tr><tr><td>train_loss_step</td><td>0.39011</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83019</td></tr><tr><td>val_auc</td><td>0.43398</td></tr><tr><td>val_f1</td><td>0.82439</td></tr><tr><td>val_loss_epoch</td><td>0.40874</td></tr><tr><td>val_loss_step</td><td>0.47112</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/r65vsfv9' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/r65vsfv9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_032939-r65vsfv9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5772078399394d44a0c69ef8324f563b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_040312-78x0y5e7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/78x0y5e7' target=\"_blank\">GINConv_2_16_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/78x0y5e7' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/78x0y5e7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.1 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdc6be0109444948bbf22c1105849ccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▆▆▇▇▇▇▇▇▇█▇▇█▇▇▇▇▇▇▇██▇██████▇██▇███</td></tr><tr><td>train_auc</td><td>▁▆▆▆▆▇▇▇▇▇▇▇▇██▇█████▇████▇█████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▆▇▇▇▇▇▆▇▇▇█▇▇▇▇▇▇▇▇████████▇██▇███</td></tr><tr><td>train_loss_epoch</td><td>█▅▃▄▃▃▃▃▃▃▂▂▂▂▂▃▂▂▂▂▂▂▂▂▁▁▂▂▁▂▂▁▁▂▁▁▂▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▆▆▅▄▆▄▅▃▄▄▃▃▅▄▃▅▁▃▃▃▄▅▃▄▂▁▄▂▃▆▄▂▄▃▄▃▂▃█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▄▃▄▆▆▄▅▆▆▆▆▅▆▇█▆▆▇▆█▆▇▅▆▆▇▆█▇█▇▆▆▅▇▆▆▆</td></tr><tr><td>val_auc</td><td>▁▄▅▅▆▆▆▆▇▇▆▇▇▇▇▇▇█▇███▇▇▇█▇▇▇▇█▇▇▆▇▇▇▇█▇</td></tr><tr><td>val_f1</td><td>▁▃▅▃▅▇▇▃▄▆▆▇▇▄▆▇█▇▇█▇█▇▇▇▇▆▆▇███▇▆▇▄█▆▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▄▄▆▄▃▃▄▄▃▃▃▂▂▁▃▃▂▁▄▁▂▂▃▃▁▃▃▂▂▂▂▃▄▃▄▂▃▂▂</td></tr><tr><td>val_loss_step</td><td>▆▃▅█▆▄▄▆▅▄▄▅▃▂▁▄▅▄▁▇▂▄▂▃▄▁▅▄▄▁▄▂▄▄▅▅▃▅▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8417</td></tr><tr><td>train_auc</td><td>0.9049</td></tr><tr><td>train_f1</td><td>0.84651</td></tr><tr><td>train_loss_epoch</td><td>0.41016</td></tr><tr><td>train_loss_step</td><td>0.63451</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81368</td></tr><tr><td>val_auc</td><td>0.89127</td></tr><tr><td>val_f1</td><td>0.82005</td></tr><tr><td>val_loss_epoch</td><td>0.40499</td></tr><tr><td>val_loss_step</td><td>0.31871</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/78x0y5e7' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/78x0y5e7</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_040312-78x0y5e7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0e5bac086ca4bc8b654d4c7bae4149b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_043715-f0j9in0o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/f0j9in0o' target=\"_blank\">GINConv_2_16_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/f0j9in0o' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/f0j9in0o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.1 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "1.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇██▇▇</td></tr><tr><td>train_auc</td><td>▁▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇█████▇▇█▇██▇█████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇▇▇▇▇▇▇▆▇██▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▃▂▂▂▂▂▂▂▁▁▂▂▂▂▁▁▂▂▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▆▆▄▅▅▄▅▃▄▆▄▃▃▆▅▄▅▃▅▆▁▃▅▄▄▄▅▅▅▅▃▂▄▄▅▃▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▂▄▅▇▅▅▅▅▇▅▇▆▇▆▆▇▅▆▇▆█▆▇▆▆▇▇▇▇▅█▆█▇▇▇██</td></tr><tr><td>val_auc</td><td>▁▄▄▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▅▇▇▇▇▇▇▇█▇██▇█▇█▇███▇</td></tr><tr><td>val_f1</td><td>▂▄▁▅▅▇▅▅▅▆▇▆▇▆█▇▇▇▄▇▇▇█▇▇▆▇▇▇██▇▇▇█▇█▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▄▆▃▃▄▃▃▂▂▃▂▃▃▂▂▂▂▄▄▁▂▂▂▂▁▂▃▃▂▃▂▁▁▁▂▂▂▂▁</td></tr><tr><td>val_loss_step</td><td>█▅▆▅▄▆▃▄▄▄▇▃▅▇▃▄▅▃▄▇▂▄▅▄▅▃▄▇▇▄█▅▂▂▂▃▄▄▅▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84288</td></tr><tr><td>train_auc</td><td>0.91261</td></tr><tr><td>train_f1</td><td>0.84129</td></tr><tr><td>train_loss_epoch</td><td>0.3707</td></tr><tr><td>train_loss_step</td><td>0.23454</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82783</td></tr><tr><td>val_auc</td><td>0.89817</td></tr><tr><td>val_f1</td><td>0.81975</td></tr><tr><td>val_loss_epoch</td><td>0.38219</td></tr><tr><td>val_loss_step</td><td>0.22262</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/f0j9in0o' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/f0j9in0o</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_043715-f0j9in0o\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "524db078907b4a9a8d6a4a63bf381fdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_051125-9vgak3li</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9vgak3li' target=\"_blank\">GINConv_2_32_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9vgak3li' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9vgak3li</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 3.8 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef024f32684241bcabc646418c10d778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇██████</td></tr><tr><td>train_auc</td><td>▁▅▄▆▆▆▆▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇██▇██▇█▇██████</td></tr><tr><td>train_f1</td><td>▁▄▆▆▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇█▇█████████</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▃▂▂▂▂▂▁▁▂▁▁▂▂▂▁▂▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>▇▆▇▆█▅▆▅▄▄▅▅▅▃▆▃▄▄▃▄▄▄▄▄▄▃▃▁▃▃▃▆▄▃▄▄▃▅▅▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▂▅▆▇▅▅▆▇▇▆▇▆▇▄▄▇▇▆▇▆▇▆▇▇█▇▅▇▆▅▅▆▇█▆▇▄▆</td></tr><tr><td>val_auc</td><td>▁▄▄▅▅▇▇▇▆▇▆▆▇▇▇▇▇▇█▇█▇▆▇▆▇▇▇▆▇▇▆▆▇██▇█▆▆</td></tr><tr><td>val_f1</td><td>▄▄▁▄▅▆▄▆▆▆▇▅▆▇▆▄▆▆█▅▇▇▇▆▇█▇▇▆▆▅▆▆▅▇▇▅█▆▆</td></tr><tr><td>val_loss_epoch</td><td>█▄▅▄▅▄▄▂▃▃▃▃▂▂▃▄▄▂▁▃▂▄▅▂▄▁▃▃▃▃▂▃▂▄▂▂▅▃▇▄</td></tr><tr><td>val_loss_step</td><td>█▃▃▂▆▅▃▃▅▅▄▃▂▂▂▄▄▂▁▄▃▅▄▂▅▁▄▄▃▃▃▂▂▅▃▂▄▃▇▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87242</td></tr><tr><td>train_auc</td><td>0.9389</td></tr><tr><td>train_f1</td><td>0.87019</td></tr><tr><td>train_loss_epoch</td><td>0.31174</td></tr><tr><td>train_loss_step</td><td>0.33675</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81132</td></tr><tr><td>val_auc</td><td>0.89089</td></tr><tr><td>val_f1</td><td>0.80198</td></tr><tr><td>val_loss_epoch</td><td>0.43096</td></tr><tr><td>val_loss_step</td><td>0.40588</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9vgak3li' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9vgak3li</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_051125-9vgak3li\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "610742225e58459ab4749c3a4339e854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_054632-yyg80bhf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yyg80bhf' target=\"_blank\">GINConv_2_32_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yyg80bhf' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yyg80bhf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 3.8 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▆▆▆▇▇▇▆▇▇▇█▇▇▇▇▇█▇▇█▇████▇██████████</td></tr><tr><td>train_auc</td><td>▁▅▅▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇██████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▆▇▇▇▇▇▇▇█▇▇▇▇▇█▇▇█▇███████████████</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▄▃▃▃▃▃▃▃▂▃▃▂▃▂▂▂▂▂▁▂▂▁▂▂▂▂▁▁▂▁▁▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>██▆▅▆▄▄▄▂▃▃▅▄▂▄▃▃▃▂▃▁▄▂▂▃▂▂▂▂▁▄▃▄▃▁▃▁▂▄▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▃▃▆▅▆▇▅▆▆▆▆▇▆▆▆▆▇▆▆▇▇▇▆▄▆▆▆▅▆▆▇▆▇▆▆█▅▇</td></tr><tr><td>val_auc</td><td>▁▄▅▅▆▆▆▆▆▇▆▆▇▇▇▇▇███▇▇▇██▇▇█▇▇▇▇▇██▇▇█▇█</td></tr><tr><td>val_f1</td><td>▁▄▂▂▆▆▆▇▇█▅▆▆▇▇▇▆▇▇▆▇▇▆▇▇▁▆▇▇▃▇▇▆▆▇▆▆█▅█</td></tr><tr><td>val_loss_epoch</td><td>█▄▄▄▄▃▂▃▄▃▃▂▂▂▂▃▂▁▁▃▂▂▃▁▂▃▃▂▁▃▃▁▃▃▂▂▃▂▃▂</td></tr><tr><td>val_loss_step</td><td>█▄▃▃▆▅▂▄▆▅▅▂▃▃▃▄▄▂▂▆▃▃▃▃▄▃▅▃▂▃▆▁▃▅▃▂▅▃▅▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84643</td></tr><tr><td>train_auc</td><td>0.92078</td></tr><tr><td>train_f1</td><td>0.84375</td></tr><tr><td>train_loss_epoch</td><td>0.348</td></tr><tr><td>train_loss_step</td><td>0.43634</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82075</td></tr><tr><td>val_auc</td><td>0.90886</td></tr><tr><td>val_f1</td><td>0.83478</td></tr><tr><td>val_loss_epoch</td><td>0.38852</td></tr><tr><td>val_loss_step</td><td>0.274</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yyg80bhf' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yyg80bhf</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_054632-yyg80bhf\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec1f723cfdd34847b52fd620a92cfb24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_062038-l7df4iyr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/l7df4iyr' target=\"_blank\">GINConv_2_32_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/l7df4iyr' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/l7df4iyr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 3.8 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▆▆▅▆▆▆▆▆▆▇▆▇▇▆▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇███▇▇▇██</td></tr><tr><td>train_auc</td><td>█▇▆▆▇▇▇▇▇▅▅▄▄▆▆▄▃▄▃▃▃▃▃▄▄▅▃▂▂▂▃▃▃▂▃▃▂▁▂▁</td></tr><tr><td>train_f1</td><td>▁▄▆▆▅▆▆▆▆▆▇▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇▇███</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▄▃▃▃▃▃▂▂▂▃▄▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▂▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▄▆▅▆▆▆▆▆▄▆▇▆▇█▇▇▇▇▇▇▇▇█▇██▄▆▆▅▇▆▇▆▇▇▆▅</td></tr><tr><td>val_auc</td><td>█▄▃▃▄▄▇▇▅▂▃▂▂▃▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_f1</td><td>▁▃▁▄▃▄▅▅▅▅▃▆▇▄▆█▆▇▇▆▇█▇▆▇▅██▅▃▆▅▆▅▅▆▇▆▄▅</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▂▃▂▂▂▃▂▂▁▁▂▁▂▂▁▁▂▂▁▂▁▂▁▂▁▂▃▂▂▁▂▂▁▃▁▄▂</td></tr><tr><td>val_loss_step</td><td>█▂▂▂▃▃▂▂▄▂▃▂▂▂▂▃▃▁▂▃▃▃▃▁▃▁▃▃▃▃▂▂▁▃▂▂▃▁▅▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84997</td></tr><tr><td>train_auc</td><td>0.1348</td></tr><tr><td>train_f1</td><td>0.85041</td></tr><tr><td>train_loss_epoch</td><td>0.35992</td></tr><tr><td>train_loss_step</td><td>0.48494</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.79953</td></tr><tr><td>val_auc</td><td>0.10503</td></tr><tr><td>val_f1</td><td>0.80638</td></tr><tr><td>val_loss_epoch</td><td>0.42565</td></tr><tr><td>val_loss_step</td><td>0.40266</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/l7df4iyr' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/l7df4iyr</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_062038-l7df4iyr\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c72ac8562fe45cfb324276b9b71aa9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_065458-wxwzfuj9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wxwzfuj9' target=\"_blank\">GINConv_2_32_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wxwzfuj9' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wxwzfuj9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 3.8 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.018     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▅▅▆▆▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇█▇██▇▇▇▇█▇████</td></tr><tr><td>train_auc</td><td>▁▅▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████▇█▇▇██████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████▇▇▇▇██████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▃▄▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>▇▅▆▆▅▄▅▄▄▅▅▆█▄▅▃▃▆▄▆▄▅▆▄▄▃▅▁▄▄▃▂▄▄▃▃▄▆▄▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▆▇▅▇█▇█▅█▇▆▇█▆▇▇▇▆▇▇▇▇▇▇█▆▅▇▅█▆▇▇▇▇█▇▆</td></tr><tr><td>val_auc</td><td>▁▃▄▅▅▆▆▇▇▄▇▇█▇▇▆▇▆▅▅█▇█▇▇█▇▇▅▇▄▇▅▇▆▆▄▇▆▄</td></tr><tr><td>val_f1</td><td>▅▁▅▇▆▇█▇█▇▇█▇██▆▇▇▇▆▇▇▇█▆██▇▄▇▄█▇▇▇▆▆█▇▆</td></tr><tr><td>val_loss_epoch</td><td>█▆▄▃▄▃▃▂▂▅▂▂▃▃▃▃▁▅▃▃▂▅▄▁▃▁▃▆▅▂▄▄▄▃▃▅▄▄▄▄</td></tr><tr><td>val_loss_step</td><td>▅▄▄▅▄▅▅▃▅▅▂▂▅▅▆▃▃▆▃▄▃█▇▃▃▂▅▇▆▁▄▅▆▄▃▃▄▅▆▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86533</td></tr><tr><td>train_auc</td><td>0.93621</td></tr><tr><td>train_f1</td><td>0.86682</td></tr><tr><td>train_loss_epoch</td><td>0.31668</td></tr><tr><td>train_loss_step</td><td>0.20605</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.79481</td></tr><tr><td>val_auc</td><td>0.87702</td></tr><tr><td>val_f1</td><td>0.77863</td></tr><tr><td>val_loss_epoch</td><td>0.46577</td></tr><tr><td>val_loss_step</td><td>0.48384</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wxwzfuj9' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wxwzfuj9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_065458-wxwzfuj9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c66fcd152cdc4a0aa48ef22ba49e783b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333332417533, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_072850-varryjwi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/varryjwi' target=\"_blank\">GINConv_2_32_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/varryjwi' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/varryjwi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 3.8 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "5.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.4 K     Total params\n",
      "0.022     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16007c6d555545c8b264823bee3dbaef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▅▅▅▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇█▇██▇██▇█▇█████</td></tr><tr><td>train_auc</td><td>▁▄▄▅▅▅▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████</td></tr><tr><td>train_f1</td><td>▁▅▅▅▆▆▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇█▇██▇██▇█▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▃▂▂▂▂▂▂▂▂▂▂▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▆▇▅▅▄▅▄▇▅▃▄▅▄▄▅▄▅▄▅▄▆▃▄▄█▄▁▅▄▇▃▂▂▃▅▃▂▃▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▄▃▅▆▅▅▂▇▄▇▆█▇▆▇█▇▆▇▇▆▅▇▅▁▇▆▆█▇▆▅▇▅▆▆▇▇▆▅</td></tr><tr><td>val_auc</td><td>▁▄▅▅▅▆▄▆▆▇▇█▇▆▇█▇▇▇▇▇▆▇▇▁█▆▇▇▇▅▄▆▇▇▆▆▆▄▆</td></tr><tr><td>val_f1</td><td>▅▁▄▆▆▅▅▆▆▆▆█▇▅██▆▇▇█▇▃▇▇▅▇▆▇▇▆▇▄▇▇█▆█▆▅▅</td></tr><tr><td>val_loss_epoch</td><td>▅▆▅▂▃▄▃▃▃▂▂▁▄▃▂▃▃▃▂▄▁▄▂▄█▃▂▃▄▃▅▄▃▃▅▃▅▄▄▄</td></tr><tr><td>val_loss_step</td><td>▅▇▇▃▅█▄▆▄▃▄▃▇▄▃▇▅▃▄▇▁▃▃▆▃▆▂▂▃▃▇▄▃▃▇▃▆▆▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87064</td></tr><tr><td>train_auc</td><td>0.94354</td></tr><tr><td>train_f1</td><td>0.87018</td></tr><tr><td>train_loss_epoch</td><td>0.3</td></tr><tr><td>train_loss_step</td><td>0.39337</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.79009</td></tr><tr><td>val_auc</td><td>0.88328</td></tr><tr><td>val_f1</td><td>0.7845</td></tr><tr><td>val_loss_epoch</td><td>0.47262</td></tr><tr><td>val_loss_step</td><td>0.46655</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/varryjwi' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/varryjwi</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_072850-varryjwi\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7297921fd58d4495822822441cfbf7a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.017183333332650364, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_080230-0usd2ncl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0usd2ncl' target=\"_blank\">GINConv_2_64_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0usd2ncl' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0usd2ncl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 13.8 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.9 K    Total params\n",
      "0.064     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8867449250394278a3d380baaa211491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▅▅▅▆▆▆▆▆▅▆▇▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇█</td></tr><tr><td>train_auc</td><td>▁▄▅▅▅▆▆▆▆▆▆▆▆▇▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██▇████▇██</td></tr><tr><td>train_f1</td><td>▁▄▅▅▆▆▆▆▆▆▆▅▆▇▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▅▄▄▄▄▄▄▄▄▃▃▄▃▄▃▃▃▂▃▃▃▃▃▂▂▃▂▂▂▁▂▁▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▆▄▅▄▅▂▆▅▄▄▅▃▆▆▄▇▄▃▃▃█▆▃▅▄▂▃▃▄▃▂▃▂▁▂▃▃▆</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▄▃▁▄▆▄▆▇▄▁▆▃▆▃▇▅▃▅▆▅▇▆▅▅▆█▇▆▃▄▅▆▆▆▆▃▆▇▅▄</td></tr><tr><td>val_auc</td><td>▄▅▅▆▇▇▆█▅▄▆▂▇▆█▇▆▇▆▆▇▇▆▅▇█▇█▁▇▅▆▆▅▆▂▆▇▄▄</td></tr><tr><td>val_f1</td><td>▇▅▁▅█▄█▇▆▁█▅▆▄▇█▃▇▇█▇█▆▇▇███▅▄▆▇█▇▆▃▇▇▆▇</td></tr><tr><td>val_loss_epoch</td><td>▃▃▅▃▂▄▂▂▁▅▃▄▂▃▂▂▃▂▂▂▁▃▄▄▁▂▂▂▄▃▂▂▃▄▅█▄▄▃▄</td></tr><tr><td>val_loss_step</td><td>▄▄▄▄▄▅▅▄▂▇▅▆▄▄▄▄▃▃▃▃▁▄▂▅▂▂▃▄▃▁▂▃▄▄█▇▂▄▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.88718</td></tr><tr><td>train_auc</td><td>0.95708</td></tr><tr><td>train_f1</td><td>0.88678</td></tr><tr><td>train_loss_epoch</td><td>0.27455</td></tr><tr><td>train_loss_step</td><td>0.45198</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.78066</td></tr><tr><td>val_auc</td><td>0.86667</td></tr><tr><td>val_f1</td><td>0.79007</td></tr><tr><td>val_loss_epoch</td><td>0.52035</td></tr><tr><td>val_loss_step</td><td>0.45634</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0usd2ncl' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0usd2ncl</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_080230-0usd2ncl\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6c6bfabf3424a64ba61fa3a5cd901a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_083939-25ulqtwx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/25ulqtwx' target=\"_blank\">GINConv_2_64_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/25ulqtwx' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/25ulqtwx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 13.8 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.9 K    Total params\n",
      "0.064     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38c3e09aa687484b8f60d9bab2d175b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▆▆▆▆▆▆▆▆▆▇▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇█████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇█████████████</td></tr><tr><td>train_f1</td><td>▁▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇██▇███████</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▃▂▂▂▂▃▂▃▂▂▂▂▁▂▂▂▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▅▃▅▅▆▃▄▅▆▄▅▄▅▄▄█▃▂▄▃▅▆▃▂▄▂▃▁▃▃▄▂▂▂▁▃▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▂▁▄▅▆▄▄▆▆▆▆▆▇▅▇▆▆▆▇▆▆▇█▇▄▇▆▇▆▅▄▆▅▇▅▆▆▅▆▆</td></tr><tr><td>val_auc</td><td>▁▅▅▅▇▆▇▇▇▇█▇▇▇███▇▇█▇██▇▇▇▇▇▇▆▇▇▇▇▆▇▆▆▇▆</td></tr><tr><td>val_f1</td><td>▄▁▆▆▇▄▆▆▆▆▆▇▇▅▇▆▇▇▇▇▇▇██▄█▇█▇▆▄▇▅▇▅▇▇▆▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▅▃▄▃▅▅▄▁▄▃▆▁▄▂▁▂▃▃▃▃▂▂▄▂▅▄▅▂▂▄▆▄▆▇▇▅▆▆▇</td></tr><tr><td>val_loss_step</td><td>▅▄▃▅▅▅▅▅▃▆▄█▃▃▃▂▂▄▃▄▂▃▂▄▂▄▃▄▂▁▃▆▅▆▇▅▄▃▂▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.90845</td></tr><tr><td>train_auc</td><td>0.96779</td></tr><tr><td>train_f1</td><td>0.90888</td></tr><tr><td>train_loss_epoch</td><td>0.22826</td></tr><tr><td>train_loss_step</td><td>0.20471</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82311</td></tr><tr><td>val_auc</td><td>0.8906</td></tr><tr><td>val_f1</td><td>0.8227</td></tr><tr><td>val_loss_epoch</td><td>0.5091</td></tr><tr><td>val_loss_step</td><td>0.57783</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/25ulqtwx' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/25ulqtwx</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_083939-25ulqtwx\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d95f88ae2548bb91653fc57b9f0fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333332417533, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_091754-cjrguk86</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/cjrguk86' target=\"_blank\">GINConv_2_64_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/cjrguk86' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/cjrguk86</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 13.8 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.9 K    Total params\n",
      "0.064     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▆▆▆▆▆▆▆▆▆▇▆▆▇▆▇▇▇▇▆▇▅▇▆▇▇▇▇███████▇█</td></tr><tr><td>train_auc</td><td>▄▄▄▅▅▃▄▅▄▆▅▅▄▅▆▅▅▄▂▄▆▆▃▅▃▆▅▇██▅▆▅▆▇▇▆▆▁▂</td></tr><tr><td>train_f1</td><td>▁▃▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▆▇▇▇▇▇▇▆▇▇▇█▇▇███████▇█</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▂▂▁▁▁▁▁▁▁▁▁▂▁▁▁▁▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▆▆▇▆▅▇▇▇▆▇▇▇█▇█▄▇▇██▇▇▇▇▇█▅█▆▇▇█▇▇▇▇▆▆</td></tr><tr><td>val_auc</td><td>▆▇▇█▇▇▇▇█▇▇█▇████▇▆█████████▇█████████▁▄</td></tr><tr><td>val_f1</td><td>▁▂▄▄▅▄▅▆▆▆▅▇▇▄▇▇▆▄▇█▇▇▆▅▅▇▇█▁▇▄▇▆▆▅▅▄▆▆▅</td></tr><tr><td>val_loss_epoch</td><td>█▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▂▂▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▃▂▂▂▂▃▂▂▂▂▂▂▂▂▂▁▂▁▁▁▂▁▂▁▂▁▂▂▁▁▁▂▂▃▂▁▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86474</td></tr><tr><td>train_auc</td><td>0.56248</td></tr><tr><td>train_f1</td><td>0.86616</td></tr><tr><td>train_loss_epoch</td><td>0.34139</td></tr><tr><td>train_loss_step</td><td>0.56184</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.78774</td></tr><tr><td>val_auc</td><td>0.51631</td></tr><tr><td>val_f1</td><td>0.7907</td></tr><tr><td>val_loss_epoch</td><td>0.44146</td></tr><tr><td>val_loss_step</td><td>0.38564</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/cjrguk86' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/cjrguk86</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_091754-cjrguk86\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cd086ede7d548d38996b63d65ba008f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333332417533, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_095617-p9dmw3to</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/p9dmw3to' target=\"_blank\">GINConv_2_64_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/p9dmw3to' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/p9dmw3to</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 13.8 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "16.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "16.0 K    Total params\n",
      "0.064     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▃▅▃▅▅▅▄▅▅▅▆▆▆▆▆▆▅▇▇▇▆▆▇▅▇▇▆▇▇▇█▇▆▇█▇██</td></tr><tr><td>train_auc</td><td>▁▄▄▅▄▅▆▆▅▆▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▆▇▇▇▇▇▇█▇▇▇████</td></tr><tr><td>train_f1</td><td>▁▃▄▅▃▅▆▅▅▅▆▅▆▆▆▆▆▆▅▇▇▇▇▆▇▅▇▇▆▇▇▇█▇▆▇████</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▆▅▄▄▅▄▄▄▄▄▃▃▃▃▄▃▃▃▃▃▂▄▃▂▃▂▂▂▁▂▃▂▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▅▅▅▄▇▃▅▃▄▇█▃▄▆▄▅▃▃▆▂▅▄▂▂▂▄▂▂▁▃▂▂▃▂▄▂▂▇</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▅▇▄▇█▆▆█▆▂▇▇▇█▅▇▅▇▆▇▆▇▇▇▆▆▅▇▇▇▇▂▇▅▇▅▇█</td></tr><tr><td>val_auc</td><td>▁▃▅▇▆▅▆▇▆▇▆▂▆▇▆▇▃▇▅▅▅▅▅▇▆▇▆▆▄▇▇▇█▅▆▅▅▆▆▆</td></tr><tr><td>val_f1</td><td>▃▅▇▆▃▇█▇▆█▆▆██▇█▆█▄▇▆▇▇█▇▇▆▇▇▆▇▇█▁▇▅█▇▇█</td></tr><tr><td>val_loss_epoch</td><td>▃▂▂▂▃▁▁▂▂▂▃▃▂▁▂▂▂▁▂▂▂▂▁▂▁▁▂▂▃▂▃▂▃▅▁▃▄█▃▃</td></tr><tr><td>val_loss_step</td><td>▃▂▃▃▄▁▂▄▃▃▄▂▂▁▂▄▃▁▃▄▂▂▁▂▁▂▃▂▃▂▄▂▂▃▂▃▄█▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.89663</td></tr><tr><td>train_auc</td><td>0.96717</td></tr><tr><td>train_f1</td><td>0.89676</td></tr><tr><td>train_loss_epoch</td><td>0.24897</td></tr><tr><td>train_loss_step</td><td>0.50673</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82547</td></tr><tr><td>val_auc</td><td>0.89419</td></tr><tr><td>val_f1</td><td>0.8271</td></tr><tr><td>val_loss_epoch</td><td>0.4843</td></tr><tr><td>val_loss_step</td><td>0.3521</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/p9dmw3to' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/p9dmw3to</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_095617-p9dmw3to\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81d130fb3d284db5b51323335a843006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_103212-amnn2cd5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/amnn2cd5' target=\"_blank\">GINConv_2_64_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/amnn2cd5' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/amnn2cd5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 13.8 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "20.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.1 K    Total params\n",
      "0.080     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ccb3d3c900044bb860ab95318c1ff4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▃▅▅▅▅▆▆▆▆▆▆▆▆▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇██▇▇█</td></tr><tr><td>train_auc</td><td>▁▄▄▅▅▆▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇██████</td></tr><tr><td>train_f1</td><td>▁▃▃▅▅▅▅▆▆▆▆▆▆▇▆▇▆▇▇▆▇▇▇▇▇▇▆▇▇▇▇█▇▇▇██▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▃▃▃▃▂▂▂▂▂▁▂▃▁▂▂▁▁▂▂▁▁</td></tr><tr><td>train_loss_step</td><td>▇▇▆▆▆▇▅▄▄▄▅▆▇▃▃█▄▅▃▄▃▃▃▃▂▃▅▂▂▂▃▁▂▂▁▃▁▂▃▆</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▄▂▅▇▇█▅▄▅██▅▆▁▅▂▇▄▅▇▅▇▅▇▅▄▇▇▅▄▆▄▅▅▇▆▆▄▅▇</td></tr><tr><td>val_auc</td><td>▂▁▃▅▆▆▅▃▅▇▇▃▆▄▆▁▄▇█▆▅▆▅▆▃▄▅▅▂▅▅▁▄▄▅▅▄▂▄▅</td></tr><tr><td>val_f1</td><td>▆▃▆▇▆█▆▆▆██▆▆▁▅▃▇▃▇█▇▇▄▇▅▇▇▇▆▄▇▆▇▆▇█▇▅▆▇</td></tr><tr><td>val_loss_epoch</td><td>▅▆▃▂▃▃▃▄▂▁▁▄▃█▅▄▃▆▄▃▅▁▅▅▅▅▃▄▇▄▃▇▄█▄▅▇▅▅▅</td></tr><tr><td>val_loss_step</td><td>▄▅▂▁▃▄▅▅▄▂▁▅▃▆▃▃▄▅▃▃▃▂▄▇▃▄▃▄█▁▃▆▃▆▄▅▆▃▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.89368</td></tr><tr><td>train_auc</td><td>0.95722</td></tr><tr><td>train_f1</td><td>0.89374</td></tr><tr><td>train_loss_epoch</td><td>0.27841</td></tr><tr><td>train_loss_step</td><td>0.44368</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82311</td></tr><tr><td>val_auc</td><td>0.89292</td></tr><tr><td>val_f1</td><td>0.81928</td></tr><tr><td>val_loss_epoch</td><td>0.48491</td></tr><tr><td>val_loss_step</td><td>0.50361</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/amnn2cd5' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/amnn2cd5</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_103212-amnn2cd5\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02b355ede5e343dd89749808791731d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_110926-8gusxypr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8gusxypr' target=\"_blank\">GINConv_3_16_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8gusxypr' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8gusxypr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.7 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88c04b8880ae4b23ba1543347939c383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▆▇▇▇▇▇▇▇▇▇▇███▇█▇███████████████████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████████</td></tr><tr><td>train_f1</td><td>▁▇▇▇▇▇▇▇▇▇▇▇▇█▇█████████████████████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▃▃▃▃▂▂▃▂▂▂▂▂▂▃▂▁▂▂▂▂▁▁▁▁▂▁▁▁▂▁▂▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▅▅▅▄▆▃▃▄▅▃▁▄▅▃▄▂▄▂▅▄▅▃▄▃▃▃▅▂▄▄▄▃▁▂▃▄▄▆</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▃▂▆▂▆▁▆▇▆▆▆▃▇▆▆▇▆▇▆▇▅▆▅▇▇█▄▆▄▅▅▆██▆▇▆▇</td></tr><tr><td>val_auc</td><td>▁▄▅▄▆▆▆▆▇▆▇▇▇▄▇▇▇█▆▆▇█▇▇▇▇▇▇▅▆▅▆▇▇▇▇▆▆▆▇</td></tr><tr><td>val_f1</td><td>▅▅▄▃▆▁▆▁▆▇▆▇▇▄▇▆▇▇▆▇▇▇▇▆▄▇▇▇▆▆▆▄▇▆▇█▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▃▅▄▂▄▂▄▁▂▁▂▃▄▂▂▂▂▂▃▁▁▃▃▃▂▂▃▂▄▃▃▃▂▃▂▃▂▃▂</td></tr><tr><td>val_loss_step</td><td>█▄▅▃▂▄▅▄▂▃▁▃▇▆▇▅▅▅▄▆▃▅▃▆▃▇▅▇▁▄▄▄▄▂▇▄▆▃▄▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84347</td></tr><tr><td>train_auc</td><td>0.92467</td></tr><tr><td>train_f1</td><td>0.84831</td></tr><tr><td>train_loss_epoch</td><td>0.3631</td></tr><tr><td>train_loss_step</td><td>0.5149</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82311</td></tr><tr><td>val_auc</td><td>0.89728</td></tr><tr><td>val_f1</td><td>0.82014</td></tr><tr><td>val_loss_epoch</td><td>0.43154</td></tr><tr><td>val_loss_step</td><td>0.51517</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8gusxypr' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8gusxypr</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_110926-8gusxypr\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efac46a9fbb24f7384303e8af38e9a75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_114658-agil4ysw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/agil4ysw' target=\"_blank\">GINConv_3_16_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/agil4ysw' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/agil4ysw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.7 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▇▇▆▇▇▇▇▇▇▇▇█▇▇▇▇██████████▇█████████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▇▆▇▇▇▇▇▇█▇▇▇▇▇▇████████████████████</td></tr><tr><td>train_f1</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇██▇█▇█████████████████████</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▃▃▃▃▃▃▃▂▂▃▂▂▂▃▂▁▂▂▂▂▁▁▁▂▂▂▂▁▂▂▂▂▂▁▂</td></tr><tr><td>train_loss_step</td><td>█▆▆▃▄▅▆▁▃▃▃▂▁▂▅▃▂▂▂▂▄▄▂▃▃▂▁▂▃▁▃▃▃▂▂▂▁▄▂█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▅▄▅▅▄▅▄▅▅▅▆▆▇█▇▆▅▅▇▅▆▆▇▆▆▇▆▆▅▅▇▇▆▇▇▆▇▆</td></tr><tr><td>val_auc</td><td>▁▆▆▆▆▆▆▆▇▆▆▇▇▇▇██▇█▇▇▇█▇▇█▇▇▇▇▇▇█▇▇▇█▇█▇</td></tr><tr><td>val_f1</td><td>▁▅▂▃▅▅▃▅▄▅▅▅▅▆▇█▇▅▆▆▇▆▇▆▇▆▆▇▆▄▆▅▇▆▆▇▇▅▇▆</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▂▂▃▂▃▂▂▂▁▂▁▂▁▁▁▂▁▁▂▁▂▂▃▂▃▁▁▃▁▁▁▂▂▁▂▁▃</td></tr><tr><td>val_loss_step</td><td>█▄▄▃▄▅▃▇▃▄▃▃▆▃▇▆▅▃▆▃▄▅▃▆▃▆▄█▂▂▅▁▃▃▇▅▃▃▂▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.82398</td></tr><tr><td>train_auc</td><td>0.9046</td></tr><tr><td>train_f1</td><td>0.82614</td></tr><tr><td>train_loss_epoch</td><td>0.41588</td></tr><tr><td>train_loss_step</td><td>0.6502</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80189</td></tr><tr><td>val_auc</td><td>0.89132</td></tr><tr><td>val_f1</td><td>0.81897</td></tr><tr><td>val_loss_epoch</td><td>0.47479</td></tr><tr><td>val_loss_step</td><td>0.61847</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/agil4ysw' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/agil4ysw</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_114658-agil4ysw\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8408cedfb1741a8981acdd7855890e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333332417533, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_122218-jp80drmm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jp80drmm' target=\"_blank\">GINConv_3_16_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jp80drmm' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jp80drmm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.7 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "138e40e3ddc9413d878506e357aad5ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▅▆▆▇▆▆▇▇▇▇▇▇▇█▇▇▇▇▇▇█▇▇███████▇██████</td></tr><tr><td>train_auc</td><td>▁▂▃▄▄▄▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇█████████</td></tr><tr><td>train_f1</td><td>▁▃▅▅▆▆▇▆▇▇▇▇▇▇▇▇█▇▇▇█▇▇█▇▇███████▇██████</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▂▂▂▂▂▂▂▂▁▂▃▂▂▁▂▁▂▂▂▂▂▂▁▂▂▁▂▂▂▂▁▁▁▁▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▆▇▇▇▇▇▇█▇▇█▇████▆█▇▇██▇▇▇█▇▇▆▇▇▇▇██▇▇▇</td></tr><tr><td>val_auc</td><td>▁▃▅▇▇▇▇▇▇███████████▇█████▇█▇█▇▇████████</td></tr><tr><td>val_f1</td><td>▁▆▇▇▇▇▇▇▇█████████▆█▇▇███████▇▆▇█▇▇██▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▆▄▃▂▃▃▃▂▃▁▂▂▂▂▂▂▂▃▂▂▃▁▂▁▂▃▂▂▃▃▂▁▂▂▁▃▃▃▄</td></tr><tr><td>val_loss_step</td><td>▇▇▅▄▂▄▆▅▂▅▁▃▅▄▅▆▅▄▅▆▃▅▂▆▃▅▆▇▂▇▄▄▄▃▅▃█▅▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.81689</td></tr><tr><td>train_auc</td><td>0.89066</td></tr><tr><td>train_f1</td><td>0.82565</td></tr><tr><td>train_loss_epoch</td><td>0.40562</td></tr><tr><td>train_loss_step</td><td>0.48573</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80189</td></tr><tr><td>val_auc</td><td>0.89332</td></tr><tr><td>val_f1</td><td>0.78238</td></tr><tr><td>val_loss_epoch</td><td>0.47637</td></tr><tr><td>val_loss_step</td><td>0.61838</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jp80drmm' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jp80drmm</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_122218-jp80drmm\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8d8d291ecd848cb8929a9fe152d3b9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_125742-y6dhpsi3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/y6dhpsi3' target=\"_blank\">GINConv_3_16_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/y6dhpsi3' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/y6dhpsi3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.7 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▆▇▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇▆▇█▇▇▇█▇██▇▇▇█████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇█████▇▇███████</td></tr><tr><td>train_f1</td><td>▁▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████▇██████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▄▃▃▄▃▃▃▂▃▂▂▂▂▃▂▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▇▅▃▆▅▃▃▇▂▆▁▄▁▄▅█▂▄▂▄▂▂▄▃▂▃▂▃▂▃▄▂▁▁▃▃▅█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▆▆▆▇▆▃▇▆▆▆▇▇▇▆▇▇▇▇██▇▇▆█▆▇▇▇▇▇▆▇▆▇██▇█</td></tr><tr><td>val_auc</td><td>▁▄▆▅▅▇▆▇▇▆▅▇▆▇▆▆█▇▇▇▇▇▇▇▇█▇▇▆▇▇▇▆▇▆▇██▇█</td></tr><tr><td>val_f1</td><td>▅▆▆▅▅▆▅▁▇▆▆▇▇▇▇▇▇▇▇██▇█▇▅█▇▇▇▇█▇▆▇▇▇▇█▇█</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▄▄▃▃▄▂▃▂▂▃▃▂▂▁▁▃▂▁▃▃▂▄▁▃▂▂▂▂▂▃▃▄▃▂▂▂▃</td></tr><tr><td>val_loss_step</td><td>█▄▄▇▄▅▃▄▅▅▃▃▅▅▃▄▁▂▇▄▂▄▅▄▅▂▅▃▃▁▆▁▅▆█▃▄▄▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85706</td></tr><tr><td>train_auc</td><td>0.92484</td></tr><tr><td>train_f1</td><td>0.85815</td></tr><tr><td>train_loss_epoch</td><td>0.36016</td></tr><tr><td>train_loss_step</td><td>0.57864</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83491</td></tr><tr><td>val_auc</td><td>0.90109</td></tr><tr><td>val_f1</td><td>0.83254</td></tr><tr><td>val_loss_epoch</td><td>0.44292</td></tr><tr><td>val_loss_step</td><td>0.50143</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/y6dhpsi3' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/y6dhpsi3</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_125742-y6dhpsi3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bcbf620b5224593a4d064004699870a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_133419-jqb7ykzi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jqb7ykzi' target=\"_blank\">GINConv_3_16_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jqb7ykzi' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jqb7ykzi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.7 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "2.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.2 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▆▇▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇█▇██▇▇██████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██▇███▇██▇█▇██████████</td></tr><tr><td>train_f1</td><td>▁▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█▇█▇▇███████▇██████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▃▃▄▃▂▄▃▃▂▂▂▂▂▂▂▂▂▂▁▂▂▁▂▁▂▂▁▂▂▁▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▇▆▃▅▅▃▆▂▃▄▃▂▂▃▄▂▄▃▁▄▁▅▁▂▂▂▁▃▂▂▄▂▂▂▂▃▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▃▂▇▇▄▄▇▇▆▆▆▅▆▅▇▆▆▇▇▄▄▆▆▆▇▃▂▇█▃▆▆▆▆▆▆▇▅</td></tr><tr><td>val_auc</td><td>▁▄▅▅▇▇▅▆███▇▇▆▇▆▇▇▆██▆▇██▇▇▅▄▇█▅▇██▇██▇▅</td></tr><tr><td>val_f1</td><td>▅▄▃▁▇▇▅▄▇▆▆▇▆▄▇▆▇▆▇▇█▅▂▆▇▆▇▅▄▇█▆▇▅▆▆▇▅█▆</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▆▄▃▃▄▂▃▂▁▂▃▂▃▁▁▁▂▁▂▄▁▁▁▁▃▃▂▂▄▃▂▂▂▂▃▂▄</td></tr><tr><td>val_loss_step</td><td>▆▆▃█▇▄▅█▃▅▄▂▅▄▆▆▁▄▂▄▄▃▅▃▃▂▃▆▃▃▅▆▄▄▃▅▄▄▃▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85292</td></tr><tr><td>train_auc</td><td>0.91932</td></tr><tr><td>train_f1</td><td>0.8531</td></tr><tr><td>train_loss_epoch</td><td>0.36339</td></tr><tr><td>train_loss_step</td><td>0.34428</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.79717</td></tr><tr><td>val_auc</td><td>0.8762</td></tr><tr><td>val_f1</td><td>0.79621</td></tr><tr><td>val_loss_epoch</td><td>0.47785</td></tr><tr><td>val_loss_step</td><td>0.61236</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jqb7ykzi' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jqb7ykzi</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_133419-jqb7ykzi\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "790cc1a02d6a486fb17b9ea2abe54a81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_141150-6s0xo1yw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6s0xo1yw' target=\"_blank\">GINConv_3_32_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6s0xo1yw' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6s0xo1yw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 6.0 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "6.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.6 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eb5f949c630443f8e24389d4f6bea8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▅▆▆▆▆▇▇▇▇▆▇▇▇▇▇▇█▇▇▇▇▇▇▇▇███▇██▇████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇██████▇███████</td></tr><tr><td>train_f1</td><td>▁▄▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇█▇▇███▇██▇████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▄▃▃▄▃▃▃▂▃▃▂▂▃▃▃▂▂▂▂▂▂▂▂▁▂▂▁▂▁▁▂▂▁▂▁</td></tr><tr><td>train_loss_step</td><td>▇▅▆▅▆▅▅▄▅▄▄▄▃▄▅▅▆█▆▅▅▄▂▃▂▃▃▅▄▄▂▂▆▃▁▅▅▃▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▄▆▅▃▆▆▆▆▇▅▇▇▇▇▇▆▄▇▆▆▅▄▄▇█▇▆▆▇▆▇▇▇▇▇█▇█</td></tr><tr><td>val_auc</td><td>▃▅▅▆▄▁▆▆▅▇▇▇▇▆▇▇█▇▇▇▆▆▇▃▆▇▇█▇▇█▆▇▇█▇▆▇▇▇</td></tr><tr><td>val_f1</td><td>▁▃▄▇▆▃▇▆▇▆▇▅▇▇▇▇▇▇▄█▇▆▅▅▄██▇▆▆▇▇▇▇▇▇▇█▇█</td></tr><tr><td>val_loss_epoch</td><td>█▇█▃▅▆▃▄▄▃▃▂▁▂▂▁▃▂▆▂▃▅▅▅▅▃▂▂▄▄▁▃▂▄▃▄▄▄▃▄</td></tr><tr><td>val_loss_step</td><td>▇▇█▇▇▅▆██▆▆▂▃▃▄▂▆▄▆▅▆▂▆▆▄▇▄▄▇▄▁▄▃▆▅▆▅▆▅▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8736</td></tr><tr><td>train_auc</td><td>0.94323</td></tr><tr><td>train_f1</td><td>0.87367</td></tr><tr><td>train_loss_epoch</td><td>0.29637</td></tr><tr><td>train_loss_step</td><td>0.21238</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83491</td></tr><tr><td>val_auc</td><td>0.90251</td></tr><tr><td>val_f1</td><td>0.83796</td></tr><tr><td>val_loss_epoch</td><td>0.4797</td></tr><tr><td>val_loss_step</td><td>0.57171</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6s0xo1yw' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6s0xo1yw</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_141150-6s0xo1yw\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4fad5027b194c2ea4ac072f41243f06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333332417533, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_144723-ayd0mlto</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ayd0mlto' target=\"_blank\">GINConv_3_32_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ayd0mlto' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ayd0mlto</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 6.0 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "6.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.6 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇███▇██████▇███████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇██▇▇█████████████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇██████████▇███████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▃▃▃▃▂▃▃▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▂▁▂▁▁▂▂▂▂▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▆▄▆▃▅▄▄▄▃▃▃▄▄▅▅▆▅▄▄▄▁▂▃▃▂▂▂▄▄▂▄▂▁▄▃▃▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▆▇▇▇██▇█▇▇▇▇█▇███▇▇███▇▇██▇█▇▇██▇██▇█▇</td></tr><tr><td>val_auc</td><td>▁▆▆▇▆▇▇▇█▇▇▇▇▇█▇██▇██▇██▇▇▇▇▇▇▇▇▇█▇████▇</td></tr><tr><td>val_f1</td><td>▁▆▇█████████▇███████████████████████████</td></tr><tr><td>val_loss_epoch</td><td>█▅▃▂▃▂▂▃▂▂▃▁▂▂▂▂▂▁▁▂▁▁▁▂▂▂▂▂▄▂▂▁▁▁▂▂▂▁▂▂</td></tr><tr><td>val_loss_step</td><td>▇▆▃▄▆▄▄▆▅▆▆▂▂▄▃▃▅▂▁▂▂▁▂▄▅▄▂▃█▂▂▃▂▂▂▅▄▃▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85292</td></tr><tr><td>train_auc</td><td>0.92889</td></tr><tr><td>train_f1</td><td>0.85413</td></tr><tr><td>train_loss_epoch</td><td>0.3336</td></tr><tr><td>train_loss_step</td><td>0.26473</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.79009</td></tr><tr><td>val_auc</td><td>0.89076</td></tr><tr><td>val_f1</td><td>0.79819</td></tr><tr><td>val_loss_epoch</td><td>0.45265</td></tr><tr><td>val_loss_step</td><td>0.55428</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ayd0mlto' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ayd0mlto</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_144723-ayd0mlto\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e555ec44c4294de98709e3348ea3c52c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_152148-u7m4ofd9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/u7m4ofd9' target=\"_blank\">GINConv_3_32_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/u7m4ofd9' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/u7m4ofd9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 6.0 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "6.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.6 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fda3c13525744d1a5be1ab2cbef08bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▆▆▆▆▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇█▇█▇▇███████████▇█</td></tr><tr><td>train_auc</td><td>█▄▃▂▂▂▂▂▂▂▂▂▁▁▂▂▁▂▄▂▃▃▁▃▃▃▃▄▄▅▃▄▃▆▃▄▆▄▅▃</td></tr><tr><td>train_f1</td><td>▁▃▄▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇████████████▇█</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▂▂▂▂▂▂▁▂▂▂▁▁▁▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▂▁▁▂▁▁▂▂▁▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▃▁▄▃▆▄▆▄▅▆▅▅▆▆▆▆▇▆▇▆▃▇▄▄▇▇▄▇█▇▇▇▆█▇▅▇▆▆▄</td></tr><tr><td>val_auc</td><td>█▃▂▂▂▂▁▂▁▁▂▁▁▁▁▁▁▁▂▁▃▁▁▁▁▁▁▁▁▂▂▁▂▁▁▂▂▁▂▁</td></tr><tr><td>val_f1</td><td>▅▁▄▄▆▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▅▇▄▄▇█▄███▇█▇▇▇▇▇▆▇▄</td></tr><tr><td>val_loss_epoch</td><td>█▅▄▃▃▃▂▃▂▂▂▂▂▁▁▁▂▁▁▂▃▂▃▄▁▂▅▁▂▁▁▂▁▃▅▃▃▃▄▅</td></tr><tr><td>val_loss_step</td><td>▇▇▆▅▆▅▅▆▆▅▅▃▄▃▄▂▄▃▂▄▄▁▅▆▃▆▅▃▇▂▂▃▂▆▅▆▄▅██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84525</td></tr><tr><td>train_auc</td><td>0.31203</td></tr><tr><td>train_f1</td><td>0.85011</td></tr><tr><td>train_loss_epoch</td><td>0.36856</td></tr><tr><td>train_loss_step</td><td>0.47996</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.77594</td></tr><tr><td>val_auc</td><td>0.11193</td></tr><tr><td>val_f1</td><td>0.73389</td></tr><tr><td>val_loss_epoch</td><td>0.54722</td></tr><tr><td>val_loss_step</td><td>0.6849</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/u7m4ofd9' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/u7m4ofd9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_152148-u7m4ofd9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ca6937d0b7410ea1caf1ddb90d991c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_155505-yauoh5ll</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yauoh5ll' target=\"_blank\">GINConv_3_32_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yauoh5ll' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yauoh5ll</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 6.0 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "6.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.6 K     Total params\n",
      "0.027     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇███████</td></tr><tr><td>train_auc</td><td>▁▅▆▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇████▇███████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇████▇███████</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▅▄▄▄▃▄▃▃▃▂▃▂▂▂▂▂▃▂▂▃▁▂▂▂▂▁▂▁▁▂▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>▇▆█▇▇▆▆▅█▄▄▅▃▄▄▆▄▁▄▄▃▄▇▆▄▅▅▅▂▄▅▄▃▃▃▄▃▂▃▇</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▆▆▆▇▅▇▇▆█▆█▇▇▇▇▇▆▇██▇█▇▇▇▇██▇█▇▇▇█▇█▆▇</td></tr><tr><td>val_auc</td><td>▃▅▄▄▆▆▁▇▆▇██▇████▇▇▇▇▇▇▇▇▆▇▇▇█▇█▇▇▆█▇▇▄▅</td></tr><tr><td>val_f1</td><td>▁▃▇▇▇▇▇█▇▆█▆███▇▇▇▇▇██▇█▇▇▇▇██▇███▇█▇█▆█</td></tr><tr><td>val_loss_epoch</td><td>▇█▃▄▂▃▅▃▂▄▂▄▂▂▂▂▃▄▃▃▂▂▃▃▁▃▂▃▅▁▃▂▄▂▆▁▃▅▆▅</td></tr><tr><td>val_loss_step</td><td>▆▇▅▇▆▅▄█▂▆▅▅▅▅▄▃▇▇▆▄▅▃█▇▂▄▃▆█▅▄▄█▁▇▁▅██▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87832</td></tr><tr><td>train_auc</td><td>0.94866</td></tr><tr><td>train_f1</td><td>0.87854</td></tr><tr><td>train_loss_epoch</td><td>0.30164</td></tr><tr><td>train_loss_step</td><td>0.50619</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80189</td></tr><tr><td>val_auc</td><td>0.88036</td></tr><tr><td>val_f1</td><td>0.80734</td></tr><tr><td>val_loss_epoch</td><td>0.49578</td></tr><tr><td>val_loss_step</td><td>0.50956</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yauoh5ll' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yauoh5ll</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_155505-yauoh5ll\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01555b1dea6a40618568ded35ded60b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_163108-qtkaluzf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qtkaluzf' target=\"_blank\">GINConv_3_32_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qtkaluzf' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qtkaluzf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 6.0 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "7.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.7 K     Total params\n",
      "0.031     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▅▆▆▆▆▆▆▇▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇█</td></tr><tr><td>train_auc</td><td>▁▅▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████████</td></tr><tr><td>train_f1</td><td>▁▅▅▆▆▆▆▇▆▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇███▇█</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▄▄▄▃▄▃▄▃▃▃▃▃▂▂▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▂▂</td></tr><tr><td>train_loss_step</td><td>▇▅▅▄▄▄▄▃▆▃▅▅▆▃▃▆▂▄▂▄▂▃▄▄▃▃▂▁▃▂▃▃▃▂▃▄▂▁▁█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▅▅▆▇▇▇▇█▇█▆█▆█▇▇▇▇▇▇▇█▇██▇▅██▆█▇▇▇██▇█</td></tr><tr><td>val_auc</td><td>▁▄▂▅▄▅▆▆▇▆▇▇▇▆▇▇▆▇█▇█▇▇▇▇▇▇▇▄▇▇█▇▇▆▇▇█▇▆</td></tr><tr><td>val_f1</td><td>▁▆▇▆▆▇▇███▇█▇█▇██▇▇▇█▇▇█▇███▆██▇█▇█▇██▇█</td></tr><tr><td>val_loss_epoch</td><td>█▃▄▃▄▂▂▁▁▃▁▂▃▂▂▂▂▃▂▃▁▂▄▃▃▂▄▁▄▄▃▃▄▄▂▄▄▃▂▄</td></tr><tr><td>val_loss_step</td><td>█▃▃▂▆▄▂▁▃▆▂▃▅▄▄▃▂▃▂▅▁▄▄▅▅▂▇▂▅▇▆▃█▄▃▅▄▅▂▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.88069</td></tr><tr><td>train_auc</td><td>0.94375</td></tr><tr><td>train_f1</td><td>0.88283</td></tr><tr><td>train_loss_epoch</td><td>0.31441</td></tr><tr><td>train_loss_step</td><td>0.61728</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82547</td></tr><tr><td>val_auc</td><td>0.89539</td></tr><tr><td>val_f1</td><td>0.81026</td></tr><tr><td>val_loss_epoch</td><td>0.4842</td></tr><tr><td>val_loss_step</td><td>0.57265</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qtkaluzf' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qtkaluzf</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_163108-qtkaluzf\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf43c3e293d04b6993be3634b15809bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_170415-5e8l5q51</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5e8l5q51' target=\"_blank\">GINConv_3_64_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5e8l5q51' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5e8l5q51</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 22.3 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "24.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.5 K    Total params\n",
      "0.098     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "128ae5da152742e4ad30bd7f2134f9c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▇▆▇▇▇▆▇▇▇▇▇▇████</td></tr><tr><td>train_auc</td><td>▁▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇█████▇████</td></tr><tr><td>train_f1</td><td>▁▄▄▄▅▅▅▅▅▅▅▆▅▅▆▆▆▆▆▆▆▆▆▆▇▆▇▆▇▆▇▇▇▇▇▇████</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▃▂▃▃▃▂▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>▇▇▆▅▆▄▄▃▃▅▄▄▇▄▅▄▄▄▅▇▄▄▅▂▃▃▁█▃▃▂▃▄▂▂▁▄▃▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▅▅▅▄▃▁▇▇▇█▅▆▇▃▇▆▆▇▇▆▄▇▆▇▇▆▆▆▆▅▇▄▅▅▆▆█▇▅▆</td></tr><tr><td>val_auc</td><td>▆▆▆▅▅▄▇█▆▇▅▅█▁█▅▇█▇▆▂▇▆▇▆▆▄▆▇▅▆▅▅▆▅▆▇▆▃▃</td></tr><tr><td>val_f1</td><td>▇▆▆▅▅▁▇█▇█▇▇█▆█▇▇▇█▇▆█▇▇▇▇▇▇▇▇█▄▆▇▇▇█▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>▂▄▄▄▃▆▂▁▂▁▂▂▁▄▁▃▂▂▂▃▃▂▃▂▃▄▃▂▃▄▂█▆▅▄▃▂▄▅▇</td></tr><tr><td>val_loss_step</td><td>▄▆█▆▃▆▃▄▄▂▃▃▄▅▃▆▄▅▃▅▄▆▆▄▃▇▅▃▄▅▂▅▇▅▄▅▁▄█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.91376</td></tr><tr><td>train_auc</td><td>0.96924</td></tr><tr><td>train_f1</td><td>0.91402</td></tr><tr><td>train_loss_epoch</td><td>0.21705</td></tr><tr><td>train_loss_step</td><td>0.19848</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.77594</td></tr><tr><td>val_auc</td><td>0.84238</td></tr><tr><td>val_f1</td><td>0.78747</td></tr><tr><td>val_loss_epoch</td><td>0.71431</td></tr><tr><td>val_loss_step</td><td>0.72264</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5e8l5q51' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5e8l5q51</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_170415-5e8l5q51\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bbc3608492048f8921b621ed3a8a639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_173807-paiueviq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/paiueviq' target=\"_blank\">GINConv_3_64_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/paiueviq' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/paiueviq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 22.3 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "24.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.5 K    Total params\n",
      "0.098     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▅▅▆▅▅▆▆▆▇▆▆▆▆▇▇▆▇▇▇▇▇▇▇█▇▇▆██▇█▇██▇█▇</td></tr><tr><td>train_auc</td><td>▁▄▄▅▅▆▅▆▆▆▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇█▇█▇███████▇██</td></tr><tr><td>train_f1</td><td>▁▄▄▅▅▆▅▅▆▆▆▇▆▇▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇██▇▇▇██▇█▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▅▅▄▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▃▂▃▂▃▂▁▂▂▂▁▂▂▂▂</td></tr><tr><td>train_loss_step</td><td>██▇▅▆▄▄▅▄▄▄▄▅▆▄▅▄▅▆▄▃▄▂▂▅▃▁▅▂▃▂▃▂▃▁▁▂▄▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▁▄▆▅▁▇▆▆▆▆▇▅▁▆▆▇▆▅▃▆▇▆▆█▆▆▇▇▃▆▅▆▂▅▆▅▄▃</td></tr><tr><td>val_auc</td><td>▁▄▃▅▅▅▅▆▅▆▅▇▅▅▅▂▇█▇▅▄▇▇▇▄▇█▆█▇▅▆▆▆▄▄▆▅▄▇</td></tr><tr><td>val_f1</td><td>▄▂▁▄▆▆▁▇▆▆▆▇▇▆▅▆▆▆▅▅▆▇▆▇▇█▇▆█▇▆▆▆▇▂▅▅▇▆▆</td></tr><tr><td>val_loss_epoch</td><td>▅▅▅▅▁▂▄▂▂▁▁▂▂▂▄▃▁▅▃▂▅▂▂▂▃▃▅▃▁▃▄▇▃▂▃▅▄▄█▆</td></tr><tr><td>val_loss_step</td><td>▄▅▆▆▂▃▃▃▃▂▃▂▂▃▅▅▃▆▃▄▅▃▃▃▂▃▅▃▂▅▂▆▃▁▃▅▃▃█▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87301</td></tr><tr><td>train_auc</td><td>0.9385</td></tr><tr><td>train_f1</td><td>0.8736</td></tr><tr><td>train_loss_epoch</td><td>0.28592</td></tr><tr><td>train_loss_step</td><td>0.21376</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.77358</td></tr><tr><td>val_auc</td><td>0.88464</td></tr><tr><td>val_f1</td><td>0.79661</td></tr><tr><td>val_loss_epoch</td><td>0.53429</td></tr><tr><td>val_loss_step</td><td>0.55292</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/paiueviq' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/paiueviq</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_173807-paiueviq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e1b04a8e7574b72980f7dc769effcec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_181436-6q1j7rj3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6q1j7rj3' target=\"_blank\">GINConv_3_64_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6q1j7rj3' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6q1j7rj3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 22.3 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "24.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.5 K    Total params\n",
      "0.098     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▅▅▅▅▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▇█▇███████</td></tr><tr><td>train_auc</td><td>▄▂▂▂▃▁▁▃▂▃▄▅▅▅▅▅▅▅▄▄▄▅▅▄▅▆▅▄▃▅██▇█████▇▇</td></tr><tr><td>train_f1</td><td>▁▄▅▆▅▆▆▅▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▇█▇███████</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▂▁▁▁▁▂▂▂▂▁▁▁▁▂▂▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▃▆▆▅▆▇▆▇▇█▇██▆█▆▆▅▇▆▇▇▇▇▄▆▆▅▇▄▇▅▅▃▁▄▇▆▅▄</td></tr><tr><td>val_auc</td><td>▆▂▃▅▄▂▂▃▁████▇█████▅███▇█▇█▄▆▇████▇▇████</td></tr><tr><td>val_f1</td><td>▄▆▆▄▅▆▆▆▇▇▇█▇▆█▇▆▄▆▇▇▆▆▆▄▇▆▅▇▆█▄▄▃▁▆▇▆▅▄</td></tr><tr><td>val_loss_epoch</td><td>▆▄▃▄▂▂▃▃▂▁▂▁▂▂▁▃▂▄▂▃▂▄▂▃▄▅▃▃▂▅▂▆▅█▇▇▃▆▅▅</td></tr><tr><td>val_loss_step</td><td>▃▅▅▅▁▃▄▃▃▁▂▂▅▂▂▇▃▅▁▃▃▅▃▃▄█▃▃▃▅▃▂▄▆▅▆▂▅▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.886</td></tr><tr><td>train_auc</td><td>0.79759</td></tr><tr><td>train_f1</td><td>0.88614</td></tr><tr><td>train_loss_epoch</td><td>0.29935</td></tr><tr><td>train_loss_step</td><td>0.28675</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.75472</td></tr><tr><td>val_auc</td><td>0.85679</td></tr><tr><td>val_f1</td><td>0.73196</td></tr><tr><td>val_loss_epoch</td><td>0.53933</td></tr><tr><td>val_loss_step</td><td>0.56276</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6q1j7rj3' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6q1j7rj3</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_181436-6q1j7rj3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c62873bccae458aa8a5cf00a7352492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_184919-5sdqj2j2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5sdqj2j2' target=\"_blank\">GINConv_3_64_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5sdqj2j2' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5sdqj2j2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 22.3 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "24.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.5 K    Total params\n",
      "0.098     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ea5b15bf6d84a7089237223b65c9428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▄▄▅▅▅▆▆▆▆▆▆▆▆▆▆▆▇▆▆▆▇▇▇▇▇▇▇▆▆▇▆▇█████</td></tr><tr><td>train_auc</td><td>▁▄▄▅▅▅▅▅▆▆▆▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇█████</td></tr><tr><td>train_f1</td><td>▁▃▄▄▄▅▅▄▅▆▆▆▆▆▆▆▆▆▆▇▆▆▆▇▇▇▇▇▇▇▆▆▇▆▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▅▅▄▅▅▄▄▄▄▃▃▃▃▄▄▃▂▃▃▃▂▂▂▂▂▂▂▂▄▂▂▂▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>▇▆▅▇▆▄▅▅▅▃▅▄▃▅▅▃▄█▃▃▅▃▄▃▄▂▄▁▂▁▁▄▄▃▃▄▅▃▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▂▅▅▅▇▇▆▅▃▆▂▆▆▇█▁▆▅█▇▆▅▆▅▅▅▆▅▅▄▆▅▆▂▅▅▅▅▅▅</td></tr><tr><td>val_auc</td><td>▂▅▄▆▇▆▇▆▅▇▅▆▇▇▇▇▇█▇▅▅▇█▅▅▅▆▄▅▅▆▇▅▁▆▅▅▅▅▄</td></tr><tr><td>val_f1</td><td>▆▆▆▇▇▇▇▅▄▆▆▇▇▇█▁▆▅█▇▇▇▇▇▆▆▇▆▇▆▇▆▇▄▆▅▅▇▆▇</td></tr><tr><td>val_loss_epoch</td><td>▄▂▄▂▁▂▁▃▃▂▇▂▂▁▂▇▂▄▂▃▂▄▁▃▃▄▃▆▄▃▅▃▆▇▂█▆█▅█</td></tr><tr><td>val_loss_step</td><td>▄▃▄▃▃▄▂▂▃▂▅▂▄▂▅▇▂▄▄▁▂▇▂▄▂▅▅▅▅▁▅▆▇▆▁█▄▅▅▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.90018</td></tr><tr><td>train_auc</td><td>0.96253</td></tr><tr><td>train_f1</td><td>0.89982</td></tr><tr><td>train_loss_epoch</td><td>0.24951</td></tr><tr><td>train_loss_step</td><td>0.26395</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.78538</td></tr><tr><td>val_auc</td><td>0.86616</td></tr><tr><td>val_f1</td><td>0.79551</td></tr><tr><td>val_loss_epoch</td><td>0.61624</td></tr><tr><td>val_loss_step</td><td>0.64309</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5sdqj2j2' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5sdqj2j2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_184919-5sdqj2j2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d98f1b41c1e41b2896851c9b1fb8328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_192356-y4ft1d0w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/y4ft1d0w' target=\"_blank\">GINConv_3_64_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/y4ft1d0w' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/y4ft1d0w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 22.3 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "28.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "28.7 K    Total params\n",
      "0.115     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▅▅▅▆▅▅▅▆▇▅▆▇▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇████▇██</td></tr><tr><td>train_auc</td><td>▁▅▅▅▆▆▆▆▆▆▆▆▇▆▇▇▆▇▇▆▇▇▇▇▇▇█▇█▇██████████</td></tr><tr><td>train_f1</td><td>▁▄▅▅▅▅▆▆▅▅▅▆▇▅▆▇▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇████▇██</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▅▄▄▄▄▄▄▄▃▃▄▄▃▃▃▂▃▃▃▃▂▂▂▂▂▁▂▂▂▂▁▁▁▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▆▆▇▆▄▅▅▄▄▅▄▅▃▅▃▆▃▄▄▅▆▅▄▃▂▂▃▂▂▂▄▃▂▂▃▄▁▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▅▄▂▄▅▄▆▆▇▇▄▅▅▆█▇▅▆▆▆▆▅▅▆▅▃▆▃▂▃▄▃▅▄▃▆▅▃</td></tr><tr><td>val_auc</td><td>▄▆▇▇▂▅▆▆▇▇▇▇▅▇█▇█▇▆▇▆▆▇▆▅▆▅▅▇▄▁▅▆▄▅▇▅▇▅▃</td></tr><tr><td>val_f1</td><td>▅▃▆▃▃▆▃▃▇▆██▆▆▄▇█▇▇▆▇▆▇▇▆▇▆▁▇▃▄▆▃▅▆▇▄▆▆▃</td></tr><tr><td>val_loss_epoch</td><td>▄▃▂▃▃▂▄▂▂▃▁▁▃▂▃▃▁▄▃▄▃▂▃▆▄▃▄▆▅▅▆▅▇▆▄▇▅▃▅█</td></tr><tr><td>val_loss_step</td><td>▅▄▃▃▂▂▄▃▄▄▁▃▂▂▄▅▁▇▄▇▄▁▂▇▄▃▃▃▅▇▄▃█▇▃▆▁▂▃▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.90195</td></tr><tr><td>train_auc</td><td>0.96521</td></tr><tr><td>train_f1</td><td>0.90072</td></tr><tr><td>train_loss_epoch</td><td>0.23681</td></tr><tr><td>train_loss_step</td><td>0.28928</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.77123</td></tr><tr><td>val_auc</td><td>0.8553</td></tr><tr><td>val_f1</td><td>0.75931</td></tr><tr><td>val_loss_epoch</td><td>0.62381</td></tr><tr><td>val_loss_step</td><td>0.70876</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/y4ft1d0w' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/y4ft1d0w</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_192356-y4ft1d0w\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "751b6513cf464cc4b36c2f0e197b55f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_195733-bodqyj15</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/bodqyj15' target=\"_blank\">GINConv_4_16_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/bodqyj15' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/bodqyj15</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 2.4 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇██▇█▇████▇███████</td></tr><tr><td>train_auc</td><td>▁▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇█▇████████████</td></tr><tr><td>train_f1</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇███▇▇████▇████▇████▇███████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▃▃▃▃▃▃▂▂▂▂▂▃▃▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>▇▅▃▄▃▃▃▃▄▃▂▃▁▃▃▃▁▇▄▂▃▂█▂▂▂▃▄▂▄▄▂▁▄▂▁▂▄▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▇▆▇▇▇▇▇▇▇▇▇█▇█▆▇▇█▇▇▇▇▇█▇▇▇▇▇▇▇▇█▇▇▇██</td></tr><tr><td>val_auc</td><td>▁▃▅▅▆▇▆▇▇█▇█▇█▇█▇▇██▇█▇▆▇▇▇▆▆▆▇▇▇▇▇▇▇▆▇▇</td></tr><tr><td>val_f1</td><td>▁▆▆▄▆▆▆▇▇▇▇▅▆█▇█▆▆▇▇▆▇▆▆▆▇▇▆▅▇▅▇▇▆▇▅▆▆█▇</td></tr><tr><td>val_loss_epoch</td><td>█▃▄▄▃▃▂▂▁▁▁▂▂▁▂▁▂▁▂▂▁▂▂▂▁▂▂▄▂▂▄▂▂▂▂▂▃▂▂▂</td></tr><tr><td>val_loss_step</td><td>█▄▇▆▇▄▄▅▃▃▂▃▄▃▅▃▄▁▆▄▃▄▄▃▂▃▄▆▂▄▇▅▆▆▄▂▇▄▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83934</td></tr><tr><td>train_auc</td><td>0.90307</td></tr><tr><td>train_f1</td><td>0.84404</td></tr><tr><td>train_loss_epoch</td><td>0.39229</td></tr><tr><td>train_loss_step</td><td>0.40818</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81604</td></tr><tr><td>val_auc</td><td>0.8935</td></tr><tr><td>val_f1</td><td>0.80102</td></tr><tr><td>val_loss_epoch</td><td>0.43496</td></tr><tr><td>val_loss_step</td><td>0.42194</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/bodqyj15' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/bodqyj15</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_195733-bodqyj15\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae2ee3cdb5ed461e8575968b7a000399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_203200-cipqb4gj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/cipqb4gj' target=\"_blank\">GINConv_4_16_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/cipqb4gj' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/cipqb4gj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 2.4 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2a9559525f54296926a7d974fa880ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇██▇█████████████████▇</td></tr><tr><td>train_auc</td><td>▁▄▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇████▇▇██▇████████▇</td></tr><tr><td>train_f1</td><td>▁▆▇▇▇▇▇▇▇▇█▇▇██▇▇▇███▇███▇████▇████▇███▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▃▃▃▃▃▃▃▂▂▃▂▂▃▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▂▁▂▂▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▆▄▄▃▄▃▃▆▅▃▄▂▂▄▄▂█▄▃▄▃▄▂▃▂▃▃▃▄▄▁▂▄▄▁▂▄▂▆</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▅▅▆▆▆▇█▇▇▆▇▇▆▅▅████▆▇▇█▆▆█▇▇█▇▇▇█▇█▆▇▆</td></tr><tr><td>val_auc</td><td>▁▆▅▅▆▆▇▇▇▇█▇██▇▇▇▇▇█▇▇▇▇▇▇█▇█▇██▇▇███▇█▇</td></tr><tr><td>val_f1</td><td>▁▃▄▄▅▆▅▆▇▇▇▆▇▇▆▆▅▇██▇▆▆▇█▆▆▆▇▆▆▇▇▇█▇▇▇▇▆</td></tr><tr><td>val_loss_epoch</td><td>█▃▄▃▄▂▂▃▂▂▁▂▂▁▂▂▂▁▂▂▂▃▂▂▂▂▂▂▁▃▂▂▃▂▃▁▂▂▂▃</td></tr><tr><td>val_loss_step</td><td>█▃▇▄█▄▃▆▃▃▂▄▂▂▄▅▄▂▅▄▂▆▂▂▃▁▃▄▁▅▅▅▆▂▆▁▇▄▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.79327</td></tr><tr><td>train_auc</td><td>0.86573</td></tr><tr><td>train_f1</td><td>0.80181</td></tr><tr><td>train_loss_epoch</td><td>0.44884</td></tr><tr><td>train_loss_step</td><td>0.58909</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.77594</td></tr><tr><td>val_auc</td><td>0.8811</td></tr><tr><td>val_f1</td><td>0.80167</td></tr><tr><td>val_loss_epoch</td><td>0.46086</td></tr><tr><td>val_loss_step</td><td>0.48465</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/cipqb4gj' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/cipqb4gj</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_203200-cipqb4gj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d4a7b1a4ac14ce6955d7905b6b6c79a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_211245-xtgntq7n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/xtgntq7n' target=\"_blank\">GINConv_4_16_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/xtgntq7n' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/xtgntq7n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 2.4 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35fb5e388f7e484b9380bd62db4a05e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██▇▇█▇▇▇██▇██▇██████▇█</td></tr><tr><td>train_auc</td><td>█▇▆▄▄▃▂▃▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▂▂▂▁▂▂▁▁▂▂▁▁▁▁▁▂</td></tr><tr><td>train_f1</td><td>▁▃▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇███▇███████████████</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▂▂▂▂▂▂▁▁▂▂▂▁▂▂▁▁▁▂▁▂▂▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▇▇▇▇▇█▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇█▇▇█▇█▇</td></tr><tr><td>val_auc</td><td>█▇▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_f1</td><td>▁▅▆▆▆▆▆▇▆▇▆▆▅▆▄▄▆▅▅▇▄▇▆▅▅▇▆▇▆▅▅█▅█▅▅▇▅▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▄▄▃▃▂▂▂▂▂▂▂▂▁▂▁▁▁▂▁▂▂▂▂▁▂▂▂▁▂▂▁▂▁▂▂▂▂▂▂</td></tr><tr><td>val_loss_step</td><td>█▃▅▄▄▃▃▃▂▂▂▃▃▂▃▂▂▁▃▂▂▄▃▂▂▂▃▃▁▂▄▂▄▂▃▂▃▄▅▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.82044</td></tr><tr><td>train_auc</td><td>0.16164</td></tr><tr><td>train_f1</td><td>0.82766</td></tr><tr><td>train_loss_epoch</td><td>0.42889</td></tr><tr><td>train_loss_step</td><td>0.40613</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80425</td></tr><tr><td>val_auc</td><td>0.12106</td></tr><tr><td>val_f1</td><td>0.80742</td></tr><tr><td>val_loss_epoch</td><td>0.43237</td></tr><tr><td>val_loss_step</td><td>0.43151</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/xtgntq7n' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/xtgntq7n</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_211245-xtgntq7n\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "072c1e2b25df4faf953850954a367209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_215056-i4red3og</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/i4red3og' target=\"_blank\">GINConv_4_16_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/i4red3og' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/i4red3og</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 2.4 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "2.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad84266546454d97ad07aa534bdd3dd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█▇█████▇████▇██</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇████████████████████</td></tr><tr><td>train_f1</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇██████▇██████████▇██</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▃▃▄▃▃▂▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▂▂▁▁▂▂▁▁▂▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▄▅▃▄▄▃▅▄▃▂▅▅▆▃▄▃▅▃▄▄▃▂▄▂▃▃▄▁▃▃▃▃▂▄▅▃▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▇▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇███▇█▇▇▇██▇████▇██▇█</td></tr><tr><td>val_auc</td><td>▁▅▄▆▅▆▆▆▇▇▇▇▇▇▅▇▅▇▆▅▇▇▇▇▇▅▆▆▇▇▆▆█▇▇▆█▇▅█</td></tr><tr><td>val_f1</td><td>▁▆▅▅▅▄▄▆▆▇▃▇▅▆▆▆▆▇▆▇▇▇▆▆▇▄▆▇▇▇▆▇▇▇▇▇█▆▅█</td></tr><tr><td>val_loss_epoch</td><td>█▂▃▂▂▃▃▁▁▂▃▂▂▂▂▂▂▁▂▂▁▁▂▃▁▂▂▂▁▂▁▂▁▁▂▃▁▂▂▂</td></tr><tr><td>val_loss_step</td><td>▇▂▄▃▂▆▅▂▂▃▆▅▃▃▃▂▃▃▄▃▁▃▃▆▁▂▂▃▂▃▁▃▁▂▃█▁▅▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84938</td></tr><tr><td>train_auc</td><td>0.91935</td></tr><tr><td>train_f1</td><td>0.85235</td></tr><tr><td>train_loss_epoch</td><td>0.36053</td></tr><tr><td>train_loss_step</td><td>0.39253</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.8184</td></tr><tr><td>val_auc</td><td>0.89839</td></tr><tr><td>val_f1</td><td>0.82299</td></tr><tr><td>val_loss_epoch</td><td>0.44107</td></tr><tr><td>val_loss_step</td><td>0.46015</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/i4red3og' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/i4red3og</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_215056-i4red3og\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61f011de8a5648f39dcb90d886a95f34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_223042-o8aughr6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/o8aughr6' target=\"_blank\">GINConv_4_16_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/o8aughr6' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/o8aughr6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 2.4 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "2.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.8 K     Total params\n",
      "0.011     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bc5cf3b507c497ea76160dfe4911262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇███▇▇██▇▇███████████</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█████▇▇▇███████████████</td></tr><tr><td>train_f1</td><td>▁▆▇▇▇▇▇▇▇▇▇█▇██████████████▇████████████</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▂▁▁▂</td></tr><tr><td>train_loss_step</td><td>▆▄▃▃▄▄▃▃▂▃▃▂▁▂▃▃▂▁▂▃▃▂▂▂▃▂▂▃▂▃▃▃▂▂▁▂▂▂▂█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▇▅▆▇▆▆▇▇▇▇▆▇█▇▇▇▇▇█▇▇█▇▇▇▇▇█████▇▇▇▆▇▇</td></tr><tr><td>val_auc</td><td>▁▅▅▆▇▇▃▆▆▅▆▆▅▆▇█▆▆▇▇▇▆▇█▆█▇▇▅██▇▇█▇▇▇▄██</td></tr><tr><td>val_f1</td><td>▄▆▇▁▅▆▅▅▆▇▇▇▆▅▇▇█▇▆▆▇▆▇▇▇▆▇▇▆█▇▇▇█▇▇▇▅▇█</td></tr><tr><td>val_loss_epoch</td><td>█▂▂▅▁▂▃▂▃▃▂▂▃▂▂▃▂▃▃▂▁▂▃▂▃▂▂▂▂▁▂▂▂▂▂▂▃▃▂▂</td></tr><tr><td>val_loss_step</td><td>▆▃▂▇▁▄▂▃▄▄▃▂▄▂▃▆▃▄▅▃▂▄█▃▆▄▃▄▃▂▂▃▄▁▄▂▇▃▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83343</td></tr><tr><td>train_auc</td><td>0.90297</td></tr><tr><td>train_f1</td><td>0.8405</td></tr><tr><td>train_loss_epoch</td><td>0.42009</td></tr><tr><td>train_loss_step</td><td>0.84554</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80425</td></tr><tr><td>val_auc</td><td>0.89143</td></tr><tr><td>val_f1</td><td>0.81917</td></tr><tr><td>val_loss_epoch</td><td>0.42649</td></tr><tr><td>val_loss_step</td><td>0.34199</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/o8aughr6' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/o8aughr6</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_223042-o8aughr6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "131bf01f720a4639b5f5e3212d3fe974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_231230-ua05izwy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ua05izwy' target=\"_blank\">GINConv_4_32_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ua05izwy' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ua05izwy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 8.3 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "8.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.8 K     Total params\n",
      "0.035     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "753d45a36f0b4e01b8fdbabe9202bed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█████▇▇███▇▇█</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇████▇██████████</td></tr><tr><td>train_f1</td><td>▁▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████▇▇████▇█</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▃▄▃▃▃▃▃▃▂▃▂▂▂▂▃▂▃▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>▅▅▄▄▃▂▄▃▃▃▃▂▄▃▃▂▃▁▂▂▂▂▄▂▂▃▂▁▂▂▁▃▃▂▂▁▂▂▁█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▁▅▄▄▄▂▅▇▄▆█▇▆▆▇▅▆█▆▆▅▂▆▅▆█▄▇▆▆▆▆▄▅▆▆█▇▃</td></tr><tr><td>val_auc</td><td>▁▄▆▇▇▃▇▆▇▅▇▇█▇▇▇▇▇▇▇▇▆▇▇▆▅▇▅▇▆▆▆▆▅▆▆▆▆▇▇</td></tr><tr><td>val_f1</td><td>▃▂▆▄▅▆▁▆▇▆▆█▇▆▇▇▅▆█▆▆▅▂▆▆▇▇▆▇▇▇▇▆▄▇▆▇██▃</td></tr><tr><td>val_loss_epoch</td><td>▅▇▂▄▃▄█▃▃▃▁▃▂▄▃▁▄▃▃▅▄▄▅▃▄▅█▄▄▄▅▄▅▆▆▃▅▅▃▇</td></tr><tr><td>val_loss_step</td><td>▄▃▂▃▃▃▆▄▃▃▂▄▃▄▅▁▂▃▄▃▄▃▃▂▄▅█▂▆▆▃▃▅▄▆▂▅▅▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87183</td></tr><tr><td>train_auc</td><td>0.94039</td></tr><tr><td>train_f1</td><td>0.87076</td></tr><tr><td>train_loss_epoch</td><td>0.32902</td></tr><tr><td>train_loss_step</td><td>0.75071</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.77594</td></tr><tr><td>val_auc</td><td>0.89497</td></tr><tr><td>val_f1</td><td>0.73239</td></tr><tr><td>val_loss_epoch</td><td>0.52335</td></tr><tr><td>val_loss_step</td><td>0.56968</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ua05izwy' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ua05izwy</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_231230-ua05izwy\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0d46647dfad47b6aafe0202decc9404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231228_235005-ngaqfpgi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ngaqfpgi' target=\"_blank\">GINConv_4_32_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ngaqfpgi' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ngaqfpgi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 8.3 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "8.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.8 K     Total params\n",
      "0.035     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇████████████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇███████████████</td></tr><tr><td>train_f1</td><td>▁▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇███▇▇▇███████████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▃▃▃▂▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>██▅▅▄▃▄▃▄▄▄▂▇▃▄▃▄▁▃▃▃▂▄▄▄▃▄▃▃▃▂▃▄▁▂▂▃▄▂▇</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▄▁▅▅▆▆▅▇▆▆▆▆▇█▇▇▅█▇▆▇▇▆██▇▆▆▇▇█▇▇▇▇▇▇▆█▇</td></tr><tr><td>val_auc</td><td>▁▅▅▆▆▇▆▇▇▆▇▇█▇▇█▆██▇██▆▇▇▆▆▇▇▇█▇▇▇▇▇▆▆▇▇</td></tr><tr><td>val_f1</td><td>▆▁▆▆▇▇▅██▇▇▇▇███▇█▇▆▇▇▇█▇█▇▇███▇▇▇███▆██</td></tr><tr><td>val_loss_epoch</td><td>██▃▃▂▃▃▂▂▂▂▂▂▂▃▁▃▁▁▂▂▁▃▂▂▃▄▁▂▃▂▂▃▃▃▂▃▃▂▃</td></tr><tr><td>val_loss_step</td><td>▆▇▂▄▂▅▅▃▃▃▂▄▅▄▆▂▄▃▃▃▄▂▃▂▃▅█▁▅▅▄▂▄▅▅▂▅▄▂▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85529</td></tr><tr><td>train_auc</td><td>0.92929</td></tr><tr><td>train_f1</td><td>0.85529</td></tr><tr><td>train_loss_epoch</td><td>0.34432</td></tr><tr><td>train_loss_step</td><td>0.59698</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80189</td></tr><tr><td>val_auc</td><td>0.89263</td></tr><tr><td>val_f1</td><td>0.81166</td></tr><tr><td>val_loss_epoch</td><td>0.4584</td></tr><tr><td>val_loss_step</td><td>0.5514</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ngaqfpgi' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ngaqfpgi</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231228_235005-ngaqfpgi\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "354fe18d3e8d48d8b9852f35841025e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_002647-6h24qfuy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6h24qfuy' target=\"_blank\">GINConv_4_32_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6h24qfuy' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6h24qfuy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 8.3 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "8.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.8 K     Total params\n",
      "0.035     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇██▇█████▇█</td></tr><tr><td>train_auc</td><td>▃▁▂▃▂▃▃▅▆▆▄▅▅▅▅▅▆▅▅▆▆▆▃▃▄▆▆▆▅▇▆▆▅▅▅▆▅█▅▆</td></tr><tr><td>train_f1</td><td>▁▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇████████▇█</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▃▃▂▂▃▂▂▂▂▂▃▃▂▁▂▂▂▂▂▁▃▁▂▂▂▂▁▁▂▂▂▁▁▂▂▁▁▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▅▆▇▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇█▇█▇█▆▇▇█▆▇▇█▅█▇▆▆▇▆</td></tr><tr><td>val_auc</td><td>▅▁▃▇▇▇█▇██████████████▆▇████████████████</td></tr><tr><td>val_f1</td><td>▁▃▃▄▅▆▅▅▆▆▆▅▆▆▇▆▆▆▆▅▇▄▇▅▇▄▅▆▇▄▇▅▇▁█▆▂▂▅▅</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▃▃▃▃▃▃▃▂▂▂▂▃▁▂▁▂▃▂▃▁▃▂▃▄▂▃▄▂▃▄▅▂▃▄▆▄▃</td></tr><tr><td>val_loss_step</td><td>▆▅▄▄▃▅▆▄▅▆▃▄▆▄▅▂▄▂▄▃▅▅▃▃▆▆█▁▅█▅▅█▄▅▆▆▇▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85233</td></tr><tr><td>train_auc</td><td>0.69632</td></tr><tr><td>train_f1</td><td>0.85294</td></tr><tr><td>train_loss_epoch</td><td>0.34869</td></tr><tr><td>train_loss_step</td><td>0.60501</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.79009</td></tr><tr><td>val_auc</td><td>0.87424</td></tr><tr><td>val_f1</td><td>0.7824</td></tr><tr><td>val_loss_epoch</td><td>0.45303</td></tr><tr><td>val_loss_step</td><td>0.4297</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6h24qfuy' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6h24qfuy</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_002647-6h24qfuy\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbeb0ac6d6c2474fbf8248a028242ac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_010328-v6i6g83c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/v6i6g83c' target=\"_blank\">GINConv_4_32_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/v6i6g83c' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/v6i6g83c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 8.3 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "8.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.9 K     Total params\n",
      "0.036     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e342616d605542bea566bf5b26b75763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▅▅▆▆▆▆▇▆▆▆▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇██▇█▇████▇██</td></tr><tr><td>train_auc</td><td>▁▄▅▅▆▆▆▆▆▇▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇████▇██</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▆▆▇▇▇▇▇▇▆▇▇▇▇▇▇██▇█▇▇███▇█▇████▇██</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▄▄▄▄▄▃▃▄▄▄▃▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▃▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▇▇▇▆▅▄▅▄▆▅▅▃▄▄▅▅▅▄▅▂▂▃▃▂▅▂▂▂▆▂▃▁▃▄▁▄▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▁▄▆▄▁▆▆▃▅▆▃▂▅▃▅▇▆▆▇▅▇▅▅▇▅▆▄█▇▅▆▃▅▆▅▂▅▆▂</td></tr><tr><td>val_auc</td><td>▁▅▅▃▆▂▆▆▆▆▆▆▆▄▇▆▇▅▇▆▇█▆▇█▇▇▃█▇▆▆▄▆█▇▅▇█▂</td></tr><tr><td>val_f1</td><td>▆▁▆▇▆▆▇▇▃▆▇▄▂▇▄▆█▇▇▇▆█▇▆▇▇▇▇██▆▆▆▅█▇▃▅█▅</td></tr><tr><td>val_loss_epoch</td><td>▅▅▃▄▂▄▁▂▄▃▂▄▄▂▄▃▁▂▄▂▄▂▃▅▂▄▁▅▃▃▂▄▄▅▂▂▅▄▂█</td></tr><tr><td>val_loss_step</td><td>▃▅▃▅▃▃▂▃▃▄▄▁▃▂▄▂▂▂▅▃▆▃▄▆▄▄▁▅▃▄▁▄▄▄▂▁▅▄▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87242</td></tr><tr><td>train_auc</td><td>0.94831</td></tr><tr><td>train_f1</td><td>0.87112</td></tr><tr><td>train_loss_epoch</td><td>0.28675</td></tr><tr><td>train_loss_step</td><td>0.25439</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.76887</td></tr><tr><td>val_auc</td><td>0.85745</td></tr><tr><td>val_f1</td><td>0.7598</td></tr><tr><td>val_loss_epoch</td><td>0.61598</td></tr><tr><td>val_loss_step</td><td>0.95804</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/v6i6g83c' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/v6i6g83c</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_010328-v6i6g83c\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "375188d2ae1e4188a65ca929fd87aeaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_014004-j0oyf9sf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/j0oyf9sf' target=\"_blank\">GINConv_4_32_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/j0oyf9sf' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/j0oyf9sf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 8.3 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "9.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "9.9 K     Total params\n",
      "0.040     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▆▆▆▆▆▇▇▆▆▆▆▇▇▇▇▇▇▆▇▇▇▇▇█▇▇▇██▇█▇▇███</td></tr><tr><td>train_auc</td><td>▁▄▅▆▆▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▆▇▇██▇▇▇█▇██▇████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▇▇▇▆▇▇▆▆▇▇▇▇▇▇▇█▇▇▇▇▇██▇▇▇█████████</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▄▄▃▄▄▃▄▃▃▃▃▃▃▂▃▂▃▂▄▃▃▂▂▂▃▂▁▂▂▁▃▂▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▇▆▆▇▅▇▅▇▅▅▆▃▅▆▅▅▄▃▄▄▅▃▄▄▅▄▃▄▄▅▅▅▆▄▄▂▅▆▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▅▆▃▇▇▇▇▆▇▅▆▇▄▆▇▇▇▇▇▇▇▆▇▇█▇▇▇▇▇▆▇▇▆▇▅▆▇</td></tr><tr><td>val_auc</td><td>▁▄▄▄▅▅▇▆▅▅▇▇▆▇▁▄▆▆▇▇▇▆▆▄█▆█▇▇▆▇▅▅▆▅▄▅▅▆▇</td></tr><tr><td>val_f1</td><td>▁▆▆▇▃█▇█▇▇▇▅▇█▅▆█▇██▇██▆███▇█▇▇▇▇█▇▇▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▃█▃▂▂▃▄▃▅▄▃▅▇▂▃▃▂▃▃▃▅▂▃▄▆▁▃▃█▆▃█▅▅▃▇▆</td></tr><tr><td>val_loss_step</td><td>▅▂▂▁▅▂▁▂▂▃▃▄▄▄▃▅▂▂▃▂▂▄▃▃▂▂▃▅▁▄▁▅▆▁▆▅▄▂█▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87183</td></tr><tr><td>train_auc</td><td>0.9422</td></tr><tr><td>train_f1</td><td>0.86967</td></tr><tr><td>train_loss_epoch</td><td>0.29558</td></tr><tr><td>train_loss_step</td><td>0.13384</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80896</td></tr><tr><td>val_auc</td><td>0.90124</td></tr><tr><td>val_f1</td><td>0.78628</td></tr><tr><td>val_loss_epoch</td><td>0.50565</td></tr><tr><td>val_loss_step</td><td>0.58709</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/j0oyf9sf' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/j0oyf9sf</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_014004-j0oyf9sf\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dabea7613083480e99fb5ce6075041ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_021640-jkex47p5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jkex47p5' target=\"_blank\">GINConv_4_64_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jkex47p5' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jkex47p5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 30.9 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "33.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "33.1 K    Total params\n",
      "0.132     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇█▇█</td></tr><tr><td>train_auc</td><td>▁▅▅▆▆▆▆▆▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇█▇▇█████▇█████</td></tr><tr><td>train_f1</td><td>▁▄▄▅▅▅▅▅▅▆▅▅▆▆▆▆▆▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇█▇▇█▇█▇█</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▅▅▄▅▄▄▄▃▃▃▃▃▄▃▃▃▂▃▂▂▂▃▂▂▂▂▂▂▁▂▂▂▂▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▅▅▆▅▆▅▅▅▄▄▅▃▄▄▄▄▁▄▄▃▃▂▄▂▅▃▄▃▃▃▄▂▂▃▃▃▂▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▆▆▇▁▆▆▇█▆██▇▅█▆▆▆█▇█▇▇▆▇▇▇█▆▆▇▆█▇███▇█▆▇</td></tr><tr><td>val_auc</td><td>▆▆▇▁█▇▇█▆██▇▇█▇▇▇█▇█▇▇▆▇▇▇█▇▆▇▅▇▇██▇▇▇▇▇</td></tr><tr><td>val_f1</td><td>▇▆█▁▆▆▇█▇███▇██▆▆█▇██▇▇█▇▇▇▇▇▇▇█▇█████▇▇</td></tr><tr><td>val_loss_epoch</td><td>▂▃▁█▃▂▂▂▂▁▁▁▃▁▄▃▃▂▂▃▂▂▃▃▂▁▂▄▅▆▃▄▂▃▄▄▂▃▄▄</td></tr><tr><td>val_loss_step</td><td>▄▄▃▅▄▂▄▄▂▃▃▂▂▃▆▃▃▃▄▆▃▄▂▄▂▂▂▄▄█▂▄▂▄▆▅▁▃▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.89959</td></tr><tr><td>train_auc</td><td>0.96124</td></tr><tr><td>train_f1</td><td>0.89845</td></tr><tr><td>train_loss_epoch</td><td>0.24756</td></tr><tr><td>train_loss_step</td><td>0.25729</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.78774</td></tr><tr><td>val_auc</td><td>0.86943</td></tr><tr><td>val_f1</td><td>0.78049</td></tr><tr><td>val_loss_epoch</td><td>0.57616</td></tr><tr><td>val_loss_step</td><td>0.53214</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jkex47p5' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jkex47p5</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_021640-jkex47p5\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a88ad441c3a14ace8a98a5e3079af3ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_025321-8zkkqghl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8zkkqghl' target=\"_blank\">GINConv_4_64_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8zkkqghl' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8zkkqghl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 30.9 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "33.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "33.1 K    Total params\n",
      "0.132     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▅▆▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇██▇█▇▇█████</td></tr><tr><td>train_auc</td><td>▁▄▅▅▆▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇██▇████████</td></tr><tr><td>train_f1</td><td>▁▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇██▇█▇▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▄▅▄▄▄▃▃▃▃▃▃▂▃▂▂▃▂▂▂▁▂▂▂▂▃▂▂▂▂▂▂▂▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▆▆▆▅▆▅▄▄▄▄▅▄▄▄▄▄▁▃▃▃▄▃▃▃▄▃▅▄▃▃▃▃▃▃▃▃▄▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▆▅▅▆▇▆▅▆▇▆▅▆▇▄▅▅▆▆▆▇█▆▅▆▆▅▇▅▅▆▆▇▄▇▆▆▇▆</td></tr><tr><td>val_auc</td><td>▁▄▄▄▇▇▇█▆▇▇▇▇█▇▇█▇▆▇▆█▇▆▇▇▇▆▇▆▇█▇▇▆█▇▇▇▇</td></tr><tr><td>val_f1</td><td>▁▄▆▆▅▆▇▇▆▆▇▆▄▅▇▃▇▄▅▅▇▇█▆▄▇▅▆▇▅▄▅▇▇▆▇▇▅█▅</td></tr><tr><td>val_loss_epoch</td><td>▇▃▂▃▃▁▃▁▂▂▂▁▂▁▄▂▄▂▄▆▃▁▄▅▁▄▃▃▂▇▃▃▃▄█▄▂▃▄▅</td></tr><tr><td>val_loss_step</td><td>▆▄▄▄▅▃▆▄▃▄▄▃▄▄▆▃▄▄▆▇▄▄▆▆▂▄▄▄▄█▅▆▃▃█▇▁▃▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.89309</td></tr><tr><td>train_auc</td><td>0.95544</td></tr><tr><td>train_f1</td><td>0.89397</td></tr><tr><td>train_loss_epoch</td><td>0.25537</td></tr><tr><td>train_loss_step</td><td>0.2942</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80425</td></tr><tr><td>val_auc</td><td>0.88352</td></tr><tr><td>val_f1</td><td>0.79903</td></tr><tr><td>val_loss_epoch</td><td>0.50492</td></tr><tr><td>val_loss_step</td><td>0.3926</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8zkkqghl' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8zkkqghl</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_025321-8zkkqghl\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26afadfd102942ff8765b5c32897c845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_032935-m9b5ab4z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/m9b5ab4z' target=\"_blank\">GINConv_4_64_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/m9b5ab4z' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/m9b5ab4z</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 30.9 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "33.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "33.1 K    Total params\n",
      "0.132     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ebff241c899493dbd3b74251f6b669f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇████▇███</td></tr><tr><td>train_auc</td><td>▅▆██▇▇▆▅▆▅▆▄▃▃▃▂▃▃▄▃▄▄▃▃▂▁▁▂▃▃▃▄▄▄▄▃▃▃▃▃</td></tr><tr><td>train_f1</td><td>▁▃▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇████▇███</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▂▂▂▂▂▂▂▂▂▁▂▁▁▂▂▂▁▂▁▁▁▁▂▂▂▁▂▂▁▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▃▂▄▅▆▆▆▇▆▆▆▅▅▅▆▆▆▆▆▇▇▇▆▆▇▆▆▇▇▆▃▅█▅▆▆▆▅▁▆</td></tr><tr><td>val_auc</td><td>▂▇████▇▄▄▃▄▂▂▂▁▁▁▁▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▂▁▁▂▁▆▁</td></tr><tr><td>val_f1</td><td>▅▅▅▅▇▇▇▇▇▆▇▆▇▅█▆▇▇▇▇█▇▆▇▇▇▆██▆▃▅█▆▇▇▆▅▁▆</td></tr><tr><td>val_loss_epoch</td><td>█▂▂▁▁▁▂▁▁▁▁▁▂▂▁▁▁▁▁▂▁▂▂▂▁▁▂▂▁▂▃▃▁▂▁▂▂▄▅▂</td></tr><tr><td>val_loss_step</td><td>█▃▃▂▄▂▄▃▂▃▃▂▃▃▄▃▂▃▄▄▂▄▃▄▁▂▂▃▂▆▆▅▁▄▃▅▂▄▇▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87832</td></tr><tr><td>train_auc</td><td>0.38449</td></tr><tr><td>train_f1</td><td>0.87782</td></tr><tr><td>train_loss_epoch</td><td>0.2917</td></tr><tr><td>train_loss_step</td><td>0.32598</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.78774</td></tr><tr><td>val_auc</td><td>0.12767</td></tr><tr><td>val_f1</td><td>0.75</td></tr><tr><td>val_loss_epoch</td><td>0.57062</td></tr><tr><td>val_loss_step</td><td>0.59206</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/m9b5ab4z' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/m9b5ab4z</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_032935-m9b5ab4z\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae880c69321d4a9894f0571462468a71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_040555-dw2rrirh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/dw2rrirh' target=\"_blank\">GINConv_4_64_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/dw2rrirh' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/dw2rrirh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 30.9 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "33.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "33.1 K    Total params\n",
      "0.132     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▄▄▄▅▅▆▆▆▅▆▆▆▆▆▆▆▆▆▇▆▆▇▆▇▆▆▇▇▆▇▇▇▇▇▇▇█</td></tr><tr><td>train_auc</td><td>▁▃▅▅▅▅▅▆▆▆▆▆▆▇▆▆▇▇▇▆▇▇▆▆▇▇▇▆▇█▇▇▇███████</td></tr><tr><td>train_f1</td><td>▁▄▄▅▄▄▅▅▆▅▆▆▆▆▆▆▆▆▆▆▆▇▅▆▇▆▇▆▆▇▇▆▇▇▇▇▇▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▅▅▅▄▄▄▃▄▄▃▃▃▃▃▃▃▃▃▄▄▂▃▂▄▃▂▃▃▂▂▂▂▁▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▇▆▆▅▅▆▄▄▅▅▅▇▅▆▅▅▁▄▄▄▄█▃▅▄▃▅▂▃▅▂▂▂▂▄▂▃▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▁▆▇▇▇▇██▅▇▅▅▇▆▇▆▆▇▅▆█▅▆▆▄▆▃▇█▇▇▅▇▇▆▇▆▇</td></tr><tr><td>val_auc</td><td>▁▃▄▅▅▇▆▅█▆▃▇▃▅▅▃▅▅▅▆▃▅█▅▆▅▅█▁▆▅▅▅▁▅▆▆▅▄▄</td></tr><tr><td>val_f1</td><td>▆▅▁▆█▇▇▇▇█▆▇▆▆▇▇█▇▆▇▅▆█▅▇▆▇▇▄██▇▇▆█▇▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>▆▅█▂▁▂▃▂▁▂▃▁▂▆▂▂▁▄▄▃▃▂▂▃▂▃▇▂▆▅▃▃▃▅▅▅▇▆▇▅</td></tr><tr><td>val_loss_step</td><td>▅▃▆▃▁▄▅▃▂▃▅▁▃▇▄▃▂▆▄▃▂▃▅▃▃▂▄▄▄▅▅▂▃▄▃▅▄█▅▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.91317</td></tr><tr><td>train_auc</td><td>0.96852</td></tr><tr><td>train_f1</td><td>0.91307</td></tr><tr><td>train_loss_epoch</td><td>0.22949</td></tr><tr><td>train_loss_step</td><td>0.28286</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80425</td></tr><tr><td>val_auc</td><td>0.87751</td></tr><tr><td>val_f1</td><td>0.80285</td></tr><tr><td>val_loss_epoch</td><td>0.51566</td></tr><tr><td>val_loss_step</td><td>0.43354</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/dw2rrirh' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/dw2rrirh</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_040555-dw2rrirh\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb56187d31f54926839bf31c2481e12a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_044136-o3dgfvld</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/o3dgfvld' target=\"_blank\">GINConv_4_64_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/o3dgfvld' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/o3dgfvld</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 30.9 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "37.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "37.3 K    Total params\n",
      "0.149     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▅▄▅▅▅▆▆▅▆▆▆▆▆▆▆▆▇▆▆▆▇▇▇▇▇▇▆▇▇▇█▇▇▆▇▇█</td></tr><tr><td>train_auc</td><td>▁▄▅▅▅▆▅▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇██▇██▇▇███</td></tr><tr><td>train_f1</td><td>▁▃▄▅▄▅▅▅▅▆▅▅▆▆▆▆▅▆▆▇▆▆▆▇▇▇▇▇▇▆▇▇▇█▇▇▆▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▅▄▅▄▄▄▄▄▄▄▃▃▄▃▃▃▃▃▃▂▂▃▂▃▂▃▂▂▃▂▂▂▃▂▂▁</td></tr><tr><td>train_loss_step</td><td>▆▅▆▃▃▆▇▃▃▃▄▃▄▄▅▅▃▄▂▂▃▃▅▂▄▃▃█▃▂▃▃▃▂▂▃▂▂▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▅▅▇▁▇▇▇█▆▇▆▇▇▇▆▆▇▇▄▇▇▄▆▇▆▆▇▆▆▇▇▆█▅█▃█▆▆▆</td></tr><tr><td>val_auc</td><td>▅▆█▁▇█▇▇▇▇█▇▇▇▇▆▆▇▆▇▇▄▆█▇▇▇█▅▇▆▆█▄▇▅▇▅▆▆</td></tr><tr><td>val_f1</td><td>▇▅▇▁▇█▇█▇▇▇▇▇▇▆▆▇▇▄▇▇▅▆█▇▆▇▅▇▇▇▆█▆█▂▇▆▇▇</td></tr><tr><td>val_loss_epoch</td><td>▃▄▁▆▂▁▂▁▂▂▁▂▂▂▂▃▂▄▃▃▃▃▃▂▄▄▂▃▆▄▅▅▃▄▃█▄▄▄█</td></tr><tr><td>val_loss_step</td><td>▃▃▃▅▅▂▆▂▃▅▃▃▃▄▃▆▃█▄▄▅▄▅▃▇▇▃▄▄▆▆▅▁▄▂▆▅▆▆▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.91081</td></tr><tr><td>train_auc</td><td>0.96726</td></tr><tr><td>train_f1</td><td>0.90898</td></tr><tr><td>train_loss_epoch</td><td>0.22578</td></tr><tr><td>train_loss_step</td><td>0.16405</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.77123</td></tr><tr><td>val_auc</td><td>0.865</td></tr><tr><td>val_f1</td><td>0.78867</td></tr><tr><td>val_loss_epoch</td><td>0.75195</td></tr><tr><td>val_loss_step</td><td>0.74444</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/o3dgfvld' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/o3dgfvld</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_044136-o3dgfvld\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3a62646f7ca4d2397dff454c254e042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_051542-81rst59j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/81rst59j' target=\"_blank\">GINConv_2_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/81rst59j' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/81rst59j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▆▆▇▇▇▇██▇▇█████▇▇██████████████████▇</td></tr><tr><td>train_auc</td><td>▁▆▆▆▆▇▇▇▇▇█▇▇███████████████████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇███▇▇██████▇███████▇███▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▃▃▄▃▃▂▂▃▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁▂▁▁▁▁▂▁▁▁▁▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▅▄▅▅▄▄▆▄▅▅▃▆▃▄▄▄▄▃▃▅▅▂▄▃▃▂▄▂▄▅▃▅▂▃▂▃▄▁▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▅▅▅▆▅▇▆▆▆▆▆▇▇▇▆▇▆▇▇▆▆▆▇▇█▇▆▇▇▆▆▆▇▆▇▇▆▇</td></tr><tr><td>val_auc</td><td>▁▄▄▅▅▆▆▇▇▇▆▇▇▇▇▇▇█▇▇▇▇▇▇▇▇█▇▇▇▇▇▇██▇██▇█</td></tr><tr><td>val_f1</td><td>▁▄▅▆▆▇▅▇▆▇▇▅▇▇▇▆▆█▆▇▇▇▆▆█▆██▆▇▇▇▆▆▇▆▇▇▆▇</td></tr><tr><td>val_loss_epoch</td><td>█▄▄▄▃▂▃▃▂▂▅▃▂▂▂▂▂▁▂▃▂▂▃▁▂▂▁▃▂▂▂▁▁▂▁▃▂▂▂▁</td></tr><tr><td>val_loss_step</td><td>█▅▆▇▅▄▅▇▅▃█▆▅▅▄▃▅▂▃▆▇▄▆▁▄▆▄▆▃▄▆▃▃▄▃▅▅▇▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8294</td></tr><tr><td>train_auc</td><td>0.90095</td></tr><tr><td>train_f1</td><td>0.834</td></tr><tr><td>train_loss_epoch</td><td>0.40611</td></tr><tr><td>train_loss_step</td><td>0.41869</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82979</td></tr><tr><td>val_auc</td><td>0.90831</td></tr><tr><td>val_f1</td><td>0.82</td></tr><tr><td>val_loss_epoch</td><td>0.36643</td></tr><tr><td>val_loss_step</td><td>0.27441</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/81rst59j' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/81rst59j</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_051542-81rst59j\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6fa2ebb27e2438cbcd1c4ff13dd8b41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_054835-2dtqkzay</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/2dtqkzay' target=\"_blank\">GINConv_2_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/2dtqkzay' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/2dtqkzay</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▇▆▇▇▇▇▇▇█▇█▇█▇▇▇▇▇█▇█████████▇▇██████</td></tr><tr><td>train_auc</td><td>▁▅▆▇▇▇▇▇▇▇▇▇▇▇▇██▇██████████████████████</td></tr><tr><td>train_f1</td><td>▁▄▇▇▇▇▇▇▇▇▇█▇█▇█▇█▇█▇███████████▇███████</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▃▃▃▃▃▂▂▂▂▂▂▂▁▂▂▂▂▂▂▁▂▁▂▂▁▂▂▁▂▂▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▃▄▄▃▃▄▃▄▄▂▄▂▃▃▃▄▂▂▃▃▁▃▂▃▂▃▁▃▃▂▅▂▃▂▁▂▁▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▅▅▅▅▆▆▆▆▆▇▅▇▇▆▇▇▇▇▇▇▇▇▇█▇▇▆▇▇█▇███▇▇▆▇</td></tr><tr><td>val_auc</td><td>▁▄▅▅▅▆▆▆▇▇▇▇▆█▇▇▇▇█▇▇███▇██▇▇█▇▇██▇██▇▇▇</td></tr><tr><td>val_f1</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇██▆▇▇▇▇▇▇▇▇▇█▇██▇████▇█▇█</td></tr><tr><td>val_loss_epoch</td><td>█▅▄▃▃▃▃▄▃▂▂▂▃▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▁▂▂▂▃▂▂</td></tr><tr><td>val_loss_step</td><td>█▆▆▅▅▄▅▇▆▃▆▄▅▄▄▃▃▃▃▃▅▅▅▁▄▆▃▄▄▅▃▃▃▂▄▅▅▅▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.81051</td></tr><tr><td>train_auc</td><td>0.88997</td></tr><tr><td>train_f1</td><td>0.81834</td></tr><tr><td>train_loss_epoch</td><td>0.4217</td></tr><tr><td>train_loss_step</td><td>0.46642</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80851</td></tr><tr><td>val_auc</td><td>0.88997</td></tr><tr><td>val_f1</td><td>0.8</td></tr><tr><td>val_loss_epoch</td><td>0.43026</td></tr><tr><td>val_loss_step</td><td>0.48715</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/2dtqkzay' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/2dtqkzay</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_054835-2dtqkzay\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d74faee0a474096beb8edc188300209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_062127-exkx1fcl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/exkx1fcl' target=\"_blank\">GINConv_2_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/exkx1fcl' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/exkx1fcl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇███▇█▇████▇████████</td></tr><tr><td>train_auc</td><td>▆█▇▆▄▃▂▂▂▃▂▂▃▄▃▁▂▃▂▂▃▃▃▃▃▃▃▃▃▄▃▄▂▂▃▄▃▂▃▃</td></tr><tr><td>train_f1</td><td>▁▄▅▅▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇█████▇████▇████████</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▂▂▂▂▂▁▂▁▁▂▁▁▁▁▁▁▁▁▁▂▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▂▃▅▆▅▅▆▆▆▆▆▆▅▆▅▅▅▆▅▆▇▆▇▇▇▇▆▇▇▇█▇██▆▇▇▇█</td></tr><tr><td>val_auc</td><td>████▆▂▂▂▂▂▂▂▂▂▂▁▂█▁▂▁▄▃▆▄▂▇▂█▂▁▃▁▁▃▁▁▁▁▁</td></tr><tr><td>val_f1</td><td>▁▂▅▅▆▅▆▆▆▆▆▆▆▆▆▆▄▅▆▅▇▇▆▇▇▇██▇▇█▇██▇▆▇▇▆▇</td></tr><tr><td>val_loss_epoch</td><td>█▅▆▅▄▄▅▅▅▃▅▄▃▄▃▃▄▃▂▃▃▃▄▁▃▃▃▅▂▂▄▂▂▂▂▃▂▃▃▁</td></tr><tr><td>val_loss_step</td><td>█▄▆▅▄▄▆▇▆▃▇▅▄▆▄▃▄▂▂▃▅▅▆▁▄▄▃▅▄▃▅▃▃▃▃▅▃▆▄▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.81523</td></tr><tr><td>train_auc</td><td>0.47905</td></tr><tr><td>train_f1</td><td>0.82485</td></tr><tr><td>train_loss_epoch</td><td>0.41762</td></tr><tr><td>train_loss_step</td><td>0.4189</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.8227</td></tr><tr><td>val_auc</td><td>0.12662</td></tr><tr><td>val_f1</td><td>0.80315</td></tr><tr><td>val_loss_epoch</td><td>0.38051</td></tr><tr><td>val_loss_step</td><td>0.29166</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/exkx1fcl' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/exkx1fcl</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_062127-exkx1fcl\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed2ed823ee6b4033a4be9c5f3d778378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.017183333332650364, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_065440-w9sfsjy6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/w9sfsjy6' target=\"_blank\">GINConv_2_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/w9sfsjy6' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/w9sfsjy6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.1 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▆▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇████▇█▇█▇██▇▇▇██▇</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇████▇██████▇█████</td></tr><tr><td>train_f1</td><td>▁▆▆▆▆▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇█▇████▇█▇█▇████▇███</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▄▄▃▃▃▂▂▂▂▃▂▂▂▂▂▂▁▂▂▁▁▂▁▁▂▁▁▁▂▁▁▂▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▆▅▅▄▄▅▂▅▇▃█▄▅▄▄▂▃▃▅▆▃▄▆▁▃▄▃▃▂▃▃▂▃▅▃▃▃▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▃▅▅▅▃▆▅▆▇▆▆▅▆▆▆▆▇▆█▆▆▇▇▅▅▆▇▇▇▅▇▅▆▆▆▇▅▅</td></tr><tr><td>val_auc</td><td>▁▄▄▅▆▅▆▇▅▆▆▇█▇▇▇▇▇█▇▇▇▇▇█▇█▇█▇▇▇█▇▇▇▇█▇▇</td></tr><tr><td>val_f1</td><td>▁▄▄▅▅▆▃▆▅▆█▆▇▆▆▆▆▇▇▇█▆▆▇▇▄▅▆▇▇▇▅▇▅▆▆▇▇▅▅</td></tr><tr><td>val_loss_epoch</td><td>█▄▄▃▃▃▄▃▄▃▂▂▃▂▂▂▂▂▁▂▂▂▂▁▂▃▄▂▂▃▃▂▂▂▂▃▃▃▄▃</td></tr><tr><td>val_loss_step</td><td>█▅▃▃▄▄▅▆▆▇▂▄▆▄▄▄▃▄▃▃▂▂▅▁▅▂█▃▄▇▅▂▄▄▃▆▆▅█▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83353</td></tr><tr><td>train_auc</td><td>0.91113</td></tr><tr><td>train_f1</td><td>0.84211</td></tr><tr><td>train_loss_epoch</td><td>0.37599</td></tr><tr><td>train_loss_step</td><td>0.40248</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.79905</td></tr><tr><td>val_auc</td><td>0.89518</td></tr><tr><td>val_f1</td><td>0.76584</td></tr><tr><td>val_loss_epoch</td><td>0.42185</td></tr><tr><td>val_loss_step</td><td>0.4486</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/w9sfsjy6' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/w9sfsjy6</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_065440-w9sfsjy6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4517812debd34d14a90e3608ef06439b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_073013-36znp1q8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/36znp1q8' target=\"_blank\">GINConv_2_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/36znp1q8' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/36znp1q8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.1 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "1.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇██▇███▇█▇██▇██████▇█████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████▇█▇███████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇█████▇█▇▇█▇██▇███▇▇███▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▃▂▂▂▂▂▁▁▂▁▁▂▁▂▁▁▂▂</td></tr><tr><td>train_loss_step</td><td>▆▅▄▂▃▃▃▄▃▅▃▃▂▂▄▃▄▂▂▃▂▄█▂▃▂▂▅▁▃▃▃▄▂▂▂▃▃▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▅▃▃▇▆▅▇▆▅▇▇▆▆▆▆▇█▇▇█▆▇▇▇▇▇▆▇▆▆▇██▇▇▇▇▆</td></tr><tr><td>val_auc</td><td>▁▄▅▅▅▆▇▇▇▇▆▇▇▇█▇█▇█▇█▇▇██▇▇▇▇▇▇▇▇▇▆▇█▇▇▇</td></tr><tr><td>val_f1</td><td>▁▃▅▄▄▇▆▆▇▆▆▇▇▇▆▆▆▇█▇▇▇▆▆█▆█▇▆▇▇▆▇██▆▇█▇▆</td></tr><tr><td>val_loss_epoch</td><td>█▃▅▃▄▃▃▂▂▂▃▃▃▃▂▂▄▃▂▃▂▁▁▂▂▃▃▂▃▂▃▃▃▂▃▃▄▄▂▂</td></tr><tr><td>val_loss_step</td><td>▇▂█▃▆▄▅▃▄▅▅▄▇▄▃▅█▅▅▅▂▂▁▄▄▅▄▃▅▄▃▄▄▃▃▆▆▇▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83058</td></tr><tr><td>train_auc</td><td>0.90063</td></tr><tr><td>train_f1</td><td>0.83758</td></tr><tr><td>train_loss_epoch</td><td>0.40071</td></tr><tr><td>train_loss_step</td><td>0.3746</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80615</td></tr><tr><td>val_auc</td><td>0.89083</td></tr><tr><td>val_f1</td><td>0.77838</td></tr><tr><td>val_loss_epoch</td><td>0.40795</td></tr><tr><td>val_loss_step</td><td>0.36807</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/36znp1q8' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/36znp1q8</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_073013-36znp1q8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f63e275969425b9a021a9fe28b742e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_080352-ozopsp3o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ozopsp3o' target=\"_blank\">GINConv_2_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ozopsp3o' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ozopsp3o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 3.8 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a68bd94712544f288c948f0dca1597c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█████▇████</td></tr><tr><td>train_auc</td><td>▁▅▅▅▅▅▄▆▆▆▆▆▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████▇████</td></tr><tr><td>train_f1</td><td>▁▄▅▆▅▆▆▆▆▆▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇█▇▇██████████</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▂▃▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▆▆▄▅▅▄▆▃▃▃▃▆▄▃▃▂▂▃▃▂▄▂▄▅▂▃▄▄▃▄▂▃▅▂▂▄▂▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▂▁▁▄▂▄▅▅▆▆▆▅▇▅▅▆▄▇█▆▅▆▄▃▂▆█▇▇▅▄▂▇▄▆▄▅▆▆▄</td></tr><tr><td>val_auc</td><td>▁▃▅▅▆▇▆▇▆▇▇▇█▇▆▇▇▇█▇█▇▅▆▆▆▇▇█▅▅▆▇▅▆▅▆▇▇▆</td></tr><tr><td>val_f1</td><td>▄▂▃▆▃▄▆▆▇▇▇▅▇▆▅▆▃▇█▆▆▆▅▃▂▆█▇▇▅▃▁▇▄▇▄▅▆▆▆</td></tr><tr><td>val_loss_epoch</td><td>▇▅▅▅▃▃▃▄▂▂▂▃▃▃▄▂▃▁▂▄▄▃▅▅▃▄▄▅▂▇▄▆▆▅▅▄▄▄▅█</td></tr><tr><td>val_loss_step</td><td>▄▄▅▅▃▅▃▅▂▃▃▅▂▃▄▃▃▁▁▆▅▃▄▅▂▅▃▄▃█▃▅▇▄▃▂▅▃▅▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87013</td></tr><tr><td>train_auc</td><td>0.94214</td></tr><tr><td>train_f1</td><td>0.87254</td></tr><tr><td>train_loss_epoch</td><td>0.29294</td></tr><tr><td>train_loss_step</td><td>0.22701</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80378</td></tr><tr><td>val_auc</td><td>0.89509</td></tr><tr><td>val_f1</td><td>0.80471</td></tr><tr><td>val_loss_epoch</td><td>0.5101</td></tr><tr><td>val_loss_step</td><td>0.2928</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ozopsp3o' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ozopsp3o</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_080352-ozopsp3o\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a754b479d6db4f0cb9800db5cd0264bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_083757-cu07ijm4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/cu07ijm4' target=\"_blank\">GINConv_2_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/cu07ijm4' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/cu07ijm4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 3.8 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▆▆▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇█▇██▇█████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▃▃▃▃▃▃▃▃▂▂▂▃▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▂▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▅▄▄▅▄▅▃▁▂▃▆▃▂▂▁▁▂▃▁▄▂▃▄▂▁▄▃▂▂▂▁▅▂▁▁▁▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▆▅▆▆▆▄▅▆▇▆▆▆▆▇▇█▇▇▇▇█▆▇▇▆▆▇█▇▆▇▆▇▆▇▇▇▇</td></tr><tr><td>val_auc</td><td>▁▅▆▇▇▇▇▆▇▇▇▇▇▇▇▇█▇▇▇▇█▇▇▇█▇█▇██▇█▇██████</td></tr><tr><td>val_f1</td><td>▁▄▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇█▇█▇▇▇▇██▇▇▇▇▇████</td></tr><tr><td>val_loss_epoch</td><td>█▅▃▃▂▂▂▅▂▂▂▂▁▂▃▂▂▂▂▅▂▁▁▂▁▂▂▂▂▂▂▂▃▃▂▃▂▂▂▁</td></tr><tr><td>val_loss_step</td><td>▆▅▅▄▃▃▂▅▁▃▅▄▁▃▄▃▄▂▃█▃▂▃▄▁▄▂▅▅▅▃▄▆▅▄▂▃▄▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85832</td></tr><tr><td>train_auc</td><td>0.93065</td></tr><tr><td>train_f1</td><td>0.86095</td></tr><tr><td>train_loss_epoch</td><td>0.33088</td></tr><tr><td>train_loss_step</td><td>0.36229</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.8156</td></tr><tr><td>val_auc</td><td>0.9038</td></tr><tr><td>val_f1</td><td>0.80303</td></tr><tr><td>val_loss_epoch</td><td>0.38189</td></tr><tr><td>val_loss_step</td><td>0.23393</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/cu07ijm4' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/cu07ijm4</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_083757-cu07ijm4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4b8d2782a6c496a906b9321600d1f5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_091449-986uopg3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/986uopg3' target=\"_blank\">GINConv_2_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/986uopg3' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/986uopg3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 3.8 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51d8c89a17ac45e38424c4387fc9c17c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▆▆▆▆▆▆▆▆▆▆▆▇▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇</td></tr><tr><td>train_auc</td><td>▅▂▁▃▄▄▄▃▄▄▅▄▂▂▃▃▅▆▆▆▆▄▃▁▁▅█▇▆▇█▇▆▅▄▃▃▃▃▄</td></tr><tr><td>train_f1</td><td>▁▃▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▃▂▂▃▂▃▂▂▂▂▃▂▂▂▂▁▁▂▂▂▂▂▂▂▂▃▁▂▂▂▂▂▂▁▂▁▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▆▇▇▆▇▇▆▆▇▇▇▇▇▇▆▇▇▇▇▇▇█▇▇▇█▇█▇▇▇▇▇█▆█▇▇</td></tr><tr><td>val_auc</td><td>▅▂▂▂▅▆▃▂▂▆▆▂▁▂▁▇▇████▃▁▁▁████████▇▂▅▁▂▂▁</td></tr><tr><td>val_f1</td><td>▁▂▅▅▅▄▆▆▆▅▅▆▆▅▇▆▅▅▇▄▇▅█▇█▆▇▇▆█▇▅▇▆▆█▆█▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▃▂▂▁▂▂▂▁▂▂▁▂▂▁▁▁▂▃▂▂▁▁▂▂▂▂▄▂▂▂▂▂▁▂▂▃▁</td></tr><tr><td>val_loss_step</td><td>▅▄▄▅▃▃▂▄▃▃▃▄▃▃▄▄▃▂▂▄▄▄▄▄▂▄▄▄▃█▂▄▆▅▄▃▄▄▅▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84475</td></tr><tr><td>train_auc</td><td>0.49302</td></tr><tr><td>train_f1</td><td>0.85048</td></tr><tr><td>train_loss_epoch</td><td>0.35752</td></tr><tr><td>train_loss_step</td><td>0.39474</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81324</td></tr><tr><td>val_auc</td><td>0.09839</td></tr><tr><td>val_f1</td><td>0.802</td></tr><tr><td>val_loss_epoch</td><td>0.37871</td></tr><tr><td>val_loss_step</td><td>0.19611</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/986uopg3' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/986uopg3</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_091449-986uopg3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b134452e329242ca909827f34885c770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333332417533, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_095107-1f16u9mz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1f16u9mz' target=\"_blank\">GINConv_2_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1f16u9mz' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1f16u9mz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 3.8 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.018     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▅▆▆▆▆▆▇▆▇▆▇▇▇▇▇▇▇▇█▇▆▆▇███▇▇█▇▇███▇▇█</td></tr><tr><td>train_auc</td><td>▁▅▅▅▅▆▅▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇███▇██████</td></tr><tr><td>train_f1</td><td>▁▅▅▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇█▇█▇▆▇▇███▇▇█▇▇███▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▄▄▃▄▃▃▃▃▃▃▃▂▃▃▂▂▂▂▂▃▂▂▂▁▃▁▁▂▂▁▁▂▁▁▂</td></tr><tr><td>train_loss_step</td><td>▅▅▆▄▄▆▄▄▄▄▄▃▁▂▂▄▃█▅▃▃▅▄▃▄▃▁▂▃▂▄▃▄▄▂▁▄▄▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▃▆▅▅▇▆▇▆▇▆▆▇▇▇▇█▇█▇▆▆▅▇▇█▇▇▇█▇▇▇▇▆▇▆▇▇</td></tr><tr><td>val_auc</td><td>▁▂▁▅▅▆▆▆▆▇█▇▆████▆▇▇▇▇▆▆▇▆▇▇▇▆█▆▆▇▇▆▇▆▇▇</td></tr><tr><td>val_f1</td><td>▄▃▁▆▅▃▇▅▆▅▇▆▆▇▇▆▆▇▇█▇▅▅▅▇▇▇▇▇▇█▆▆▆▇▆▇▅▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▄▆▃▂▃▂▂▁▁▂▁▂▂▂▁▂▃▂▂▁▃▃▂▃▄▂▂▄▂▃▃▃▃▃▄▂▃▂▄</td></tr><tr><td>val_loss_step</td><td>▇▇▇▃▃▆▃▄▂▁▂▂▅▄▅▃▅▆▂▃▁▄▅▁▇█▄▄▃▃▅▃▄▆▄▃▁▄▂█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86246</td></tr><tr><td>train_auc</td><td>0.92527</td></tr><tr><td>train_f1</td><td>0.86493</td></tr><tr><td>train_loss_epoch</td><td>0.33697</td></tr><tr><td>train_loss_step</td><td>0.24903</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82033</td></tr><tr><td>val_auc</td><td>0.90342</td></tr><tr><td>val_f1</td><td>0.80808</td></tr><tr><td>val_loss_epoch</td><td>0.44633</td></tr><tr><td>val_loss_step</td><td>0.59752</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1f16u9mz' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1f16u9mz</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_095107-1f16u9mz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73dde2d21ba94686af320951087e430d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_102725-gs18beop</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gs18beop' target=\"_blank\">GINConv_2_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gs18beop' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gs18beop</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 3.8 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "5.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.4 K     Total params\n",
      "0.022     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▅▆▆▆▆▆▇▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇██▇███▇██▇▇█</td></tr><tr><td>train_auc</td><td>▁▅▅▅▅▅▆▆▆▅▇▆▆▆▆▆▆▅▇▆▇▇▆▇▇▆▇▇▇▇▇█▇████▇██</td></tr><tr><td>train_f1</td><td>▁▅▅▆▆▆▆▆▆▆▇▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇██▇▇█▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▃▂▂▂▂▂▂▂▂▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>▆▅▄▄▃▄▄▃▄▃▄▄▁▃▃▃▂▁▂▂▃▁▁▃▃▄▂▇▃▃▂▁▁▂▄▁▃▃▂█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▁▅▆▆▆▆▇▆▇▆▆▆▄▆▆▇▆█▅▇█▅▇▇▅▇▆█▇▇▆▇▆▆▇▆▄▇▆</td></tr><tr><td>val_auc</td><td>▁▂▄▅▅▇▇█▇███▇▇██▇▇▇█▇█▇▇█▆▇▇▇▆▇▇▇▆▇▆▅▆▇▆</td></tr><tr><td>val_f1</td><td>▅▁▆▇▇▇▇█▇▇▆▆▆▄▇▇▇▇█▄▇█▆▇▇▆▇▇▇▇▇▇▆▇▆█▆▄█▆</td></tr><tr><td>val_loss_epoch</td><td>█▇▃▃▃▃▃▃▅▂▂▁▂▄▂▄▂▄▃▂▃▂▃▃▄▂▂▃▄▄▄▅▄▄▄▅▅▆▃▅</td></tr><tr><td>val_loss_step</td><td>▆▅▄▃▄▆▅▄▇▄▃▁▃▇▂▆▂▅▆▂▄▃▂▄█▂▃▂▇▅▆▇▅▃▅▄▇▇▁▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87485</td></tr><tr><td>train_auc</td><td>0.93664</td></tr><tr><td>train_f1</td><td>0.879</td></tr><tr><td>train_loss_epoch</td><td>0.32518</td></tr><tr><td>train_loss_step</td><td>0.67586</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80851</td></tr><tr><td>val_auc</td><td>0.89176</td></tr><tr><td>val_f1</td><td>0.77929</td></tr><tr><td>val_loss_epoch</td><td>0.44898</td></tr><tr><td>val_loss_step</td><td>0.40333</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gs18beop' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gs18beop</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_102725-gs18beop\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65fa69fa9b4b4dfe98280da542e6317b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_110332-7im5izdm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7im5izdm' target=\"_blank\">GINConv_2_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7im5izdm' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7im5izdm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 13.8 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.9 K    Total params\n",
      "0.064     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▄▅▅▅▆▆▆▆▆▆▆▇▆▆▇▆▅▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇███▇█</td></tr><tr><td>train_auc</td><td>▁▄▄▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▆▇▇▇▇▇▇█▇▇▇▇█▇▇████▇█</td></tr><tr><td>train_f1</td><td>▁▄▄▄▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇▅▆▇▇▇▆▇▇▇▇▆▇▇▇▇▇███▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▅▅▄▄▄▄▄▃▄▃▄▃▃▃▃▃▅▃▃▃▃▃▂▂▂▃▂▃▂▂▂▂▂▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>▆▆▆▅▅▆▅▅▄▅▅▃▃▄▃▄▃█▄▃▃▂▄▃▂▃▄▁▃▄▄▂▃▂▃▃▂▂▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▄▃▅▆▆▇▇█▇▆▇▇▇▇▇▆█▇▆▆▇▇▇▇▆▇▇█▇▆▁▇▇▆▆▇▇▇▇▇</td></tr><tr><td>val_auc</td><td>▄▅▆▇▇█▇█▇▆▇████▅▇▇▆▇████▇▇▆▇▆▇▁▇▆▅▄▇▇▆▇▇</td></tr><tr><td>val_f1</td><td>▄▁▅▆▆▇▇█▇▆▇▇▆▇▇▇█▇▅▆█▇▇▇▆█▇█▆▆▄▇█▅▅▇▆▇▇█</td></tr><tr><td>val_loss_epoch</td><td>▂▄▂▂▂▂▁▁▂▂▂▁▁▁▃▃▂▃▃▂▂▃▂▁▃▂▂▃▂▂█▂▂▄▄▃▂▄▂▅</td></tr><tr><td>val_loss_step</td><td>▂▃▃▂▅▂▃▂▄▃▂▂▁▃▃▃▁▅▂▃▃█▂▂▄▁▁▂▁▃█▄▂▄▅▅▂▅▃▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.88489</td></tr><tr><td>train_auc</td><td>0.95829</td></tr><tr><td>train_f1</td><td>0.88709</td></tr><tr><td>train_loss_epoch</td><td>0.26764</td></tr><tr><td>train_loss_step</td><td>0.32217</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.8227</td></tr><tr><td>val_auc</td><td>0.89126</td></tr><tr><td>val_f1</td><td>0.81928</td></tr><tr><td>val_loss_epoch</td><td>0.58317</td></tr><tr><td>val_loss_step</td><td>0.86121</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7im5izdm' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7im5izdm</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_110332-7im5izdm\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba66fb1be9944bea89e0e7d42eec3528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_114051-tyofiqyz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tyofiqyz' target=\"_blank\">GINConv_2_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tyofiqyz' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tyofiqyz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 13.8 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.9 K    Total params\n",
      "0.064     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5725b76d66b04b218e57f10d158a53a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███████▇█</td></tr><tr><td>train_auc</td><td>▁▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██▇██▇███████████████</td></tr><tr><td>train_f1</td><td>▁▅▅▅▆▆▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇██████████</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▄▄▃▃▄▃▄▃▃▃▃▃▃▂▂▂▃▂▂▂▂▂▂▂▂▂▁▂▂▁▂▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▆▇▅▆▇▅▅▄▅▄▅▃▄▄▅▃▅▄▃▃▃█▃▃▂▃▁▃▃▃▃▃▂▃▄▂▃▃▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▅▅▅▆▅▇▆▇▇▇▇▇▇▇▇▄█▇▇▇▆▆▇▇█▇▇▇▆█▆▇▆█▅▇██</td></tr><tr><td>val_auc</td><td>▁▅▆▆▇▇▇▇▇▇██▇█▇▇▇▇█▇▇██▇▇█████▇█▇█▇█▇▇██</td></tr><tr><td>val_f1</td><td>▁▃▅▅▅▆▆▇▆▇█▇▇▇██▇▂█▇▇▇▇▇▇█▇▇▇▇▅▇▇▇▅█▇▆▇█</td></tr><tr><td>val_loss_epoch</td><td>▆▃▃▃▃▃▄▁▄▂▁▁▃▂▂▃▃█▁▅▂▅▂▄▅▂▂▂▃▂▇▅▃▃▆▄▅█▃▅</td></tr><tr><td>val_loss_step</td><td>▄▃▄▄▅▄▄▃▆▃▁▃▃▃▃▄▃█▂▆▂█▃▃▆▁▂▃▂▃▆▄▂▂▄▅▄▅▄▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8961</td></tr><tr><td>train_auc</td><td>0.96182</td></tr><tr><td>train_f1</td><td>0.89885</td></tr><tr><td>train_loss_epoch</td><td>0.25334</td></tr><tr><td>train_loss_step</td><td>0.31508</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83452</td></tr><tr><td>val_auc</td><td>0.90441</td></tr><tr><td>val_f1</td><td>0.81183</td></tr><tr><td>val_loss_epoch</td><td>0.49668</td></tr><tr><td>val_loss_step</td><td>0.69553</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tyofiqyz' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tyofiqyz</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_114051-tyofiqyz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e266ee246e4580be83adbb687964b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_121520-jwz4ad9b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jwz4ad9b' target=\"_blank\">GINConv_2_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jwz4ad9b' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jwz4ad9b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 13.8 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.9 K    Total params\n",
      "0.064     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dfadaa9889e46e6b2abb5432cf17b96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▆▆▆▆▆▆▆▆▆▆▆▇▆▇▇▆▇▇▇▇▇█▇▇▇▇▇█▇▇▇█████</td></tr><tr><td>train_auc</td><td>▃▂▁▂▁▂▂▃▃▃▄▄▆▅▆▆▆▆▄▆▆▇▆▆▆▆▆▇▇▇▇▅▄▅▆▇▆▇██</td></tr><tr><td>train_f1</td><td>▁▃▅▅▆▅▆▆▆▆▆▆▆▇▆▇▆▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▂▂▂▂▂▂▂▂▂▂▁▂▁▂▁▂▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▁▃▄▄▅▅▅▅▅▅▆▄▆▇▁▆▃▅▅▇██▇▅█▇▇▇█▄▇▄▂▅▇▅▅█▅</td></tr><tr><td>val_auc</td><td>▃▃▁▃▃▄▅▆▅▃▆▇▇▇▇▄▇▇▆▇██████████▆████▇▇▇██</td></tr><tr><td>val_f1</td><td>▅▁▄▄▅▅▆▅▆▆▆▆▅▆▇▅▇▂▆▆▆▇▇▇▅█▆▇▇█▄▇▆▁▆█▅▅█▅</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▂▂▂▃▂▂▂▂▂▂▁▂▃▃▅▂▂▂▃▁▂▃▁▁▂▁▂▃▂▂▄▂▃▂▂▂▄</td></tr><tr><td>val_loss_step</td><td>▂▄▄▃▄▃▄▄▄▄▂▃▂▂▃▃▃█▃▃▂▇▂▂▅▂▁▂▁▂▄▃▂▄▄▅▄▃▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86836</td></tr><tr><td>train_auc</td><td>0.90857</td></tr><tr><td>train_f1</td><td>0.87322</td></tr><tr><td>train_loss_epoch</td><td>0.32007</td></tr><tr><td>train_loss_step</td><td>0.28056</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80851</td></tr><tr><td>val_auc</td><td>0.89466</td></tr><tr><td>val_f1</td><td>0.76791</td></tr><tr><td>val_loss_epoch</td><td>0.56257</td></tr><tr><td>val_loss_step</td><td>0.76135</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jwz4ad9b' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jwz4ad9b</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_121520-jwz4ad9b\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "587a52a552714534b634fc6ac3345737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_124942-4vebqzzc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4vebqzzc' target=\"_blank\">GINConv_2_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4vebqzzc' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4vebqzzc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 13.8 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "16.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "16.0 K    Total params\n",
      "0.064     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c559524381242a2a2fc545245b74e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▃▅▄▅▅▆▆▆▆▆▆▆▆▆▅▇▆▇▇█▆▇▇▇█▇▆▇▇█▇▇█▇██▇█</td></tr><tr><td>train_auc</td><td>▁▄▄▅▅▅▅▆▆▆▆▆▆▇▇▆▆▇▇▇▇▇▆▇▇▇█▇▇▇██▇███████</td></tr><tr><td>train_f1</td><td>▁▄▄▅▄▅▅▆▅▆▆▆▆▇▆▆▅▇▆▇▇█▆▇▇▇█▇▆▇▇█▇▇█▇██▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▅▅▅▄▄▄▄▄▄▃▃▃▄▄▃▃▂▃▂▃▃▃▂▂▃▃▂▂▂▃▂▂▂▁▁▂▂</td></tr><tr><td>train_loss_step</td><td>█▅▄▃▅▄▄▄▃▃▄▃▅█▅▄▃▂▂▃▃▄▄▅▂▂▄▁▁▂▂▁▂▂▂▂▁▃▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▃▁▄▄▆▄▇▆▆▆▆▅▆▅▄▆▅▆▇▅▅▅▆▃█▆▄▆▆▆▆▆▆▆▆▆▅▆▇▆</td></tr><tr><td>val_auc</td><td>▁▁▄▆▆▄▆▆▆▇▇▆▇▆▃▅▆▇▇▆▅▆▆▇█▆▅▇▇▇▇▅▆▆▅▆▆▅▆▆</td></tr><tr><td>val_f1</td><td>▅▁▅▅▇▅▇▆▆▆▆▆▇▆▅▇▆▇▇▅▆▇▇▆█▇▄▆▆▇▇▇▆▇▆▆▇▆▇▆</td></tr><tr><td>val_loss_epoch</td><td>▄▄▃▂▂▂▂▂▂▂▁▁▂▃▄▃▁▂▁▃▄▄▃▆▁▃▅▃▂▂▄▂▂▃▆▃█▃▃▃</td></tr><tr><td>val_loss_step</td><td>▄▃▄▃▃▃▃▄▃▃▂▂▃▄▄▄▂▃▂▃▄▃▄▃▃▄▄▅▂▂▄▂▃▃▆▂█▁▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.88548</td></tr><tr><td>train_auc</td><td>0.95296</td></tr><tr><td>train_f1</td><td>0.88863</td></tr><tr><td>train_loss_epoch</td><td>0.27669</td></tr><tr><td>train_loss_step</td><td>0.29671</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.8156</td></tr><tr><td>val_auc</td><td>0.89529</td></tr><tr><td>val_f1</td><td>0.79581</td></tr><tr><td>val_loss_epoch</td><td>0.46825</td></tr><tr><td>val_loss_step</td><td>0.59764</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4vebqzzc' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4vebqzzc</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_124942-4vebqzzc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42042636d1814ec2b6b1c9f4b03064da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_132504-tndc79gs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tndc79gs' target=\"_blank\">GINConv_2_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tndc79gs' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tndc79gs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 13.8 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "20.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.1 K    Total params\n",
      "0.080     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "734b9f2c30aa46c885821c40421d699c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▄▄▅▅▆▅▅▆▆▆▇▆▆▆▆▆▇▇▆▇▇▇▆▇▇▆▇█▇█▇▇█▇▇█▇</td></tr><tr><td>train_auc</td><td>▁▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▆▇▇▇▇██████████</td></tr><tr><td>train_f1</td><td>▁▄▅▅▅▅▆▆▅▆▆▆▆▇▆▆▆▆▆▇▇▆▆▇▇▆▇▇▇▇█▇█▇▇█▇█▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▅▄▅▃▃▄▄▃▃▃▃▃▃▃▃▃▂▂▃▃▂▂▃▂▂▃▂▁▁▁▂▂▁▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▆█▇▅▆▄▅▄▃▂▄▆▂▃▆▆▅▂▂▃▃▄▄▄▂▂▁▆▂▄▂▂▂▂▃▄▃▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▃▁▆▆▅▆█▇▇▆▇▆▇██▆▇▆█▇▆▆▇▇▅▅▁▆▅▄▄▄▆▇▄▆▄▆▇▆</td></tr><tr><td>val_auc</td><td>▁▂▆▆▆▇█▇▇▇▆▇▇██▆▇▆▇▆▇▇▆▆▅▆▅▆▇▄▄▃▅▇▃▄▅▄▆▅</td></tr><tr><td>val_f1</td><td>▄▁▇▇▆▆█▇▇▆▆▅▇█▇▅▇▇█▇▆▆▇▇▃▄▅▆▅▆▅▃▇█▂▅▆▇▆▆</td></tr><tr><td>val_loss_epoch</td><td>▄▃▂▃▂▁▂▁▃▃▂▂▁▁▁▃▂▃▂▃▂▂▃▃▄▄█▃▂▇▄▆▅▄▅▄▄▆▃▄</td></tr><tr><td>val_loss_step</td><td>▅▅▅▇▃▂▄▃▅▆▃▂▂▂▂▇▄▅▃▅▁▂▄▅▆▇▇▄▄█▂▄▁▅▆▆▁▇▂▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87485</td></tr><tr><td>train_auc</td><td>0.94688</td></tr><tr><td>train_f1</td><td>0.87485</td></tr><tr><td>train_loss_epoch</td><td>0.2918</td></tr><tr><td>train_loss_step</td><td>0.27758</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81087</td></tr><tr><td>val_auc</td><td>0.88352</td></tr><tr><td>val_f1</td><td>0.78723</td></tr><tr><td>val_loss_epoch</td><td>0.4956</td></tr><tr><td>val_loss_step</td><td>0.61187</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tndc79gs' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tndc79gs</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_132504-tndc79gs\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "604e3c1dd3144b50ae31f469ad8a8f79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_140049-kcjpm2bz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kcjpm2bz' target=\"_blank\">GINConv_3_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kcjpm2bz' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kcjpm2bz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.7 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "666627aea6f0462eabd92e6cbc9b6798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇██████▇█</td></tr><tr><td>train_auc</td><td>▁▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇██████████████</td></tr><tr><td>train_f1</td><td>▁▆▆▆▆▆▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇████████</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▄▄▃▃▃▃▃▃▃▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▃▁▁▁▂▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▆█▄▄▄▄▅▄▅▄▆▄▄▅▃▃▂▂▃▄▄▃▄▅▃▂▃▃▂▄▃▂▁▃▄▃▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▆▆▅▇▆▇▇▇▇▇▇▆█▇▇███▆█▇█▇▇▇███▇▇█▇▇█▇▇▇█</td></tr><tr><td>val_auc</td><td>▁▄▅▆▅▆▆▇▇▇▇▇▇▆▆▇▇█▇▇▅▇▇█▇▆▇▇█▇▇▇▇▇▇▇▇█▇▇</td></tr><tr><td>val_f1</td><td>▂▄▅▆▂▆▅▅▅▆▆▆▆▁▇▇▅█▆▇▂█▆▇▆▇▅▇▇▆▆▆▇▄▆▇▆▆▅▇</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▂▂▂▂▂▂▁▂▁▂▂▂▂▂▁▂▁▃▁▂▁▁▄▂▂▁▁▂▂▁▂▂▂▂▂▂▂</td></tr><tr><td>val_loss_step</td><td>█▄▅▃▁▃▅▄▄▂▆▂▃▂▃▅▃▃▃▃▅▃▄▁▂▅▅▂▃▂▁▃▂▁▂▁▄▅▆▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85419</td></tr><tr><td>train_auc</td><td>0.91796</td></tr><tr><td>train_f1</td><td>0.85878</td></tr><tr><td>train_loss_epoch</td><td>0.36685</td></tr><tr><td>train_loss_step</td><td>0.38965</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81797</td></tr><tr><td>val_auc</td><td>0.89627</td></tr><tr><td>val_f1</td><td>0.80307</td></tr><tr><td>val_loss_epoch</td><td>0.40515</td></tr><tr><td>val_loss_step</td><td>0.35912</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kcjpm2bz' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kcjpm2bz</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_140049-kcjpm2bz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "343dd84662a34c75be293b86fac80d2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_143603-0x047ox0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0x047ox0' target=\"_blank\">GINConv_3_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0x047ox0' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0x047ox0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.7 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███▇▇▇▇▇███████████████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇████▇▇██▇██████████████</td></tr><tr><td>train_f1</td><td>▁▆▇▇▇▇▇▇▇▇▇▇█▇▇██████▇▇████████▇████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▄▃▃▃▃▃▃▃▃▂▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>▇▆▆▆▄▃▃▄▅▃▃▃█▃▄▃▃▆▂▃▂▃▅▃▃▅▃▄▃▃▃▃▃▃▁▄▃▃▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▆▇▇▆▇▇▇▇▇▇▇▇██▇▇▇▇▇███▇████████████▇██</td></tr><tr><td>val_auc</td><td>▁▇▇▇▇▇█▇▇▇▇▇▇▇██▇██████▇███████▇████████</td></tr><tr><td>val_f1</td><td>▁▃▄▅▅▅▇▆▆▆▅▆▆▇▇█▅▆█▇▇▇▇▇▇▇██▇▇█▇▇▆▇██▇█▇</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▂▂▂▃▂▂▂▃▁▂▁▂▂▂▁▂▂▂▂▂▁▁▂▂▂▁▁▁▂▁▁▂▁▁▃▂▂</td></tr><tr><td>val_loss_step</td><td>█▄▅▄▃▄▅▄▅▄▇▁▃▂▄▄▃▃▄▃▄▃▄▁▄▅▄▄▂▁▂▃▃▂▄▃▂▃▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.81995</td></tr><tr><td>train_auc</td><td>0.90075</td></tr><tr><td>train_f1</td><td>0.82661</td></tr><tr><td>train_loss_epoch</td><td>0.39723</td></tr><tr><td>train_loss_step</td><td>0.29768</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.8156</td></tr><tr><td>val_auc</td><td>0.89036</td></tr><tr><td>val_f1</td><td>0.79897</td></tr><tr><td>val_loss_epoch</td><td>0.42533</td></tr><tr><td>val_loss_step</td><td>0.38191</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0x047ox0' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0x047ox0</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_143603-0x047ox0\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc1eea464f0c49d789a52275976f1398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_151144-lpgfnbie</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/lpgfnbie' target=\"_blank\">GINConv_3_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/lpgfnbie' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/lpgfnbie</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.7 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▄▅▅▆▆▆▆▆▆▇▆▇▆▇▇▇▇▆▇▆▇█▇▇█▇▇▇▇▇▇███▇▇██</td></tr><tr><td>train_auc</td><td>▄▄▃▃▃▂▁▂▃▃▃▃▃▄▅▅▄▅▅▅▆▆▆▅▅▆▆▄▆▅▅▅██▆▇▆▆▅▆</td></tr><tr><td>train_f1</td><td>▁▂▅▅▅▆▆▆▆▆▇▇▇▇▆▇▇▇▇▇▇▆▇█▇▇█▇▇▇▇▇▇███▇▇██</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▂▃▂▁▁▂▂▂▂▁▂▁▂▂▂▂▂▁▁▁▃▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▇▇▇▇▇▇▇▇██▇████▇█▇█▇███████████████████</td></tr><tr><td>val_auc</td><td>▁▆▆▇▆▆▆▇▇██▇██▇█████▇███████████████████</td></tr><tr><td>val_f1</td><td>▁▇▇▆▇▇▇▇▇██▇▇▇██▆▇▆▇▆█▇▇▇▇▇██▇█▇█▇▇████▇</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▂▂▂▂▂▂▂▂▁▁▁▂▂▂▂▂▂▂▂▁▁▁▂▁▁▁▁▁▁▂▁▂▁▁▁▂▁</td></tr><tr><td>val_loss_step</td><td>█▄▄▃▃▃▄▃▄▃▄▂▃▃▄▃▄▄▃▃▄▃▃▂▃▄▃▃▃▁▂▃▃▂▃▂▃▃▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83117</td></tr><tr><td>train_auc</td><td>0.76509</td></tr><tr><td>train_f1</td><td>0.84164</td></tr><tr><td>train_loss_epoch</td><td>0.39328</td></tr><tr><td>train_loss_step</td><td>0.38942</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.8156</td></tr><tr><td>val_auc</td><td>0.88873</td></tr><tr><td>val_f1</td><td>0.79793</td></tr><tr><td>val_loss_epoch</td><td>0.41561</td></tr><tr><td>val_loss_step</td><td>0.36699</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/lpgfnbie' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/lpgfnbie</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_151144-lpgfnbie\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d947b408fd894028a323580d17d7490f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_154728-nvw05d4i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/nvw05d4i' target=\"_blank\">GINConv_3_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/nvw05d4i' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/nvw05d4i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.7 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█▇▇███▇███████</td></tr><tr><td>train_auc</td><td>▁▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇██▇▇▇▇▇██▇▇███████</td></tr><tr><td>train_f1</td><td>▁▆▆▇▇▇▇▇▇▇▇▇█▇▇▇▇██▇█▇███▇██████████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▁▂▂▁▁▁▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>██▅▆▄▅▄▄▄▄▅▅▃▄▅▄▃▂▄▄▄▃▅▄▂▃▃▃▅▃▂▃▃▄▂▂▄▁▂▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▄▅▅▆▆▆▆▇▆▆▇▇▆▆▆▇▆▇▅▅▇▇▇▆▇▅▆▇▅▆▇▇▆▆▇█▇▇</td></tr><tr><td>val_auc</td><td>▁▃▄▆▆▆▇▇▇▇█▇█▇▇▇▇▇██▇▇▇▇▇▇█▇▇█▇▇▇▇▇▇█▇█▇</td></tr><tr><td>val_f1</td><td>▁▃▂▁▃▄▂▃▅▆▅▅▆▅▅▅▂▆▅▆▂▅▆▇▅▃▇▁▅▆▂▄▆▅▅▄▆█▅▇</td></tr><tr><td>val_loss_epoch</td><td>█▄▄▃▃▃▃▂▂▃▁▂▁▂▁▂▃▃▂▂▃▄▃▃▃▄▃▂▂▃▃▂▃▂▂▂▁▄▁▂</td></tr><tr><td>val_loss_step</td><td>▇▆▆▅▅▆▅▄▄▆▂▃▂▃▁▄▅▆▅▄▄▄▅▄▅█▆▄▄▇▆▃▅▅▄▂▁█▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85006</td></tr><tr><td>train_auc</td><td>0.91766</td></tr><tr><td>train_f1</td><td>0.85181</td></tr><tr><td>train_loss_epoch</td><td>0.375</td></tr><tr><td>train_loss_step</td><td>0.5085</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82506</td></tr><tr><td>val_auc</td><td>0.89651</td></tr><tr><td>val_f1</td><td>0.81313</td></tr><tr><td>val_loss_epoch</td><td>0.40567</td></tr><tr><td>val_loss_step</td><td>0.40568</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/nvw05d4i' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/nvw05d4i</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_154728-nvw05d4i\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49c5ec318b7d4d33a81b7f7f24a66ef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_162203-x1gutm63</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/x1gutm63' target=\"_blank\">GINConv_3_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/x1gutm63' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/x1gutm63</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.7 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "2.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.2 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇█▇▇▇█▇▇▇█▇</td></tr><tr><td>train_auc</td><td>▁▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇███▇█▇███████▇████████</td></tr><tr><td>train_f1</td><td>▁▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇▇▇█▇▇▇█▇▇▇██</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▄▄▃▃▃▂▃▃▃▂▂▂▃▂▂▂▂▂▂▂▂▂▁▂▂▂▂▃▂▁▁▁▂▂▁▂</td></tr><tr><td>train_loss_step</td><td>█▅▄▄▄▄▄▄▃▅▅▅▄▂▁▃▃▃▁▃▂▃▄▄▃▃▂▇▁▂▃▃▃▅▂▃▃▃▆▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▅▅▅▆▇▆▇▆▆▆▇▇▇▇▇▆█▆▇▇▇▆▆▇▆▇▆▇▇█▅▇▇▆▇█▆▇</td></tr><tr><td>val_auc</td><td>▁▄▅▆▆▆▇▆▇▇▇▇▇███▇███▇▇█▇▇█▇▇▇▇▇▇▇▆▇▆▇▇▆▇</td></tr><tr><td>val_f1</td><td>▂▄▁▄▁▃▇▃▅▃▃▃█▅▅▇▆▂█▂▆▇▅▃▃▇▅▇▃▆▅▇▂▇▅▅▇█▃▇</td></tr><tr><td>val_loss_epoch</td><td>█▄▄▂▃▃▁▃▁▂▂▃▄▁▂▂▂▂▂▂▂▂▁▂▂▂▄▂▂▂▂▂▂▄▃▃▃▂▄▃</td></tr><tr><td>val_loss_step</td><td>▆▆▅▃▅▅▂▄▁▄▅▄▆▃▅▅▂▂▄▄▂▅▂▂▄▃█▄▃▃▄▂▁▅▅▄▄▂▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83884</td></tr><tr><td>train_auc</td><td>0.9152</td></tr><tr><td>train_f1</td><td>0.85057</td></tr><tr><td>train_loss_epoch</td><td>0.3872</td></tr><tr><td>train_loss_step</td><td>0.50195</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81324</td></tr><tr><td>val_auc</td><td>0.89321</td></tr><tr><td>val_f1</td><td>0.81412</td></tr><tr><td>val_loss_epoch</td><td>0.44879</td></tr><tr><td>val_loss_step</td><td>0.47177</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/x1gutm63' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/x1gutm63</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_162203-x1gutm63\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "987ed738822a4d4ca0e9ba492681a148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_165733-t9leg016</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/t9leg016' target=\"_blank\">GINConv_3_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/t9leg016' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/t9leg016</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 6.0 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "6.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.6 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c427d1ab82154097b769a23f240e60fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▅▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇█▇▇█▇█▇▇███▇█</td></tr><tr><td>train_auc</td><td>▁▅▅▅▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██████▇████</td></tr><tr><td>train_f1</td><td>▁▅▅▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇█▇██▇█▇▇███▇█</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▃▃▂▃▂▂▂▃▃▂▂▂▂▁▂▁▁▁▂▁▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▄▇▆▅▆▆▅▄▄▄▄▅▄▆▄▅▆▆▂▅▄▂▄▃▄▃▃▄▃▂▂▂▃▅▂▄▃▄▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▅▆▆▆▆▇▇▇▆▇▇▇▆▇▇▇▆▇▆▇▇▅▇▅▇▇█▇█▇▇█▇▇▇▇▇▇</td></tr><tr><td>val_auc</td><td>▁▃▃▅▆▅▆▆▆▇▆▇▇▇▇▇▇▆▇▇▆▇▇▇█▆▆▇▇▇█▆▆█▇▇▆▆▇▇</td></tr><tr><td>val_f1</td><td>▁▄▆▇▇▇▇▇▇█▇█▇█▇▇▇█▇█▇█▇▆▇▆▇▇███▇▇██▇█▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>██▄▃▃▃▂▃▂▂▃▂▂▃▃▂▂▂▃▂▃▁▂▄▁▅▄▂▂▂▁▄▃▂▂▃▃▃▃▃</td></tr><tr><td>val_loss_step</td><td>▇▆▅▅▄▄▄▆▄▄▄▃▃▅▆▃▃▄▅▄▄▂▃▅▃▆▅▂▅▃▁█▄▄▃▆▅▄▆▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87544</td></tr><tr><td>train_auc</td><td>0.94078</td></tr><tr><td>train_f1</td><td>0.87654</td></tr><tr><td>train_loss_epoch</td><td>0.29838</td></tr><tr><td>train_loss_step</td><td>0.24001</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81324</td></tr><tr><td>val_auc</td><td>0.90969</td></tr><tr><td>val_f1</td><td>0.76968</td></tr><tr><td>val_loss_epoch</td><td>0.41806</td></tr><tr><td>val_loss_step</td><td>0.44326</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/t9leg016' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/t9leg016</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_165733-t9leg016\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "363caca4d4624a4faaac3b66c5abc637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_173258-mlp7oc0u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/mlp7oc0u' target=\"_blank\">GINConv_3_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/mlp7oc0u' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/mlp7oc0u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 6.0 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "6.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.6 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇██████▇█</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█████████▇████████</td></tr><tr><td>train_f1</td><td>▁▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇████▇██████▇█</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▃▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▅▆▅▅▅▅▅▃▃▄▄▄▃▄▄▄▆▄▃▄▄▄▄▂▃▃▃▄▂▂▃▂▃▂▃▄▃▄▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇██▇▇▇▇▇▇▇▇█▇▇███▇▇▇▇▇██▇▇▇</td></tr><tr><td>val_auc</td><td>▁▅▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇█▇▇▇███▇█▇█▇▇▇▇▇██▇▇▇█</td></tr><tr><td>val_f1</td><td>▁▆▇▇▇██▇███▇█████▇█████████████▇█████▇██</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▃▂▂▂▃▃▃▂▂▃▃▄▁▂▃▁▃▃▂▁▂▁▃▂▂▂▂▃▃▃▃▂▂▄▂▃▂</td></tr><tr><td>val_loss_step</td><td>▇▅▅▄▂▃▄▅▅▄▄▃▄▆█▂▂▄▃▄▆▂▁▃▂▁▃▂▄▁▂▇▄▄▂▃▆▃▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86187</td></tr><tr><td>train_auc</td><td>0.93355</td></tr><tr><td>train_f1</td><td>0.86583</td></tr><tr><td>train_loss_epoch</td><td>0.3196</td></tr><tr><td>train_loss_step</td><td>0.23876</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80615</td></tr><tr><td>val_auc</td><td>0.89869</td></tr><tr><td>val_f1</td><td>0.79188</td></tr><tr><td>val_loss_epoch</td><td>0.41867</td></tr><tr><td>val_loss_step</td><td>0.46347</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/mlp7oc0u' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/mlp7oc0u</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_173258-mlp7oc0u\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad209ebb59ec4781a6c34e8b99ffb424",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_180853-hgqovgk6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hgqovgk6' target=\"_blank\">GINConv_3_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hgqovgk6' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hgqovgk6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 6.0 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "6.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.6 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a6a07498f5d48108fff9216c7e3c00c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▆▆▆▆▆▇▆▇▆▆▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇█</td></tr><tr><td>train_auc</td><td>▁▃▁▁▄▄▅▄▄▅▆▅▄▅▆▄▃▄▆▅▃▄▄▅▆██▆▇█▇▇▆▆▅▃▅▃▅▇</td></tr><tr><td>train_f1</td><td>▁▃▅▅▆▆▆▆▆▇▆▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▂▂▂▂▁▁▂▁▃▂▂▂▂▂▂▁▂▁▁▂▁▂▁▁▁▁▁▁▁▁▁▁▂▁▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▂▃▄▅▆▄▄▆▆▅▅▆▆▄▆▆▅▅▅▅▄▆▆▇▇▅▅▆▅▅▅▆▇█▇▇▅▆▄</td></tr><tr><td>val_auc</td><td>▁▃▆▇▇▇██▇███▇██▇▆███▇█▇████▇███████▇█▆██</td></tr><tr><td>val_f1</td><td>▂▁▂▄▅▇▅▄▆▆▅▆▇▆▅▆▆▅▅▅▆▃▆▆▇▇▅▆▇▃▅▅▅▇██▇▄▇▃</td></tr><tr><td>val_loss_epoch</td><td>█▅▄▃▃▃▃▃▃▃▃▂▃▄▄▂▃▅▂▃▄▃▂▃▂▂▃▄▃▄▂▅▃▄▁▆▂▃▂▅</td></tr><tr><td>val_loss_step</td><td>▅▆▄▄▄▃▅▆▅▅▅▃▄█▇▂▄▄▃▅▅▁▂▅▄▃▄▃▆▃▁▇▅▇▁▆▃▃▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86659</td></tr><tr><td>train_auc</td><td>0.77671</td></tr><tr><td>train_f1</td><td>0.86982</td></tr><tr><td>train_loss_epoch</td><td>0.3213</td></tr><tr><td>train_loss_step</td><td>0.32048</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.78723</td></tr><tr><td>val_auc</td><td>0.88302</td></tr><tr><td>val_f1</td><td>0.74576</td></tr><tr><td>val_loss_epoch</td><td>0.49294</td></tr><tr><td>val_loss_step</td><td>0.48767</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hgqovgk6' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hgqovgk6</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_180853-hgqovgk6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c9f9502513c4903a7e0726ce68e5f7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333332417533, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_184258-3x78oozi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/3x78oozi' target=\"_blank\">GINConv_3_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/3x78oozi' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/3x78oozi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 6.0 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "6.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.6 K     Total params\n",
      "0.027     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09172404936044eb9d90d8f6ec4fa34b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▅▆▆▆▆▆▆▆▇▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇███▇████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█▇██▇████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▇▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇███▇████</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▄▄▃▃▃▃▃▃▃▃▂▃▃▂▃▃▂▃▂▃▂▃▂▂▂▂▂▂▁▁▁▂▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▅▆▆▅▆▄▅▄▃▃▃▅▄▂▄▃▁▃▃▃▄▄▃▃▄▁▁▄▃▅▆▂▂▁▁▅▃▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▂▂▁▃▅▄▆▇▅▅▆▁▇▄▇▅▆█▇▆▆▄▆▇▆▇▅▇▆▆▆▆▇▇▆█▇▇▇▇</td></tr><tr><td>val_auc</td><td>▁▂▄▄▅▆▆▆▇▆▇▇▇▅▇▇▇▇█▇█▆▇▇▆█▆▇▇▇█▆▆▇▆▆▇▆▆▆</td></tr><tr><td>val_f1</td><td>▃▄▂▄▆▄▇▇▆▆▇▁▇▅█▅▇█▇▇▆▅▆█▆█▆▇▆▆▆▆▇▇▆█▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▄▆▃▃▃▂▁▂▂▁▆▁▄▃▄▂▃▂▂▂▃▃▂▅▇▃▃▁▂▃▅▃▂▆▄▄▄▃▄</td></tr><tr><td>val_loss_step</td><td>▇▄▇▃▄▄▄▂▅▃▃▆▁▅▂▇▂▅▄▂▂▄▅▃▅█▃▄▃▃▆▅▃▄▇▄▅▃▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.88135</td></tr><tr><td>train_auc</td><td>0.94613</td></tr><tr><td>train_f1</td><td>0.88442</td></tr><tr><td>train_loss_epoch</td><td>0.29315</td></tr><tr><td>train_loss_step</td><td>0.24407</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81797</td></tr><tr><td>val_auc</td><td>0.89502</td></tr><tr><td>val_f1</td><td>0.79467</td></tr><tr><td>val_loss_epoch</td><td>0.44663</td></tr><tr><td>val_loss_step</td><td>0.42166</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/3x78oozi' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/3x78oozi</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_184258-3x78oozi\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30c99646de66450b8941c89572d9e83d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_191745-7crbvipp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7crbvipp' target=\"_blank\">GINConv_3_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7crbvipp' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7crbvipp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 6.0 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "7.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.7 K     Total params\n",
      "0.031     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▆▆▆▆▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇██▇▇▇████▇▇██</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇█████████████</td></tr><tr><td>train_f1</td><td>▁▅▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇████▇▇██</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▄▄▄▃▄▃▃▃▃▃▃▃▃▃▃▂▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▅▄▄▄▅▄▅▃▅▅▆▅▃▄▂▇▂▂▃▄▆▅▄▄▂▁▂▁▂▃▃▃▆▄▂▂▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▁▅▆▅▄▄▆▆▆▇▅▇▅▇▅▇▇▆▆█▇▆▆▂▇▇▇▇▇▃▆▅▆▄▇▇▇▇▇</td></tr><tr><td>val_auc</td><td>▁▁▄▄▅▅▆▆▇▇▆▆▆▇▇▅▇█▇▇▆▇▆▆▆██▆█▅▆▆▅▅▆▅▇▆▅▆</td></tr><tr><td>val_f1</td><td>▁▂▆▇▆▅▄▇▇▇▇▆▇▅▇▆▇█▇▇█▇▇▇▃▇███▇▄▆▆▇▅▇▇▇█▇</td></tr><tr><td>val_loss_epoch</td><td>█▆▂▄▄▃▄▁▂▂▁▁▁▃▂▅▁▂▂▇▁▂▃▅▇▂▃▆▂▂▄▄▇▅▅▃▃▄▄▃</td></tr><tr><td>val_loss_step</td><td>▅▃▂▅▅▂▅▂▃▄▃▂▂▄▃▆▁▂▃▆▂▄▄▆▃▄▄█▃▂▂▄▂▅▃▂▅▄▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.88076</td></tr><tr><td>train_auc</td><td>0.94462</td></tr><tr><td>train_f1</td><td>0.88019</td></tr><tr><td>train_loss_epoch</td><td>0.29688</td></tr><tr><td>train_loss_step</td><td>0.2267</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82742</td></tr><tr><td>val_auc</td><td>0.89572</td></tr><tr><td>val_f1</td><td>0.80533</td></tr><tr><td>val_loss_epoch</td><td>0.43073</td></tr><tr><td>val_loss_step</td><td>0.27247</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7crbvipp' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7crbvipp</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_191745-7crbvipp\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ebd442787974c038a88d0cfee11e80f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_195206-3gcsapp2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/3gcsapp2' target=\"_blank\">GINConv_3_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/3gcsapp2' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/3gcsapp2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 22.3 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "24.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.5 K    Total params\n",
      "0.098     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67abba48fc414689bef98ede5ccfe90a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▄▅▅▅▆▆▆▆▆▆▆▆▆▇▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇█▇█▇██</td></tr><tr><td>train_auc</td><td>▁▄▄▅▅▅▅▆▅▆▆▆▅▅▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇████████</td></tr><tr><td>train_f1</td><td>▁▄▄▄▅▅▅▆▆▆▆▆▆▆▅▆▇▆▆▆▆▇▆▆▇▇▇▆▇▇▇▇▇▇█▇▇▇██</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▅▅▄▅▄▄▄▄▄▄▄▄▃▃▄▃▃▄▃▃▃▂▃▃▂▂▃▂▂▂▂▁▂▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>██▆▇▅▇▅▆▆▆▅▅▄▅▆▄▄█▄▄▄▅▂▄▄▃▄▁▅▄▄▃▃▅▄▅▃▂▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▅▅▅▆▆▇▆▇█▅█▇▆▆▆▇▅▇▇▆▇▅▆▇▆▆▆▇▅▄▅▅▅▄▄▄▅▄</td></tr><tr><td>val_auc</td><td>▄▃▄▇▆█▇███▇▄▇▇▇▇▇▇▆▆▆▄▇▆▂▇▆▆▅▆▄▄▄▃▅▁▄▁▅▃</td></tr><tr><td>val_f1</td><td>▅▁▅▅▄▇▆▇▆██▆██▆▆▇▇▄▇▇▆▇▆▆█▇▆▆▇▆▄▅▅▆▅▅▅▅▆</td></tr><tr><td>val_loss_epoch</td><td>▄▃▂▁▂▂▁▁▁▁▂▃▁▂▂▁▂▁▂▂▂▁▁▃▃▃▃▂▅▂▄▃▃▅▄▆▆▅▄█</td></tr><tr><td>val_loss_step</td><td>▃▃▂▃▂▃▂▂▃▂▂▄▂▄▂▂▂▂▂▂▃▁▂▄▃▄▃▂▄▂▅▃▃▆▃█▆▅▄█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.89374</td></tr><tr><td>train_auc</td><td>0.95963</td></tr><tr><td>train_f1</td><td>0.89535</td></tr><tr><td>train_loss_epoch</td><td>0.24034</td></tr><tr><td>train_loss_step</td><td>0.15475</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.77541</td></tr><tr><td>val_auc</td><td>0.87345</td></tr><tr><td>val_f1</td><td>0.78161</td></tr><tr><td>val_loss_epoch</td><td>0.7549</td></tr><tr><td>val_loss_step</td><td>1.1212</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/3gcsapp2' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/3gcsapp2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_195206-3gcsapp2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4063bf622d7a41069e99521ffb52a1fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333332417533, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_202753-1uw2c5ba</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1uw2c5ba' target=\"_blank\">GINConv_3_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1uw2c5ba' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1uw2c5ba</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 22.3 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "24.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.5 K    Total params\n",
      "0.098     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9d0d01daa6945e1810bc0a23dc618b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▅▆▆▆▆▆▇▇▆▇▆▆▆▆▇▇▇▇▇▇▇▇▇▇█████▇██████</td></tr><tr><td>train_auc</td><td>▁▅▅▅▅▅▆▆▆▆▇▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████████</td></tr><tr><td>train_f1</td><td>▁▄▅▅▆▆▆▆▆▆▇▇▆▇▆▆▇▆▇▇▇▇▇▇▇▇▇▇█████▇██████</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▄▄▄▄▄▄▃▄▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▁▁▁▁▂▂▁▂▂▂▁</td></tr><tr><td>train_loss_step</td><td>██▅▅▅▅▄▅▅▄▅▄▂▄▅▄▄▄▄▄▄▃▂▄▄▂▃▁▄▅▃▃▄▂▅▄▃▂▄▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▂▁▄▄▄▄▅▅▅▆▆▇▆▄▅▄▆▆▆▆█▆▆▆▆▆▆▇▅▅▆▇▆▇█▅▇▇█▆</td></tr><tr><td>val_auc</td><td>▂▁▂▄▂▅▄▅▅▆▇▇▆▃▆▆▆▆▇▇█▅▇▆▇▇▇▇▆▇▇▆▆▅▇▅▇▇█▆</td></tr><tr><td>val_f1</td><td>▅▁▄▆▅▆▆▅▆▇▇▇▅▅▇▆▆▇▆▇▇▆▆▆▇▇▆▇▅▇▇▇▇▇█▆▆██▇</td></tr><tr><td>val_loss_epoch</td><td>▇▆▄▃▄▄▂▃▃▃▂▃▂▆▃▄▂▃▃▂▃▄▁▄▃▄▃▃▄▇▅▄▆▆▄▆▃█▄▇</td></tr><tr><td>val_loss_step</td><td>▄▄▃▃▃▅▃▄▃▃▃▅▂▇▃▄▂▂▃▃▆▄▁▅▂▄▅▃▃▆▅▃▄▆▃▂▃█▃▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.88843</td></tr><tr><td>train_auc</td><td>0.95801</td></tr><tr><td>train_f1</td><td>0.89056</td></tr><tr><td>train_loss_epoch</td><td>0.254</td></tr><tr><td>train_loss_step</td><td>0.2217</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80378</td></tr><tr><td>val_auc</td><td>0.89151</td></tr><tr><td>val_f1</td><td>0.79805</td></tr><tr><td>val_loss_epoch</td><td>0.54154</td></tr><tr><td>val_loss_step</td><td>0.66287</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1uw2c5ba' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1uw2c5ba</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_202753-1uw2c5ba\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e3fc263426a4b57ba3bc9345c5124f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333332417533, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_210627-ytr0b90h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ytr0b90h' target=\"_blank\">GINConv_3_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ytr0b90h' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ytr0b90h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 22.3 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "24.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.5 K    Total params\n",
      "0.098     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "522a9ad6e0ff4bedab23ed6eb89d22b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▆▅▆▆▆▆▇▆▆▆▇▇▇▆▆▇▇▇▆▇▇▇▇█▇▇▇████▇███▇</td></tr><tr><td>train_auc</td><td>█▅▃▂▁▁▂▃▂▂▁▂▂▂▂▁▁▄▃▄▄▆▆▅▃▃▄▇█▆▅▄▄▃▃▁▂▁▃▅</td></tr><tr><td>train_f1</td><td>▁▃▅▅▆▅▆▆▆▆▇▆▆▆▇▇▇▆▇▇▇▇▆▇▇▇▇█▇▇▇████▇███▇</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁▂▂▂▂▂▁▂▂▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▆▅▇▇▆▇█▆▆▇█▅▇▇▇▇▇▇▇▇█▅█▆▇▇▇█▇▅▇▆▆▇▆▆▇▇</td></tr><tr><td>val_auc</td><td>▆▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▂▁▁▁▁█▃▅▁▁▁▁▁▁▁▁▂▃</td></tr><tr><td>val_f1</td><td>▃▆▆▄▆▇▅▆▇▇▆▇█▄▇▅▇█▆▅▆▇█▁█▆▇▇▇▇▇▁▇▅▅▅▇▆▇▅</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▃▂▃▂▂▂▂▂▃▁▄▂▃▂▂▃▃▃▁▂▅▂▃▄▄▂▂▂▅▄▇▆▃▅▅▃▃</td></tr><tr><td>val_loss_step</td><td>▄▃▃▃▃▄▂▂▃▂▃▃▂▅▂▃▂▃▃▃▃▁▃▆▂▃▃▂▃▂▂▃▄█▅▃▄▅▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8595</td></tr><tr><td>train_auc</td><td>0.40835</td></tr><tr><td>train_f1</td><td>0.86431</td></tr><tr><td>train_loss_epoch</td><td>0.33434</td></tr><tr><td>train_loss_step</td><td>0.26064</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81324</td></tr><tr><td>val_auc</td><td>0.34642</td></tr><tr><td>val_f1</td><td>0.77493</td></tr><tr><td>val_loss_epoch</td><td>0.49623</td></tr><tr><td>val_loss_step</td><td>0.46991</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ytr0b90h' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ytr0b90h</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_210627-ytr0b90h\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16697a52cee34892af7c8695e7815240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_214327-w6kz4zrq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/w6kz4zrq' target=\"_blank\">GINConv_3_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/w6kz4zrq' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/w6kz4zrq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 22.3 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "24.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.5 K    Total params\n",
      "0.098     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b541de72cc49508446f756c272dd90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▅▅▆▆▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇█▇▇▇▇█▇▇████▆████</td></tr><tr><td>train_auc</td><td>▁▄▅▆▆▅▆▆▆▆▇▆▇▆▇▇▇▇▇▇▇▇████▇▇██▇████▇████</td></tr><tr><td>train_f1</td><td>▁▃▅▅▅▄▆▆▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇█▇▇▇▇█▇▇███▇▆████</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▅▄▃▄▄▃▄▃▄▃▃▃▂▂▂▃▂▂▂▂▁▂▂▁▂▂▂▁▂▂▃▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>▅▅▅▄▆▅▄▄▄▄▅▃▆▅▄▄▃▁▃▃▃▃▄▁▃▃▅█▅▂▄▅▃▂▅▁▂▄▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▅▁▆▆▇▇▇▆▇▆▆▇▄▇▅▇▆▆█▆▇▇█▆██▇▄▇▇█▆█▆▅▇▆▆▇█</td></tr><tr><td>val_auc</td><td>▁▁▆▇█▇▇▇▇▇▇▆▄▇▅▇▆▇▇▆▇▆▇▆▇▇▇▅▅▇█▆▇▆▄▄▄▆▆▇</td></tr><tr><td>val_f1</td><td>▇▁▇▇▇██▆██▇█▄█▅▇▇▆█▆▇▇█▇██▇▄█▇█▇█▇▅▇▇▇██</td></tr><tr><td>val_loss_epoch</td><td>▃█▂▁▁▂▁▂▂▂▁▂▅▂▃▂▂▂▂▂▂▂▂▄▃▂▂▇▄▂▂▂▄▅▇▃▃▃▄▃</td></tr><tr><td>val_loss_step</td><td>▃▅▂▂▂▂▂▃▁▃▂▃▆▃▂▂▂▂▂▂▂▂▂▂▃▂▂▆▃▂▃▁▄▅█▃▂▃▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.88194</td></tr><tr><td>train_auc</td><td>0.95164</td></tr><tr><td>train_f1</td><td>0.88506</td></tr><tr><td>train_loss_epoch</td><td>0.2819</td></tr><tr><td>train_loss_step</td><td>0.30312</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82979</td></tr><tr><td>val_auc</td><td>0.89255</td></tr><tr><td>val_f1</td><td>0.81538</td></tr><tr><td>val_loss_epoch</td><td>0.4867</td></tr><tr><td>val_loss_step</td><td>0.61186</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/w6kz4zrq' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/w6kz4zrq</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_214327-w6kz4zrq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55a9cef72451401eba7010ab06402f26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333332417533, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_221955-kuszrx1g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kuszrx1g' target=\"_blank\">GINConv_3_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kuszrx1g' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kuszrx1g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 22.3 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "28.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "28.7 K    Total params\n",
      "0.115     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac3d54e3b66a48cdbf883a2fa60456be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▅▅▅▆▆▆▆▆▆▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇█▇████▇████▇</td></tr><tr><td>train_auc</td><td>▁▄▅▅▅▆▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██████████</td></tr><tr><td>train_f1</td><td>▁▄▄▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█▇████▇████▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▅▄▅▄▄▄▄▃▃▄▄▃▃▃▃▃▃▂▂▂▃▂▃▂▁▂▂▂▁▂▂▁▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▅▅▆▇▆▅▅▄▅▄▅▄▄▅▃▄▁▅▄▃▃▁▃▄▂▄█▂▂▃▂▃▂▁▃▃▂▂▇</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▄▂▆▄▅▆▆▆█▆▇▇▇▇▇▆▅▇█▇▆▆▇▇▇▁▆▇▆▇▆▅▆▇▆▆▆▆▅▇</td></tr><tr><td>val_auc</td><td>▁▂▆▆▆▆▇▅▇▇█▆▇▆▆▆▅▆▇▇▆▇▆▆▆▄▆▅▂▆▄▅▆▅▇▅▆▅▃▇</td></tr><tr><td>val_f1</td><td>▆▃▇▇▆▇▇█▇▆███▇▇▇▅▇██▇▇▇▇█▁█▇▆▇▇▅▇▇▇▇▇▇▆▇</td></tr><tr><td>val_loss_epoch</td><td>▃▃▂▃▁▂▁▂▂▂▂▂▃▂▂▃▂▁▁▃▂▂▄▁▂█▃▃▆▃▅▆▄▃▃▅▄▆▄▅</td></tr><tr><td>val_loss_step</td><td>▄▄▄▅▂▃▃▃▄▃▄▁▅▅▃▅▃▂▃▇▂▃▇▂▄▇▂▅▇▄▄▆▃▃▆█▄▅▄█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87898</td></tr><tr><td>train_auc</td><td>0.95474</td></tr><tr><td>train_f1</td><td>0.87673</td></tr><tr><td>train_loss_epoch</td><td>0.28955</td></tr><tr><td>train_loss_step</td><td>0.53759</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82033</td></tr><tr><td>val_auc</td><td>0.89479</td></tr><tr><td>val_f1</td><td>0.8</td></tr><tr><td>val_loss_epoch</td><td>0.54005</td></tr><tr><td>val_loss_step</td><td>0.8137</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kuszrx1g' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kuszrx1g</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_221955-kuszrx1g\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eea8662f19e4322a00cad093fb6b7ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_225652-1487djuf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1487djuf' target=\"_blank\">GINConv_4_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1487djuf' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1487djuf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 2.4 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bebb5fdf79f41b0a22ff89f67edc0d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇█▇█</td></tr><tr><td>train_auc</td><td>▁▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇███▇█████████████</td></tr><tr><td>train_f1</td><td>▁▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇██▇▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▃▃▂▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▂▂▁▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▄▅▅▄▅▃▅▃▄▅▄▃▃▅▃▅▃▄▄▅▆▄▄▃▄▃▃▃▄▂▂▂▃▄▂▂▄▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▇▇▇▇▇▇▇▇██▇█▇▇▇▇▆▇██▇███████▇█████▇███▇</td></tr><tr><td>val_auc</td><td>▁▄▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████▇█▇███▇▇█▇███</td></tr><tr><td>val_f1</td><td>▁▆▆▆▆▇▆▆▇▇▇▆▇▇▇▇▇▂▅█▇▅▇██▇█▇█▆▇▇█▇▇▆▆██▆</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▂▃▂▂▃▂▂▂▂▂▂▂▂▂▃▂▂▁▂▂▂▂▁▁▂▁▂▂▂▂▁▂▂▂▂▂▂</td></tr><tr><td>val_loss_step</td><td>█▆▄▄▃▁▃▅▃▂▂▁▂▃▁▂▂▅▂▃▁▃▃▄▄▂▁▅▂▃▃▅▄▁▄▂▄▄▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84357</td></tr><tr><td>train_auc</td><td>0.91044</td></tr><tr><td>train_f1</td><td>0.84476</td></tr><tr><td>train_loss_epoch</td><td>0.37523</td></tr><tr><td>train_loss_step</td><td>0.23376</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80615</td></tr><tr><td>val_auc</td><td>0.90462</td></tr><tr><td>val_f1</td><td>0.76836</td></tr><tr><td>val_loss_epoch</td><td>0.41174</td></tr><tr><td>val_loss_step</td><td>0.48758</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1487djuf' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1487djuf</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_225652-1487djuf\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57400fc2f0384a45be9cb7149cebbad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.017200000000108653, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231229_233256-icfx0gph</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/icfx0gph' target=\"_blank\">GINConv_4_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/icfx0gph' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/icfx0gph</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 2.4 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇█▇██▇██▇█▇███████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇██▇███████████████</td></tr><tr><td>train_f1</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇██▇█▇███▇██▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▃▃▃▂▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▂▁▂▂▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▄▄▅▄▅▂▅▄▅▅▃▃▃▅▃▆▄▃▄▆▅▆▂▃▅▃▃▂▄▁▁▂▃▃▃▁▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▇█▇▇▇█████▇███▇▇█▇▇█████▇▇██▇▇▇▇▇▇▇▇█▇▇</td></tr><tr><td>val_auc</td><td>▁▅▅▆▆▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████▇██▇███▇</td></tr><tr><td>val_f1</td><td>▁▅▇▅▇▇▇▇▇▇█▇▇▇█▇▇█▇▇▇██▇█▇▇▇▇▇▇▇▆▇▇▆▇█▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▂▂▂▂▄▂▂▂▂▂▂▂▂▂▂▂▃▁▂▂▂▁▃▂▂▂▂▂▃▂▂▃▂▂▂▂▂</td></tr><tr><td>val_loss_step</td><td>█▃▄▃▃▂▃▇▄▄▄▃▃▄▃▁▃▄▂▅▁▄▄▅▁▃▃▄▃▃▃▄▄▃▇▃▄▄▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.80874</td></tr><tr><td>train_auc</td><td>0.88366</td></tr><tr><td>train_f1</td><td>0.80986</td></tr><tr><td>train_loss_epoch</td><td>0.42252</td></tr><tr><td>train_loss_step</td><td>0.39435</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.74941</td></tr><tr><td>val_auc</td><td>0.8914</td></tr><tr><td>val_f1</td><td>0.76856</td></tr><tr><td>val_loss_epoch</td><td>0.4604</td></tr><tr><td>val_loss_step</td><td>0.5213</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/icfx0gph' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/icfx0gph</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231229_233256-icfx0gph\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "219c0140d88d44f09cd79176b56a4a96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_000743-c263avzi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/c263avzi' target=\"_blank\">GINConv_4_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/c263avzi' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/c263avzi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 2.4 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇█▇█▇▇</td></tr><tr><td>train_auc</td><td>██▇▅▇▅▅▅▄▅▅▄▄▄▁▃▃▃▂▃▃▆▃▅▂▃▂▄▄▄▄▅▅▂▅▄▄▃▅▁</td></tr><tr><td>train_f1</td><td>▁▃▅▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇█▇█▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▃▃▃▃▃▂▂▂▃▃▂▂▂▃▂▂▂▂▂▃▄▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▇▇█▇▇▇▇▇▇▇█▆▇█▇█▇▇</td></tr><tr><td>val_auc</td><td>▇█▇▆▅▃▃▂▂▁▂▂▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▂▁▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_f1</td><td>▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇▇▇▇█▇██▆████▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▆▅▅▄▃▃▄▂▂▂▂▂▂▁▁▂▂▂▂▁▃▂▃▂▁▁▂▂▁▁▂▃▃▂▁▃▂▃▂</td></tr><tr><td>val_loss_step</td><td>█▇▆▇▅▂▄█▄▃▄▂▄▄▂▂▃▆▃▅▁▃▅▅▃▃▁▄▄▃▃▅▆▄▃▃▇▄▆▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.82408</td></tr><tr><td>train_auc</td><td>0.31782</td></tr><tr><td>train_f1</td><td>0.83202</td></tr><tr><td>train_loss_epoch</td><td>0.39582</td></tr><tr><td>train_loss_step</td><td>0.22383</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.79196</td></tr><tr><td>val_auc</td><td>0.09821</td></tr><tr><td>val_f1</td><td>0.75</td></tr><tr><td>val_loss_epoch</td><td>0.42103</td></tr><tr><td>val_loss_step</td><td>0.50918</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/c263avzi' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/c263avzi</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_000743-c263avzi\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "356e0fa8314e4ae1b2d6759a3d091097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_004251-dv7w5jhs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/dv7w5jhs' target=\"_blank\">GINConv_4_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/dv7w5jhs' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/dv7w5jhs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 2.4 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "2.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86cbd439867441169dd33189b2157919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇▇▇█▇██▇▇███▇██</td></tr><tr><td>train_auc</td><td>▁▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇█▇▇█▇██████████</td></tr><tr><td>train_f1</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇██▇████▇███████▇███████</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▃▃▃▃▃▂▃▂▃▂▃▂▂▂▂▂▂▁▂▃▂▂▂▂▂▁▂▂▂▂▂▁▁▁▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▇▅▅▆▄▆▆▃▄▃▅▅▃▅▃▂▇▅▃▁▂▇▂▃▃▃▃▁▂▃▂▆▃▁▁▇▂▄▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▇▇▇▇▇▇▇▇▇▇▇██▇▇██▇▇█▇▇▇█▇███▇█▇▇▇██▇▇▇▇</td></tr><tr><td>val_auc</td><td>▁▅▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇██▇▇██▇▇▇▇▇▇▇██▇▇▇▇▇▇</td></tr><tr><td>val_f1</td><td>▁▇▅▅▅▅▇▄▇▇▄▆▇▇▆▆▇█▆▆█▆▆▆█▄▇▇▇▇▇▆▇▅▇█▆▅▆▅</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▂▂▃▂▃▁▁▃▁▂▁▂▂▁▁▂▂▁▁▂▁▂▃▁▁▁▁▁▂▁▂▃▂▁▂▂▂</td></tr><tr><td>val_loss_step</td><td>█▄▄▄▅▆▅▅▃▃▃▂▆▄▄▆▄▃▅▇▄▅▅▄▅▇▄▃▃▃▄▅▅▆▇▄▁▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83294</td></tr><tr><td>train_auc</td><td>0.91063</td></tr><tr><td>train_f1</td><td>0.83819</td></tr><tr><td>train_loss_epoch</td><td>0.37588</td></tr><tr><td>train_loss_step</td><td>0.35382</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.77541</td></tr><tr><td>val_auc</td><td>0.88814</td></tr><tr><td>val_f1</td><td>0.73538</td></tr><tr><td>val_loss_epoch</td><td>0.41863</td></tr><tr><td>val_loss_step</td><td>0.38936</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/dv7w5jhs' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/dv7w5jhs</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_004251-dv7w5jhs\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d569ccc32c2140d7aab84f9565c9226b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_011917-gwhtf1zf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gwhtf1zf' target=\"_blank\">GINConv_4_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gwhtf1zf' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gwhtf1zf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 2.4 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "2.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.8 K     Total params\n",
      "0.011     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇██▇▇█▇█▇█████▇▇██▇███</td></tr><tr><td>train_auc</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█████▇█▇█████████████</td></tr><tr><td>train_f1</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇█▇█████▇▇██▇███</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▃▃▃▃▂▂▂▂▃▂▂▂▂▂▂▂▁▂▂▂▂▁▂▁▁▂▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>▅▅▃▃▂▂▃▃▂▂▃▃█▂▂▃▁▃▂▂▂▃▄▂▃▂▂▁▁▁▂▂▂▂▂▁▂▂▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▇▆▇▇▇▇▇▇▆▇▇▆▇▇▇▇▇▇███▇▇▇▇▇▇█▇▇█▇█▇▇██▇▇</td></tr><tr><td>val_auc</td><td>▁▄▆▇▇▆▆▇▇▆█▇▅▇▇▇██████▇█▇▇███▇▇██▇█████▇</td></tr><tr><td>val_f1</td><td>▁▆▄▄▅▅▅▆▅▁▆▇▄▆▆▆▇▆▇▇▆▇▇▆▇▅▇▆█▅▅█▆█▆▄▆█▅▄</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▃▂▂▂▂▂▃▁▁▃▂▁▂▁▂▁▂▂▁▂▂▂▃▂▃▁▂▂▂▂▂▂▂▁▂▂▃</td></tr><tr><td>val_loss_step</td><td>█▅▆▄▃▄▃▅▄▄▃▂▃▇▃▃▂▄▃▄▄▁▃▃▄▅▃▇▂▄▃▄▄▃▄▄▃▅▃▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84179</td></tr><tr><td>train_auc</td><td>0.90371</td></tr><tr><td>train_f1</td><td>0.84327</td></tr><tr><td>train_loss_epoch</td><td>0.37765</td></tr><tr><td>train_loss_step</td><td>0.31843</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.78487</td></tr><tr><td>val_auc</td><td>0.88241</td></tr><tr><td>val_f1</td><td>0.72836</td></tr><tr><td>val_loss_epoch</td><td>0.47671</td></tr><tr><td>val_loss_step</td><td>0.55551</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gwhtf1zf' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gwhtf1zf</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_011917-gwhtf1zf\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa4ca37f3ef646679e828e5dd62738a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_015502-z8eenp5r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/z8eenp5r' target=\"_blank\">GINConv_4_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/z8eenp5r' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/z8eenp5r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 8.3 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "8.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.8 K     Total params\n",
      "0.035     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▅▅▆▆▆▆▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇█▆▇▇██▇██████</td></tr><tr><td>train_auc</td><td>▁▅▅▅▆▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇██▇████▇█</td></tr><tr><td>train_f1</td><td>▁▅▅▅▆▆▆▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█▇█▇▇███▇██████</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▅▄▄▄▄▄▃▃▃▃▃▄▃▃▂▃▃▃▂▂▂▃▂▂▂▃▂▂▂▂▂▂▁▂▁▂▂</td></tr><tr><td>train_loss_step</td><td>██▆▅▆▆▆▅▇▅▅▆▄▆▆▅▇▁▄▅▅▇▂▂▄▄▅▂▄▂▃▄▃▄▅▂▂▂▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▃▃▃▆▄▇▇▄▇▂▆▇▇▅▅▅▅▁▇▅▆▄▇██▇▇▇▇▅█▂▃▆▆▄▅▇▄▇</td></tr><tr><td>val_auc</td><td>▁▃▄▅▅▇▆▆█▆█▆▇█▅▇▇▆▇▆▆▇▅▇▇▇▇▅▆▇▅▆▆█▆▅▅▆▁▅</td></tr><tr><td>val_f1</td><td>▄▄▃▇▅▇▇▄▇▂▇▇▇▆▆▅▅▁█▅▆▄▆▇▇▇▇▇▇▄█▂▃▅▇▅▄▇▅▇</td></tr><tr><td>val_loss_epoch</td><td>▄▄▄▃▃▃▁▄▁█▂▃▃▁▃▃▄▆▅▄▂▃▄▃▂▂▁▃▂▅▆██▅▄▇█▅▆▄</td></tr><tr><td>val_loss_step</td><td>▃▄▃▃▃▃▁▅▂▄▃▄▄▂▃▂▆▆▄▄▂▂▅▃▂▂▁▃▂▄▄▃▄▃▅▆█▅▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.866</td></tr><tr><td>train_auc</td><td>0.93542</td></tr><tr><td>train_f1</td><td>0.86962</td></tr><tr><td>train_loss_epoch</td><td>0.31424</td></tr><tr><td>train_loss_step</td><td>0.23745</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81087</td></tr><tr><td>val_auc</td><td>0.88857</td></tr><tr><td>val_f1</td><td>0.79695</td></tr><tr><td>val_loss_epoch</td><td>0.44369</td></tr><tr><td>val_loss_step</td><td>0.39502</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/z8eenp5r' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/z8eenp5r</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_015502-z8eenp5r\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23fb61c209c54a91ab8385331eac1ec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_023008-w5nuau25</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/w5nuau25' target=\"_blank\">GINConv_4_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/w5nuau25' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/w5nuau25</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 8.3 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "8.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.8 K     Total params\n",
      "0.035     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇▇██████▇██</td></tr><tr><td>train_auc</td><td>▁▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇▇██████▇██</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▄▃▃▃▃▃▃▃▂▂▃▂▂▂▂▂▂▂▂▁▂▁▂▂▂▂▂▁▁▁▁▁▁▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▆▅▄▄▄▅▃▄▄▄▅▂▅▄▅▅▂▃▄▆▅▂▃▄▄▃▁▃▄▃▄▃▃▄▃▂▃▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▅▆▆▆▆▆▆▆▆▆▆▆▆▇▇▆▇▆▆▆▆▇▆▆▆▇▆▇▇▇▇█▇▇▇▇▇▇</td></tr><tr><td>val_auc</td><td>▁▅▅▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇▇█▇▇▇▇██▇██▇█▇▇▇</td></tr><tr><td>val_f1</td><td>▁▄▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇█▇▇█</td></tr><tr><td>val_loss_epoch</td><td>█▆▃▃▂▂▃▃▂▂▂▂▂▂▂▂▃▃▂▂▂▂▃▂▂▂▂▃▂▂▂▁▁▁▂▃▁▂▂▂</td></tr><tr><td>val_loss_step</td><td>▇█▄▅▃▄▅▄▃▃▃▅▃▂▄▃▆▅▄▄▃▃▅▄▃▃▂▆▂▃▅▁▁▄▄▆▃▅▅▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84593</td></tr><tr><td>train_auc</td><td>0.91369</td></tr><tr><td>train_f1</td><td>0.85179</td></tr><tr><td>train_loss_epoch</td><td>0.36481</td></tr><tr><td>train_loss_step</td><td>0.28158</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81324</td></tr><tr><td>val_auc</td><td>0.90118</td></tr><tr><td>val_f1</td><td>0.80872</td></tr><tr><td>val_loss_epoch</td><td>0.39677</td></tr><tr><td>val_loss_step</td><td>0.28785</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/w5nuau25' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/w5nuau25</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_023008-w5nuau25\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b0cdc42023b4a47bd5b4dc9217e1bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_030520-wj5358vl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wj5358vl' target=\"_blank\">GINConv_4_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wj5358vl' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wj5358vl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 8.3 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "8.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.8 K     Total params\n",
      "0.035     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdb2a176caf9417591895b49a6709b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▆▆▆▆▆▆▆▆▇▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇</td></tr><tr><td>train_auc</td><td>▁▄▅▄▅▆▆▇▆▆▆▇▇▇▇▇▆▆▆▅▆▇▇▇▇▇▇███▇██▇██████</td></tr><tr><td>train_f1</td><td>▁▄▅▆▆▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇███▇▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▂▃▂▂▂▂▂▂▂▂▁▃▃▂▂▁▂▂▃▃▁▁▂▂▂▂▁▁▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▇▇▇▆▇▇▇▇▇▇▆▇▇▇▇▇▇█▇▇█▇███▆▇▇▇█▇█▇▇████</td></tr><tr><td>val_auc</td><td>▁▅▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇▇▇▇█▇</td></tr><tr><td>val_f1</td><td>▁▄▄▅▅▄▇▆▅▅▆▇▄▆▇▇▇▃▆▆▇▇▇▆▇▆▇▂▆▆▇▇▆▇▆▅▇█▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▃▂▃▂▂▃▄▃▃▃▂▂▃▃▅▃▃▂▂▃▃▂▃▂▆▃▃▃▂▃▂▆█▃▃▁▅</td></tr><tr><td>val_loss_step</td><td>▆▃▂▃▃▄▂▃▄▄▃▃▄▁▂▃▅▅▅▄▃▁▄▃▂▃▂▃▂▄▄▁▃▃▆█▅▄▁▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83766</td></tr><tr><td>train_auc</td><td>0.87073</td></tr><tr><td>train_f1</td><td>0.8468</td></tr><tr><td>train_loss_epoch</td><td>0.35992</td></tr><tr><td>train_loss_step</td><td>0.27786</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81324</td></tr><tr><td>val_auc</td><td>0.88868</td></tr><tr><td>val_f1</td><td>0.78706</td></tr><tr><td>val_loss_epoch</td><td>0.54264</td></tr><tr><td>val_loss_step</td><td>0.62997</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wj5358vl' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wj5358vl</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_030520-wj5358vl\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9faa35e535d34b5e9dc7cc7e85e82741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_034055-hfqif4b7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hfqif4b7' target=\"_blank\">GINConv_4_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hfqif4b7' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hfqif4b7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 8.3 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "8.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.9 K     Total params\n",
      "0.036     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇███▇█▇█▇█▇███████▇</td></tr><tr><td>train_auc</td><td>▁▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇█▇█▇█▇████████</td></tr><tr><td>train_f1</td><td>▁▅▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇███▇█▇█▇█▇███████▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▅▄▃▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▁▂▂</td></tr><tr><td>train_loss_step</td><td>█▇▆▆▄▆▆▆▄▅▇▅▅▄▆▆▃▅▅▄▃▆▄▃▃▄▅▃▃▃▆▃▃▄▂▂▄▄▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▂▄▂▇▅▄▆▄▅▅▆▇▄▄▆▇▆█▅▇▆▆▆▇▇█▅▇▆▆▆▇▆█▆▅▆▄▇</td></tr><tr><td>val_auc</td><td>▁▄▅▅▆▆▅▇▇█▇▇█▇▇▇▇▇█▇██▇▇█▇█▇█▇█▆▇▇▇▇▇▆▇▆</td></tr><tr><td>val_f1</td><td>▅▁▄▂▇▅▃▅▁▃▅▄▇▄▂▅▅▆█▃▆▅▅▄▇▆█▃█▆▅▆█▅█▄▄▆▁▇</td></tr><tr><td>val_loss_epoch</td><td>█▄▄▄▃▃▄▂▃▂▂▃▃▅▅▄▃▃▃▄▁▂▃▂▂▃▁▄▅▄▂▄▆▂▄▅▆▆▅▄</td></tr><tr><td>val_loss_step</td><td>▆▄▄▄▅▄▅▃▄▂▃▆▅▇▇▇▅▄▅▅▁▃▄▂▄▇▁▆▇▆▃▄█▂▂▆█▇▂▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84475</td></tr><tr><td>train_auc</td><td>0.93019</td></tr><tr><td>train_f1</td><td>0.84736</td></tr><tr><td>train_loss_epoch</td><td>0.33003</td></tr><tr><td>train_loss_step</td><td>0.22311</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81324</td></tr><tr><td>val_auc</td><td>0.88742</td></tr><tr><td>val_f1</td><td>0.79373</td></tr><tr><td>val_loss_epoch</td><td>0.45518</td></tr><tr><td>val_loss_step</td><td>0.45709</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hfqif4b7' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hfqif4b7</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_034055-hfqif4b7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c536b314154248f5a1148e4ed12a1896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333332417533, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_041558-time4f39</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/time4f39' target=\"_blank\">GINConv_4_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/time4f39' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/time4f39</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 8.3 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "9.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "9.9 K     Total params\n",
      "0.040     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "230b4290df574f1cbe479715a0224642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▅▅▅▆▆▅▆▆▆▆▆▆▇▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇███</td></tr><tr><td>train_auc</td><td>▁▅▅▆▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇████▇█████</td></tr><tr><td>train_f1</td><td>▁▅▅▅▅▆▆▆▆▆▇▆▆▆▇▇▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▅▄▄▄▄▃▃▃▃▃▃▂▂▃▃▂▃▃▂▂▂▂▂▂▂▂▂▁▂▁▂▁▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>▄▃▃▃▃▃▂▃▃▃▂▁▃▃▁▃▂▄▂▁▃▃▁▂▂▁▂▃▁▁▂▁▂▁▁▁▁▂▁█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▂▅▅▄▃▅▄▅▃▇▅▇▆▇█▆▇▄▆▄▇▇▇██▇▇▇▆▇▁█▇▃▅▇▆▆▅</td></tr><tr><td>val_auc</td><td>▁▂▃▄▄▆▆▆▆▃▇▅▇█▆▇█▇▆▇▆▆█▆▇▇▇█▇█▇▅▇▆▆▅▆▆▆▂</td></tr><tr><td>val_f1</td><td>▂▃▆▆▅▄▅▄▅▅▆▅▇▆██▆█▅▆▅▇██▇█▇▆▇▇▇▁█▇▃▅▇▆▇▅</td></tr><tr><td>val_loss_epoch</td><td>▇▆▅▄▄▄▂▁▄█▂▄▁▂▆▄▃▃▃▃▄▃▃▅▂▃▃▃▂▃▄▇▄▄▅▄▅▆▅▆</td></tr><tr><td>val_loss_step</td><td>▆▄▅▆▄▅▃▁▅█▃▆▂▃▄▅▅▄▄▅▅▅▂▄▃▄▄▃▃▃▆▅▅▄▅▅▅▆▆▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86895</td></tr><tr><td>train_auc</td><td>0.94419</td></tr><tr><td>train_f1</td><td>0.87358</td></tr><tr><td>train_loss_epoch</td><td>0.33748</td></tr><tr><td>train_loss_step</td><td>0.93505</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.79905</td></tr><tr><td>val_auc</td><td>0.87488</td></tr><tr><td>val_f1</td><td>0.74926</td></tr><tr><td>val_loss_epoch</td><td>0.46819</td></tr><tr><td>val_loss_step</td><td>0.37902</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/time4f39' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/time4f39</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_041558-time4f39\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b0a72ea51264e8ab50d5fae4a94c0ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_045053-xxx26pc9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/xxx26pc9' target=\"_blank\">GINConv_4_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/xxx26pc9' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/xxx26pc9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 30.9 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "33.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "33.1 K    Total params\n",
      "0.132     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▃▅▄▅▅▅▅▅▆▆▆▆▆▆▆▇▆▆▇▇▇▇▆▇▆▇▇█▇███▇████</td></tr><tr><td>train_auc</td><td>▁▃▄▄▅▅▅▆▅▅▆▆▆▆▆▇▇▆▇▆▆▇▇▇▇▇▇▇█▇█▇████████</td></tr><tr><td>train_f1</td><td>▁▃▄▄▅▄▅▅▄▅▅▅▆▆▆▆▆▆▇▅▆▇▇▇▇▆▇▆▇▇█▇▇▇█▇████</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▆▅▅▄▄▄▄▄▄▃▃▃▃▃▄▂▃▄▂▂▃▃▂▂▂▂▂▁▂▂▁▁▁▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▅▄▆▆▄▃▄▄▃▃▂▂▃▅▃▅▅▂▁▃▂▄▃▂▂▂▁▂▂▃▃▁▁▃▂▁▃▁▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▅▄▃▅▄▅▆▆▆▆▄▁▇▇▆▅▅▆█▆▇▇▇▂▇▇▆█▅▇▄▆▆▇█▇▅▆▅▅</td></tr><tr><td>val_auc</td><td>▁▄▃▆▅▄▆▇▅█▆▅▆▇█▇▅▅▇▇▇█▆▆▆▆▆█▂▆▄▅▇▆▆▇▇▅▇▆</td></tr><tr><td>val_f1</td><td>▆▄▄▇▄▇▆▇▇▇▇▁██▆▅▇▇█▆▇██▃█▇▇█▆█▄▇▇▇█▇▅▆▅▆</td></tr><tr><td>val_loss_epoch</td><td>▂▃▂▁▂▂▂▂▂▁▃▃▂▂▁▂▃▃▂▂▁▄▂▃▃▃▂▁▃▄▅▄▃▄▄▃▄▄▅█</td></tr><tr><td>val_loss_step</td><td>▃▃▃▂▃▄▃▄▄▃▄▂▃▅▃▃▄▃▁▃▂▆▂▄▂▅▃▂▃▆▅▅▅▅▃▃▂▄▅█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.90142</td></tr><tr><td>train_auc</td><td>0.9583</td></tr><tr><td>train_f1</td><td>0.90452</td></tr><tr><td>train_loss_epoch</td><td>0.2723</td></tr><tr><td>train_loss_step</td><td>0.45121</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.79905</td></tr><tr><td>val_auc</td><td>0.88859</td></tr><tr><td>val_f1</td><td>0.76056</td></tr><tr><td>val_loss_epoch</td><td>0.76446</td></tr><tr><td>val_loss_step</td><td>1.01185</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/xxx26pc9' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/xxx26pc9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_045053-xxx26pc9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbe076aba48047d698f219498974f663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_052536-hgifdqb9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hgifdqb9' target=\"_blank\">GINConv_4_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hgifdqb9' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hgifdqb9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 30.9 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "33.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "33.1 K    Total params\n",
      "0.132     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▅▅▅▆▆▆▆▆▆▆▆▇▆▇▇▆▇▇▇▇▇▇▇█▇▇▇███▇██▇█</td></tr><tr><td>train_auc</td><td>▁▄▅▅▅▅▄▄▄▆▆▅▆▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██▇████▇</td></tr><tr><td>train_f1</td><td>▁▄▅▅▆▅▆▅▆▆▆▆▆▇▆▇▇▆▇▇▆▇▇▇▇▇▇▇█▇▇▇███▇██▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▄▄▄▄▃▄▄▃▃▃▃▃▃▃▃▃▂▂▃▃▂▂▂▂▁▂▂▁▁▁▁▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▆▅▆▇▅▆▄▆▄▄▄▃▃▇▄▆▅▃▃▃▃▃▃▄▃▃▂▂▃▅▃▂▃▅▄▂▅▁▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▆▅▄▄▆▆▇▇▆▇▆▇▆▇▇▇█▇▅█▇▇▇▇▆▇▇▇▇▇▇▆▇▆█▇██</td></tr><tr><td>val_auc</td><td>▁▄▅▅▄▅▅▅▇▅▆▇▆▇▆▇█▇█▇▇▇█▇▇█▇██▇▇██▇█▇▇▇█▇</td></tr><tr><td>val_f1</td><td>▃▃▅▅▁▅▆▆▅▇▆▇▇▇▇▇███▇▇██▇▇▇▇▇▇▇▇█▇▇▇▇▇▇██</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▃▄▅▃▄▃▄▃▃▂▃▃▃▄▄▁▂▃▃▃▂▁▂▄▁▂▄▃▄▃▃▃▄▂▅▂▄</td></tr><tr><td>val_loss_step</td><td>▇▄▄▃▅▆▄▅▅▅▄▄▃▄▃▄▇█▁▃▃▇▄▂▂▃▅▂▂▆▅▄▅▃▄▇▂▅▃▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87308</td></tr><tr><td>train_auc</td><td>0.92975</td></tr><tr><td>train_f1</td><td>0.87901</td></tr><tr><td>train_loss_epoch</td><td>0.31312</td></tr><tr><td>train_loss_step</td><td>0.37001</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83688</td></tr><tr><td>val_auc</td><td>0.90081</td></tr><tr><td>val_f1</td><td>0.82078</td></tr><tr><td>val_loss_epoch</td><td>0.44631</td></tr><tr><td>val_loss_step</td><td>0.64133</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hgifdqb9' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hgifdqb9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_052536-hgifdqb9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad5e1e66c37248c5a6c74d3518bb815c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_060019-cz9cdd03</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/cz9cdd03' target=\"_blank\">GINConv_4_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/cz9cdd03' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/cz9cdd03</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 30.9 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "33.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "33.1 K    Total params\n",
      "0.132     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▅▅▆▆▆▆▆▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇█▇█▇████▇███</td></tr><tr><td>train_auc</td><td>▂▂▃▃▄▃▃▂▂▂▃▄▃▂▁▁▃▃▄▄▅▆▆▄▅▅▅▆▅▄▃▄▆▆▇██▇▆▆</td></tr><tr><td>train_f1</td><td>▁▃▅▅▆▅▆▆▆▆▆▆▆▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇█▇█▇▇███▇███</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▂▂▂▂▂▂▂▁▁▁▁▂▂▁▁▁▂▂▁▂▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▂▆▅▆▆▅▇▆▆▆▆▇▇▆▆▇▇█▆█▇▇▇█▆█▇▆▇▆▇▆▅▇▆▅▃▇▇</td></tr><tr><td>val_auc</td><td>▁▅▇▇▇▇▇▃▇▆▄█▇▃▄▄▆██▇█████████▇▇▇████████</td></tr><tr><td>val_f1</td><td>▅▁▆▄▆▆▅▇▆▆▆▆▇█▆▆▇▇█▆█▆▇▆█▆██▇▇▆▇▅▆▇▇▅▃▇█</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▂▂▁▂▁▂▁▂▂▁▁▁▂▁▂▁▁▁▂▁▁▂▁▃▂▂▂▃▃▃▂▂▃▃▃▂▂</td></tr><tr><td>val_loss_step</td><td>█▄▃▂▃▃▂▃▄▃▃▃▃▄▃▂▃▃▁▂▂▄▃▃▃▃▄▃▄▄▆▄▄▄▃▄▃▄▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87898</td></tr><tr><td>train_auc</td><td>0.74229</td></tr><tr><td>train_f1</td><td>0.88225</td></tr><tr><td>train_loss_epoch</td><td>0.27375</td></tr><tr><td>train_loss_step</td><td>0.33057</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.8156</td></tr><tr><td>val_auc</td><td>0.88352</td></tr><tr><td>val_f1</td><td>0.79793</td></tr><tr><td>val_loss_epoch</td><td>0.50863</td></tr><tr><td>val_loss_step</td><td>0.57556</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/cz9cdd03' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/cz9cdd03</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_060019-cz9cdd03\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31e94f748079498e8a82d5038a643fbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_063426-kwj17wrt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kwj17wrt' target=\"_blank\">GINConv_4_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kwj17wrt' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kwj17wrt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 30.9 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "33.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "33.1 K    Total params\n",
      "0.132     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▅▅▅▅▆▅▆▅▆▅▅▆▆▆▇▆▆▆▆▇▇▆▆█▇▇▇▇▇▆██▇████</td></tr><tr><td>train_auc</td><td>▁▃▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▆▇▇▇▇▇█▇▇█▇█▇███████</td></tr><tr><td>train_f1</td><td>▁▃▄▅▄▅▅▆▅▅▅▆▅▅▆▆▆▇▆▆▆▆▆▇▆▆█▇▇▇▆▇▆██▇████</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▅▅▄▄▄▄▄▃▄▃▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▃▂▃▁▁▁▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>▅▇▃▄▅▃▄▅▃▆▄▄█▄▃▃▄▇▃▄▂▄▇▃▃▂▂▃▂▃▃▂▂▂▂▁▁▃▂▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▂▂▅▂▅▆▅▃▂▃▄▅█▃▆▅▅▅▅▆▃▆▆▆▆▃▄▆▁▄▄▄▅▅▅▅▅▄▃</td></tr><tr><td>val_auc</td><td>▁▃▄▅▆▆▆▆▇▄▄▆▅█▅▇▇▅▆▆▇▆▆▆▇▆▂▆▅▄▅▅▄▄▅▅▅▄▃▃</td></tr><tr><td>val_f1</td><td>▃▃▁▅▂▆▆▅▂▁▅▅▅█▆▇▅▅▄▅▇▂▆▇▅▇▃▄▅▄▄▅▅▅▆▅▅▆▄▃</td></tr><tr><td>val_loss_epoch</td><td>▃▂▃▂▂▂▁▁▂▂▂▂▁▁▃▁▁▂▁▂▂▂▁▄▁▂▃▂▂█▂▃▂▃▄▂▃▅▃▃</td></tr><tr><td>val_loss_step</td><td>▄▂▅▅▅▄▃▃▄▃▄▆▃▄▄▂▂▅▃▆▃▄▂▄▄▄▃▆▁▇▅▄▂▁▃▄▅█▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.88902</td></tr><tr><td>train_auc</td><td>0.95455</td></tr><tr><td>train_f1</td><td>0.88902</td></tr><tr><td>train_loss_epoch</td><td>0.28238</td></tr><tr><td>train_loss_step</td><td>0.41177</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.78723</td></tr><tr><td>val_auc</td><td>0.87116</td></tr><tr><td>val_f1</td><td>0.75806</td></tr><tr><td>val_loss_epoch</td><td>0.48831</td></tr><tr><td>val_loss_step</td><td>0.4635</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kwj17wrt' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kwj17wrt</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_063426-kwj17wrt\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76e5ed8dde314ee79fc522da3e58e5f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.017183333334590618, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_070915-yzn0g1c4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yzn0g1c4' target=\"_blank\">GINConv_4_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yzn0g1c4' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yzn0g1c4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 30.9 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "37.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "37.3 K    Total params\n",
      "0.149     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▃▄▅▅▅▅▅▅▆▅▆▆▆▆▆▇▇▆▆▆▆▇▆▇▇▇▇▇▇▇▇██▇▇███</td></tr><tr><td>train_auc</td><td>▁▄▄▅▆▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇██▇▇███</td></tr><tr><td>train_f1</td><td>▁▂▃▄▅▅▅▅▅▅▆▅▆▆▅▅▆▇▇▆▆▆▅▇▆▇▇▇▇▇▇▇▇██▇▇███</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▅▅▅▄▄▄▄▃▄▅▄▄▃▃▃▃▃▂▃▄▃▃▃▃▂▂▂▂▃▂▂▂▂▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>▄▃▃▃▃▃▃▃▃▂▂▃█▂▃▂▂▁▃▃▂▃▄▂▃▂▂▃▂▂▃▂▂▂▂▃▁▂▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▅▁▆▆▆▇▆▇▇▅█▇▄▄▇▆▇▅▇█▇▇▆▇▄▆▇▇▆▆▇▇▅▇▆█▇▆▇▇</td></tr><tr><td>val_auc</td><td>▁▄▅▅▃▇▇▆▇▂▇▇▃▆▇▆▇▆▇█▆▇▇█▇▆▆▆▆▆▇▇▅▇▃▆▅▄▄▄</td></tr><tr><td>val_f1</td><td>▇▁▇█▇▇▇██▅█▇▅▄█▇█▅▇█▇█▇▇▇▆██▇▆██▅█▇█▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>▄▆▂▃▃▁▂▂▃▄▁▂▄▆▂▅▂▅▂▁▃▄▂▂█▅▃▃▄▃▃▅▅▄▆▄▂█▆▅</td></tr><tr><td>val_loss_step</td><td>▅▄▄▃▄▂▂▄▄▄▂▄▃█▂▅▂▆▅▁▃▅▂▂██▆▃▅▃▅▄▅▄▄▅▁▇▆▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.90201</td></tr><tr><td>train_auc</td><td>0.96358</td></tr><tr><td>train_f1</td><td>0.90326</td></tr><tr><td>train_loss_epoch</td><td>0.23938</td></tr><tr><td>train_loss_step</td><td>0.26072</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80615</td></tr><tr><td>val_auc</td><td>0.87845</td></tr><tr><td>val_f1</td><td>0.77596</td></tr><tr><td>val_loss_epoch</td><td>0.52741</td></tr><tr><td>val_loss_step</td><td>0.42002</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yzn0g1c4' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yzn0g1c4</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_070915-yzn0g1c4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51bb351404244c1184b4cfb3b1958fee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_074358-ace6imfj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ace6imfj' target=\"_blank\">GINConv_2_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ace6imfj' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ace6imfj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇███████████████████</td></tr><tr><td>train_auc</td><td>▁▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇███████████████████</td></tr><tr><td>train_f1</td><td>▁▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████▇▇█████████████</td></tr><tr><td>train_loss_epoch</td><td>█▄▃▄▃▃▃▃▃▂▃▂▂▃▂▂▂▂▂▂▂▂▂▁▂▂▂▁▂▁▁▂▂▂▁▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▄▅▅▅▅▃▂▃▃▃▅▃▆▃▅▄▄▅▅▄▄▆▃▄▃▁▃▄▄▄▅▃▃▃▂▃▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▆▅▆▇▆█▇███▇▇▇▆██▆▇███▇█▇▇█▆▆▇▇▆▆▆▇▇▇▇▆</td></tr><tr><td>val_auc</td><td>▁▄▅▅▅▇▇█▆█▇▇█▇▇███▇▆▇███▇▇▇█▆▇▇█▇▇█▇▇▇▇▆</td></tr><tr><td>val_f1</td><td>▁▅▆▅▇▇▆▇▇▇██▇██▆▇▇▇▇██▇▇▇▇▇█▆▆▇▇▆▇▅▇▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▃▃▃▃▁▃▂▁▃▁▂▂▂▃▁▃▃▁▃▂▂▂▂▃▂▃▂▂▃▅▄▃▄▄▄▄▄</td></tr><tr><td>val_loss_step</td><td>▆▃▂▃▄▄▄▁▃▅▂▄▁▂▂▂▆▃▂▄▁▃▃▂▁▃▃▃▃▃▁▃█▁▂▃▄▆▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84947</td></tr><tr><td>train_auc</td><td>0.92311</td></tr><tr><td>train_f1</td><td>0.85149</td></tr><tr><td>train_loss_epoch</td><td>0.34989</td></tr><tr><td>train_loss_step</td><td>0.31443</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.77305</td></tr><tr><td>val_auc</td><td>0.86162</td></tr><tr><td>val_f1</td><td>0.79039</td></tr><tr><td>val_loss_epoch</td><td>0.50676</td></tr><tr><td>val_loss_step</td><td>0.49119</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ace6imfj' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ace6imfj</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_074358-ace6imfj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2527f8ecdb1d473fb644d5b08e265d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333332417533, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_081744-iz2qf9yo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/iz2qf9yo' target=\"_blank\">GINConv_2_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/iz2qf9yo' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/iz2qf9yo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▇▇▇▇▇▇█▇▇▇▇█▇▇██▇▇▇█████████████████</td></tr><tr><td>train_auc</td><td>▁▅▆▇▇▇▇▇▇▇█▇▇█▇█████████████████████████</td></tr><tr><td>train_f1</td><td>▁▅▇▇▇▇▇▇▇▇█▇▇▇▇█▇█▇▇▇▇███▇██████████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▃▃▃▂▃▃▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▁▁▂▂▁▁▁▁▂▂▁▁▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▄▄▅▄▅▄▃▄▄▃▄▄▅▄▄▃▄▅▅▄▄▅▄▄▃▁▂▄▃▄▅▃▃▃▃▅▂▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▆▄▆▄▅▄▅▅▅▅▅▅▆▆▅▆▆▆▅█▇▆█▇▅▇▇▅▅███▇▅█▇▇█</td></tr><tr><td>val_auc</td><td>▁▃▅▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇█</td></tr><tr><td>val_f1</td><td>▁▄▆▅▆▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇█▇▇▇████</td></tr><tr><td>val_loss_epoch</td><td>█▅▃▃▃▄▃▃▃▄▃▃▃▃▃▂▃▂▂▄▄▂▂▂▁▂▂▂▂▂▂▂▂▁▂▄▁▂▂▁</td></tr><tr><td>val_loss_step</td><td>█▆▄▃▅▇▄▃▃█▄▃▄▄▄▃▄▄▃█▆▂▄▂▁▃▁▅▃▄▃▃▅▁▂▅▃▅▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8229</td></tr><tr><td>train_auc</td><td>0.89488</td></tr><tr><td>train_f1</td><td>0.82877</td></tr><tr><td>train_loss_epoch</td><td>0.41116</td></tr><tr><td>train_loss_step</td><td>0.47792</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80142</td></tr><tr><td>val_auc</td><td>0.89613</td></tr><tr><td>val_f1</td><td>0.81416</td></tr><tr><td>val_loss_epoch</td><td>0.42586</td></tr><tr><td>val_loss_step</td><td>0.45509</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/iz2qf9yo' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/iz2qf9yo</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_081744-iz2qf9yo\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d594d276add941549e4508b5cfcebd7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_085546-9l0xnd6u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9l0xnd6u' target=\"_blank\">GINConv_2_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9l0xnd6u' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9l0xnd6u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇██▇█▇▇████▇██</td></tr><tr><td>train_auc</td><td>▁▄▅▅▅▆▆▆▆▇▇▇▇▆▇▇▇▇▇▆▇▇▇▇▇█▇█▇▇█▇▇▇▇██▇▇▇</td></tr><tr><td>train_f1</td><td>▁▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇██▇█▇▇████▇██</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▁▂▂▁▁▁▁▁▁▁▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▅▆▅▆▆▆▆▆▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▆▆▇▆▆▇▆▇▇▆▇▇▆▅▆</td></tr><tr><td>val_auc</td><td>▅▁▅▅▅▆▆▆▆▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇█▇▆█▇▇▇▇▇▇▇▇▇▇▆▆</td></tr><tr><td>val_f1</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇██▇▇██▇██▇▇▇▇▇▇▇▇█▇▇▇▇█▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▄▂▂▃▃▂▂▃▃▂▂▁▂▁▂▃▂▁▁▁▁▂▂▁▂▂▂▂▂▁▂▃▁▂▂▃▃▃▂</td></tr><tr><td>val_loss_step</td><td>█▆▃▃▅▅▄▂▅▅▂▄▂▄▂▃▆▄▁▂▃▁▃▃▁▃▄▄▃▄▁▄▇▁▃▃▆▆▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.82231</td></tr><tr><td>train_auc</td><td>0.83032</td></tr><tr><td>train_f1</td><td>0.83156</td></tr><tr><td>train_loss_epoch</td><td>0.40643</td></tr><tr><td>train_loss_step</td><td>0.358</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.79196</td></tr><tr><td>val_auc</td><td>0.84936</td></tr><tr><td>val_f1</td><td>0.80444</td></tr><tr><td>val_loss_epoch</td><td>0.49297</td></tr><tr><td>val_loss_step</td><td>0.45627</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9l0xnd6u' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9l0xnd6u</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_085546-9l0xnd6u\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03823078ddbc4197941f58d73ccfd159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_093309-l73ti7rm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/l73ti7rm' target=\"_blank\">GINConv_2_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/l73ti7rm' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/l73ti7rm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.1 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "366a01ddeef34f24b302d2dc1a9adb77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇█▇▇▇▇██▇█▇▇▇████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███▇████▇█████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇█▇█▇▇▇▇██▇█▇▇▇████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▃▃▃▃▂▂▂▃▂▂▂▃▂▂▂▁▂▂▁▁▁▃▂▂▁▁▂▁▂▂▂▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>▇▆▅▅▅▃▃▄▃▅▄▅█▄▃▄▆▂▃▃▄▄▄▂▆▂▆▇▃▁▃▃▄▂▃▄▁▃▁▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▂▃▄▄▄▆▆▆█▆▇█▆▇▇█▆▇▇█▆▇▆▇▇▇▇▆▆▇█▇▆▇█▆▇▆▇</td></tr><tr><td>val_auc</td><td>▁▄▄▅▅▆▆▆▇▇▇▇▇█▇▇▇▇▇█▇▇▇▇███▇▇▆▇█▇█▇▇▇▇▇█</td></tr><tr><td>val_f1</td><td>▁▄▃▄▄▅▆▆▆█▆▇█▇▇▇▇▇▇▇▇▆▇▇▆▇▇█▇▇▇▇▇▇▇██▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▃▄▄▄▂▂▂▂▂▃▃▂▂▁▂▂▂▅▂▂▃▁▃▂▁▁▂▂▄▃▂▃▃▂▂▄▂▄▁</td></tr><tr><td>val_loss_step</td><td>▇▃▄▄▅▂▃▄▃▄▅▆▃▃▂▄▅▃█▅▄▅▂▆▆▁▃▂▃▅▇▄▃▄▅▅▅▃▇▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85478</td></tr><tr><td>train_auc</td><td>0.91982</td></tr><tr><td>train_f1</td><td>0.85698</td></tr><tr><td>train_loss_epoch</td><td>0.36672</td></tr><tr><td>train_loss_step</td><td>0.47255</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.79905</td></tr><tr><td>val_auc</td><td>0.87956</td></tr><tr><td>val_f1</td><td>0.80813</td></tr><tr><td>val_loss_epoch</td><td>0.43646</td></tr><tr><td>val_loss_step</td><td>0.35607</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/l73ti7rm' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/l73ti7rm</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_093309-l73ti7rm\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64773caa75de437ca487f6e9b2d106d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_100937-dj6m3fnm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/dj6m3fnm' target=\"_blank\">GINConv_2_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/dj6m3fnm' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/dj6m3fnm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.1 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "1.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06203c081e4c478ba45e11e55edd1d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▇▇▇▇▇▇█▇▇▇▇▇█▇█▇▇▇████▇▇████████████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████▇▇████████████</td></tr><tr><td>train_f1</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████▇▇████████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▅▄▄▄▅▇▅▅▄▄▅▃▅▆▄▂▄▃▄▅█▃▄▅▄▅▄▄▄▄▆▄▃▄▄▆▄▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▃▃▅▅▅▅▆▆▅▆▇▆▆▆█▇▃▆▆▆▆▅▆▇▅▆▆▅▆▅▆▇▆▇▅▆▆▆</td></tr><tr><td>val_auc</td><td>▁▄▄▅▆▆▇▆▇▇▇▇▇▇▇██▇▇▇▇▇███▇▇▇█▇█▇▇████▇█▇</td></tr><tr><td>val_f1</td><td>▁▅▃▃▅▆▆▆▇▇▇▇█▇▇▇██▆▇▆▇█▆▇▇▆█▇▅▇▇█▇▇█▆▆▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▄▅▆▄▃▃▃▃▁▂▁▂▃▄▂▂▂▆▂▂▂▁▅▁▂▃▃▂▁▅▃▂▂▂▂▃▂▂▃</td></tr><tr><td>val_loss_step</td><td>▅▃▃▆▅▄▄▃▄▂▂▂▃▄▆▄▄▃▆▃▂▃▂▇▁▂▄▃▄▂█▃▃▃▃▄▄▄▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84061</td></tr><tr><td>train_auc</td><td>0.91601</td></tr><tr><td>train_f1</td><td>0.84571</td></tr><tr><td>train_loss_epoch</td><td>0.36129</td></tr><tr><td>train_loss_step</td><td>0.2217</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.7896</td></tr><tr><td>val_auc</td><td>0.86862</td></tr><tr><td>val_f1</td><td>0.80694</td></tr><tr><td>val_loss_epoch</td><td>0.48094</td></tr><tr><td>val_loss_step</td><td>0.43057</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/dj6m3fnm' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/dj6m3fnm</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_100937-dj6m3fnm\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4a009d92bdd4709ba593abcc4e3558b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_104952-p3fvmri6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/p3fvmri6' target=\"_blank\">GINConv_2_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/p3fvmri6' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/p3fvmri6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 3.8 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▅▅▆▆▆▆▆▇▆▆▇▇▆▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇███</td></tr><tr><td>train_auc</td><td>▁▄▅▅▆▅▆▅▆▅▆▆▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇█▇█████</td></tr><tr><td>train_f1</td><td>▁▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇█▇▇▇▇▇█▇█▇███</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▅▄▄▄▄▃▄▃▃▃▃▃▃▃▃▂▂▂▂▂▃▃▂▂▂▂▃▂▂▂▂▂▁▂▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▇▅▇▇█▅▆▅▆▆▄▆▄▅▄▃▄▅▅▄▃▅▆▄▄▅▄▅▅▄▆▃▃▄▃▆▅▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▃▅▄▃▆▇█▅▃▆▇▆▃▅▅▆▅▇▅▅▄▅▆▆▁▅▆▅▆▃▆▇▄▄▃▅▅▅</td></tr><tr><td>val_auc</td><td>▁▂▃▂▅▅▅▄▇▇▅▇▇▆▇▆▇█▇▆▇▆▇▅▆▇▂▇▇▆▆▆▇▆▇█▄▇▇▆</td></tr><tr><td>val_f1</td><td>▃▁▁▇▅▄▆█▇▆▅▇▆▅▅▃▆▆▇▇▆▆▂▅▅▄▂▄▆▄▇▂▆▆▆▅▂▅▄▄</td></tr><tr><td>val_loss_epoch</td><td>▆▅▄▃▂▂▂▅▁▂▄▂▂▁█▂▃▁▆▃▂▆▁▃▃▂▇▃▃▁▄▂▃▄▁▄▃█▃▅</td></tr><tr><td>val_loss_step</td><td>▆▄▄▄▂▄▅▇▅▄▆▅▄▄▄▃▆▃▆▄▃▃▃▅▅▄▅▆▆▃▃▄▄▅▁▅▃█▃▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.88489</td></tr><tr><td>train_auc</td><td>0.94165</td></tr><tr><td>train_f1</td><td>0.88316</td></tr><tr><td>train_loss_epoch</td><td>0.2836</td></tr><tr><td>train_loss_step</td><td>0.14717</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.78014</td></tr><tr><td>val_auc</td><td>0.86916</td></tr><tr><td>val_f1</td><td>0.77482</td></tr><tr><td>val_loss_epoch</td><td>0.51436</td></tr><tr><td>val_loss_step</td><td>0.61315</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/p3fvmri6' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/p3fvmri6</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_104952-p3fvmri6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a20b3644fb2c4b319cb908bc6defa980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_112725-9xc7v4rk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9xc7v4rk' target=\"_blank\">GINConv_2_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9xc7v4rk' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9xc7v4rk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 3.8 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb6b2e2fd6ce43428a232b0a3e2e7679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▆▆▆▆▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇█▇███▇█▇▇█▇█████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇████████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██████████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▁▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▆▄▆▅▅▅▇▃▅▅▅▅▄▄▃▅▃▄▃▂▁▅▃▂▃▄▅▅▆▄▄▂▃▃▄▃▄▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▅▅▅▄▅▄▅▅▆▆▅▅▆▆▆▆▇▇▆▆▇▆▇▆▆▅▇▇▇▇▆▇▆▆▄▇█▅</td></tr><tr><td>val_auc</td><td>▁▄▅▅▅▅▅▆▆▆▇▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇█▇▇▇██▇██▇███▇</td></tr><tr><td>val_f1</td><td>▁▃▆▆▆▅▆▆▆▆▇▆▇▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇▆▇█▇</td></tr><tr><td>val_loss_epoch</td><td>█▆▄▃▃▄▃▅▄▃▃▄▄▂▃▃▄▂▂▃▂▁▃▃▃▂▄▄▃▃▁▂▃▂▂▃▅▂▁▆</td></tr><tr><td>val_loss_step</td><td>▇▇▅▃▂▄▄█▅▄▆▆▆▄▅▄▇▃▄▄▄▁▄▃▆▃▅▅▅▄▃▄▄▃▃▄▅▄▃▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8595</td></tr><tr><td>train_auc</td><td>0.93194</td></tr><tr><td>train_f1</td><td>0.86</td></tr><tr><td>train_loss_epoch</td><td>0.31584</td></tr><tr><td>train_loss_step</td><td>0.21488</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.75887</td></tr><tr><td>val_auc</td><td>0.88388</td></tr><tr><td>val_f1</td><td>0.78838</td></tr><tr><td>val_loss_epoch</td><td>0.52687</td></tr><tr><td>val_loss_step</td><td>0.56032</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9xc7v4rk' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9xc7v4rk</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_112725-9xc7v4rk\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ee71e2650444598b07cecde7328a7f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_120414-uob82vtq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/uob82vtq' target=\"_blank\">GINConv_2_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/uob82vtq' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/uob82vtq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 3.8 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "678ac7e5c51842bb8d66379adc261a94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█▇▇▇▇██▇█▇▆▇███▇█████</td></tr><tr><td>train_auc</td><td>▇▅▅▅▅▄▄▆▅▅▃▄▄▅▄▄▅▅▆▄▄▄▄▂▁▂▃▄▅▁▄▅▅█▆▄▄▄▆▅</td></tr><tr><td>train_f1</td><td>▁▄▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇██▇██▇▇███▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▄▃▃▄▃▃▃▂▃▃▃▃▃▂▂▂▂▃▂▂▂▃▃▂▂▂▂▄▂▂▃▂▂▂▂▃▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▄▅▅▆▆▆▇█▆▆▆▇▆▆▇▇▆▇▅▇▇▅▅▆▄▅▅▆▆▄▅▆▅▅▆▅▄▅</td></tr><tr><td>val_auc</td><td>▄▃▃▂▂▂▁▃▁▁▁▁▂▂▁▁▁▂▂▂▂▁▁▁▁▁▁▁▁▁▁▂▁█▃▁▁▁▁▁</td></tr><tr><td>val_f1</td><td>▂▂▃▅▅▅▆▅▇█▆▇▆▇▆▆▇▆▆▇▆▆▆▅▆▅▅▄▃▅▆▁▅▆▆▆▆▄▄▆</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▂▁▂▂▄▂▂▂▃▂▁▃▂▅▂▂▃▃▂▃▂▄▃▃▂▅▄▂▄▄▁▂▆▂▃▂▅</td></tr><tr><td>val_loss_step</td><td>▇▄▄▃▃▄▅▇▄▃▅▆▅▄▃▄█▃▄▄▃▂▆▅▇▄▄▅▆▃▁▅▆▄▁▅▃█▄▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85478</td></tr><tr><td>train_auc</td><td>0.41301</td></tr><tr><td>train_f1</td><td>0.85444</td></tr><tr><td>train_loss_epoch</td><td>0.32532</td></tr><tr><td>train_loss_step</td><td>0.16408</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.78014</td></tr><tr><td>val_auc</td><td>0.15498</td></tr><tr><td>val_f1</td><td>0.79101</td></tr><tr><td>val_loss_epoch</td><td>0.54592</td></tr><tr><td>val_loss_step</td><td>0.62581</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/uob82vtq' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/uob82vtq</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_120414-uob82vtq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52dc21639bb04c22bc671638e9768502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_124057-uepuvt47</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/uepuvt47' target=\"_blank\">GINConv_2_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/uepuvt47' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/uepuvt47</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 3.8 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.018     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1a0e5c566ba4fe2b2e820e928cfc909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▅▆▆▆▆▇▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇█▇▇███▇▇█████▇</td></tr><tr><td>train_auc</td><td>▁▅▅▆▅▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████▇▇██████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▅▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇███▇▇██████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▅▄▄▃▃▃▃▃▃▃▃▂▃▃▃▂▂▃▂▂▂▂▁▂▂▁▂▂▂▂▁▂▁▁▂▂</td></tr><tr><td>train_loss_step</td><td>██▅▆▇▆▅▇▅▄▅▂▅▅▃▄▂▆▅▅▃▄▄▃▃▃▄▁▂▁▃▂▄▃▃▃▁▂▅▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▅▇▄▇▅▇▆█▇█▇█▇█▇▇▇▇▇▇▇▇█▇▇▇▇█▆▇▆██▇▇▇▇▆</td></tr><tr><td>val_auc</td><td>▁▂▃▅▂▆▆▆▆▇▆▇█▇█▇▇▇▆▇▆▆▇▇▇▇▆▇▆▇▆▇▇▇▇█▇▇▆▆</td></tr><tr><td>val_f1</td><td>▃▃▃▆▁▇▆▇▆█▆█▇█▇▇▇▇▆▄▆▆▆▇▇▅▆▇▇▇▃█▆▆▇▇▆▅▅▅</td></tr><tr><td>val_loss_epoch</td><td>█▄█▄▅▄▃▄▃▃▂▂▄▄▆▃▄▂▃▄▄▂▃▄▁▃▅▂█▃▄▇▅▂▃▅▄▆▅▃</td></tr><tr><td>val_loss_step</td><td>▅▃█▄▄▅▁▆▄▂▃▂▄▆▆▂▆▃▃▅▄▂▄▅▂▂▇▂█▃▄▄▅▃▂▅▃▅▅▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86364</td></tr><tr><td>train_auc</td><td>0.93951</td></tr><tr><td>train_f1</td><td>0.86467</td></tr><tr><td>train_loss_epoch</td><td>0.31634</td></tr><tr><td>train_loss_step</td><td>0.38213</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.77069</td></tr><tr><td>val_auc</td><td>0.86453</td></tr><tr><td>val_f1</td><td>0.77283</td></tr><tr><td>val_loss_epoch</td><td>0.46226</td></tr><tr><td>val_loss_step</td><td>0.33168</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/uepuvt47' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/uepuvt47</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_124057-uepuvt47\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "258abae8a39b4afcbe793c76cf01987c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_131527-zu6wzt8f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zu6wzt8f' target=\"_blank\">GINConv_2_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zu6wzt8f' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zu6wzt8f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 3.8 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "5.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.4 K     Total params\n",
      "0.022     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▅▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇█▇▇██▇▇▇▇▇███████████</td></tr><tr><td>train_auc</td><td>▁▅▅▅▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇█▇██▇▇███████████</td></tr><tr><td>train_f1</td><td>▁▅▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇▇▇███████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▄▄▄▄▄▃▃▃▃▂▃▂▃▂▂▂▂▂▂▁▂▂▂▂▂▁▂▁▂▂▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▆▃▆▄█▆▃▃▄▄▄▃▃▄▆▂▃▃▂▂▁▃▄▄▄▃▃▁▃▂▃▃▁▃▄▄▃▆</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▅▅▇▅▇▆▇▆▇▇▇▇▇▇▇▆▇▇█▇▇▅▇▇▆▆▇▆▅▆█▆▆▆▇▇▆▇</td></tr><tr><td>val_auc</td><td>▁▂▃▅▅▄▇▅▆▆▇██▇▆▇▇█▇█████▆▇▅██▅▅▇█▅█▇▇▇▆▇</td></tr><tr><td>val_f1</td><td>▂▁▃▅▆▄▇▃█▆▇▇▆█▆▇█▆▆▆█▇▄▆▆▇▆▃▇▅▄▆▇▆▆▆▇▆▅▇</td></tr><tr><td>val_loss_epoch</td><td>█▇▅▂▄▄▂▂▃▃▁▂▁▂▁▄▄▃▂▂▃▄▃▇▅▇▃▃▃▆▄▄▂▅▇▃▅▃▅▅</td></tr><tr><td>val_loss_step</td><td>▇▄▆▂▅▆▃▁▅▅▂▄▃▃▂▆▃▂▃▃▄▅▅▄▆█▄▅▃▇▅▄▂▂▇▂▂▄▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87249</td></tr><tr><td>train_auc</td><td>0.93784</td></tr><tr><td>train_f1</td><td>0.87383</td></tr><tr><td>train_loss_epoch</td><td>0.31697</td></tr><tr><td>train_loss_step</td><td>0.47081</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.78723</td></tr><tr><td>val_auc</td><td>0.87341</td></tr><tr><td>val_f1</td><td>0.79911</td></tr><tr><td>val_loss_epoch</td><td>0.52104</td></tr><tr><td>val_loss_step</td><td>0.50463</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zu6wzt8f' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/zu6wzt8f</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_131527-zu6wzt8f\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0bd622cf99042e3a5444e3aff4b3433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_134957-m5jnomkh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/m5jnomkh' target=\"_blank\">GINConv_2_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/m5jnomkh' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/m5jnomkh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 13.8 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.9 K    Total params\n",
      "0.064     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "174c4c284aed43d7b8050b4d96b062cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▄▅▄▅▅▅▆▅▅▅▆▆▆▆▆▆▆▇▇▆▆▇▇▆▇▇▇▇▇▇▇▇███▇█</td></tr><tr><td>train_auc</td><td>▁▄▄▄▅▄▅▅▆▆▆▆▆▆▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇███▇█</td></tr><tr><td>train_f1</td><td>▁▃▄▄▅▄▅▅▅▆▅▅▅▆▆▆▆▆▆▆▇▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▆▆▅▅▄▄▄▄▄▄▄▄▃▃▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▅█▆▇█▅▆▅▇█▄▄▄▅▇▅▄▅▄▃▂▅▂▃▄▄▃▄▅▃▃▆▃▄▃▃▂▁▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▄▁▄▆▇▇█▇▅█▇▆▇▇▇▄▇▆▇▃▄▆▄▅▅▁▅▅▇▆▇▄▄▄▃▅▅▄▇▄</td></tr><tr><td>val_auc</td><td>▂▂▄▆▇▆▇█▇▇▇██▆▅▄▇▇▆▆▇▇▃▄▆▁▅▅▆▄▇▅▅▃▃▅▅▄▆▅</td></tr><tr><td>val_f1</td><td>▅▁▄▇▇▇█▇▇█████▇▅▇▇▇▂▇▇▅▆▆▄▇▆▇▇▇▆▅▆▅▇▅▆▇▅</td></tr><tr><td>val_loss_epoch</td><td>▃▅▃▂▂▂▂▁▃▂▂▃▁▃▃▃▂▂▃▃▆▆▃▅▃▅▃▄▃▅▆▄▄▆▅▇▇█▇▄</td></tr><tr><td>val_loss_step</td><td>▃▂▂▂▃▂▂▂▃▂▂▂▁▃▃▄▂▂▃▃▃▅▃▄▂▂▂▄▃▃▅▃▂▅▃▅▄█▆▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.90083</td></tr><tr><td>train_auc</td><td>0.96711</td></tr><tr><td>train_f1</td><td>0.90059</td></tr><tr><td>train_loss_epoch</td><td>0.23274</td></tr><tr><td>train_loss_step</td><td>0.26803</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.76123</td></tr><tr><td>val_auc</td><td>0.85229</td></tr><tr><td>val_f1</td><td>0.76235</td></tr><tr><td>val_loss_epoch</td><td>0.57283</td></tr><tr><td>val_loss_step</td><td>0.27116</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/m5jnomkh' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/m5jnomkh</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_134957-m5jnomkh\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ee47082fe8140f8b8eea642d77dcfb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333332417533, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_142446-tzqhvnq5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tzqhvnq5' target=\"_blank\">GINConv_2_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tzqhvnq5' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tzqhvnq5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 13.8 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.9 K    Total params\n",
      "0.064     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0292a3fffe5b4b3d9de3fd50a193f2c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇███▇██▇█</td></tr><tr><td>train_auc</td><td>▁▅▅▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇████▇████████</td></tr><tr><td>train_f1</td><td>▁▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇███▇██▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▅▄▄▃▄▃▄▃▃▃▃▃▃▂▂▃▂▂▂▂▂▂▃▂▂▂▂▂▁▁▁▂▂▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▆█▅▆▆▅▅▄▇▅▄▄▃▄▄▄▃▃▄▄▂▄▁▂▃▃▂▂▄▃▃▄▃▂▃▁▂▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▂▅▅▅▆▆▃█▆▆▇▆▅▅█▇▇▅▆▆▄▃▇▆▆▆▇▇▇▇▅▇▇▃▅▇▅▇</td></tr><tr><td>val_auc</td><td>▁▅▅▇▆▇▇▇▇▇█▇███▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇</td></tr><tr><td>val_f1</td><td>▁▃▄▆▅▆▆▇▅█▇▅█▇▇▇█▆▇▇▇▆▆▅▇▇▇▆▇▆▆▇▆▇▇▆▆▇▆▇</td></tr><tr><td>val_loss_epoch</td><td>▄▂▂▂▂▂▂▂▃▂▁▂▁▂▃▄▂▂▂▂▃▂▂▅▂▂▂▃▂▂▃▂▃▃▃█▃▅▃▂</td></tr><tr><td>val_loss_step</td><td>▃▂▂▃▃▃▃▂▃▃▁▂▁▂▄▅▃▂▃▂▂▃▁▃▂▁▁▃▃▃▄▃▂▃▂█▄▇▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.90378</td></tr><tr><td>train_auc</td><td>0.96671</td></tr><tr><td>train_f1</td><td>0.9044</td></tr><tr><td>train_loss_epoch</td><td>0.22824</td></tr><tr><td>train_loss_step</td><td>0.158</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81087</td></tr><tr><td>val_auc</td><td>0.88164</td></tr><tr><td>val_f1</td><td>0.81132</td></tr><tr><td>val_loss_epoch</td><td>0.46811</td></tr><tr><td>val_loss_step</td><td>0.25634</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tzqhvnq5' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tzqhvnq5</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_142446-tzqhvnq5\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad681a9d04874bc292b5f0ad87caf63e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_150247-td8el6f2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/td8el6f2' target=\"_blank\">GINConv_2_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/td8el6f2' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/td8el6f2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 13.8 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.9 K    Total params\n",
      "0.064     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba9f0a5951f4aae9d6aef90c866d18c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▅▆▅▆▆▆▆▆▆▆▇▆▆▆▇▇▇▇▇▇▇▇█▇▇▇████▇▇▇████</td></tr><tr><td>train_auc</td><td>▆▆▄▃▃▃▄▄▃▄▄▄▄▄▄▄▅▆▅▅▅▃▄▄▃▄▃▂▃▂▁▄▄▅▅▅▅▅▇█</td></tr><tr><td>train_f1</td><td>▁▃▅▆▆▅▆▆▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇█▇▇█████▇▇▇████</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▃▁▁▂▂▁▂▂▂▂▂▁▂▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▂▄▅▆▆▆▆▆▇▆▇▆▆▆▆▁▇▆▄▅▇▅▇▇▆▆▆▆▇██▇▅▆▇▆▅▆▇▆</td></tr><tr><td>val_auc</td><td>▇▇▇▅▅▅▇▇▇▇▇▇██▇▇██▆▇█▆▇▇▇▇▃▃▂▂▁▅▇██▇▇███</td></tr><tr><td>val_f1</td><td>▂▁▃▄▃▄▅▅▇▅▇▄▆▆▆▃▅▃▅▅▆▂▆▆▂▆▆▃▆▇█▅▅▆▆▆▂▅▇▅</td></tr><tr><td>val_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▃▁▁▂▁▁▂▁▁▁▁▁▂▁▁▂▁▁▂▂▁▂▂▁▁</td></tr><tr><td>val_loss_step</td><td>▅▃▂▄▄▃▃▂▃▃▂▃▂▄▄█▂▂▄▃▂▇▂▄▃▂▃▅▅▃▆▃▂▅▃▄▄▇▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.866</td></tr><tr><td>train_auc</td><td>0.82863</td></tr><tr><td>train_f1</td><td>0.86795</td></tr><tr><td>train_loss_epoch</td><td>0.30495</td></tr><tr><td>train_loss_step</td><td>0.19337</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.78251</td></tr><tr><td>val_auc</td><td>0.842</td></tr><tr><td>val_f1</td><td>0.78095</td></tr><tr><td>val_loss_epoch</td><td>0.50436</td></tr><tr><td>val_loss_step</td><td>0.2404</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/td8el6f2' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/td8el6f2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_150247-td8el6f2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74850998a0494a0f9ac67479f9ab8121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_154331-dfgy0wie</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/dfgy0wie' target=\"_blank\">GINConv_2_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/dfgy0wie' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/dfgy0wie</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 13.8 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "16.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "16.0 K    Total params\n",
      "0.064     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4935eaa391b49e1aebc98176b5dfef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▅▆▆▆▆▇▆▇▆▇▇▇▇██▇▇█▇▇█▇██</td></tr><tr><td>train_auc</td><td>▁▄▄▅▅▅▅▅▆▆▅▆▇▆▆▆▆▇▇▇▇▇▇▇▆▇▇▇▇██▇▇██▇████</td></tr><tr><td>train_f1</td><td>▁▄▄▅▄▄▅▅▅▅▅▆▆▆▆▆▅▇▆▆▆▇▆▇▆▇▇▇▇██▇▇█▇▇█▇██</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▅▅▅▄▄▄▄▅▄▃▄▃▄▄▃▃▄▃▃▃▃▃▂▂▃▂▁▂▂▃▂▂▂▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▄▅▄▆▄▃▃▄▄▃▄▄▃▃▅▁▃▃▄▃▄▃▃▃▃▅▂▂▃▁▃▁▃▃▁▃▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▃▃▇▂▇▁▇██▅█▄▆▆▇▆▇▇▆▆▆▅▄▆▇▆▅▄▆▄▅▆▆▆▃▃▅▅▃▄</td></tr><tr><td>val_auc</td><td>▁▂▅▂▇▇▆▇▆▇▇█▇▆▆▇▆▇▇▇▇▄▅▄▆▇▆▄▆▅▆▅▅▇▄▃▅▅▁▄</td></tr><tr><td>val_f1</td><td>▅▁▆▁▇▅▇▇█▇█▇▇▇▆▇▇█▆▅▇▆▅▆▆▇▆▃▇▅▃▆▇▅▅▅▆▆▃▆</td></tr><tr><td>val_loss_epoch</td><td>▄▅▂▄▂▅▂▂▁▃▁▅▄▃▃▃▂▃▃▃▅▆▂▆▁▅▄▅▄▄▅▄▄▄▇▇▇▅██</td></tr><tr><td>val_loss_step</td><td>▄▃▄▄▄▅▃▄▂▃▄▅▄▃▅▃▂▄▃▅▇█▁▇▃▄▅▂▃▄▅▃▂▃▆▇▆▁▃▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.91086</td></tr><tr><td>train_auc</td><td>0.96914</td></tr><tr><td>train_f1</td><td>0.91049</td></tr><tr><td>train_loss_epoch</td><td>0.23181</td></tr><tr><td>train_loss_step</td><td>0.24937</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.76832</td></tr><tr><td>val_auc</td><td>0.85256</td></tr><tr><td>val_f1</td><td>0.78696</td></tr><tr><td>val_loss_epoch</td><td>0.66151</td></tr><tr><td>val_loss_step</td><td>0.73308</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/dfgy0wie' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/dfgy0wie</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_154331-dfgy0wie\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dd73bd4cc0545d0add0c483ef50bec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.017200000000108653, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_162245-0ffg5d75</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0ffg5d75' target=\"_blank\">GINConv_2_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0ffg5d75' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0ffg5d75</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 13.8 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "20.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.1 K    Total params\n",
      "0.080     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▅▅▅▅▅▅▆▆▅▆▆▆▅▆▇▆▆▇▇▆▇▇▇▇▆▇▇██▇▇████▇</td></tr><tr><td>train_auc</td><td>▁▄▅▅▅▆▆▆▅▅▆▆▅▆▆▇▆▇▇▇▇▇▇▇▇▇▇█▇▇▇██▇██████</td></tr><tr><td>train_f1</td><td>▁▄▅▅▅▅▆▅▅▅▆▆▅▆▆▆▆▆▇▇▇▇▇▆▇▇▇▇▆▇▇██▇▇████▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▅▅▄▅▅▅▄▄▅▃▄▃▄▃▂▃▃▃▃▃▂▃▃▂▃▃▂▁▁▃▂▁▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>▆▇▅▄▆▅▅█▆▅▂▆▇▅▅▃▄▃▄▄▄▄▂▃▄▄▂▂▂▂▃▂▂▃▃▂▂▁▃▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▂▃▅█▁▄▅▂▂▇▅▄▄█▁▅▅▅█▆▅▅▅▆▆▅▅▇▆▂▄▄▄▂▁▂▁▂▅</td></tr><tr><td>val_auc</td><td>▁▃▃▆█▃▇▆▄▇▇▆▇▅▇▄▆█▆▇▆▆▆▆▇▆▆▆▇▅▄▃▅▅▆▅▂▆▃▅</td></tr><tr><td>val_f1</td><td>▄▃▆▅▇▃▇▇▆▆█▆▇▇▇▆▇▇▅█▆▇▇▆▇█▇▆▇▇▃▆▆▆▆▆▄▁▅▇</td></tr><tr><td>val_loss_epoch</td><td>▃▄▃▄▂▃▃▅▃▄▁▂▄▄▂█▂▂▃▃▄▃▄▂▂▄▄▃▂▃▄█▆▅▇▆▇▆█▆</td></tr><tr><td>val_loss_step</td><td>▃▃▄▄▄▄▃▅▅▃▁▃▆▄▃▅▃▃▃▄▄▃▄▂▁▃▅▂▃▄▄█▄▆▂▂▆▃▇▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.89079</td></tr><tr><td>train_auc</td><td>0.95762</td></tr><tr><td>train_f1</td><td>0.8915</td></tr><tr><td>train_loss_epoch</td><td>0.26573</td></tr><tr><td>train_loss_step</td><td>0.37057</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.78723</td></tr><tr><td>val_auc</td><td>0.86191</td></tr><tr><td>val_f1</td><td>0.79545</td></tr><tr><td>val_loss_epoch</td><td>0.59302</td></tr><tr><td>val_loss_step</td><td>0.69158</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0ffg5d75' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0ffg5d75</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_162245-0ffg5d75\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3db9045b38574a21b9d9fab0109f4542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_170024-yjcsle6i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yjcsle6i' target=\"_blank\">GINConv_3_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yjcsle6i' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yjcsle6i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.7 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▇▇▇▇▇▇▇█▇█▇▇▇████▇███▇█▇███▇████████</td></tr><tr><td>train_auc</td><td>▁▆▆▆▇▇▇▇▇▇▇▇▇█▇▇▇██▇███████▇████████████</td></tr><tr><td>train_f1</td><td>▁▆▇▇▇▇▇▇▇▇▇███▇▇▇████▇█████▇███▇████████</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▃▃▃▃▃▃▂▂▃▃▂▂▂▂▂▂▂▂▂▂▁▂▂▁▂▂▂▂▂▁▂▂▂▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▄▅▆▃▅▄▆▄▄▄█▄▄▄▃▅▃▂▅▃▄▃▄▃▃▁▄▄▃▃▅▄▃▃▄▃▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▄▇▇▆▆▇▇▇█▇███▇▆███▆▇▇▇▇▇▇▆█▇▆▇▆▇▇▇▅▇██</td></tr><tr><td>val_auc</td><td>▁▃▄▆▆▇▆▆█▇█▇▇█▇█▇▇██▇▇▇▇▇█▇▆▇▇▇▇▆█▇▇▃▇██</td></tr><tr><td>val_f1</td><td>▂▁▄▆▆▆▆▅▇█▇▆▆▇▇▆▇▇██▄▆▇▆▆▅▇▅█▇▆▆▅▇▇▇▃▆█▇</td></tr><tr><td>val_loss_epoch</td><td>█▆▄▃▄▃▃▃▂▂▂▂▃▂▂▁▄▃▂▁▂▂▃▃▃▂▂▄▃▂▃▂▃▂▃▂▆▂▂▁</td></tr><tr><td>val_loss_step</td><td>█▆▄▃▅▄▄▅▃▃▄▂▆▅▄▁▆▄▃▁▃▄▆▄▃▃▂▄▆▃▄▃▄▄▅▂█▄▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84475</td></tr><tr><td>train_auc</td><td>0.91707</td></tr><tr><td>train_f1</td><td>0.84611</td></tr><tr><td>train_loss_epoch</td><td>0.36986</td></tr><tr><td>train_loss_step</td><td>0.31509</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.79905</td></tr><tr><td>val_auc</td><td>0.87971</td></tr><tr><td>val_f1</td><td>0.79518</td></tr><tr><td>val_loss_epoch</td><td>0.42744</td></tr><tr><td>val_loss_step</td><td>0.40365</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yjcsle6i' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yjcsle6i</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_170024-yjcsle6i\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "470e85febeac41ab8d6bb1392f3df18a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_173831-8emc1kau</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8emc1kau' target=\"_blank\">GINConv_3_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8emc1kau' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8emc1kau</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.7 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cb70704953a4a2998c6fded36efb1c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇█▇█▇█▇▇█████▇▇███████</td></tr><tr><td>train_auc</td><td>▁▅▆▇▇▇▇▇▇▇▇▇██▇▇▇███▇███▇███████████████</td></tr><tr><td>train_f1</td><td>▁▆▇█▇▇▇▇▇▇███▇▇████████████████▇████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▃▃▃▂▂▂▂▂▂▁▂▂▂▁▂▁▂▁▁▁▂▁▁▁▂▂▁▂▁▂▂▂▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▅▅▆▃▅▅▅▄▄▄▅▄▅▄▄▄▄▃▆▃▃▄▅▃▅▁▃▄▃▃▅▄▃▄▄▄▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▆▅▆▅▄▅▅▆▆▇▅█▂▅▆▆▅▇▅▆▆▆▆▆▆▇▆▆▅▅█▇▇▆▆▆▆▇</td></tr><tr><td>val_auc</td><td>▁▃▅▄▆▆▅▆▆▇▆▇▆▇▇▇▆▇▇▇▆▇▇▇▇▇▇▆▇█▇▇█████▇█▇</td></tr><tr><td>val_f1</td><td>▂▁▄▃▆▆▅▆▅▆▅▇▅▇▅▆▆▆▆▇▆▇▆▇▆▆▇▆▇▇▇▇█▇█▇▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▃▃▃▄▃▂▁▂▁▂▂▄▂▂▂▂▂▂▂▂▁▁▃▁▂▄▁▃▂▁▁▂▁▄▄▃▂</td></tr><tr><td>val_loss_step</td><td>█▅▄▄▅▅▆▅▄▂▂▂▄▄▆▄▅▄▂▁▄▂▃▂▂▆▂▂▇▂▅▄▃▂▅▁▆▇▅▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.82763</td></tr><tr><td>train_auc</td><td>0.90242</td></tr><tr><td>train_f1</td><td>0.83409</td></tr><tr><td>train_loss_epoch</td><td>0.3986</td></tr><tr><td>train_loss_step</td><td>0.31112</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.74704</td></tr><tr><td>val_auc</td><td>0.85571</td></tr><tr><td>val_f1</td><td>0.77185</td></tr><tr><td>val_loss_epoch</td><td>0.48781</td></tr><tr><td>val_loss_step</td><td>0.43976</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8emc1kau' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8emc1kau</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_173831-8emc1kau\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cff49b91b9aa404ca872215f5d741b09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333332417533, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_181907-p6eas8a7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/p6eas8a7' target=\"_blank\">GINConv_3_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/p6eas8a7' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/p6eas8a7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.7 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9603726735d48bc81d0b205aab31ed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇████████████</td></tr><tr><td>train_auc</td><td>▁▂▄▅▆▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇█▇▇█▇█▇██▇███████</td></tr><tr><td>train_f1</td><td>▁▄▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇████████████</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▂▂▂▁▁▂▂▂▁▂▂▁▁▁▁▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▆▇▇▇▇▇█▇████▇██▇▇▇▇▇▇██████▇▇▇▇█▇█▇▇█▇</td></tr><tr><td>val_auc</td><td>▁▆▆▇▇▇▇▇█▇▇███████▇█████████████████▇███</td></tr><tr><td>val_f1</td><td>▁▄▅▆▆▆▇▆▇▇▇▇█▇▇▇█▆▇▆▆▇▇▇▇▇▇▇█▆▇▇▆▇▆▇▆▇█▇</td></tr><tr><td>val_loss_epoch</td><td>█▂▂▂▂▂▂▂▁▂▂▁▁▂▂▁▂▂▂▁▁▁▂▂▂▂▁▂▁▁▂▁▂▁▁▁▃▂▁▂</td></tr><tr><td>val_loss_step</td><td>█▃▃▂▃▃▃▃▃▃▃▂▃▃▃▂▄▃▄▁▃▃▄▃▂▃▂▂▃▂▃▃▃▃▂▂▅▄▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.82586</td></tr><tr><td>train_auc</td><td>0.87389</td></tr><tr><td>train_f1</td><td>0.82799</td></tr><tr><td>train_loss_epoch</td><td>0.39711</td></tr><tr><td>train_loss_step</td><td>0.31834</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.78723</td></tr><tr><td>val_auc</td><td>0.86077</td></tr><tr><td>val_f1</td><td>0.79358</td></tr><tr><td>val_loss_epoch</td><td>0.49529</td></tr><tr><td>val_loss_step</td><td>0.52751</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/p6eas8a7' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/p6eas8a7</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_181907-p6eas8a7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8dfb70425e943669cf73ec1ce934f76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.017183333332650364, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_190028-0z40ykcu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0z40ykcu' target=\"_blank\">GINConv_3_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0z40ykcu' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0z40ykcu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.7 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4c22b8982ec452ca6f294ad1d2623bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▆▇▇▇▇▇▇▇▇█▇▇▇▇█▇████▇██▇████████████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇█▇█▇██▇████▇█████▇█████████</td></tr><tr><td>train_f1</td><td>▁▇▆▇▇▇▇▇▇▇▇▇▇█▇▇███▇████▇███████████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▄▃▃▂▃▂▃▃▂▂▂▂▂▂▂▂▂▁▁▁▂▁▁▂▂▁▂▂▁▂▁▁▂▁▁▂</td></tr><tr><td>train_loss_step</td><td>▇▆▄▄▆▅▅▃▄▃▆▃▃▂▄▃▁▁▃▃▂▄▂▂▃▂▃▅▅▃▄▃▂▃▂▂▄▃▄█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▆▇▇▆███▇▇▇██▇▇▇▇███▇▇▆▆██▇▇█▇███▇▇▇▇▇▇</td></tr><tr><td>val_auc</td><td>▁▄▅▅▆▆▇▇▆▆▆▇▇█▇▆▇██▇██▇▆▆▇▇▇█▇██▇▇▇▇▇▇█▇</td></tr><tr><td>val_f1</td><td>▁▁▄▄▆▅█▇▆▇▇▇▇▆▇▆▇█▇██▇▆▅▆▇▇▅▄▇▆██▇█▄▇█▅▇</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▄▂▂▂▃▃▃▂▂▂▂▃▄▂▃▁▂▂▂▁▅▃▃▁▁▂▂▂▁▃▂▂▃▁▃▁▂</td></tr><tr><td>val_loss_step</td><td>█▇▆▅▄▁▄▆▇▄▄▄▅▅▇█▃▅▄▄▄▆▃▆▃▇▃▃▇▃▅▃▆▆▂█▂▄▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84829</td></tr><tr><td>train_auc</td><td>0.9168</td></tr><tr><td>train_f1</td><td>0.85067</td></tr><tr><td>train_loss_epoch</td><td>0.39022</td></tr><tr><td>train_loss_step</td><td>0.66785</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.7896</td></tr><tr><td>val_auc</td><td>0.87721</td></tr><tr><td>val_f1</td><td>0.80089</td></tr><tr><td>val_loss_epoch</td><td>0.4494</td></tr><tr><td>val_loss_step</td><td>0.4299</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0z40ykcu' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0z40ykcu</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_190028-0z40ykcu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b998110d9ca04773b94b0531fe3c2a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.017200000000108653, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_193803-ud9q1s2t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ud9q1s2t' target=\"_blank\">GINConv_3_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ud9q1s2t' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ud9q1s2t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.7 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "2.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.2 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "248973c6d3904c4485e4405c068b284f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇███████▇████▇██▇█</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇████████▇██████▇█</td></tr><tr><td>train_f1</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇█▇███████▇█████████</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▃▃▃▃▃▃▂▃▂▂▃▂▂▂▃▂▂▂▂▂▂▁▁▁▁▁▁▂▂▁▂▁▁▁▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▆▆▄▆▃▅▄▅▄▅▅▃▃▃▃▃▆▄▄▄▃▂▅▅▄▅▁▂▄▄▃▃▃▃▃▄▄▅▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▆▅▆▇▇▇▇▇▇▇▇▇▇██▇▇▇▆▇▇█▇▇▇▇▇▆▇▇▇▆▇▇▇█▇▇</td></tr><tr><td>val_auc</td><td>▁▃▅▅▆▆▆▇▆▇▆▇▇▇▇█▇▇▇▇▅▇▇█▇▇▇▇▇▇█▇█▇▇▇▇▇▇▇</td></tr><tr><td>val_f1</td><td>▂▁▃▄▄▇▇█▇▇▆▇▆▆▆▇█▆▇▆▅▇▅██▆▇▆▇▄▅▆▇▆▅▅▆▇▅▆</td></tr><tr><td>val_loss_epoch</td><td>█▅▄▃▃▃▃▃▂▃▂▃▃▁▂▂▂▃▄▂▃▁▂▁▂▂▄▃▂▂▃▃▂▃▄▄▂▂▂▂</td></tr><tr><td>val_loss_step</td><td>▇▅▅▄▆▅▄▆▄▅▄▄▆▁▅▄▃▄█▄▃▂▁▃▃▂▆▄▂▂█▅▄▃██▃▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84357</td></tr><tr><td>train_auc</td><td>0.92408</td></tr><tr><td>train_f1</td><td>0.85087</td></tr><tr><td>train_loss_epoch</td><td>0.3562</td></tr><tr><td>train_loss_step</td><td>0.35299</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.77778</td></tr><tr><td>val_auc</td><td>0.86947</td></tr><tr><td>val_f1</td><td>0.78539</td></tr><tr><td>val_loss_epoch</td><td>0.4659</td></tr><tr><td>val_loss_step</td><td>0.42554</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ud9q1s2t' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ud9q1s2t</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_193803-ud9q1s2t\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "446a5eab8df249d09f3739c61a1c44d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_201519-8lw6ogze</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8lw6ogze' target=\"_blank\">GINConv_3_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8lw6ogze' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8lw6ogze</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 6.0 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "6.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.6 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25b3029ceabe491a97c7d2f4d3e68ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▆▆▆▆▇▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇██▇██▇█</td></tr><tr><td>train_auc</td><td>▁▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇██████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇█████▇██▇█</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▃▂▃▃▂▂▃▂▂▂▂▂▂▂▂▂▂▁▂▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▆█▆▅▆▅▇▅▅▆▅▃▃▆▅▅▂▄▃▇▆▇▃▃▆▄▇▆▃▆▅▃▂▃▃▄▃▄▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▆▇▆▇▅█▇▆▇▆▇▆▇▇▇███▇▇▇▇▇▇█▇▆▇▆█▇▇▇▇█▇▇▇</td></tr><tr><td>val_auc</td><td>▁▅▄▅▅▆▄▆▆▇▆▇▆▇▆▆▆▇▆▆█▇█▇█▇██▃▇▇▇▆▆▅▆▇▆▇▇</td></tr><tr><td>val_f1</td><td>▁▅▇█▆█▆█▇▇█▆█▇▇█▇████▇▇█▇▇██▇▇▆█▇█▇██▇▇█</td></tr><tr><td>val_loss_epoch</td><td>▇▆▃▁▄▂▃▂▃▁▂▃▁▂▄▂▃▁▆▃▃▅▃▂▂▄▁▃▅▂▆▅▂▆▄▆▇▆▄█</td></tr><tr><td>val_loss_step</td><td>▄▃▃▁▃▄▃▂▅▃▃▃▂▃▅▂▄▁▆▃▄▄▄▄▄▂▂▃▃▃▂▄▂▆▂█▅▃▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.89374</td></tr><tr><td>train_auc</td><td>0.95101</td></tr><tr><td>train_f1</td><td>0.8926</td></tr><tr><td>train_loss_epoch</td><td>0.27247</td></tr><tr><td>train_loss_step</td><td>0.16771</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.76832</td></tr><tr><td>val_auc</td><td>0.86408</td></tr><tr><td>val_f1</td><td>0.78788</td></tr><tr><td>val_loss_epoch</td><td>0.62323</td></tr><tr><td>val_loss_step</td><td>0.62789</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8lw6ogze' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8lw6ogze</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_201519-8lw6ogze\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48f4187debb245a1961e3ed2d9f8b0f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_205253-hu08f8to</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hu08f8to' target=\"_blank\">GINConv_3_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hu08f8to' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hu08f8to</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 6.0 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "6.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.6 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "618d8373166c46a8b79858bf4bc631f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇███████████▇█</td></tr><tr><td>train_auc</td><td>▁▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██▇████████████████████</td></tr><tr><td>train_f1</td><td>▁▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇██████████████▇█</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▂▁▁▂▂▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▇▅▅▆▄▅▄▄▅▅▃▃▄▄▄▂▂▂▅▄▄▃▄▄▃▁▃▃▄▄▂▃▃▂▃▃▄▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▅▅▆▆▆▆▆▇▅▇▇▇▇▇█▇▇▇▅██▆█▆▇▇█▇▇▇█▇█▇▆█▇▇</td></tr><tr><td>val_auc</td><td>▁▃▅▄▅▅▆▆▆▇▇▇▇▇▇▇█▇▇▇▇██▇█▇▇███▇██▇▇▇▇█▇▇</td></tr><tr><td>val_f1</td><td>▁▄▆▇▇▇▇▇▇▇▇███▇██▇██▇██▇█▇███▇██████▇███</td></tr><tr><td>val_loss_epoch</td><td>█▇▄▄▃▃▂▂▄▂▄▃▂▂▃▂▁▂▃▂▇▂▂▄▂▄▂▂▃▁▁▂▁▄▂▄▄▂▅▃</td></tr><tr><td>val_loss_step</td><td>▇▅▅▄▄▅▄▃▇▅▇▆▄▄▇▄▃▁▅▃█▅▃▅▄▅▄▄▅▃▁▅▁▆▁█▅▃█▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85714</td></tr><tr><td>train_auc</td><td>0.93256</td></tr><tr><td>train_f1</td><td>0.85864</td></tr><tr><td>train_loss_epoch</td><td>0.32188</td></tr><tr><td>train_loss_step</td><td>0.23032</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.78251</td></tr><tr><td>val_auc</td><td>0.88108</td></tr><tr><td>val_f1</td><td>0.79646</td></tr><tr><td>val_loss_epoch</td><td>0.48133</td></tr><tr><td>val_loss_step</td><td>0.53476</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hu08f8to' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hu08f8to</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_205253-hu08f8to\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3756fbd775348a49163b9f4463c126d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_212853-dk53l6d9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/dk53l6d9' target=\"_blank\">GINConv_3_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/dk53l6d9' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/dk53l6d9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 6.0 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "6.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.6 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae11a3813fde4913aae33dcb9b1e3cb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇████</td></tr><tr><td>train_auc</td><td>██▅▃▃▃▄▄▄▂▃▃▃▄▄▅▃▃▃▃▂▃▃▄▂▂▂▄▄▃▂▂▁▂▂▂▃▂▂▃</td></tr><tr><td>train_f1</td><td>▁▃▄▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇████</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▁▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▇▇▇▇▇█▇▇▇▇███▇███▇▇██▇▇████▇▇█▇▇█▇█▆▇█</td></tr><tr><td>val_auc</td><td>▇█▂▂▁▁▁▂▂▁▁▁▁▁▂▁▁▁▁▁▁▂▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_f1</td><td>▁▃▅▅▆▆▇▇█▆█▆█▇▇▆█▇█▅▇██▇▆▇▇█▇▇▆█▆▇█▅█▄▅█</td></tr><tr><td>val_loss_epoch</td><td>█▂▂▁▁▁▁▂▂▁▂▂▂▁▂▂▁▁▂▂▂▁▂▂▂▁▁▁▁▂▂▂▂▂▂▂▁▂▂▃</td></tr><tr><td>val_loss_step</td><td>█▂▂▁▂▃▂▂▄▃▄▃▃▂▄▁▃▁▅▃▄▃▃▃▄▁▂▂▃▂▁▂▂▄▁▄▂▄▇▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.866</td></tr><tr><td>train_auc</td><td>0.31125</td></tr><tr><td>train_f1</td><td>0.86702</td></tr><tr><td>train_loss_epoch</td><td>0.31528</td></tr><tr><td>train_loss_step</td><td>0.15482</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.78487</td></tr><tr><td>val_auc</td><td>0.15404</td></tr><tr><td>val_f1</td><td>0.79365</td></tr><tr><td>val_loss_epoch</td><td>0.61989</td></tr><tr><td>val_loss_step</td><td>0.6346</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/dk53l6d9' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/dk53l6d9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_212853-dk53l6d9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8acf5d18bb6149c696370e5f3e52ff0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.017200000000108653, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_220558-9249k0t9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9249k0t9' target=\"_blank\">GINConv_3_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9249k0t9' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9249k0t9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 6.0 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "6.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.6 K     Total params\n",
      "0.027     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bff32e27034b4f82a46a4d2e8cf63986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▆▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇█▇█▇▇▇███▇████▇███</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████▇█▇██████████████</td></tr><tr><td>train_f1</td><td>▁▆▆▆▇▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇███▇████▇███</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▃▁▃▁▂▂▁▁▂▂▂▁▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>▇▆▅▃▃▃▂▃▂▃▃▄▆▂▂▁▂▁▁▃▂▂▃▂▃▃▂▃▄▂▄▄▃▁▂▂▂▅▃█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▆▅▇▆▆▆▇█▇███▅▇▇██▇█▅▇█▇▆▆▆▇▆█▇█▇▆▇▇▇█▇</td></tr><tr><td>val_auc</td><td>▁▃▃▆▇▄▆▆▅▇▆█▄▇▅▆▇▅▇██▆▇▆▇▆▇▄▆▇█▆▄▇▃▅▇▆▇▆</td></tr><tr><td>val_f1</td><td>▁▆▇▅██▇▆▇█▇██▇▅█▇████▅██▇▆▆▇█▆████▆██▇█▆</td></tr><tr><td>val_loss_epoch</td><td>▇▅▄▃▃▅▁▃▃▁▂▃▄▁▅▄▁▅▃▇▃▅█▅▆▃▆▅▄▅▂▅▄▄▇▆▄▄▄▆</td></tr><tr><td>val_loss_step</td><td>▅▄▄▂▄▅▂▅▄▃▂▅▄▁▄▃▁▆▄█▂▃▆▆▆▃▄▄▄▄▂▅▃▅▆▅▅▁▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87544</td></tr><tr><td>train_auc</td><td>0.95033</td></tr><tr><td>train_f1</td><td>0.87654</td></tr><tr><td>train_loss_epoch</td><td>0.29989</td></tr><tr><td>train_loss_step</td><td>0.66749</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.75887</td></tr><tr><td>val_auc</td><td>0.85459</td></tr><tr><td>val_f1</td><td>0.71978</td></tr><tr><td>val_loss_epoch</td><td>0.57791</td></tr><tr><td>val_loss_step</td><td>0.45624</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9249k0t9' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9249k0t9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_220558-9249k0t9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81c9224f1a664a5986b701a5f6043e38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333332417533, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_224204-7eolosna</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7eolosna' target=\"_blank\">GINConv_3_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7eolosna' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7eolosna</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 6.0 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "7.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.7 K     Total params\n",
      "0.031     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4de097431fb8447f8333ec8be4c96d40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇█▇█▇▇█▇▇█▇▇██▇▇██████</td></tr><tr><td>train_auc</td><td>▁▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█████▇██████▇██████</td></tr><tr><td>train_f1</td><td>▁▆▆▇▆▇▇▇▇▇▆▇▇▇▇▇▇▇▇█▇██▇██▇██████▇██████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▃▃▃▃▂▃▂▃▃▂▂▂▃▂▂▂▂▂▂▁▂▂▁▁▂▂▁▂▂▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▅▅▃▅▆▄▇▄▆▄▆▃▂▂▆▅▅▂▃▂█▅▃▃▃▁▂▁▃▂▃▃▅▃▃▁▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▆▆▇▇▇▆▇▆▇█▇▇▇█▇▇▇▇▇▇█▇▇▇██▇▇█▇▇▇▆▇█▇▇▅</td></tr><tr><td>val_auc</td><td>▁▂▃▁▄▅▇▅▇▅▅▇▆▆▆█▆▇▆▇▆▆▇▇▇▆█▇▇▄▆▇▅▅▇▆▅▆▆▅</td></tr><tr><td>val_f1</td><td>▁▇▆▇▇▇█▇▇▇▇█▇▇██████▇▇█▇▇▇███▇█▇██▇▇███▆</td></tr><tr><td>val_loss_epoch</td><td>▇▃█▄▄▃▂▂▂▂▂▂▃▇▅▂▃▂▄▂▂▂▃▃▃▂▁▂▁▆▄▅▃▄▅▄▇▆▆▆</td></tr><tr><td>val_loss_step</td><td>▄▂▆▅▅▄▄▂▄▃▃▄▄█▅▄▄▃▅▂▄▃▃▄▃▃▃▁▂▇▃▅▄▅▅▂▆▆▇▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87721</td></tr><tr><td>train_auc</td><td>0.94551</td></tr><tr><td>train_f1</td><td>0.87619</td></tr><tr><td>train_loss_epoch</td><td>0.29114</td></tr><tr><td>train_loss_step</td><td>0.20313</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.7234</td></tr><tr><td>val_auc</td><td>0.84871</td></tr><tr><td>val_f1</td><td>0.66282</td></tr><tr><td>val_loss_epoch</td><td>0.58464</td></tr><tr><td>val_loss_step</td><td>0.51555</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7eolosna' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/7eolosna</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_224204-7eolosna\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e94b220c540847748174aaf901c80132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_231853-wwiicpx7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wwiicpx7' target=\"_blank\">GINConv_3_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wwiicpx7' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wwiicpx7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 22.3 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "24.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.5 K    Total params\n",
      "0.098     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▄▄▅▅▅▅▅▅▅▅▆▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇██▇█</td></tr><tr><td>train_auc</td><td>▁▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█████</td></tr><tr><td>train_f1</td><td>▁▄▄▄▄▅▄▅▅▅▅▅▆▆▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇██▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▄▃▃▃▃▃▃▂▂▂▂▃▂▂▂▁▂▂▁▁▂▂</td></tr><tr><td>train_loss_step</td><td>█▆▅█▃▄▅▄▅▄▇▅▄▄▃▃▃▄▄▃▂▄▂▃▃▃▃▁▁▃▂▂▁▃▃▂▃▂▁▆</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▂▄▅▇▆█▄▇▇▇▇▇▅▇▆▇▇▇▆▅█▆▇▇▁▇▅▄▅▇▃▄▇▅▅▅▇▄▅▇</td></tr><tr><td>val_auc</td><td>▂▅▆▆▇█▇▇▇▇██▇▇▆▇▇▇▆▇▇▇▇▆▁▇▆▅▅▆▅▅▇▆▅▅▆▆▅▆</td></tr><tr><td>val_f1</td><td>▃▆▇▇▇█▄█▇█▇█▇█▇█▆█▆▅█▇▇█▁█▅▅▆▇▇▄█▅▆▇▇▃▆█</td></tr><tr><td>val_loss_epoch</td><td>▄▃▂▂▂▁▃▂▂▃▁▂▄▂▂▃▂▃▂▄▃▂▃▂▆▄▄▄▃▃█▄▂▄▅▆▅▆▆▅</td></tr><tr><td>val_loss_step</td><td>▄▄▄▂▃▁▄▄▂▄▂▃▇▁▂▄▃▄▂▆▂▃▇▃▅▄▅▆▃▂█▅▃▃▇▃▄▅▆▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.90732</td></tr><tr><td>train_auc</td><td>0.96611</td></tr><tr><td>train_f1</td><td>0.90682</td></tr><tr><td>train_loss_epoch</td><td>0.25027</td></tr><tr><td>train_loss_step</td><td>0.47328</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.78014</td></tr><tr><td>val_auc</td><td>0.85061</td></tr><tr><td>val_f1</td><td>0.79101</td></tr><tr><td>val_loss_epoch</td><td>0.66585</td></tr><tr><td>val_loss_step</td><td>0.6299</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wwiicpx7' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wwiicpx7</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_231853-wwiicpx7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02a18774da5549a895d31787e34a8c87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231230_235452-gwuqh14r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gwuqh14r' target=\"_blank\">GINConv_3_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gwuqh14r' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gwuqh14r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 22.3 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "24.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.5 K    Total params\n",
      "0.098     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60680c50c53a4c51a43868c28c2c0570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▄▅▅▅▆▅▆▆▆▆▆▅▆▆▇▇▇▇▇▇▇▆▇▇▇▆▇▇▇▇▇▇▇████</td></tr><tr><td>train_auc</td><td>▁▄▅▅▆▆▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇██▇▇▇█████████</td></tr><tr><td>train_f1</td><td>▁▄▅▄▆▆▅▆▆▆▆▆▆▆▅▆▆▇▇▇▇▇▇▇▆▇▇▇▆▇▇▇▇▇▇▇████</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▅▄▄▄▄▄▄▃▃▃▃▄▃▃▃▃▂▂▂▂▂▃▂▂▂▃▂▂▂▂▂▂▂▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▆▄▇▄▄▅▅▅▃▆▅▂▃▅▅▄▃▃▄▂▃▂▂▄▆▂▂▄▃▃▁▁▂▃▁▂▂▃▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▁▂▁▅▃▂▅▃▂▄▃▅▃▁▆▆▂▆▆▇▄█▆▃▅▄▄▃▇▅▅▄▅▇▅▆▄▆▇</td></tr><tr><td>val_auc</td><td>▁▃▅▄▆▆▅▆▅▆██▆▇▆▇▇▆▇▇▇▆▇▇▆▇▇▇▆▇▆▆▆▆▇▇▇█▇█</td></tr><tr><td>val_f1</td><td>▂▁▃▃▅▅▃▄▃▄▅▅▆▅▃▇▆▄▇▆▇▄█▇▅▅▆▆▅▇▆▆▅▆▇▆▆▆▇▇</td></tr><tr><td>val_loss_epoch</td><td>▄▄▃▃▃▂▃▂▃▃▂▂▃▃▃▂▁▄▂▄▁▃▃▃▄▂▇▅▃▁▃▃▆▃▃▂▃█▄▂</td></tr><tr><td>val_loss_step</td><td>▅▅▅▂▅▃▃▄▃▅▃▃▅▁▃▃▂▄▃▇▁▃█▂▆▃▅▇▄▁▄▆▅▄▆▂▂▇▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.88371</td></tr><tr><td>train_auc</td><td>0.95129</td></tr><tr><td>train_f1</td><td>0.88405</td></tr><tr><td>train_loss_epoch</td><td>0.27971</td></tr><tr><td>train_loss_step</td><td>0.34491</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81324</td></tr><tr><td>val_auc</td><td>0.89759</td></tr><tr><td>val_f1</td><td>0.82327</td></tr><tr><td>val_loss_epoch</td><td>0.46452</td></tr><tr><td>val_loss_step</td><td>0.53542</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gwuqh14r' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gwuqh14r</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231230_235452-gwuqh14r\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d741948215447e49611789e1e1f6e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231231_002851-ilzn6f07</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ilzn6f07' target=\"_blank\">GINConv_3_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ilzn6f07' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ilzn6f07</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 22.3 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "24.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.5 K    Total params\n",
      "0.098     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "051ffbc452a1418dbc83c47efce65477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▅▆▆▆▆▆▆▆▆▆▆▇▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇████████</td></tr><tr><td>train_auc</td><td>▇▆▄▄▄▄▄▄▄▄▃▃▃▃▃▃▂▃▅▅▆▆▇██▆▇▆█▆▄▃▃▂▂▂▂▁▁▂</td></tr><tr><td>train_f1</td><td>▁▃▅▅▅▆▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▁▂▂▁▂▁▂▂▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▃▅▅▆▆▇▆▆▆▇▇▃▅▇▇█▅▅▅▁▅▆▄▇▅▅▄▅▃▂▅▅▅▆▃▄▆▃▃▅</td></tr><tr><td>val_auc</td><td>▇▆▂▁▁▁▂▁▂▁▁▁▁▁▁▁▁▁▃▅▄▆███▆███▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_f1</td><td>▆▆▆▇▇█▇▇▇██▆▆▇██▆▇▇▁▆▇▄█▅▇▆▆▆▅▇▆▆▇▆▅▇▅▄▆</td></tr><tr><td>val_loss_epoch</td><td>█▂▂▁▁▁▂▁▁▂▁▂▂▁▁▁▂▂▂▃▂▂▂▂▂▂▂▂▂▃▂▂▁▃▄▂▂▂▃▂</td></tr><tr><td>val_loss_step</td><td>█▂▂▁▂▁▂▂▂▂▂▂▃▁▁▂▂▂▂▃▂▂▅▂▂▃▂▃▂▂▂▂▂▃▆▁▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.88784</td></tr><tr><td>train_auc</td><td>0.16557</td></tr><tr><td>train_f1</td><td>0.88837</td></tr><tr><td>train_loss_epoch</td><td>0.28387</td></tr><tr><td>train_loss_step</td><td>0.20643</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.76596</td></tr><tr><td>val_auc</td><td>0.14628</td></tr><tr><td>val_f1</td><td>0.75188</td></tr><tr><td>val_loss_epoch</td><td>0.62543</td></tr><tr><td>val_loss_step</td><td>0.56185</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ilzn6f07' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ilzn6f07</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231231_002851-ilzn6f07\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14e2fc5a49254e2ebef246258fc5b1cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231231_010240-n94efc25</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/n94efc25' target=\"_blank\">GINConv_3_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/n94efc25' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/n94efc25</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 22.3 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "24.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.5 K    Total params\n",
      "0.098     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "622ee51986bf425298ea2efd9e3580a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▄▅▅▆▆▆▆▆▆▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇███▇▇█▇▇▇█▇██</td></tr><tr><td>train_auc</td><td>▁▄▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇███▇██████▇██</td></tr><tr><td>train_f1</td><td>▁▄▄▄▅▅▆▅▆▅▆▆▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇███▇▇█▇▇▇█▇██</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▂▂▂▂▁▂▂▂▁▃▂▁</td></tr><tr><td>train_loss_step</td><td>█▇▆▅▆▅▄▆▆▄▅▅▆▃▃▄▄▃▅▃▃▄█▅▃▄▃▂▄▄▄▃▂▂▆▃▃▁▂▆</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▃▅▅▇▇█▅▆█▁▅▆▁▄▆▅▅▆▆▅▇▆▆▆▆▆▅▅▆▅▆▅▅▃▅▅▅▆▅▅</td></tr><tr><td>val_auc</td><td>▁▃▂▆▆▆▅▇█▄▆▇▄▂▅▆▅▆▇▆▆▆▆▅▄▅▄▃▄▅▅▆▄▁▄▄▂▅▄▅</td></tr><tr><td>val_f1</td><td>▆▅▆███▇▇█▆▇▇▁▇▇▇▇▇▆▇█▇▇▇▇▇▆▇▇▇█▅▇▅▇▇▇▆▇▇</td></tr><tr><td>val_loss_epoch</td><td>▃▃▃▂▁▂▂▁▁▄▂▂▄▄▂▃▃▂▂▂▃▃▄▃▄▃▄▆▄▄▅▃█▄▄▅▆▃▄▃</td></tr><tr><td>val_loss_step</td><td>▄▆▄▃▃▄▃▃▂▂▃▃▆▄▄▅▄▃▂▂▃▅▆▄▄▄▅▅▄▅▆▃▇▃▅▄█▄▅▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.90614</td></tr><tr><td>train_auc</td><td>0.96684</td></tr><tr><td>train_f1</td><td>0.90519</td></tr><tr><td>train_loss_epoch</td><td>0.24141</td></tr><tr><td>train_loss_step</td><td>0.41506</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.76596</td></tr><tr><td>val_auc</td><td>0.85757</td></tr><tr><td>val_f1</td><td>0.78525</td></tr><tr><td>val_loss_epoch</td><td>0.55175</td></tr><tr><td>val_loss_step</td><td>0.24332</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/n94efc25' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/n94efc25</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231231_010240-n94efc25\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ec63852d99b450998985fe370fc11b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.017200000000108653, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231231_013642-rznd12tw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/rznd12tw' target=\"_blank\">GINConv_3_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/rznd12tw' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/rznd12tw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 22.3 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "28.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "28.7 K    Total params\n",
      "0.115     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9450243b3c554553a0fb61d3f84368dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▆███▇▇▇▆██</td></tr><tr><td>train_auc</td><td>▁▄▄▅▅▆▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇█▇▇██▇▇███▇██▇██</td></tr><tr><td>train_f1</td><td>▁▄▄▄▅▅▅▅▅▅▆▆▅▆▆▆▆▇▆▆▇▇▆▆▇▇▇▇▇▇▆█▇█▇▇▇▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▅▅▄▄▄▄▄▄▃▄▃▃▄▃▂▂▃▂▃▃▃▂▂▂▂▁▂▂▁▂▁▂▂▂▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▅▄▃▄▅▃▄▃▄▃▅▃▂▃▂▅▃▃▃▂▃▄▂▂▂▃▅▂▃▁▄▂▁▂▃▄▁▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▃▂▄▄▅█▆▆▇▇█▇▅▅▇▄▆▃▂▇▆▃▇▆▅▅▆▇▅▁▇▄▄▄▅▅▅▇▅▅</td></tr><tr><td>val_auc</td><td>▁▃▄▄▇▇█▇▇█▇▇▆▆▇▇▆▅▃▆▇▄▇▆▆▆▆▆▅▆▆▄▅▅▆▅▅▇▆▄</td></tr><tr><td>val_f1</td><td>▅▄▆▄▆██▆▇██▇▇▇█▇▇▆▆▇▇▆█▇▇▅▆▇▅▁▇▆▇▅▇▆▇▇▇▆</td></tr><tr><td>val_loss_epoch</td><td>▄▅▂▂▂▂▂▂▃▂▁▂▄▃▃▅▂▇▅▂▄█▂▂▄▃▃▄▄▅▃▇▆▄▇▃▆▄▇▅</td></tr><tr><td>val_loss_step</td><td>▄▄▃▂▂▃▄▃▅▃▁▃▄▄▂▆▂▄▄▁▃▆▁▂▁▄▃▃▂▅▂▄▃▃█▂▄▃▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.90791</td></tr><tr><td>train_auc</td><td>0.9665</td></tr><tr><td>train_f1</td><td>0.90714</td></tr><tr><td>train_loss_epoch</td><td>0.2396</td></tr><tr><td>train_loss_step</td><td>0.30317</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.77069</td></tr><tr><td>val_auc</td><td>0.84122</td></tr><tr><td>val_f1</td><td>0.76739</td></tr><tr><td>val_loss_epoch</td><td>0.60996</td></tr><tr><td>val_loss_step</td><td>0.55863</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/rznd12tw' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/rznd12tw</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231231_013642-rznd12tw\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5645ed68ca24fc681ab36a0c81812f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.017183333332650364, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231231_021031-ry22z88i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ry22z88i' target=\"_blank\">GINConv_4_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ry22z88i' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ry22z88i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 2.4 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a98f497660f4929ae931cb3626e4fcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇███████████████████</td></tr><tr><td>train_auc</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇████████████████████</td></tr><tr><td>train_f1</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇████████▇██████████</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▃▃▃▃▂▂▂▂▂▃▂▂▂▂▂▂▂▂▁▂▂▂▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▅▃▅▄▅▃▃▄▄▅▇▃▄▃▃▃▃▄▃▂▄▃▃▃▄▂▃▂▄▂▃▃▃▂▂▁▁▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▇▇▇▇▇▇▇▇▆▇▇████▇▇█▇███▇█▇▇▇██▇██▆▇█▇▇▇</td></tr><tr><td>val_auc</td><td>▁▅▆▆▆▇▇▇▇▇▅▆▇██▇█▇▇▇▇██▇▇█▇▇▇▇▇███▅▆█▇▇▆</td></tr><tr><td>val_f1</td><td>▁▅▅▆▅▇▇▇▇▅▅▆▇▇▇▇█▇▄█▅▇█▇▇▇▅▆▅▇▇▇██▆▆▇▆▇▅</td></tr><tr><td>val_loss_epoch</td><td>█▄▄▃▂▂▂▃▂▂▂▄▂▂▁▂▂▂▃▂▂▂▂▃▂▁▂▂▂▂▂▁▂▁▇▃▂▂▂▄</td></tr><tr><td>val_loss_step</td><td>▆▂▄▃▂▃▃▄▃▃▁▄▃▃▃▃▃▃▄▄▄▄▃▄▂▃▃▂▄▂▂▃▃▂█▃▃▂▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83707</td></tr><tr><td>train_auc</td><td>0.91069</td></tr><tr><td>train_f1</td><td>0.83394</td></tr><tr><td>train_loss_epoch</td><td>0.37066</td></tr><tr><td>train_loss_step</td><td>0.43381</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.74468</td></tr><tr><td>val_auc</td><td>0.83853</td></tr><tr><td>val_f1</td><td>0.75566</td></tr><tr><td>val_loss_epoch</td><td>0.53227</td></tr><tr><td>val_loss_step</td><td>0.59041</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ry22z88i' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ry22z88i</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231231_021031-ry22z88i\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb6d756b7a04d1c9ad92302f44d0ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231231_024406-y0kndaii</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/y0kndaii' target=\"_blank\">GINConv_4_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/y0kndaii' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/y0kndaii</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 2.4 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "649103a507a646c2b0e8f3368da95635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▇▇▇▇▇▇▇█▇▇▇▇▇▇▇██▇██▇████████████████</td></tr><tr><td>train_auc</td><td>▁▅▅▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█▇██████████████</td></tr><tr><td>train_f1</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇██▇█▇██▇██████████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▃▃▃▂▂▃▂▂▃▂▂▂▂▂▂▂▂▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▇▆▄▅▄▄▃▃▃▄▅▇▃▃▃▄▅▂▃▂▂▁▄▃▃▄▄▄▂▄▂▂▃▂▃▂▁▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▆▇▇▇▇▇▆▆▇▆▇▇▇▆▆▇▇██▆█▇█▆██▆▇▇▇▇█▆█▇▇██</td></tr><tr><td>val_auc</td><td>▁▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█▇▇█▇▇▇████▇▇▇▇██</td></tr><tr><td>val_f1</td><td>▁▁▄▆▆▆▆▆▅▅▇▆▆▆▆▆▅▆▆▇▇▆▇▇▇▆▇▇▆▆▆▇▇▇▆▇▆▆██</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▃▃▂▂▃▃▃▂▃▂▂▂▂▂▂▂▂▂▃▂▁▂▂▁▁▂▁▂▂▁▁▅▁▂▃▁▂</td></tr><tr><td>val_loss_step</td><td>▇▂▅▄▄▄▃▄▃▄▂▄▄▅▃▃▃▃▄▅▄▅▄▁▂▃▂▁▃▂▃▃▃▂█▂▄▄▂▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.81287</td></tr><tr><td>train_auc</td><td>0.88953</td></tr><tr><td>train_f1</td><td>0.81298</td></tr><tr><td>train_loss_epoch</td><td>0.40455</td></tr><tr><td>train_loss_step</td><td>0.33286</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.77069</td></tr><tr><td>val_auc</td><td>0.88247</td></tr><tr><td>val_f1</td><td>0.79834</td></tr><tr><td>val_loss_epoch</td><td>0.4705</td></tr><tr><td>val_loss_step</td><td>0.55754</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/y0kndaii' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/y0kndaii</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231231_024406-y0kndaii\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "856e49919bf74294824f0505692c9f83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333332417533, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231231_031816-m5ijwk8l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/m5ijwk8l' target=\"_blank\">GINConv_4_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/m5ijwk8l' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/m5ijwk8l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 2.4 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0667d0c901a84ad3961b2f43267f6843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▅▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇███████████████</td></tr><tr><td>train_auc</td><td>▅▅████▆▆▃▂▂▃▃▃▁▂▃▂▂▂▂▂▃▃▃▃▄▃▂▃▂▃▄▃▃▂▂▂▃▂</td></tr><tr><td>train_f1</td><td>▁▁▄▅▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇███████████████</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▃▂▂▃▂▂▂▂▂▂▂▂▂▁▂▂▁▂▁▁▂▂▁▂▂▂▂▁▂▁▁▁▁▁▁▁▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▇███████████▇▇█████████▇█▇███▇▇▇██████</td></tr><tr><td>val_auc</td><td>▅▇█████▇▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_f1</td><td>▁▇█████████████████████████████▇████████</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▃▂▂▂▃▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▃▄▃▂▁▂▂▁▂▂▂▂▂▂▁▂▂</td></tr><tr><td>val_loss_step</td><td>▆▅▆▄▃▄▄▇▄▄▁▅▄▅▆▅▄▄▆▅▅▄▆██▇▄▂▆▄▂▄▃▄▆▃▂▂▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.82822</td></tr><tr><td>train_auc</td><td>0.37744</td></tr><tr><td>train_f1</td><td>0.83362</td></tr><tr><td>train_loss_epoch</td><td>0.40565</td></tr><tr><td>train_loss_step</td><td>0.48806</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.7896</td></tr><tr><td>val_auc</td><td>0.13979</td></tr><tr><td>val_f1</td><td>0.79059</td></tr><tr><td>val_loss_epoch</td><td>0.47105</td></tr><tr><td>val_loss_step</td><td>0.48599</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/m5ijwk8l' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/m5ijwk8l</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231231_031816-m5ijwk8l\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba80ab4731b48e8b771a7036a119752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231231_035128-jsl9vqy0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jsl9vqy0' target=\"_blank\">GINConv_4_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jsl9vqy0' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jsl9vqy0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 2.4 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "2.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd0597bafa649e4a73a18a13790bfa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▆▇▇▇▇▇▇▇▇█▇▇█▇▇▇██▇█▇▇▇█▇▇██████████</td></tr><tr><td>train_auc</td><td>▁▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███▇████▇█▇█████████████</td></tr><tr><td>train_f1</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇█▇████▇████▇█▇█████████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▃▃▃▃▃▂▂▃▃▂▂▂▂▂▂▂▁▂▂▂▂▂▁▂▂▂▂▁▂▁▂▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>▆▅▅▅▃▃▃▄▃▄▂▃█▄▄▂▃▇▃▄▃▃▄▂▃▃▃▁▄▂▃▂▄▃▃▂▄▂▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▅▇▇▇▇▅▇▆▆▆▅█▇▇▆▇▅▇██▇▇▇▇██▆▇▇▇▇▆▇▆▇▇▇▇</td></tr><tr><td>val_auc</td><td>▁▅▆▆▇▆▇▅▇▇▇▇▆▇▇▇█▇▆███▇▇▇▇█▇█▇█▇█▇▇▆▇▇▇▇</td></tr><tr><td>val_f1</td><td>▁▄▃▄▆▅▆▂▅▄▁▅▁▇▆▆▆▆▁▇▇█▇▆▆▅█▇▂▇▆▇▆▆▅▄▆▇▇▆</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▄▃▂▂▄▂▂▂▄▃▂▂▄▂▃▃▃▂▁▂▂▃▁▂▃▃▃▂▃▂▂▃▃▃▁▃▅</td></tr><tr><td>val_loss_step</td><td>▆▃▂▅▅▃▃▄▃▄▄▅▆▃▃▆▄▅▃▄▅▂▄▄▅▁▃▃▄▃▄▄▃▂▅▄▃▂▄█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83766</td></tr><tr><td>train_auc</td><td>0.91714</td></tr><tr><td>train_f1</td><td>0.83965</td></tr><tr><td>train_loss_epoch</td><td>0.35846</td></tr><tr><td>train_loss_step</td><td>0.27457</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.78251</td></tr><tr><td>val_auc</td><td>0.86189</td></tr><tr><td>val_f1</td><td>0.78605</td></tr><tr><td>val_loss_epoch</td><td>0.56094</td></tr><tr><td>val_loss_step</td><td>0.82888</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jsl9vqy0' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jsl9vqy0</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231231_035128-jsl9vqy0\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38eea7eeb98545f3aa4dbf8482fb612f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333332417533, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231231_042443-cg5wd42m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/cg5wd42m' target=\"_blank\">GINConv_4_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/cg5wd42m' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/cg5wd42m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 2.4 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "2.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.8 K     Total params\n",
      "0.011     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "844c7558e239446389290ed138722c73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██▇██▇▇█████▇███████████</td></tr><tr><td>train_auc</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████▇▇█████████████████</td></tr><tr><td>train_f1</td><td>▁▆▇▇▇▇▇▇▇▇█▇▇▇█▇█████▇▇█████▇███████████</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▃▃▃▃▃▂▃▂▂▃▂▂▃▂▂▂▂▂▂▃▂▂▂▂▁▂▂▁▂▂▂▁▁▂▂▁▂</td></tr><tr><td>train_loss_step</td><td>█▆▅▅▅▅▄▄▃▅▄▄▇▅▅▆▃▂▃▅▄▄▄▃▃▄▅▁▄▃▄▃▃▃▄▄▃▄▃▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▆▇▇▇▇▇▇▇▇▆▇▇▇▆▇▇▇▇█▇█▆▇█▇▇▇▇▇█▇█▇█▆██▇</td></tr><tr><td>val_auc</td><td>▁▄▅▆▆▆▇▇▇▇▅▆▇▇▇▅▇▇▇▇▇▇▆▇▇█▇▇▇▇▇█▆▇▆█▅▇▇▇</td></tr><tr><td>val_f1</td><td>▁▅▅▆▆▇▇▇▆▇▅▃▆▄▆▄▆▅▇▇▇▆▇▄▆▇▅▇▇▅▆▇▄▇▆█▄██▆</td></tr><tr><td>val_loss_epoch</td><td>█▃▄▃▂▃▂▃▃▂▃▃▃▂▃▃▃▃▂▂▂▃▃▂▂▂▂▂▂▂▃▁▃▂▃▁▄▃▄▂</td></tr><tr><td>val_loss_step</td><td>█▃▆▆▃▆▄▆▆▃▄▅▆▆▄▄▇▇▄▅▅▃▇▃▃▃▃▄▆▅▆▄▄▄▃▁█▆▇▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84416</td></tr><tr><td>train_auc</td><td>0.90987</td></tr><tr><td>train_f1</td><td>0.84828</td></tr><tr><td>train_loss_epoch</td><td>0.36962</td></tr><tr><td>train_loss_step</td><td>0.38459</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.78487</td></tr><tr><td>val_auc</td><td>0.8675</td></tr><tr><td>val_f1</td><td>0.78984</td></tr><tr><td>val_loss_epoch</td><td>0.45266</td></tr><tr><td>val_loss_step</td><td>0.43078</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/cg5wd42m' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/cg5wd42m</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231231_042443-cg5wd42m\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6c9bec3ccaa4eb3acb797e4603d87a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231231_045741-0wgx4nf0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0wgx4nf0' target=\"_blank\">GINConv_4_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0wgx4nf0' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0wgx4nf0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 8.3 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "8.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.8 K     Total params\n",
      "0.035     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1d6f41c4a2345398433eab5852cc270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▅▆▆▆▆▆▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇██▇▇▇█▇█████</td></tr><tr><td>train_auc</td><td>▁▅▅▆▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇██▇█▇███▇████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▆▆▇▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇█▇██▇▇▇███████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▅▄▄▄▄▃▃▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▂▁▁▂▂▂▁▂▂▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>██▆▆▇▆▅▆▅▅▆▄▄▇▄▆▄▅▄▂▃▅▂▂▅▄▅▂▂▄▃▄▂▂▂▄▄▂▄▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▅▅▆▆▅▆▇▇▆█▇███▅▇▆█▁▇▇▇▇▇█▇█▇██▆▇█▇▆▇▇▇▇▇</td></tr><tr><td>val_auc</td><td>▃▄▅▅▅▆▅▆▇▆▇▇▇▇▇█▆▇▁█▇▆▆▇█▇▇███▆█▇█▇▇▆█▇▇</td></tr><tr><td>val_f1</td><td>▆▆▇▇▇▇▇▇▆▇▇█▇▇▅▇▇█▁▇▇▇▆▇█▇█▇▇█▆▆█▇▆▇█▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>▂▅▃▂▂▃▂▃▃▂▂▁▂▂▃▁▃▂█▃▂▄▂▂▄▂▄▂▂▁▃▄▂▃▃▄▅▃▂▂</td></tr><tr><td>val_loss_step</td><td>▂█▇▅▄▅▅▇▅▅▅▂▅▄▆▅▆▅▆▅▅█▄▂█▃▄▆▄▁▃▄▂▄▇█▅▃▁▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87426</td></tr><tr><td>train_auc</td><td>0.94543</td></tr><tr><td>train_f1</td><td>0.8758</td></tr><tr><td>train_loss_epoch</td><td>0.28826</td></tr><tr><td>train_loss_step</td><td>0.21011</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.78251</td></tr><tr><td>val_auc</td><td>0.86712</td></tr><tr><td>val_f1</td><td>0.78704</td></tr><tr><td>val_loss_epoch</td><td>0.49667</td></tr><tr><td>val_loss_step</td><td>0.51723</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0wgx4nf0' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0wgx4nf0</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231231_045741-0wgx4nf0\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ebc6b5b13f48c79dfcaf45948fe266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.017183333332650364, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231231_053054-y9otl3zx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/y9otl3zx' target=\"_blank\">GINConv_4_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/y9otl3zx' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/y9otl3zx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 8.3 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "8.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.8 K     Total params\n",
      "0.035     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16083cb2265b4cc9aca10d6450ccb733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇████████▇█████████</td></tr><tr><td>train_auc</td><td>▁▆▇▆▇▇▇▇▇▇▇▇█▇▇▇▇▇██████████████████████</td></tr><tr><td>train_f1</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇██▇████████▇█████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▁▂▁▂▂▂▁▁▁▁▂▂▁▁▂▂▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▅▅▆▄▄▄▄▅▃▂▃▆▄▄▂▆▄▃▃▃▃▃▄▂▄▁▃▄▂▃▂▂▃▃▃▂▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▆▆▅▆▇▅▇▆▆▆▆▇▆▆▆▇▇▇▇▆▆▇▇▇▇▇▇▇▆▇█▇▇█▇█▇▇</td></tr><tr><td>val_auc</td><td>▁▄▅▆▆▆▆▇▆▆▇▇▆▇▇█▇▇▇▇▇▇▇▇▇▇█▇████▇▇██████</td></tr><tr><td>val_f1</td><td>▁▄▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇██▇██▇█████████</td></tr><tr><td>val_loss_epoch</td><td>▇█▄▃▃▂▃▃▂▃▂▃▃▂▂▂▂▂▁▃▂▅▃▂▅▁▃▅▃▁▃▁▁▂▂▃▃▁▂▃</td></tr><tr><td>val_loss_step</td><td>▅█▆▅▄▄▅▄▄▅▄▂▄▃▅▄▅▄▃▅▆▇▄▂█▂▃▆▄▁▃▃▁▃▄▆▅▃▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84475</td></tr><tr><td>train_auc</td><td>0.91565</td></tr><tr><td>train_f1</td><td>0.84629</td></tr><tr><td>train_loss_epoch</td><td>0.35859</td></tr><tr><td>train_loss_step</td><td>0.35235</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.77305</td></tr><tr><td>val_auc</td><td>0.87227</td></tr><tr><td>val_f1</td><td>0.79832</td></tr><tr><td>val_loss_epoch</td><td>0.5053</td></tr><tr><td>val_loss_step</td><td>0.51873</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/y9otl3zx' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/y9otl3zx</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231231_053054-y9otl3zx\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a388c74ab54794b4ca1265fe0f47b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231231_060342-c8w2h80v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/c8w2h80v' target=\"_blank\">GINConv_4_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/c8w2h80v' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/c8w2h80v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 8.3 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "8.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.8 K     Total params\n",
      "0.035     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇██▇███▇▇▇▇▇████▇██</td></tr><tr><td>train_auc</td><td>▁▃▄▄▅▅▅▅▆▅▆▅▅▅▅▅▆▆▆▆▆▅▇▆▇▆▇▆▇███▇▇██████</td></tr><tr><td>train_f1</td><td>▁▃▅▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇██▇████▇▇█▇████▇██</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▂▂▃▂▂▂▂▂▂▁▁▂▂▂▂▂▁▁▂▂▁▁▁▁▂▁▁▂▁▂▁▁▁▂▂▁▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▇▅▆▄▆▆▆▄▇▄▇▆▄▅▆▅▅▆▇▆██▆▇█▆▆▇▄▆▇▇▇▄▅▄█▆▆</td></tr><tr><td>val_auc</td><td>▁▇▆▆▆▆▆▆▅▆▆▆▆▇▇▇▇▇▇▇▇▇█▇▇█▇▇▇▇▇▇▆▆▇▇▇▇█▇</td></tr><tr><td>val_f1</td><td>▁▇▄▇▅▆▆▆▄▇▆█▆▅▄▆▆▅▇▇▇██▇▇▆▆▆▇▆▇▇▇▇▄▄▆█▆▆</td></tr><tr><td>val_loss_epoch</td><td>▄▄▃▂▄▃▃▄▄▃▆▂▄▄▄▅▃▂▂▆▂▃▁▂▄▃▂▂▃▃▁▂▁▃▄█▄▅▃▄</td></tr><tr><td>val_loss_step</td><td>▃▄▄▂▄▃▃▅▄▄▅▂▃▃▅▇▅▃▂▄▃▃▂▁▄▂▁▃▃▁▂▃▁▂▅█▂▁▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86482</td></tr><tr><td>train_auc</td><td>0.87994</td></tr><tr><td>train_f1</td><td>0.86832</td></tr><tr><td>train_loss_epoch</td><td>0.3387</td></tr><tr><td>train_loss_step</td><td>0.37461</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.77778</td></tr><tr><td>val_auc</td><td>0.84743</td></tr><tr><td>val_f1</td><td>0.77512</td></tr><tr><td>val_loss_epoch</td><td>0.56694</td></tr><tr><td>val_loss_step</td><td>0.59496</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/c8w2h80v' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/c8w2h80v</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231231_060342-c8w2h80v\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "841df8be5a694897bd571bff3fe0beb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231231_063721-wshdwdus</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wshdwdus' target=\"_blank\">GINConv_4_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wshdwdus' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wshdwdus</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 8.3 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "8.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.9 K     Total params\n",
      "0.036     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b669931034124fc883ea7a32f5a9d04e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇████████</td></tr><tr><td>train_auc</td><td>▁▅▅▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇██▇████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▅▅▄▄▃▃▃▃▂▃▃▂▂▃▃▂▂▂▂▂▂▂▃▂▂▂▁▂▂▁▂▁▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>▄▅▄▃▃▃▄▄▃▃▃▂▆▂▃▄▂█▃▂▃▃▆▂▁▂▃▁▃▂▂▂▂▁▂▁▂▁▄▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▁▃▄▄▅▅▄▅▂▅▆▆▇▆▇▇▇▃▂▆▄▇█▆▄▆▇▆▄▆▆▆▃▆▆▄▄▆▇</td></tr><tr><td>val_auc</td><td>▁▄▄▄▆▆▆▅▇▅▅▇▆▇▇▇▇█▆▄▇▇██▇▆▇█▇▇███▆▇█▅▇▇█</td></tr><tr><td>val_f1</td><td>▅▁▆▅▇▇▆▅▅▃▇▇▆█▇███▄▃▆▇███▅▆██▄▇▆▇▃█▇▅▃▆▇</td></tr><tr><td>val_loss_epoch</td><td>▃█▂▂▂▁▁▁▁▃▂▂▂▁▂▂▁▄▂▂▃▄▂▄▂▁▂▁▂▄▂▂▃▆▅▄▂▄▃▄</td></tr><tr><td>val_loss_step</td><td>▄█▄▃▃▁▃▂▃▄▃▃▅▄▂▃▃▄▄▂▅▄▄█▃▂▄▃▁▅▅▅▄▆▇▆▄▅▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8778</td></tr><tr><td>train_auc</td><td>0.94632</td></tr><tr><td>train_f1</td><td>0.87845</td></tr><tr><td>train_loss_epoch</td><td>0.29699</td></tr><tr><td>train_loss_step</td><td>0.34271</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.78723</td></tr><tr><td>val_auc</td><td>0.86848</td></tr><tr><td>val_f1</td><td>0.78365</td></tr><tr><td>val_loss_epoch</td><td>0.53642</td></tr><tr><td>val_loss_step</td><td>0.53477</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wshdwdus' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wshdwdus</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231231_063721-wshdwdus\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f43d9a9159c74f41a57b185c77179eb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231231_071112-4xxf00lh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4xxf00lh' target=\"_blank\">GINConv_4_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4xxf00lh' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4xxf00lh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 8.3 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "9.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "9.9 K     Total params\n",
      "0.040     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91eadb3b660542e893bb0166855f1ebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▆▆▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇████▇█████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█▇▇█████▇█████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇█████▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▄▄▄▃▄▃▃▃▃▂▂▂▃▃▃▂▂▂▂▂▂▂▂▂▃▂▂▁▁▁▂▂▁▂▁▂</td></tr><tr><td>train_loss_step</td><td>▅▅▃▄▃▃▃▃▃▃▂▃▃▂▂▂▂▄▂▂▃▂▁▂▂▁▂▂▂▃▃▂▂▂▃▂▃▂▂█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▂▅▃▇▃▆▄▃▇▇█▆▄█▇▆█▅▆▅▅▇▆▆▇▇▅▇▇▇▅█▅▄█▃▆▄▇</td></tr><tr><td>val_auc</td><td>▁▄▄▅▄▂▆▇▇▇▆▇▇▆▇▇▅█▆██▆▇▆▇▇▇▇▇█▇▇▇▆▆█▇▇▆▇</td></tr><tr><td>val_f1</td><td>▁▁▆▅▅▅▇▆▂▆█▇▆▃█▇▇█▄▅▅▂▇▇▅▇▇▃▆▇▇▆▇▅▄▆▂▅▄▅</td></tr><tr><td>val_loss_epoch</td><td>▆▄▄▄▅▅▃▃▃▃▄▃▅▅▂▃▂▅▄▃▁▇▄▃▂▃▄▅▂▃▃▇▄▄▆▃▅▃█▄</td></tr><tr><td>val_loss_step</td><td>▅▄▄▃▃▅▃▃▃▃▄▄▅▄▃▂▁▆▄▃▁▇▄▃▂▂▅▆▁▃▃▄▂▃▇▄▄▄█▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87603</td></tr><tr><td>train_auc</td><td>0.94775</td></tr><tr><td>train_f1</td><td>0.87833</td></tr><tr><td>train_loss_epoch</td><td>0.3293</td></tr><tr><td>train_loss_step</td><td>0.91506</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.78723</td></tr><tr><td>val_auc</td><td>0.86708</td></tr><tr><td>val_f1</td><td>0.775</td></tr><tr><td>val_loss_epoch</td><td>0.50199</td></tr><tr><td>val_loss_step</td><td>0.53035</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4xxf00lh' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/4xxf00lh</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231231_071112-4xxf00lh\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bec7e4293d5477da72842eeadfc3a1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231231_074425-9y0ukynr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9y0ukynr' target=\"_blank\">GINConv_4_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9y0ukynr' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9y0ukynr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 30.9 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "33.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "33.1 K    Total params\n",
      "0.132     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee66aa312d9543fba8388b54df9806a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▄▄▅▅▅▅▅▅▅▆▅▅▆▆▆▆▆▆▇▇▇▆▆▇▆▇█▇▇▆▇▇▇▇███</td></tr><tr><td>train_auc</td><td>▁▄▄▄▃▄▄▄▄▅▅▃▃▄▅▄▅▆▆▆▅▇▆▆▆▆▇▆▇▇█▇▆▇▇▇████</td></tr><tr><td>train_f1</td><td>▁▃▃▄▅▅▅▅▅▅▅▅▆▅▅▆▆▆▆▆▆▇▇▇▆▇▇▆▇█▇▇▆▇▇▇▇███</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▆▅▅▅▄▄▄▄▄▄▄▄▃▃▃▄▃▄▂▃▃▃▂▂▃▂▂▂▃▂▁▂▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>▆▆▆▆▄▅▆▄█▅▄▄█▅▅▄▄▂▄▄▄▂▃▃▃▄▂▃▃▃▅▃▄▂▄▂▂▃▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▁▁▅▆▆▄█▆▆▃█▄▅▇▄▆▄▅▅▅▂▅▅▅▄▅▅▅▅▇▅▄▂▅▄▅▃▅▆</td></tr><tr><td>val_auc</td><td>▁▁▃▄▇▇▇▇▇▇▅█▅▇▇▅▇▆▅▄▆▂▄▆▆▅▅▆▆▆▆▅▅▃▅▅▅▅▅▅</td></tr><tr><td>val_f1</td><td>▃▁▁▆▇▆▆█▇▇▅█▆▆▇▃▆▃▆▅▆▂▄▆▅▅▄▄▅▇▇▅▃▁▆▅▆▂▃▅</td></tr><tr><td>val_loss_epoch</td><td>▅▇▄▃▂▁▁▂▂▂▃▂▄▂▂▃▃▃▃▅▃▃▃▄▂▄▃▂▅▇▅▃▄▅▄▄▅▅▇█</td></tr><tr><td>val_loss_step</td><td>▄▄▅▃▂▁▁▃▁▄▂▂▃▁▂▃▄▃▂▃▃▂▂▅▂▄▂▁▅▅▃▂▃▂▂▂▂▃▅█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.90555</td></tr><tr><td>train_auc</td><td>0.96347</td></tr><tr><td>train_f1</td><td>0.90521</td></tr><tr><td>train_loss_epoch</td><td>0.21976</td></tr><tr><td>train_loss_step</td><td>0.11863</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.77778</td></tr><tr><td>val_auc</td><td>0.85341</td></tr><tr><td>val_f1</td><td>0.76733</td></tr><tr><td>val_loss_epoch</td><td>0.75927</td></tr><tr><td>val_loss_step</td><td>1.03894</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9y0ukynr' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9y0ukynr</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231231_074425-9y0ukynr\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b08a854e534c4d8dade1e3778f11a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231231_081729-0wr7jdba</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0wr7jdba' target=\"_blank\">GINConv_4_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0wr7jdba' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0wr7jdba</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 30.9 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "33.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "33.1 K    Total params\n",
      "0.132     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▇▇▆▇▇▇▇▇█▆▇▇█▇▇█▇▇████</td></tr><tr><td>train_auc</td><td>▁▄▅▅▄▅▅▆▆▅▆▅▆▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇██▇▇█▇▇████</td></tr><tr><td>train_f1</td><td>▁▄▅▅▅▅▅▆▆▆▇▆▆▆▆▇▇▆▇▇▆▇▇▇▇▇▇▆▇▇█▇▇█▇▇██▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▅▄▄▃▄▄▃▄▄▄▃▃▃▃▃▃▃▂▂▃▃▂▂▃▂▂▂▂▂▁▂▂▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>▆▆▆▆▅▄▅▃▆▄▄▄█▃▅▂▂▁▃▁▃▁▃▂▃▂▁▃▃▂▆▃▂▄▁▂▂▁▁▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▅▆▆▇▇█▇▇▇█▆▇█▆▇█▇▇▆▆▅▇▆▇▆▆▅▇▇▇▆▇▇▆▅█▇▆</td></tr><tr><td>val_auc</td><td>▁▄▅▆▆█▇███▇▇▆▇▇███▇▇▆█▇▇▇▇▇▆▇▇▇▇▆▇▆▆▆▇▇▆</td></tr><tr><td>val_f1</td><td>▁▅▅▃▁▇▆█▇▆▆█▆▇█▆█▇▆▆▆▆▆▇▆▇▆▆▅▇▇▇▆▆▇▆▄▇▇▄</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▃▄▂▂▂▂▂▂▃▃▃▂▂▃▁▂▂▄▃▃▄▄▄▃▂▅▃▃▄▆▂▄▅▅▆▆▆</td></tr><tr><td>val_loss_step</td><td>█▅▄▄▅▂▂▅▃▄▃▃▄▅▄▄▆▂▂▂▄▅▂▅▃▄▃▂▆▄▂▄▅▁▄▄▄▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.89256</td></tr><tr><td>train_auc</td><td>0.94922</td></tr><tr><td>train_f1</td><td>0.89344</td></tr><tr><td>train_loss_epoch</td><td>0.27185</td></tr><tr><td>train_loss_step</td><td>0.32635</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.77305</td></tr><tr><td>val_auc</td><td>0.86191</td></tr><tr><td>val_f1</td><td>0.76355</td></tr><tr><td>val_loss_epoch</td><td>0.60184</td></tr><tr><td>val_loss_step</td><td>0.87267</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0wr7jdba' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0wr7jdba</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231231_081729-0wr7jdba\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dd746e491f54f78a30651b5ad421a2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231231_085220-8d591dgz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8d591dgz' target=\"_blank\">GINConv_4_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8d591dgz' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8d591dgz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 30.9 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "33.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "33.1 K    Total params\n",
      "0.132     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a3c5aa784f4ff1b8c77fad5ec17751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▅▅▅▅▆▆▆▆▅▆▆▆▆▆▇▆▇▆▇▆▇▆▇▇▆▇▇▇▇▆▇▇▇▇▇██</td></tr><tr><td>train_auc</td><td>█▇▆▅▆▅▆▅▆▆▆▅▅▅▄▄▅▅▅▇▆▆▄▄▅▄▄▅▄▃▃▄▅▃▂▁▂▂▂▁</td></tr><tr><td>train_f1</td><td>▁▃▄▅▅▅▅▆▆▆▆▅▆▆▆▆▆▇▆▇▆▇▆▇▆▇▇▆▇▇▇▇▆▇▇▇▇▇██</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▁▂▁▁▂▂▁▁▁▂▂▂▂▂▁▁▁▁▁▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▆▄▆▆▆▇█▆▅▆▆▇█▆▇▆█▇▅▅▅▅▆▆▆▅▅▆▆▆▄▃▇▆▄▆▅▄</td></tr><tr><td>val_auc</td><td>█▆▃▃▃▂▂▂▃▅▂▁▁▂▁▁▂▁▃▇▃▁▁▁▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁</td></tr><tr><td>val_f1</td><td>▄▅▆▃▆▇▅██▆▄▆▃▇█▅▆▅██▆▆▅▆▅▅▅▆▅▇▆▇▄▁▅▆▂▆▄▄</td></tr><tr><td>val_loss_epoch</td><td>█▄▂▃▂▁▁▂▁▃▂▃▂▁▁▂▂▁▂▁▂▃▂▁▄▄▂▂▃▃▂▂▃▄▄▃▇▄▄▅</td></tr><tr><td>val_loss_step</td><td>█▄▃▄▃▂▁▃▂▄▂▄▃▂▂▃▃▃▂▂▃▃▂▃▄▄▂▂▄▃▃▃▄▂▅▂▆▄▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.90968</td></tr><tr><td>train_auc</td><td>0.08061</td></tr><tr><td>train_f1</td><td>0.90963</td></tr><tr><td>train_loss_epoch</td><td>0.24067</td></tr><tr><td>train_loss_step</td><td>0.17483</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.75177</td></tr><tr><td>val_auc</td><td>0.15487</td></tr><tr><td>val_f1</td><td>0.75294</td></tr><tr><td>val_loss_epoch</td><td>0.69316</td></tr><tr><td>val_loss_step</td><td>0.81219</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8d591dgz' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/8d591dgz</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231231_085220-8d591dgz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "284711a87f974957895fc7ba368ace19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231231_092843-kpzn5mbc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kpzn5mbc' target=\"_blank\">GINConv_4_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kpzn5mbc' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kpzn5mbc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 30.9 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "33.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "33.1 K    Total params\n",
      "0.132     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33ae3bfb9a654290b5610513795fa840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▄▄▄▅▆▅▅▆▆▆▆▆▆▇▆▇▇▆▇▇▆▇▆▇▇▆▇▇▇▆▇█▇█▇█▇</td></tr><tr><td>train_auc</td><td>▁▄▄▅▅▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██████▇</td></tr><tr><td>train_f1</td><td>▁▃▄▄▄▄▅▆▅▅▆▆▆▆▆▆▇▆▇▆▆▇▇▆▇▆▇▇▆▇▇▇▆▇█▇█▇█▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▂▃▂▂▃▂▂▁▃▂▁▁▁▂▁▂</td></tr><tr><td>train_loss_step</td><td>▅▅▆▄▆█▃▅▃▆▃▄▄▂▂▂▃▃▂▄▃▂▄▃▃▂▂▄▃▄▂▁▃▂▃▂▂▂▁▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆█▇▇▅▆▇█▇█▆▄▇▆▆█▇▇▇▇▆▅▇▆▇▇▄▆▅▆▆▆▄▆▇▆▇▅▆</td></tr><tr><td>val_auc</td><td>▁▅▆▇█▇▇▇███▆▂█▇▆█▇▆▇▇▇▅▇▆▆▇▁▆▅▇▆▆▃▆▇▅▇▃▆</td></tr><tr><td>val_f1</td><td>▃▅▇▇█▆▄▇▇▅█▅▁▆▅▆▇▆▆▇▇▇▄▆▁▅▆▂▃▅▆▅▃▄▇▆▇▆▅▅</td></tr><tr><td>val_loss_epoch</td><td>▄▂▂▁▁▂▂▁▂▂▁▁▃▁▁▂▂▂▃▂▃▂▂▁▂▃▃▄▃▅▄▄▂▄▄▂▅▂█▃</td></tr><tr><td>val_loss_step</td><td>▅▃▃▃▂▄▂▁▃▃▂▂▄▃▂▃▃▄▆▁▆▁▄▂▃▃▅▃▄▆▃▆▂▂▂▁▄▃█▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87957</td></tr><tr><td>train_auc</td><td>0.95633</td></tr><tr><td>train_f1</td><td>0.87972</td></tr><tr><td>train_loss_epoch</td><td>0.27067</td></tr><tr><td>train_loss_step</td><td>0.34921</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.74704</td></tr><tr><td>val_auc</td><td>0.84667</td></tr><tr><td>val_f1</td><td>0.74341</td></tr><tr><td>val_loss_epoch</td><td>0.62699</td></tr><tr><td>val_loss_step</td><td>0.80687</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kpzn5mbc' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/kpzn5mbc</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231231_092843-kpzn5mbc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b336e6ebeb449fb8a77fc45c1481c29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231231_100241-ov6kd86q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ov6kd86q' target=\"_blank\">GINConv_4_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ov6kd86q' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ov6kd86q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 30.9 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "37.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "37.3 K    Total params\n",
      "0.149     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cdbbdc7bc824079915f409d3aab0ec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▆▇▇▆▇▇▇█▇██▇████▇█</td></tr><tr><td>train_auc</td><td>▁▄▄▅▅▅▆▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▆▇▇▇█▇▇█▇██▇██████</td></tr><tr><td>train_f1</td><td>▁▃▄▄▄▅▅▅▅▅▆▆▆▆▅▆▆▆▆▆▇▇▆▇▇▆▇▇▇█▇██▇████▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▅▅▅▄▄▄▄▄▄▄▄▃▃▄▃▃▃▃▃▃▂▂▃▂▃▂▂▂▂▂▂▂▂▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>▄▄▃▃▂▃▃▃▃▂▂▄█▂▂▁▂▃▃▂▂▂▂▂▄▁▂▁▃▃▁▃▁▁▂▁▁▂▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▆▅▅▇▆█▇▆▆▇▆▆▄▄▅▇▆▆▇▆▆▆▇▅▅▄▆▅▅▆▄▇▄▄▅▆▄▅</td></tr><tr><td>val_auc</td><td>▁▄▆▆▇▇▇█▆▇▇▇▇▆▇▅▄▇▇▆▇▆▇▆▇▆▇▄▅▅▇▇▄▆▇▆▆▆▆▅</td></tr><tr><td>val_f1</td><td>▁▄▆▇▇▆▅█▇▇▇█▇▅▇▆▆▇▇▇▆▆▇▇▇▂▇▅▆▆▃▅▅▇▇▁▅▆▂▅</td></tr><tr><td>val_loss_epoch</td><td>▄▃▁▂▁▁▁▁▁▁▃▃▃▂▅▂▂▁▂▄▂▃▂▃▂▅▅▄▄▅▂▃▅▃█▄▄▃▃▆</td></tr><tr><td>val_loss_step</td><td>▆▄▃▃▂▃▂▃▂▂▆▃▄▁▇▂▁▃▃▃▁▃▃▄▂█▆▄▅▇▁▄▅▅█▄▄▄▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.91145</td></tr><tr><td>train_auc</td><td>0.97213</td></tr><tr><td>train_f1</td><td>0.91093</td></tr><tr><td>train_loss_epoch</td><td>0.21315</td></tr><tr><td>train_loss_step</td><td>0.23402</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.7565</td></tr><tr><td>val_auc</td><td>0.83216</td></tr><tr><td>val_f1</td><td>0.753</td></tr><tr><td>val_loss_epoch</td><td>0.75064</td></tr><tr><td>val_loss_step</td><td>0.45637</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ov6kd86q' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/ov6kd86q</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231231_100241-ov6kd86q\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a69019415c4841d0a4dbbcd3ec3f35af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231231_103636-5y7b78id</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5y7b78id' target=\"_blank\">GINConv_2_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5y7b78id' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5y7b78id</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇█▇▇▇██████████▇████▇█████▇█</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇█▇██▇██████████████████▇█</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇██▇▇████▇▇▇████▇█████▇█</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▃▄▃▃▂▂▂▂▂▂▂▂▃▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁▂▂▁▁▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▄▄▃▄▃▂▄▂▄▃▅▅▂▄▄▃▃▄▃▂▃▆▄▃▃▃▃▂▃▅▆▆▃▁▃▄▄▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▅▆▆▆▇▇▇▆███▇▇▅▇█▇█▆█▇▇▇▆▇▇▇▇▇▇█▇█▆▆▇██</td></tr><tr><td>val_auc</td><td>▁▅▅▆▅▆▇▇▇▇█▇█▇▇▇█▇▆█▇▇▇▇▇▇▇▆▇▇▇▇▇▇█▆▇▇▇█</td></tr><tr><td>val_f1</td><td>▁▆▅▆▆▇▇█▇▇███▇█▅▇█▇█▇█▇▇▇▆▇▇▇▇▇▇█▇█▇▇▇▇█</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▃▃▃▃▃▂▂▂▂▂▁▃▂▁▁▂▂▂▂▂▂▁▃▁▂▂▂▂▂▁▂▁▃▂▃▂▁</td></tr><tr><td>val_loss_step</td><td>█▄▃▄▅▄▆▆▃▄▄▂▃▂▄▂▂▂▄▄▄▄▃▅▁▅▁▂▃▅▂▅▂▅▃▃▄▅▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84357</td></tr><tr><td>train_auc</td><td>0.9121</td></tr><tr><td>train_f1</td><td>0.83969</td></tr><tr><td>train_loss_epoch</td><td>0.37318</td></tr><tr><td>train_loss_step</td><td>0.36795</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82506</td></tr><tr><td>val_auc</td><td>0.90015</td></tr><tr><td>val_f1</td><td>0.84052</td></tr><tr><td>val_loss_epoch</td><td>0.38626</td></tr><tr><td>val_loss_step</td><td>0.34599</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5y7b78id' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/5y7b78id</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231231_103636-5y7b78id\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "321e206880e4455f932379bbabec29d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231231_111040-x4nzok1g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/x4nzok1g' target=\"_blank\">GINConv_2_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/x4nzok1g' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/x4nzok1g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cf08f04815b4223bec05f80dd2bbae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▇▆▆▇▇▇▇▇▇▇▇▇█▇▇▇▇▇███▇█▇█▇██▇▇█▇██▇██</td></tr><tr><td>train_auc</td><td>▁▄▆▆▇▇▇▇▇▇▇▇▇▇▇█▇█▇█████████████▇███████</td></tr><tr><td>train_f1</td><td>▁▄▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█████▇█▇███▇████▇██</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▁▁▁▂▁▂▁▁▂▂▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▅▄▄▅▃▄▃▄▄▅▄▃▄▄▄▁▄▄▄▃▄▅▂▄▃▃▂▅▄▄▆▃▃▄▂▄▃▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▇▆▇▆▇▇█▆▇█▇▇▇▇▇▇▇▇█▇▇▇▇▇▇██▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>val_auc</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇██████████████</td></tr><tr><td>val_f1</td><td>▁▆▇▇▇▇███▇▇██▇▇█▇▇▇▇█▇█▇▇█▇████▇▇▇▇▇▇▇█▇</td></tr><tr><td>val_loss_epoch</td><td>█▅▃▃▃▂▃▂▁▃▂▂▂▂▃▂▂▁▂▂▂▂▂▁▂▂▁▂▁▂▁▂▁▂▂▂▂▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▆▃▄▅▄▅▄▂▅▄▂▃▂▆▂▅▂▃▄▄▄▅▂▂▅▁▄▂▄▃▄▂▆▂▃▄▄▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.81523</td></tr><tr><td>train_auc</td><td>0.89665</td></tr><tr><td>train_f1</td><td>0.81876</td></tr><tr><td>train_loss_epoch</td><td>0.40694</td></tr><tr><td>train_loss_step</td><td>0.4398</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82506</td></tr><tr><td>val_auc</td><td>0.90006</td></tr><tr><td>val_f1</td><td>0.83772</td></tr><tr><td>val_loss_epoch</td><td>0.39679</td></tr><tr><td>val_loss_step</td><td>0.41288</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/x4nzok1g' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/x4nzok1g</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231231_111040-x4nzok1g\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "654b303d1f184cb7aa4b3ef332a1860d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231231_114359-r8d6nlfj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/r8d6nlfj' target=\"_blank\">GINConv_2_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/r8d6nlfj' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/r8d6nlfj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0d55f21d53e49df9680d210756de92b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇▇████████████</td></tr><tr><td>train_auc</td><td>▅█▇▇▇▅▂▃▂▂▂▂▃▂▂▂▂▂▂▂▅▄▃▄▄▃▄▄▄▂▃▃▂▂▃▃▂▃▁▂</td></tr><tr><td>train_f1</td><td>▁▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇██▇█▇▇████████████▇</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▂▂▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▅▅▅▄▅▄▅▅▄▅▅▆▆▆▅▅▆▆▆▆▆▄▅▇▆▆▅▅▇█▆▇▇█▆▇▇▇</td></tr><tr><td>val_auc</td><td>█████▅▃▂▁▂▃▂▂▂▂▂▂▂▂▅█▇▇▅▇▅▆▆▇▂▇▃▁▆▅▂▁▅▁▂</td></tr><tr><td>val_f1</td><td>▁▆▆▅▆▅▅▅▆▅▅▆▅▆▆▆▆▆▇▇▇▇▆▅▅█▇▇▅▆▇█▇▇▇█▆▇▇█</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▂▂▂▃▃▂▂▂▁▂▂▂▁▂▁▁▂▂▂▂▂▂▂▁▂▂▂▁▂▁▂▁▁▂▁▂▂</td></tr><tr><td>val_loss_step</td><td>█▄▂▂▃▃▄▄▂▂▃▁▂▂▃▁▂▁▁▂▂▂▂▂▁▃▁▂▃▃▁▂▂▂▁▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.81346</td></tr><tr><td>train_auc</td><td>0.47996</td></tr><tr><td>train_f1</td><td>0.80987</td></tr><tr><td>train_loss_epoch</td><td>0.42121</td></tr><tr><td>train_loss_step</td><td>0.32718</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82033</td></tr><tr><td>val_auc</td><td>0.22951</td></tr><tr><td>val_f1</td><td>0.841</td></tr><tr><td>val_loss_epoch</td><td>0.42566</td></tr><tr><td>val_loss_step</td><td>0.41179</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/r8d6nlfj' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/r8d6nlfj</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231231_114359-r8d6nlfj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86a44a06cca848118a7c8759ad453004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231231_121728-cnmkobfh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/cnmkobfh' target=\"_blank\">GINConv_2_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/cnmkobfh' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/cnmkobfh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.1 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17eb62e95efe446788b773f2d9ca5335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▆▇▇▇▇▇▇▇▇▇█▇▇▇█▇█▇█▇████▇██████▇▇███</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇█▇█▇█▇█▇██████████████</td></tr><tr><td>train_f1</td><td>▁▆▆▆▆▇▇▇▇▇▇█▇▇█▇▇▇█▇█▇█▇████▇███▇██▇▇███</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▃▃▃▂▃▃▂▂▃▂▂▂▂▂▂▁▂▂▂▁▂▁▁▂▁▁▂▂▁▁▂▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▆▆▅▅▇▄▅▄▄▃█▅▅▄▇▅▃▃▄▄▃▃▃▃▅▁▃▅▄▅▄▃▃▅▃▂▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▄▅▆▇▇▅▅▆▇▇▇▇▇▆▇▇▇▇█▇█▇▇▇▇▇█▇▇▇▇▇▇▅▇▇▇▇</td></tr><tr><td>val_auc</td><td>▁▄▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇▇██▆▇▇▇█</td></tr><tr><td>val_f1</td><td>▁▃▅▅▆▇▇▆▅▆█▇█▇▇▆▇▇▇██▇█▇▆▇▇▇█▇█▇█▇▇▅█▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▆▄▄▃▃▃▃▄▂▂▂▂▂▂▄▂▂▂▂▂▂▂▂▃▁▄▁▁▃▂▃▂▁▂▅▂▂▂▁</td></tr><tr><td>val_loss_step</td><td>█▅▅▆▆▄▅▆▅▃▄▃▅▃▃▇▅▅▄▄▄▄▄▄▆▂█▁▁▇▄▅▄▂▅█▄▅▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83884</td></tr><tr><td>train_auc</td><td>0.91515</td></tr><tr><td>train_f1</td><td>0.84082</td></tr><tr><td>train_loss_epoch</td><td>0.37109</td></tr><tr><td>train_loss_step</td><td>0.30874</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81087</td></tr><tr><td>val_auc</td><td>0.90184</td></tr><tr><td>val_f1</td><td>0.83264</td></tr><tr><td>val_loss_epoch</td><td>0.37958</td></tr><tr><td>val_loss_step</td><td>0.35573</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/cnmkobfh' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/cnmkobfh</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231231_121728-cnmkobfh\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d4c71b989b844f49def7d4bb6f38228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333332417533, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231231_125054-g5dy1kzx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/g5dy1kzx' target=\"_blank\">GINConv_2_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/g5dy1kzx' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/g5dy1kzx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.1 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "1.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇████▇█▇██████████▇██████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇█▇▇▇▇██▇████████████▇██████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███▇█▇█▇█▇██████▇██████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▃▃▃▃▂▂▂▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▂▁▂▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▆▅▃▄▃▃▅▆▇▄▄▄▁▅▄▅▁▆▃▃▃█▃▅▅▁█▂▅▃▅▅▂▄▁▃▁▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▃▂▄▅▅▇▇▆▄▆▇▆▆██▅█▇▆▆▇▆▇▅▇▇▅▆▆▇▆▄▇▇▆▆▆▇</td></tr><tr><td>val_auc</td><td>▁▅▅▅▆▇▆▇▇▇▇▇█▇▇█▇▇▇███▇▇▇█▇▇▇▇▆▇█▇██▇▇█▇</td></tr><tr><td>val_f1</td><td>▁▅▃▂▄▅▅▇█▇▄▆▇▆▆██▅█▇▆▆█▆▇▆▇▇▅▇▆▇▇▅▆▇▇▆▆▇</td></tr><tr><td>val_loss_epoch</td><td>█▅▅▅▄▃▃▃▃▃▂▂▃▃▃▃▁▂▃▂▁▂▃▃▃▂▃▃▃▂▂▄▁▂▂▂▂▂▂▂</td></tr><tr><td>val_loss_step</td><td>█▇█▆▆▅▄▆▅▆▃▂▆▅▆█▂▄▅▆▁▂▅▅▅▄█▇▅▁▄█▁▁▄▃▄▃▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8412</td></tr><tr><td>train_auc</td><td>0.91384</td></tr><tr><td>train_f1</td><td>0.84223</td></tr><tr><td>train_loss_epoch</td><td>0.3729</td></tr><tr><td>train_loss_step</td><td>0.38337</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80851</td></tr><tr><td>val_auc</td><td>0.89261</td></tr><tr><td>val_f1</td><td>0.83368</td></tr><tr><td>val_loss_epoch</td><td>0.4127</td></tr><tr><td>val_loss_step</td><td>0.396</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/g5dy1kzx' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/g5dy1kzx</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231231_125054-g5dy1kzx\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26ea7100c9b646f6859bacfa2caba497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231231_132529-rzhw1dui</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/rzhw1dui' target=\"_blank\">GINConv_2_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/rzhw1dui' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/rzhw1dui</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 3.8 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00070c25a0c641d5ae0fe65db5f629e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▅▅▅▅▆▆▆▆▅▆▆▆▆▇▆▇▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇</td></tr><tr><td>train_auc</td><td>▁▄▄▅▅▄▃▂▄▅▅▅▄▄▄▃▄▅▅▅▆▆▇▆▆▆▇▇▇▇▇▇▇█▇████▇</td></tr><tr><td>train_f1</td><td>▁▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▇▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▃▂▂▂▂▃▂▂▂▁▂▂▂▁▂▂▂▁▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▇▆▅▅▅▅▅▆▄▄▄▇▄▅▄▄▁▃▃▃▄▃▃▄▃▃▂▄▄▆▂▄▂▄▂▅▄▄▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▃▂▂▆▃▅▅▆█▆█▇▇▆▆▆▆▆██▅▆▆▇▆▇▇▇▂▄▆▅▃▄▅▆▁▆▇▆</td></tr><tr><td>val_auc</td><td>▁▃▅▅▅▅▆▅▇▇▇▇▇▇▆▆▆▇█▇▇▇▇▇▇▆▇▇▆▆▆▆▆▅▆▆▅▇▇▅</td></tr><tr><td>val_f1</td><td>▅▃▂▇▄▆▅▇█▆█▇█▆▇▇▇▆██▅▇▅▇▇█▇█▂▄▆▆▃▄▆▇▁▇█▇</td></tr><tr><td>val_loss_epoch</td><td>▆▅▅▃▄▄▂▄▃▃▃▃▂▃▃▂▂▃▁▁▃▃▃▃▂▃▃▂▇▄▂▃▆▄▃▂█▂▃▄</td></tr><tr><td>val_loss_step</td><td>▆▄▄▃▂▅▁▅▃▅▄▄▄▃▆▃▂▃▂▁▃▄▂▅▁▄▄▂█▃▁▃▆▂▃▁▆▂▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85537</td></tr><tr><td>train_auc</td><td>0.91868</td></tr><tr><td>train_f1</td><td>0.8483</td></tr><tr><td>train_loss_epoch</td><td>0.33876</td></tr><tr><td>train_loss_step</td><td>0.40104</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80615</td></tr><tr><td>val_auc</td><td>0.88372</td></tr><tr><td>val_f1</td><td>0.83128</td></tr><tr><td>val_loss_epoch</td><td>0.44961</td></tr><tr><td>val_loss_step</td><td>0.52255</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/rzhw1dui' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/rzhw1dui</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231231_132529-rzhw1dui\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7d1c93be4b2414c8dfb06437104afe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231231_135923-551luqho</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/551luqho' target=\"_blank\">GINConv_2_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/551luqho' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/551luqho</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 3.8 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92d6c67bce9e482a9d4694d8e02e68dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇██▇██▇█▇███</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇████▇███████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇███████▇███</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▃▂▃▂▂▂▂▂▂▁▂▂▃▂▂▂▂▂▂▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▆▅▄▃▄▄▄▃▄▃▅▃▄▃▄▁▃▂▂▃▄▂▃▂▂▂▃▃▄▃▃▄▂▃▄▄▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▃▆▅▆▆▆▆▆▅▆▆█▆▆▇▆▆▇█▅▇▆▆▇█▆▆▇▆▇▇▇▆▇██▇█</td></tr><tr><td>val_auc</td><td>▁▅▅▇▆▆▇▇▆▇▇▇▇▇▇▇▇█▇█▇▇▇██▇▇▇▇▇▇█▇█▇███▇█</td></tr><tr><td>val_f1</td><td>▁▂▄▇▄▆▆▆▅▆▄▇▅█▆▆▇▅▇▆▇▃▆▄▇▇█▆▅▆▆▆▇▆▆▇▇▇▆▇</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▃▃▃▂▃▃▂▃▂▂▂▃▂▁▂▁▁▂▃▂▃▁▂▂▂▃▂▂▂▃▂▂▁▂▁▃▁</td></tr><tr><td>val_loss_step</td><td>█▄▄▄▃▅▂▅▄▃▅▃▄▃▇▄▂▅▁▁▅▃▃▅▁▃▄▃▆▂▂▃▅▃▃▁▄▂▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86423</td></tr><tr><td>train_auc</td><td>0.93345</td></tr><tr><td>train_f1</td><td>0.86061</td></tr><tr><td>train_loss_epoch</td><td>0.31448</td></tr><tr><td>train_loss_step</td><td>0.23015</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.84397</td></tr><tr><td>val_auc</td><td>0.91352</td></tr><tr><td>val_f1</td><td>0.85526</td></tr><tr><td>val_loss_epoch</td><td>0.365</td></tr><tr><td>val_loss_step</td><td>0.32149</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/551luqho' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/551luqho</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231231_135923-551luqho\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92fcb07ad92043ef9385eee25a9377d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333332417533, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231231_143445-3qhmaxkx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/3qhmaxkx' target=\"_blank\">GINConv_2_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/3qhmaxkx' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/3qhmaxkx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 3.8 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19af9d5b78914e5e93025ab300e3e8af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▆▆▆▆▆▆▆▆▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇██████</td></tr><tr><td>train_auc</td><td>█▄▄▄▆█▇▇▇▅▆▄▅▅▅▅▄▃▄▅▆▄▄▃▄▅▃▁▂▂▁▃▃▆▃▃▄▄▅▅</td></tr><tr><td>train_f1</td><td>▁▃▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇████▇███████</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▁▂▁▁▂▂▂▂▂▂▁▂▁▂▂▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▂▄▃▄▄▅▆▇▇▇▇▇▄▇▇▃▇▇▇▇▇▇▆▅█▇▁▇▇▅█▇▄██▇█▆</td></tr><tr><td>val_auc</td><td>▅▂▂▂▇▇█▅▃▂▂▂▂▁▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▂▁▂▂</td></tr><tr><td>val_f1</td><td>▅▄▂▅▃▄▄▅▇▇▇▇▆▇▄▇▇▂█▆▇▇▆▇▆▅█▇▁▆▇▅█▇▄▇▇▇█▇</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▂▃▃▂▂▂▂▃▃▂▁▃▂▁▄▂▃▁▂▁▂▂▃▂▂▄▂▂▃▂▁▃▁▂▁▂▃</td></tr><tr><td>val_loss_step</td><td>█▄▃▂▃▄▁▄▃▄▄▃▃▃▅▃▂▄▂▂▂▃▁▄▁▃▄▃▆▃▂▃▄▂▂▁▄▁▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84298</td></tr><tr><td>train_auc</td><td>0.40757</td></tr><tr><td>train_f1</td><td>0.83681</td></tr><tr><td>train_loss_epoch</td><td>0.37403</td></tr><tr><td>train_loss_step</td><td>0.32677</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80851</td></tr><tr><td>val_auc</td><td>0.13553</td></tr><tr><td>val_f1</td><td>0.83897</td></tr><tr><td>val_loss_epoch</td><td>0.47768</td></tr><tr><td>val_loss_step</td><td>0.49086</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/3qhmaxkx' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/3qhmaxkx</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231231_143445-3qhmaxkx\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0243ada2c3834d33add6fca086b5079a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333332417533, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231231_151104-z9159aj9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/z9159aj9' target=\"_blank\">GINConv_2_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/z9159aj9' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/z9159aj9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 3.8 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "4.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.4 K     Total params\n",
      "0.018     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5908657d4cc84e01b672b9d8c34d6f46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▅▅▆▅▆▆▆▆▇▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇▇█▇</td></tr><tr><td>train_auc</td><td>▁▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇█▇▇██████</td></tr><tr><td>train_f1</td><td>▁▅▆▅▅▅▆▆▆▆▆▆▇▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇██▇█▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▃▂▂▂▂▂▃▂▂▂▂▂▂▂▁▁▂▁▂</td></tr><tr><td>train_loss_step</td><td>▆█▄▅▆▄▅▅▃▃▃▃▆▆▅▅▅▃▆▄▃▃▂▄▂▃▃▃▃▃▃▄▄▂▁▃▃▃▁▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▂▅▄▅▅▆▆▇▇▇▇▆█▄▄▅▇▄▆▆▂▆▄▆▆▆▆▅▆▆▅▅▅▄▆▄▆▅</td></tr><tr><td>val_auc</td><td>▁▃▅▆▄▆▇▇▇▇██▇▇█▇▇▇▇▇█▇▇▇▇▇▇█▆▇▇▆▆▇▇▂▇▆▇▆</td></tr><tr><td>val_f1</td><td>▄▅▂▅▄▅▆▆▆▇▇▇▇▇█▄▅▅▇▄▇▇▁▇▄▇▆▇▆▆▇▆▆▅▆▅▆▅▆▆</td></tr><tr><td>val_loss_epoch</td><td>█▅▇▄▅▅▁▃▃▂▂▂▁▃▁▄▅▃▃▄▂▄█▃▄▄▃▁▂▃▃▂▇▅▅▆▃▄▂▃</td></tr><tr><td>val_loss_step</td><td>▅▅▇▄▆▆▂▅▄▄▅▄▂▅▂▄▇▃▄▅▄▇▆▄▄▇▃▁▄▃▄▁▇▇█▅▅▄▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86659</td></tr><tr><td>train_auc</td><td>0.93383</td></tr><tr><td>train_f1</td><td>0.8622</td></tr><tr><td>train_loss_epoch</td><td>0.3272</td></tr><tr><td>train_loss_step</td><td>0.38185</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.79905</td></tr><tr><td>val_auc</td><td>0.88941</td></tr><tr><td>val_f1</td><td>0.8203</td></tr><tr><td>val_loss_epoch</td><td>0.4181</td></tr><tr><td>val_loss_step</td><td>0.39456</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/z9159aj9' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/z9159aj9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231231_151104-z9159aj9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f075da374704412db9c5e335a23a6268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231231_154415-e892olk6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/e892olk6' target=\"_blank\">GINConv_2_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/e892olk6' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/e892olk6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 3.8 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "5.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.4 K     Total params\n",
      "0.022     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4320958f6964d5f9fd1c0a5e76b9e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▆▆▆▅▅▆▆▇▆▆▇▇▆▇▆▇▇▇▇▇█▇▇▇▇▇▇██▇█▇█████</td></tr><tr><td>train_auc</td><td>▁▅▄▅▄▄▅▅▆▄▅▅▅▆▆▆▇▅▆▇▇▇▆▇▆▇▇▇▆▇██▇███████</td></tr><tr><td>train_f1</td><td>▁▅▅▆▆▆▆▆▆▆▇▆▇▇▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇██▇█▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▄▄▄▄▄▄▃▃▄▃▂▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▁▁▁▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>▇▇▅▆▅▅▆▅▅▄▄▄█▂▃▄▄▃▄▃▃▂▄▃▃▄▄▆▄▃▁▃▂▁▂▃▂▄▄▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▂▃▃▄▂▆▆▃▇▇▇▃▅▅█▃▆▆▃▆▄▇▆▅▄▇█▂▆▆▅▃▅▇▅▄▅▆▁</td></tr><tr><td>val_auc</td><td>▁▃▄▆▇▄▇▇▇▇▇▇▇▇█▇▆█▇█▇▇▇▇█▆▇█▇▇▇▆▇▇█▇▇▇▇▆</td></tr><tr><td>val_f1</td><td>▄▂▃▃▄▃▆▇▃▇▇█▃▅▅█▃▆▆▃▆▄▇▇▅▄▇█▂▆▇▅▃▅▇▅▄▆▇▁</td></tr><tr><td>val_loss_epoch</td><td>█▇▆▄▅▄▃▂▃▂▁▃▄▃▂▄▃▃▂▄▅▄▂▄▆▆▄▁▆▂▃▅▄▃▂▄▄▂▂▅</td></tr><tr><td>val_loss_step</td><td>▅▅▅▃▆▂▂▂▂▂▁▃▃▃▂▆▂▅▃▃▆▄▃▄██▅▂▆▂▃▅▃▄▃▄▂▂▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.86836</td></tr><tr><td>train_auc</td><td>0.91843</td></tr><tr><td>train_f1</td><td>0.86671</td></tr><tr><td>train_loss_epoch</td><td>0.33557</td></tr><tr><td>train_loss_step</td><td>0.3164</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.76596</td></tr><tr><td>val_auc</td><td>0.88658</td></tr><tr><td>val_f1</td><td>0.76596</td></tr><tr><td>val_loss_epoch</td><td>0.45403</td></tr><tr><td>val_loss_step</td><td>0.42877</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/e892olk6' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/e892olk6</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231231_154415-e892olk6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5c9c36de4db4fb7a4ac1abba1384dd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.017200000000108653, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231231_162002-z3oqn2y6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/z3oqn2y6' target=\"_blank\">GINConv_2_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/z3oqn2y6' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/z3oqn2y6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 13.8 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.9 K    Total params\n",
      "0.064     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▅▅▅▅▆▆▆▆▆▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇██▇██</td></tr><tr><td>train_auc</td><td>▁▄▄▅▅▅▅▆▆▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇██</td></tr><tr><td>train_f1</td><td>▁▄▄▅▅▅▅▅▆▆▆▅▅▆▆▆▆▆▇▆▇▇▇▆▇▇▇▇▇▇█▇▇█▇██▇██</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▃▃▂▃▃▂▂▂▁▃▂▁▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▆▆▆▆▅▅▅▅▄▅▄▅▄▄▃▅▃▄▄▄▅▃▅▃▃▃▄▂▇▃▂▆▂▃▂▁▃▃▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▆▁▄▆▆▅▆█▇█▇▆▇▇▇▄▇▆█▆▅▇▆▆▇▇▇█▇▆▇█▇▇▇▇▇▇▆▄</td></tr><tr><td>val_auc</td><td>▁▁▄▃▆▆▆▇▇▇▇▆▆▆▆▄▆▆▇▇▆▇▄▆▆▅█▆▆▇▆▆▆▇▇▆▄▆▅▄</td></tr><tr><td>val_f1</td><td>▇▁▄▆▆▆▇▇██▇▆▇▇▆▄▇▆▇▆▅▇▆▇▇▇▇▇▇▆▇█▇▇▇▇▇█▆▄</td></tr><tr><td>val_loss_epoch</td><td>▃▇▄▂▂▂▂▁▂▁▂▂▂▂▂▄▂▅▃▁▄▂▃▂▂▂▂▃▂▂▃▂▂▃▁▃▅▃▅█</td></tr><tr><td>val_loss_step</td><td>▄▄▃▂▃▄▃▂▄▃▅▄▄▃▄▄▂▅▆▁▄▃▃▁▄▂▄▅▄▁▂▂▁▁▂▄▅▃▅█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.89787</td></tr><tr><td>train_auc</td><td>0.9667</td></tr><tr><td>train_f1</td><td>0.89509</td></tr><tr><td>train_loss_epoch</td><td>0.24041</td></tr><tr><td>train_loss_step</td><td>0.36372</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.75887</td></tr><tr><td>val_auc</td><td>0.87611</td></tr><tr><td>val_f1</td><td>0.75</td></tr><tr><td>val_loss_epoch</td><td>0.6322</td></tr><tr><td>val_loss_step</td><td>0.73533</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/z3oqn2y6' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/z3oqn2y6</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231231_162002-z3oqn2y6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a474e73d98e841ed8033a86276fc5dc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231231_165420-e3v27rvk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/e3v27rvk' target=\"_blank\">GINConv_2_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/e3v27rvk' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/e3v27rvk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 13.8 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.9 K    Total params\n",
      "0.064     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▄▅▆▆▆▆▆▇▆▇▆▇▇▆▇▇▆▇▇▇▇▇█▇███▇▇▇▇▇█████</td></tr><tr><td>train_auc</td><td>▁▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇███▇███▇█████</td></tr><tr><td>train_f1</td><td>▁▅▅▅▆▆▆▆▇▆▇▇▇▇▇▇▆▇█▇▇▇▇▇▇█▇███▇▇▇█▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▅▄▄▃▄▃▄▃▃▃▃▃▂▃▃▂▃▂▂▂▂▃▂▂▂▂▁▂▂▂▂▂▂▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▆▆▆▆▄▅▃▃▃▄▃▄▃▃▂▄▂▄▄▁▃▁▅▁▂▂▂▂▄▃▂▂▂▄▁▂▁▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▂▇▆▆▇▆▇█▇▇▆▅▇▇█▇▃█▇▇▆▇█▇▆▇█▆█▆▃▆▇▁▆▆▇▇▆</td></tr><tr><td>val_auc</td><td>▁▅▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████▇▇▇▇▇███▇█▇▅▇▇▇▇█</td></tr><tr><td>val_f1</td><td>▃▂▇▇▆▇▇██▇▇▆▅█▇█▇▃██▇▆▇█▇▆██▆█▆▃▆▇▁▆▇▇▇▆</td></tr><tr><td>val_loss_epoch</td><td>█▅▂▃▃▃▂▂▂▂▄▃▄▁▃▃▂█▂▁▃▂▂▂▄▃▃▂▄▄▂▅▃▃▇▃▄▄▂▆</td></tr><tr><td>val_loss_step</td><td>▆▃▃▃▅▆▂▃▃▃▆▄▆▁▅▆▄▇▄▄▃▅▃▂▆▃▆▄▄█▄▄▂▅▆▃▅▂▃█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.89551</td></tr><tr><td>train_auc</td><td>0.96251</td></tr><tr><td>train_f1</td><td>0.89108</td></tr><tr><td>train_loss_epoch</td><td>0.25214</td></tr><tr><td>train_loss_step</td><td>0.31359</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.8156</td></tr><tr><td>val_auc</td><td>0.91068</td></tr><tr><td>val_f1</td><td>0.81604</td></tr><tr><td>val_loss_epoch</td><td>0.48727</td></tr><tr><td>val_loss_step</td><td>0.6162</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/e3v27rvk' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/e3v27rvk</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231231_165420-e3v27rvk\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ce1665c91f14f499bb1dd9bfce1ac4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231231_172708-yg15oupq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yg15oupq' target=\"_blank\">GINConv_2_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yg15oupq' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yg15oupq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 13.8 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.9 K    Total params\n",
      "0.064     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6084b63ea11e43f09407d2c343c8591a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇█▆▇▇█▇█</td></tr><tr><td>train_auc</td><td>▅▃▁▁▂▃▃▄▃▄▄▄▅▅▅▃▄▆▆▆▆▆▆▆▅▇██▆▆▆▇▆▇▇▆▆▆▆▅</td></tr><tr><td>train_f1</td><td>▁▃▄▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇█</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▂▁▂▂▁▁▁▁▁▂▁▁▁▁▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▃▁▃▄▄▅▅▅▄▆▆▆▆▇▇▇▇▅█▇▅▇█▅▇▁▅▆▇▇▅▅█▆▄▆▅▇▅▆</td></tr><tr><td>val_auc</td><td>▇▂▁▁▃▄▄▅▆▇█▇▇█▇▃█████████▇██████████████</td></tr><tr><td>val_f1</td><td>▅▁▄▅▄▆▅▅▄▆▆▆▇█▇█▆▅█▇▅▇█▅▇▅▅▇▇▇▅▅█▆▆▆▅█▅▆</td></tr><tr><td>val_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▂▁▁▁▁▂▁▁▁▁▁▁▁▁▂▁▂▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▂▁▁▂▂▂▂▁▂▁▂▂▁▂▂▂▂▂▁▂▂▁▁▂▂▂▂▂▂▂▂▁▁▁▂▂▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87603</td></tr><tr><td>train_auc</td><td>0.62396</td></tr><tr><td>train_f1</td><td>0.87226</td></tr><tr><td>train_loss_epoch</td><td>0.32786</td></tr><tr><td>train_loss_step</td><td>0.53396</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80142</td></tr><tr><td>val_auc</td><td>0.84705</td></tr><tr><td>val_f1</td><td>0.81579</td></tr><tr><td>val_loss_epoch</td><td>0.4493</td></tr><tr><td>val_loss_step</td><td>0.46246</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yg15oupq' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yg15oupq</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231231_172708-yg15oupq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34a194cecdd149febc578432e6696794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231231_175930-qtjz69f7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qtjz69f7' target=\"_blank\">GINConv_2_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qtjz69f7' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qtjz69f7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 13.8 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "16.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "16.0 K    Total params\n",
      "0.064     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75fbd523030e4e1c9dcfc07d4350864e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▅▅▆▅▆▆▅▆▆▆▆▆▆▆▆▆▇▆▆▆▇▇▇▇▇▇▇▇▇█▇▇▇███</td></tr><tr><td>train_auc</td><td>▁▄▅▆▆▆▆▆▆▆▆▆▇▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██████████</td></tr><tr><td>train_f1</td><td>▁▄▅▅▅▅▆▅▆▆▅▆▆▆▆▆▆▆▇▆▇▆▆▆▇▇▇▇▇▇▇▇▇█▇▇▇███</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▄▄▄▄▄▄▄▃▄▃▃▄▃▃▃▂▃▃▃▂▃▂▃▂▂▂▂▂▂▂▂▂▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▆▆▅▆▄▅▄▄▄▄▄▆▅▄▄▄▃▁▄▁▃▁▃▃▄▃▄▂▃▃▂▁▄▁▂▂▂▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▅▁▄█▇█▅█▇█▇▇▇▇▇▇▇▆▇▇▅▇▆▇▇▇▇▇▇▆▇▆▇▇▇▆▆▆</td></tr><tr><td>val_auc</td><td>▁▄▆▇▄█▆█▇▇████▇▇▇▆▇█▅█▇█▇▇▇▇▆▇▇▆▇▅▇▇▆▄▅▆</td></tr><tr><td>val_f1</td><td>▂▅▅▁▄█▇█▅█▇██▇▇█▇▇▇▇██▅█▆▇▇▇█▇▇▇▇▇▇▇▇▆▇▆</td></tr><tr><td>val_loss_epoch</td><td>▇▄▅█▆▁▃▂▄▂▂▃▂▂▂▂▃▂▃▃▆▃▆▁▃▃▃▂▃▃▂▅▂▇▆▄▆█▅▇</td></tr><tr><td>val_loss_step</td><td>▄▂▅▅▄▂▃▃▃▄▃▄▄▂▂▄▄▁▄▃█▄▄▁▁▃▂▃▁▂▂▅▂▇▇▄▅▅▃▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.89669</td></tr><tr><td>train_auc</td><td>0.96154</td></tr><tr><td>train_f1</td><td>0.89297</td></tr><tr><td>train_loss_epoch</td><td>0.25309</td></tr><tr><td>train_loss_step</td><td>0.29749</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.78251</td></tr><tr><td>val_auc</td><td>0.88356</td></tr><tr><td>val_f1</td><td>0.79556</td></tr><tr><td>val_loss_epoch</td><td>0.54591</td></tr><tr><td>val_loss_step</td><td>0.68604</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qtjz69f7' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qtjz69f7</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231231_175930-qtjz69f7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb047980addb4a019ecd2eac5da1eb54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333332417533, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231231_183148-wkhlbvmk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wkhlbvmk' target=\"_blank\">GINConv_2_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wkhlbvmk' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wkhlbvmk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 13.8 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "20.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.1 K    Total params\n",
      "0.080     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▅▄▅▅▅▆▅▆▆▆▆▆▆▆▇▆▆▇▇▇▇▆▆▇▇▆▇▇▇▇▇▆██▇▇▇</td></tr><tr><td>train_auc</td><td>▁▄▄▅▅▅▆▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇███▇▇███▇█</td></tr><tr><td>train_f1</td><td>▁▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▆▆▇▇▇▇▇▆▇▇▇▇▇▇█▇▇███▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▅▄▄▄▄▄▄▃▄▄▄▃▃▃▃▃▃▃▂▂▂▃▂▂▂▂▂▂▂▂▂▂▁▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▇▆▄▄▄▄▇▄▅▃▅█▃▄▄▅▄▄▃▅▅▂▃▃▄▃▄▃▅▄▃▄▃▃▂▃▂▁▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▂▄▆▁▆▇▆▇▇▆▅▅▇▅▆▇▇▅▆▆▇▆█▆▇▅▆▆▇▇▄▆▃█▆▆█▇▆▆</td></tr><tr><td>val_auc</td><td>▁▄▆▆▇▇▇▇▇▆▇▆▅█▅▇▇▆█▇▆▅█▇▇▆▅▇▆▇▅▄▆▇▆▅▆▆▂▅</td></tr><tr><td>val_f1</td><td>▃▅▇▁▆▇▇▇█▆▆▆▇▅▇██▇▆▇▇▇█▇▇▅▇▇▇█▄▇▃█▇▆█▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>▅▃▃▅▂▂▁▂▁▂▂▂▃▂▂▂▃▂▃▃▂▂▁▁▂▃▃▂▂▂▅▄█▂▂▆▄▂▃▄</td></tr><tr><td>val_loss_step</td><td>▄▅▄▄▄▃▂▄▁▃▂▂▄▁▄▂▄▂▄▆▄▂▂▂▄▂▄▂▂▃▅▇▅▄▂█▃▃▁▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.88725</td></tr><tr><td>train_auc</td><td>0.95337</td></tr><tr><td>train_f1</td><td>0.88347</td></tr><tr><td>train_loss_epoch</td><td>0.2721</td></tr><tr><td>train_loss_step</td><td>0.25771</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80851</td></tr><tr><td>val_auc</td><td>0.87989</td></tr><tr><td>val_f1</td><td>0.82198</td></tr><tr><td>val_loss_epoch</td><td>0.49292</td></tr><tr><td>val_loss_step</td><td>0.65679</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wkhlbvmk' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wkhlbvmk</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231231_183148-wkhlbvmk\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48748b3f5ada4c5e9970fbae15e5505d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231231_190715-tji1rkn1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tji1rkn1' target=\"_blank\">GINConv_3_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tji1rkn1' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tji1rkn1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.7 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "708fcc3ff08548f29be5cf42578a40ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇▇█▇███▇▇█████▇█</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇█▇▇▇█▇▇██████▇████████████</td></tr><tr><td>train_f1</td><td>▁▆▆▇▇▇▇▇▇▇▇█▇▇▇▇█▇█████████▇███▇████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▃▄▃▃▃▂▂▃▃▂▂▂▃▂▁▂▂▂▂▂▂▂▁▂▂▂▁▂▂▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>▅▄▂▄▃▃▃▃▃▂▃▂█▂▄▄▂▃▂▂▃▂▁▄▂▂▂▃▂▂▃▂▃▂▃▂▃▂▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▄▆▅▅▅▅▆▆▇▅▆▇▇▆▇▆▅▇▆▆▇▆▇█▇▆▇▆▆▆█▇▆▆▇▇▇█</td></tr><tr><td>val_auc</td><td>▁▄▅▅▅▅▆▇▆▇▇▇▇▇▇▇▇▇▇▇▄▇▄▇▇▇▇▆▆▆▆▇██▅▇▇▇▇▇</td></tr><tr><td>val_f1</td><td>▂▄▁▅▁▂▁▂▄▄▆▃▄▆▆▅▆▆▃▇▄▅▅▅▆▇▆▄▅▆▅▄█▆▅▄▆▇▆█</td></tr><tr><td>val_loss_epoch</td><td>█▄▄▄▃▅▅▄▃▃▂▃▂▂▃▃▃▂▃▂▄▃▅▃▃▃▂▃▃▃▃▃▂▁▃▃▂▂▂▂</td></tr><tr><td>val_loss_step</td><td>█▅▄▆▄▇█▆▃▃▄▄▄▄▅▆▅▂▃▄▄▄█▅▅▆▅▅▃▅▄▅▃▁▄▄▃▄▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84888</td></tr><tr><td>train_auc</td><td>0.92177</td></tr><tr><td>train_f1</td><td>0.84707</td></tr><tr><td>train_loss_epoch</td><td>0.35912</td></tr><tr><td>train_loss_step</td><td>0.38136</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.83924</td></tr><tr><td>val_auc</td><td>0.89461</td></tr><tr><td>val_f1</td><td>0.86066</td></tr><tr><td>val_loss_epoch</td><td>0.38536</td></tr><tr><td>val_loss_step</td><td>0.32497</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tji1rkn1' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tji1rkn1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231231_190715-tji1rkn1\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab7c8ee042c54df085a10a88b30971db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333332417533, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231231_194052-9bh5k264</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9bh5k264' target=\"_blank\">GINConv_3_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9bh5k264' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9bh5k264</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.7 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26ad7a242b53431aa708b337815ee353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▇▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇█▇█▇▇▇▇██▇██</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇████▇▇█▇█▇██▇███████</td></tr><tr><td>train_f1</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇███▇█▇███▇████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▃▃▃▃▃▂▃▂▂▂▂▃▂▂▂▁▂▂▁▂▂▁▂▁▂▂▂▂▁▁▂▂▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▅▆▅▃▅▄▄▄▅▂▇▃▆▅▂▄▃▃▄▃▁▅▃▃▃▆▄▂▄▃▄▄▄▄▄▃▁▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▂▆▅▅▅▅▆▆▄▄▇▆▅▆▇▇▇▇▇▇█▇▇▇▇▇█▇▇▇▆▇▇█▆██▇</td></tr><tr><td>val_auc</td><td>▁▅▄▆▆▆▆▆▇▆▆▇▇▇▇▇██▇▇▇███▇█▇▇███▇▇▇██▇███</td></tr><tr><td>val_f1</td><td>▃▃▁▆▅▆▅▆▆▆▅▃▇▇▆▇▇▇▆▇▇█▇▇▇▇▇▇█▇▇▇▆▇██▆█▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▄▄▃▃▃▃▂▂▃▂▃▂▂▃▂▁▁▂▂▂▂▃▂▂▂▃▂▂▂▂▂▂▁▂▂▂▂▁▁</td></tr><tr><td>val_loss_step</td><td>█▅▅▆▃▅▆▄▄▄▃▅▄▄▅▅▃▃▃▃▄▄▇▅▅▅▅▄▅▅▅▄▂▁▆▅▃▄▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83176</td></tr><tr><td>train_auc</td><td>0.90961</td></tr><tr><td>train_f1</td><td>0.82505</td></tr><tr><td>train_loss_epoch</td><td>0.38694</td></tr><tr><td>train_loss_step</td><td>0.4263</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82742</td></tr><tr><td>val_auc</td><td>0.90463</td></tr><tr><td>val_f1</td><td>0.84823</td></tr><tr><td>val_loss_epoch</td><td>0.38306</td></tr><tr><td>val_loss_step</td><td>0.38554</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9bh5k264' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/9bh5k264</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231231_194052-9bh5k264\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c72c3431fe4b4fb0bf2cd0c284d2c998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231231_201417-afa4gynr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/afa4gynr' target=\"_blank\">GINConv_3_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/afa4gynr' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/afa4gynr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.7 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca9d23dc25d9464392f9d3d5a1edf0db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▆▆▆▆▆▆▆▆▆▆▇▇▇▇▆█▇▇▇▇▇▇▇█▇▇▇▇▇█████▇██</td></tr><tr><td>train_auc</td><td>▁▂▃▄▄▄▄▅▅▅▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇█▇▇██▇████████</td></tr><tr><td>train_f1</td><td>▁▃▄▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█▇█▇▇▇▇██▇▇█▇▇████████</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▂▂▂▂▂▂▂▂▃▁▂▂▁▁▂▁▂▁▁▂▁▂▁▂▂▁▂▂▂▁▁▁▂▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇██▇██▇█▇█████▇▇██▇</td></tr><tr><td>val_auc</td><td>▁▆▇▇▇▇██████████████████████████████████</td></tr><tr><td>val_f1</td><td>▁▇████▇▇▇█████▇▇█▇███▇██▇████▇█████▇████</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▃▃▃▃▃▂▂▃▂▂▂▃▂▃▂▂▂▂▃▃▂▃▃▂▂▂▃▂▂▂▁▂▃▂▂▂▂</td></tr><tr><td>val_loss_step</td><td>█▅▅▆▅▇▅▆▄▃▆▅▃▃▆▄▅▄▂▄▄▇▇▅▆▆▄▆▄▂▄▅▄▁▅▆▃▃▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.82704</td></tr><tr><td>train_auc</td><td>0.8781</td></tr><tr><td>train_f1</td><td>0.82381</td></tr><tr><td>train_loss_epoch</td><td>0.39403</td></tr><tr><td>train_loss_step</td><td>0.38056</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.79196</td></tr><tr><td>val_auc</td><td>0.88543</td></tr><tr><td>val_f1</td><td>0.8009</td></tr><tr><td>val_loss_epoch</td><td>0.43985</td></tr><tr><td>val_loss_step</td><td>0.42959</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/afa4gynr' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/afa4gynr</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231231_201417-afa4gynr\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df859e19db7e4a86a4316e5fb8d1bf3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333332417533, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231231_204850-0qhvtqh2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0qhvtqh2' target=\"_blank\">GINConv_3_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0qhvtqh2' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0qhvtqh2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.7 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89d0478e3b68498c9f3795c7e0968001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▆▇▇▇▇▇▇▇█████▇██▇█▇█████████████████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇██▇█▇█▇▇▇▇▇▇███████████████</td></tr><tr><td>train_f1</td><td>▁▇▇▇▇▇▇█▇█▇▇█████▇██████████████████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▃▃▃▂▂▂▃▂▁▂▂▂▂▁▂▂▁▂▂▂▂▁▂▁▁▁▂▁▂▁▁▁▂▁▂</td></tr><tr><td>train_loss_step</td><td>▅▅▄▃▃▃▄▅▃▃▄▂▅▃▃▄▄▃▃▃▃▂▃▃▃▃▃▁▄▄▃▃▅▃▃▂▃▃▃█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▃▄▄▇▇▃▆▆▅█▇▆█▅▇▆▄▆█▇▆██▇▇▆▇▅▅▇▅▅▆▆▇▆▅▅</td></tr><tr><td>val_auc</td><td>▁▃▅▆▇▆▇▆▇▇▆▇▇▇▆███▇▅█▇▇█▇▇▇▇▆▄▇▇▅▆▇▆▆▅▆▅</td></tr><tr><td>val_f1</td><td>▅▆▃▃▂▆▆▁▆▇▅█▆▆█▄▇▅▄▅█▇▆▇█▇▇▆▇▄▄▇▅▅▆▇▇▇▆▅</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▃▄▂▃▅▂▃▂▁▂▂▂▃▁▂▃▃▃▂▃▂▁▂▁▂▂▃▃▁▃▃▂▃▃▃▂▃</td></tr><tr><td>val_loss_step</td><td>█▆▄▄▅▂▇▇▄▆▄▁▄▄▄▄▃▆▇▂█▃▆▅▁▄▂▅▅▂▆▁▄▆▄▄▆▆▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8412</td></tr><tr><td>train_auc</td><td>0.91112</td></tr><tr><td>train_f1</td><td>0.83507</td></tr><tr><td>train_loss_epoch</td><td>0.41638</td></tr><tr><td>train_loss_step</td><td>0.87251</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.78723</td></tr><tr><td>val_auc</td><td>0.8712</td></tr><tr><td>val_f1</td><td>0.80088</td></tr><tr><td>val_loss_epoch</td><td>0.43876</td></tr><tr><td>val_loss_step</td><td>0.37788</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0qhvtqh2' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/0qhvtqh2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231231_204850-0qhvtqh2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc3e9d2f8a88475a9b6312d5cba509d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.017183333334590618, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231231_212506-6sq3k28v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6sq3k28v' target=\"_blank\">GINConv_3_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6sq3k28v' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6sq3k28v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.7 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "2.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.2 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46bf9fee2db14a4494ba20abc683ae43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇▇███▇▇███▇▇</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇███▇█▇█████████████████</td></tr><tr><td>train_f1</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇█▇▇██████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▃▃▃▃▂▂▃▂▂▂▂▂▂▂▁▂▁▂▁▂▁▂▁▁▁▂▁▂▂▂▁▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▅▅▄▃▃▅▅▃▃▄▅▄▃▃▂▃▁▅▄▂▄▃▄▁▃▃▂▃▄▃▃▄▄▃▂▃▂▇▆</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▁▁▆▆█▇▇▇▇▅█▅▆▆▇▅▆▇▇▇█▅▆▄█▇▆▆▅▆▇▆▇▃▇▆▅▆</td></tr><tr><td>val_auc</td><td>▁▅▅▅▆▇▇▆▇▇▇▇█▆▇▇▇█▇▇███▇█▇████▆▇█▇▇▇▇▇▅▇</td></tr><tr><td>val_f1</td><td>▄▄▁▁▆▅█▇▆▇▇▅▇▆▅▆▆▄▅▇▆▇█▅▅▃█▆▅▅▄▆▇▅▇▁▇▆▅▇</td></tr><tr><td>val_loss_epoch</td><td>█▄▄▅▃▃▂▂▂▂▂▃▂▃▂▂▂▂▃▂▁▂▁▂▃▃▂▁▂▁▃▂▁▃▃▄▁▃▃▂</td></tr><tr><td>val_loss_step</td><td>█▆▆▇▄▅▃▃▄▄▄▇▆▅▃▄▂▃▇▃▂▅▂▅▅▄▄▁▃▁▂▄▃▄█▅▁▅▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83589</td></tr><tr><td>train_auc</td><td>0.91577</td></tr><tr><td>train_f1</td><td>0.83986</td></tr><tr><td>train_loss_epoch</td><td>0.38133</td></tr><tr><td>train_loss_step</td><td>0.51382</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80142</td></tr><tr><td>val_auc</td><td>0.88599</td></tr><tr><td>val_f1</td><td>0.82203</td></tr><tr><td>val_loss_epoch</td><td>0.42161</td></tr><tr><td>val_loss_step</td><td>0.42084</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6sq3k28v' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/6sq3k28v</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231231_212506-6sq3k28v\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a8b0cd883044f20bf449d241c355bbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333332417533, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231231_215906-o0rsqdyl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/o0rsqdyl' target=\"_blank\">GINConv_3_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/o0rsqdyl' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/o0rsqdyl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 6.0 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "6.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.6 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▆▆▆▇▆▆▆▇▇▇▇▇▇▇▇▇▇██▇▇█▇▇█▇███▇█████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▇▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇██▇▇█▇▇███████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇██▇▇██▇█████▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▃▂▂▃▃▂▁▂▂▂▂▂▂▂▁▂▁▂▂▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▆▅▅▅▅▄▃▆▅▇▁▄▃▄▅▁▃▃▄▄▇▂▃▂▄▃▃▂▃▁▃▂▄▂▂▂▄▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▅▅█▃▆▇█▇▇▆█▇▇▇▇█▆▆▇▇▇▅▄█▇▆▆▇█▇▅▇▇█▇▆▇▇</td></tr><tr><td>val_auc</td><td>▁▄▅▆▆▆▆▆▇█▆▇▇▆▇██▇██▇██▇▇█▇▇▇▇█▇▇▇▇█▇▆▇█</td></tr><tr><td>val_f1</td><td>▁▅▅▆█▃▇▇█▇▇▆█▇▆█▇█▆▆▇▇▇▅▄█▇▆▆▇█▇▅▇▇█▇▆▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▆▆▅▁▄▃▃▂▂▂▂▂▃▄▆▂▁▄▃▃▂▂▆▆▂▃▅▄▂▁▄▆▃▁▁▁▅▃▄</td></tr><tr><td>val_loss_step</td><td>▇▅▅▅▁▃▃▅▃▃▂▃▃▄▅▅▂▁▅▃▄▂▂▆▅▅▃█▃▃▂▃▆▂▁▂▂▃▄▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87485</td></tr><tr><td>train_auc</td><td>0.94249</td></tr><tr><td>train_f1</td><td>0.87042</td></tr><tr><td>train_loss_epoch</td><td>0.29993</td></tr><tr><td>train_loss_step</td><td>0.36397</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80615</td></tr><tr><td>val_auc</td><td>0.9015</td></tr><tr><td>val_f1</td><td>0.80193</td></tr><tr><td>val_loss_epoch</td><td>0.47085</td></tr><tr><td>val_loss_step</td><td>0.58195</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/o0rsqdyl' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/o0rsqdyl</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231231_215906-o0rsqdyl\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf45aaf6e5e5407191f71f78d299654d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231231_223315-yvsscqsv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yvsscqsv' target=\"_blank\">GINConv_3_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yvsscqsv' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yvsscqsv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 6.0 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "6.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.6 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ad5f22b5bdd4fc684252b22d39dadc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇████████████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▇▇▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇██▇███████████████</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▄▄▃▃▃▃▂▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▂▁▂▁▁▁▁▁▂▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▆▅▅▅▄▄▅▄▄▇▁▅▄▃▅▃▄▃▃▅▃▂▃▃▄▁▂▃▄▂▂▃▄▂▄▄▃▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▃▆▆▅▆▆▆▇▆▇▆▇▆▇▇▇▇█▇▇█▇▇▇▇▇█▇▇▆▇▇▆▇▇▇▇█▇</td></tr><tr><td>val_auc</td><td>▁▅▅▆▆▆▆▆▇▇▆▇▇▇▇▇█▇█▇▇██▇▇▇▇█▇▇▇█▇▇▇▇█▇▇▇</td></tr><tr><td>val_f1</td><td>▁▃▇▇▆▆▇▇█▇▇▇█▆█▇▇▇█▇██▇▇▇█▇█▇▇▆█▇▇▇█▇▇█▇</td></tr><tr><td>val_loss_epoch</td><td>█▇▃▃▄▃▂▃▂▂▂▁▂▃▂▁▁▁▁▂▂▂▂▂▂▂▂▂▁▂▂▁▂▂▁▂▂▂▁▂</td></tr><tr><td>val_loss_step</td><td>█▇▅▅▄▂▂▄▃▃▃▁▂▃▅▁▁▂▃▁▃▄▂▅▄▃▂▅▂▃▂▃▃▃▃▂▃▃▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84593</td></tr><tr><td>train_auc</td><td>0.93096</td></tr><tr><td>train_f1</td><td>0.84249</td></tr><tr><td>train_loss_epoch</td><td>0.34442</td></tr><tr><td>train_loss_step</td><td>0.38741</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.8156</td></tr><tr><td>val_auc</td><td>0.90134</td></tr><tr><td>val_f1</td><td>0.83117</td></tr><tr><td>val_loss_epoch</td><td>0.38951</td></tr><tr><td>val_loss_step</td><td>0.4014</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yvsscqsv' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/yvsscqsv</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231231_223315-yvsscqsv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be6265bcfe2a44529f49d868a4d04e99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231231_230759-tlooq2nl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tlooq2nl' target=\"_blank\">GINConv_3_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tlooq2nl' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tlooq2nl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 6.0 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "6.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.6 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e38a950653f64018b2f17841f1f672e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▆▆▆▆▆▆▆▇▆▆▇▆▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇██▇▇▇███</td></tr><tr><td>train_auc</td><td>▄▅▅▄▃▅▃▄▃▂▁▄▅▇▇▅▆▅▆▆▅▄▂▃▂▅▄▄▃▂▃▆▇▄▁▇▅▆█▅</td></tr><tr><td>train_f1</td><td>▁▃▅▅▆▆▆▆▆▇▆▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇██▇██▇██▇▇▇███</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▁▂▂▂▂▂▁▁▁▂▁▁▂▁▁▁▂▂▁▂▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▃▃▅▄▆▆▅▆▆▆▇▆▆▇▇▆▇▇▅▇▇▇▇█▆▇▇▃▇▄▅▇▇█▆▇█▆▅▁</td></tr><tr><td>val_auc</td><td>▆▆▇▇▆▇▇▇▆▃▁██████████▇▃▁▁███▇▃▇██▇▆█████</td></tr><tr><td>val_f1</td><td>▅▄▆▅▆▆▆▆▇▆█▆▆▇▇▇▇▇▆▇██▇█▇█▇▃▇▄▆▇██▆▇█▆▅▁</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▃▂▂▂▃▂▂▂▄▃▂▂▂▂▂▂▂▁▁▂▁▂▂▃▅▂▃▂▂▂▂▂▂▁▂▂█</td></tr><tr><td>val_loss_step</td><td>█▃▃▄▁▂▂▄▂▁▂▄▃▃▃▂▂▂▂▃▂▂▂▂▂▄▁▆▂▃▂▂▃▂▂▃▂▃▃▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8595</td></tr><tr><td>train_auc</td><td>0.60464</td></tr><tr><td>train_f1</td><td>0.85611</td></tr><tr><td>train_loss_epoch</td><td>0.3434</td></tr><tr><td>train_loss_step</td><td>0.41797</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.69504</td></tr><tr><td>val_auc</td><td>0.86888</td></tr><tr><td>val_f1</td><td>0.63248</td></tr><tr><td>val_loss_epoch</td><td>0.74456</td></tr><tr><td>val_loss_step</td><td>0.93903</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tlooq2nl' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/tlooq2nl</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231231_230759-tlooq2nl\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0d1fb7ca5c04ef4b4d16de83cb33822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231231_234144-sthlgesi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/sthlgesi' target=\"_blank\">GINConv_3_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/sthlgesi' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/sthlgesi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 6.0 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "6.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.6 K     Total params\n",
      "0.027     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b13848092a74ce585d596bfc226b74d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▅▆▆▆▆▆▇▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇███▇████▇█</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇███▇██████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▇▆▆▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇███▇████▇█</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▃▃▂▃▂▂▂▂▃▂▃▂▂▂▁▁▂▁▁▂▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▇▆▅▅▅▄▄▅▄▄▅▂▅▄▅▅▂▄▃▄▅▆▁▄▅▄▇▃▅▄▆▄▂▄▃▂▁▄▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇████▇▇█▇█▅▇█▇█▇▇██▇█▇▇██</td></tr><tr><td>val_auc</td><td>▁▃▆▆▆▅▆▆▆▇▅▆▆▇▇▇▇█▇▇▇▆▇▇▇▅▇█▇▇▆▇█▆▆▇▇▇▇▇</td></tr><tr><td>val_f1</td><td>▁▆▆▇██▇▇▇▇▇███▇██████▇███▅██████████▇▇██</td></tr><tr><td>val_loss_epoch</td><td>█▅▅▂▃▂▂▂▂▂▂▂▂▂▂▃▂▁▂▂▁▂▂▁▂▆▁▁▂▂▂▃▂▂▂▂▃▂▂▂</td></tr><tr><td>val_loss_step</td><td>█▅█▃▅▄▃▃▃▆▃▄▄▃▃▇▅▄▅▆▃▃▆▃▅█▁▃▆▅▆▅▅▃▃▁▅▃▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.866</td></tr><tr><td>train_auc</td><td>0.94276</td></tr><tr><td>train_f1</td><td>0.86201</td></tr><tr><td>train_loss_epoch</td><td>0.29744</td></tr><tr><td>train_loss_step</td><td>0.22363</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81797</td></tr><tr><td>val_auc</td><td>0.89713</td></tr><tr><td>val_f1</td><td>0.83992</td></tr><tr><td>val_loss_epoch</td><td>0.42824</td></tr><tr><td>val_loss_step</td><td>0.50809</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/sthlgesi' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/sthlgesi</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231231_234144-sthlgesi\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5df44513be214f749fde0bcf238090b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240101_001515-66z869hf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/66z869hf' target=\"_blank\">GINConv_3_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/66z869hf' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/66z869hf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 6.0 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "7.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.7 K     Total params\n",
      "0.031     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00a434372b2c48d5bbf78d8ba6a53c85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▆▆▆▆▇▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇████▇█████████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇████████████████</td></tr><tr><td>train_f1</td><td>▁▅▅▆▆▆▇▇▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇████▇█████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▂▁▁▂▂▁▂▁▁▁▁▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▃▄▃▄▄▃▃▄▅▃▃▃▂▂▄▄▄▃▃▃▄▄▁▃▂▃▃▁▂▁▃▂▂▃▁▂▂▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▅▆▇▅▇▇▇▇██▆▇██▇█▇██▇█▇▇▇▆▄▆▇▇██▇▇█▆▆█▇</td></tr><tr><td>val_auc</td><td>▁▄▅▆▆▇▇▇▇▇▇█▆▆▇█▇▇█▇▆▇▇▆▆▇▇▇▅▆▇▆▆▆▆▇▆▇▆▆</td></tr><tr><td>val_f1</td><td>▁▅▅▆▇▅██▇▇██▆▇██▇█▆██▇▇▇█▇▆▄▇▇▇██▇▇█▇▇█▇</td></tr><tr><td>val_loss_epoch</td><td>█▆▅▄▂▄▂▂▂▂▁▁▃▂▁▁▁▁▃▂▃▃▃▄▃▂▃▆▄▂▁▅▃▂▅▂▄▄▄▃</td></tr><tr><td>val_loss_step</td><td>▆▅▅▆▄▄▅▃▄▄▃▃▄▄▃▄▂▃▅▄▇▅▅▆▅▃▂▄▆▃▁▆▄▂█▃▆▆▅▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87544</td></tr><tr><td>train_auc</td><td>0.94579</td></tr><tr><td>train_f1</td><td>0.87111</td></tr><tr><td>train_loss_epoch</td><td>0.30443</td></tr><tr><td>train_loss_step</td><td>0.40813</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.79669</td></tr><tr><td>val_auc</td><td>0.88097</td></tr><tr><td>val_f1</td><td>0.80717</td></tr><tr><td>val_loss_epoch</td><td>0.43928</td></tr><tr><td>val_loss_step</td><td>0.28246</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/66z869hf' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/66z869hf</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240101_001515-66z869hf\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99b34250e2b1425c985c18b39175873f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240101_004822-a54m9fea</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/a54m9fea' target=\"_blank\">GINConv_3_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/a54m9fea' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/a54m9fea</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 22.3 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "24.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.5 K    Total params\n",
      "0.098     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eb08a1e00d64a258dcd0c1332769694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▄▄▅▅▅▅▅▆▆▆▅▅▆▆▆▇▆▆▇▆▇▇▇▇▇▇▇▇▇█▇██▇█▇█</td></tr><tr><td>train_auc</td><td>▁▄▄▅▅▆▅▅▆▆▆▆▆▅▆▆▆▆▇▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇██▇▇██</td></tr><tr><td>train_f1</td><td>▁▃▄▄▅▅▅▅▅▅▆▆▆▅▅▆▆▆▇▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇██▇█▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▅▅▅▅▅▄▄▄▄▃▄▄▄▄▄▃▄▃▃▃▃▃▃▂▂▃▃▂▂▂▂▂▂▂▂▂▁</td></tr><tr><td>train_loss_step</td><td>██▇█▅▆▇▅▄▆▅▅▁▅▅▆▄▄▃▃▄▂▃▃▄▃▃▂▄▅▄▃▄▃▂▂▂▂▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▆▅▅▅▇▇▇▆▇▇▇▆█▁▇▇▇▇█▇▄▇▅▅▅▇▆▄▆▇▄▅▅▃▆▄▆▅</td></tr><tr><td>val_auc</td><td>▁▇▇▇▇▇▇▆▇▆▇█▇██▄█▇▇▇██▇█▅▅█▇▆▆▄▄█▃▃▃▅▅▇▅</td></tr><tr><td>val_f1</td><td>▆▆▆▆▆▆▇▇▇▆██▇▆█▁▇▇████▅█▅▆▅▇▇▄▆▇▄▆▆▄▆▄█▆</td></tr><tr><td>val_loss_epoch</td><td>▄▃▂▃▁▂▂▂▂▂▂▃▂▂▁▅▁▂▄▂▁▄▄▃▃▃▄▂▂▆▅▃▅▃▇▇▃▄█▄</td></tr><tr><td>val_loss_step</td><td>▄▄▃▅▂▃▂▄▃▄▃▄▃▄▂▆▂▄▅▃▂▅▅▁▃▄▄▃▃▅▆▃▃▅█▇▄▄▅▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.90614</td></tr><tr><td>train_auc</td><td>0.97085</td></tr><tr><td>train_f1</td><td>0.90427</td></tr><tr><td>train_loss_epoch</td><td>0.21169</td></tr><tr><td>train_loss_step</td><td>0.20512</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.77305</td></tr><tr><td>val_auc</td><td>0.87012</td></tr><tr><td>val_f1</td><td>0.78082</td></tr><tr><td>val_loss_epoch</td><td>0.55137</td></tr><tr><td>val_loss_step</td><td>0.52826</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/a54m9fea' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/a54m9fea</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240101_004822-a54m9fea\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb60f2026ccf4501a7955ccfeb4ac26b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240101_012231-21ej1736</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/21ej1736' target=\"_blank\">GINConv_3_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/21ej1736' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/21ej1736</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 22.3 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "24.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.5 K    Total params\n",
      "0.098     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e939b905e151469ebe107cb379854512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▅▅▆▆▆▆▇▆▆▇▆▇▇▇▇▇▇▇▇▇███▇▇▇██▇██▇████</td></tr><tr><td>train_auc</td><td>▁▄▅▆▅▆▆▆▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇██▇██▇████</td></tr><tr><td>train_f1</td><td>▁▅▅▅▆▅▆▆▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇███▇▇▇▇█▇██▇████</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▅▄▄▄▃▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▆▇▅▆▅▆▃▅▅▅▁▃▅▅▄▆▃▄▃▃▂▃▅▃▄▂▄▄▃▃▃▄▁▃▃▃▄▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▆▆▆▆▇▇▆▆▆▇▆▆▆▇█▇▇▆▆▆▇▆▆▆▆▅▇▇▇▆▇▅▇▇▆▆▇▆</td></tr><tr><td>val_auc</td><td>▁▆▆▆▆▇▇▇▅▅▅▇▇▇▇▇█▇▆▇█▇█▇▆▅▆▆▇▇█▇█▄██▇▇▇▆</td></tr><tr><td>val_f1</td><td>▁▁▅▅▆▄▅▆▆▅▆▇▆▆▆▆█▇▇▅▅▅▅▆▆▅▅▅▆▆▇▅▇▄▇▆▅▅▆▅</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▃▂▃▂▂▃▄▄▄▂▂▂▃▂▃▄▄▂▂▃▂▃▃▄▅▂▂▅▃▃▇▃▁▆▄▃▆</td></tr><tr><td>val_loss_step</td><td>▄▄▄▅▂▃▂▂▃▄▄▆▁▄▂▄▃▅▅▂▁▃▅▂▄▃▃▅▂▂▇▂▄▆▅▂█▅▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.88076</td></tr><tr><td>train_auc</td><td>0.95342</td></tr><tr><td>train_f1</td><td>0.87875</td></tr><tr><td>train_loss_epoch</td><td>0.26202</td></tr><tr><td>train_loss_step</td><td>0.2667</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.8227</td></tr><tr><td>val_auc</td><td>0.89605</td></tr><tr><td>val_f1</td><td>0.8337</td></tr><tr><td>val_loss_epoch</td><td>0.4956</td></tr><tr><td>val_loss_step</td><td>0.48647</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/21ej1736' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/21ej1736</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240101_012231-21ej1736\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2469453078394ffe9e1abbcf4af9df74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240101_015655-hdt39fxt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hdt39fxt' target=\"_blank\">GINConv_3_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hdt39fxt' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hdt39fxt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 22.3 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "24.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.5 K    Total params\n",
      "0.098     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8807d80fa4ac4689b249d7247ecd0978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▅▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇█▇▇▇███</td></tr><tr><td>train_auc</td><td>▇▆▆▄▄▅▅▆▆▅▆▇▆▄▄▅▅▆▄▅▅▄▆▇█▆▅▆▆▅▄▂▁▃▄▃▁▃▂▁</td></tr><tr><td>train_f1</td><td>▁▄▅▅▅▆▆▆▆▆▆▆▇▆▆▆▇▇▇▇▇▇▇▇▇▆▇▇▇▇█▇▇██▇▇███</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▄▁▅▆▆▅▅▆▇▇▇▇▆██▆█▅▆▇▇▆▃█▇▅▆▇▆▅▅█▆▄▇▅▇▆▆▁</td></tr><tr><td>val_auc</td><td>▇▇▆▁▂▂▅▄▄▃▅█▃▂▂▃▄▄▂▄▃▂███▂▂▂▅▃▁▁▁▂▂▁▁▁▁▁</td></tr><tr><td>val_f1</td><td>▆▁▅▆▆▅▅▆▇▇▇▇▆██▆▇▆▇▇▇▇▄██▆▆▇▆▆▅█▇▆▇▅▇▆▆▁</td></tr><tr><td>val_loss_epoch</td><td>▆▄▂▂▁▂▂▂▂▂▂▂▂▁▁▂▂▄▄▃▂▄▅▂▂▃▂▁▂▃▃▂▂▇▃▄▃▃▂█</td></tr><tr><td>val_loss_step</td><td>▅▄▃▄▂▃▃▃▃▃▃▄▃▃▂▃▃▆▄▃▃▄▅▁▂▄▂▂▂▄▄▃▃█▅▄▄▄▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.89374</td></tr><tr><td>train_auc</td><td>0.21478</td></tr><tr><td>train_f1</td><td>0.8913</td></tr><tr><td>train_loss_epoch</td><td>0.25543</td></tr><tr><td>train_loss_step</td><td>0.23838</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.69031</td></tr><tr><td>val_auc</td><td>0.11837</td></tr><tr><td>val_f1</td><td>0.63912</td></tr><tr><td>val_loss_epoch</td><td>0.8139</td></tr><tr><td>val_loss_step</td><td>0.63057</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hdt39fxt' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/hdt39fxt</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240101_015655-hdt39fxt\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b19e8852510e4ba29c91bf657d0adbb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240101_023033-wenmsta0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wenmsta0' target=\"_blank\">GINConv_3_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wenmsta0' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wenmsta0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 22.3 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "24.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.5 K    Total params\n",
      "0.098     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a1b60ed193849158eb57f3f56bba0f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▆▆▆▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇███████▇█▇</td></tr><tr><td>train_auc</td><td>▁▄▆▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇████████▇██</td></tr><tr><td>train_f1</td><td>▁▄▅▅▆▆▆▆▆▆▅▆▆▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇████▇█▇█▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▄▄▄▄▄▄▃▄▃▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▂▁▂▁▂</td></tr><tr><td>train_loss_step</td><td>▆▆▆▄▇▄▄▄▄▅▅▄█▃▃▄▁▂▂▃▃▄█▁▄▃▃▂▅▄▁▂▃▂▃▂▁▁▄▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▄▄▇▆▅▇▅▇▆▇██▇▇▆▆▇▆▇▇▇▆▇▄▆▆▆▆▆▁▇▄▅▇▆▆▅▄▇▆</td></tr><tr><td>val_auc</td><td>▄▄▆▆▆▆▇▆▆▅█▇██▆▅▇▇▇▆▇▆▆▇▆█▅▇▅▃▆▄▆▂▄▄▁▆▅▄</td></tr><tr><td>val_f1</td><td>▇▄█▇▅█▅█▆▇████▇▇▇█▇▇█▆▇▃▆█▇▇▇▁█▄▅▇▇▇▅▃▇▆</td></tr><tr><td>val_loss_epoch</td><td>▃▃▃▂▂▁▂▂▂▂▁▂▂▁▁▃▁▃▁▂▁▂▂▄▃▃▃▂▄▅▃▃▃▄▄▃█▅▃▅</td></tr><tr><td>val_loss_step</td><td>▃▃▄▁▂▁▃▃▁▂▂▃▂▂▂▃▁▃▂▄▁▂▁▂▄▃▄▂▄▃▃▂▃▁▄▁█▄▂▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.88666</td></tr><tr><td>train_auc</td><td>0.95733</td></tr><tr><td>train_f1</td><td>0.88177</td></tr><tr><td>train_loss_epoch</td><td>0.26042</td></tr><tr><td>train_loss_step</td><td>0.21215</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.78251</td></tr><tr><td>val_auc</td><td>0.86758</td></tr><tr><td>val_f1</td><td>0.78704</td></tr><tr><td>val_loss_epoch</td><td>0.58373</td></tr><tr><td>val_loss_step</td><td>0.81593</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wenmsta0' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/wenmsta0</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240101_023033-wenmsta0\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a60c023648ab4246a77c15e344565cb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240101_030458-l62xqonc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/l62xqonc' target=\"_blank\">GINConv_3_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/l62xqonc' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/l62xqonc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 22.3 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "28.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "28.7 K    Total params\n",
      "0.115     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ed8488e0b09491bb8bf063f704cd552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▅▄▅▅▅▅▅▅▆▆▆▅▅▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇█▇▇███</td></tr><tr><td>train_auc</td><td>▁▄▅▆▅▆▆▆▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██████▇████</td></tr><tr><td>train_f1</td><td>▁▃▄▅▄▅▅▅▅▅▅▆▆▆▅▅▆▆▆▆▆▆▇▆▆▇▆▇▇▇▇▇▇▇█▇▇███</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▅▄▅▄▄▄▄▄▃▃▄▄▄▃▃▃▃▃▂▃▃▂▃▃▂▁▂▂▁▂▁▃▂▂▁▁</td></tr><tr><td>train_loss_step</td><td>██▆▆▇▅▄▅▅▅▅▄▅▄▆▃▃▅▄▄▃▂▅▅▄▂▃▇▃▄▃▃▃▅▁▂▂▂▃▆</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▅▄▇█▇██▇▆▇▆▇▇█▆▇▆▆▇▆▆▆▇▇▇▅▇▃▃▇▆▅▆▇▂▇▆▆▁▆</td></tr><tr><td>val_auc</td><td>▃▆▆▇▇██▇▇▇▇▆▇▇▆▅▆▆▇▆█▄▇▅▆▅▇▇▁▆▃▅▆▆▁▅▆▇▅▃</td></tr><tr><td>val_f1</td><td>▆▅▇█▇██▇▆▇▆███▆▇▇▇▇▆█▇▇█▇▅▇▃▃▇▇▆▆▇▃▇▆▆▁▇</td></tr><tr><td>val_loss_epoch</td><td>▂▃▂▂▂▁▂▂▂▂▂▂▁▂▂▂▂▂▂▃▂▃▂▃▂▄▂▄▅▂▄▃▃▃▅▃▄▄█▃</td></tr><tr><td>val_loss_step</td><td>▄▇▃▃▃▂▅▄▂▅▃▅▃▅▆▃▅▃▆▄▄▆▅▅▄▇▁▆▇▄▆▃▆▅█▇▅▇█▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.89906</td></tr><tr><td>train_auc</td><td>0.964</td></tr><tr><td>train_f1</td><td>0.89399</td></tr><tr><td>train_loss_epoch</td><td>0.25297</td></tr><tr><td>train_loss_step</td><td>0.43785</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.78251</td></tr><tr><td>val_auc</td><td>0.85268</td></tr><tr><td>val_f1</td><td>0.80508</td></tr><tr><td>val_loss_epoch</td><td>0.53837</td></tr><tr><td>val_loss_step</td><td>0.49955</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/l62xqonc' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/l62xqonc</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240101_030458-l62xqonc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aee1a9b12b4e4e5e9a3233d1a45e59df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.017200000000108653, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240101_033920-vvtmbr87</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/vvtmbr87' target=\"_blank\">GINConv_4_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/vvtmbr87' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/vvtmbr87</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 2.4 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36822dea2d044c43af53c445ae826d5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇█▇█████████████████</td></tr><tr><td>train_auc</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇███████████████████</td></tr><tr><td>train_f1</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇████████████████▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▃▃▃▃▃▂▃▂▂▃▂▂▂▂▂▂▂▂▂▁▂▁▂▁▁▂▂▁▂▂▁▁▂▁▂▂</td></tr><tr><td>train_loss_step</td><td>█▆▅▄▅▄▄▆▅▅▄▆▃▄▄▄▃▁▃▅▄▂▇▃▅▃▅▄▃▄▃▄▃▄▄▃▂▂▃▆</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▆▄▆▆▆▇▇▆▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▆▇▅</td></tr><tr><td>val_auc</td><td>▁▄▅▆▆▆▅▆▇▆▇▇▆█▇▇▆▇▆▆▆█▇▇█▇▇▇▆▄█▇▇█▇▇▇▇▇▅</td></tr><tr><td>val_f1</td><td>▃▆▅▁▄▅▅▇▆▅▆▆▆█▇▆▆▆▆▇▇▇▆▆▆▇▇▅▆▆▇▆▆▇▆▆▆▄▇▃</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▄▃▂▃▂▂▃▂▂▂▁▁▂▃▂▃▂▂▁▂▂▂▂▂▃▂▃▂▂▂▁▂▂▂▃▂▄</td></tr><tr><td>val_loss_step</td><td>█▅▃▄▅▂▆▄▄▃▃▅▁▂▂▄▅▃▇▅▄▃▃▂▃▄▄▄▃▂▄▃▃▂▄▂▄▅▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83058</td></tr><tr><td>train_auc</td><td>0.89996</td></tr><tr><td>train_f1</td><td>0.82118</td></tr><tr><td>train_loss_epoch</td><td>0.39962</td></tr><tr><td>train_loss_step</td><td>0.56641</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.75177</td></tr><tr><td>val_auc</td><td>0.86164</td></tr><tr><td>val_f1</td><td>0.74576</td></tr><tr><td>val_loss_epoch</td><td>0.49112</td></tr><tr><td>val_loss_step</td><td>0.49198</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/vvtmbr87' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/vvtmbr87</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240101_033920-vvtmbr87\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19e2a937dea64b39b9b8a94c6adf64cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.017183333332650364, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240101_041255-3cu5ftyp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/3cu5ftyp' target=\"_blank\">GINConv_4_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/3cu5ftyp' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/3cu5ftyp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 2.4 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c8a7eb9dfe4434eab65ca25e604441f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇███▇██▇██████████</td></tr><tr><td>train_auc</td><td>▁▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██████▇██████████</td></tr><tr><td>train_f1</td><td>▁▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█▇█▇██▇██████████</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▃▃▃▃▃▃▃▂▂▂▂▃▂▂▂▂▂▃▁▂▂▂▁▂▂▂▂▂▁▁▁▂▁▂▂</td></tr><tr><td>train_loss_step</td><td>█▆▅▅▅▄▄▆▅▅▃▅▃▅▂▄▆▂▄▆▄▃▆▃▅▂▄▁▃▄▄▄▃▃▃▃▃▂▃▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▅▅▆▆▅▇▆▇█▇▇▆▆▇██▆▇█▆▇▇▆▇▇▇▇█▇▆▇▇▆▇▇▇▆▇</td></tr><tr><td>val_auc</td><td>▁▆▆▆▆▇▇▇▇▇███▇▇███▇▇█▇▇▇▇▇▇▇▇██▇▇█▇▇█▇▇▇</td></tr><tr><td>val_f1</td><td>▁▂▃▃▃▄▃▆▄▆▇▆▆▆▆▇██▆▇█▆▇▆▆▇▆▇▇█▇▆▇▇▆▇▆▇▆▇</td></tr><tr><td>val_loss_epoch</td><td>█▃▃▃▃▂▃▂▂▂▁▂▁▂▃▂▂▁▃▂▁▃▂▂▂▂▂▁▂▁▂▂▂▁▂▁▁▂▂▃</td></tr><tr><td>val_loss_step</td><td>█▄▄▄▄▃▅▆▄▄▃▄▁▅▄▃▄▂▅▆▃▆▅▆▃▅▆▂▃▂▃▄▄▃▅▂▂▄▃▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.81641</td></tr><tr><td>train_auc</td><td>0.88664</td></tr><tr><td>train_f1</td><td>0.81299</td></tr><tr><td>train_loss_epoch</td><td>0.41477</td></tr><tr><td>train_loss_step</td><td>0.46586</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81324</td></tr><tr><td>val_auc</td><td>0.87791</td></tr><tr><td>val_f1</td><td>0.84294</td></tr><tr><td>val_loss_epoch</td><td>0.46303</td></tr><tr><td>val_loss_step</td><td>0.60807</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/3cu5ftyp' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/3cu5ftyp</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240101_041255-3cu5ftyp\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2afb112695484539afc4af28e51557be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240101_044632-gtvvebj8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gtvvebj8' target=\"_blank\">GINConv_4_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gtvvebj8' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gtvvebj8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 2.4 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "682d6bb7e60d44af8ac344daf837b772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▄▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█████████████▇█</td></tr><tr><td>train_auc</td><td>▁▃▇▇▇▅▆▇▇█▅▄▆▆▆▆█▅▃▂▃▄▃▅▅▅▆▆▆▄▅▃▂▂▁▅▅▃▁▂</td></tr><tr><td>train_f1</td><td>▁▂▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇███████████████</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▂▁▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▄▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇█▆▇▇▇▇▇██▇██▆▇█▇▇▇</td></tr><tr><td>val_auc</td><td>▁▆▆▇▇▇▇██▇▇▇▇▇▇███▆▇█▇▇▇█▇███▅█▅▃▃▄██▇█▄</td></tr><tr><td>val_f1</td><td>▁▆▇▇▇▇▇▇▇▇█████▇▇▇█▇███▇████▇██▇██▇▇█▇▇█</td></tr><tr><td>val_loss_epoch</td><td>█▇▄▃▃▂▃▄▄▃▃▃▂▂▂▄▃▂▃▃▂▂▂▄▂▃▂▃▂▁▂▃▂▂▃▃▁▂▃▃</td></tr><tr><td>val_loss_step</td><td>▆▇▄▃▅▃▆▇▆▅▄▆▁▄▄█▆▃▇▆▄▃▃▅▃▆▃▅▃▂▄▄▃▃▃▃▃▄▆▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.81995</td></tr><tr><td>train_auc</td><td>0.52903</td></tr><tr><td>train_f1</td><td>0.81704</td></tr><tr><td>train_loss_epoch</td><td>0.40532</td></tr><tr><td>train_loss_step</td><td>0.45216</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.79196</td></tr><tr><td>val_auc</td><td>0.55949</td></tr><tr><td>val_f1</td><td>0.81356</td></tr><tr><td>val_loss_epoch</td><td>0.46715</td></tr><tr><td>val_loss_step</td><td>0.57544</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gtvvebj8' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/gtvvebj8</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240101_044632-gtvvebj8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fd328d7d3a1429dbc2c2c95967deacb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240101_051950-svyt8nq9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/svyt8nq9' target=\"_blank\">GINConv_4_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/svyt8nq9' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/svyt8nq9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 2.4 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "2.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83bb722243f342b8972a2263535945e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▆▇▇▆▇▇▆▇▇▇▇▇▇████▇▇▇▇▇▇██▇▇██▇██████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇████▇▇█▇▇██████████████</td></tr><tr><td>train_f1</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇███▇███████████████████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▃▃▃▂▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▁▁</td></tr><tr><td>train_loss_step</td><td>▆▅▄▅▃▃▃▄▃▂▃▃▂▂▅▃▁▂▃▁▃▂▂▂▃▄▃█▁▂▂▂▃▁▁▂▃▂▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▄▅▆▃▆▆▆▇▇▆▆▆▄▇▇▇▇▇▆▅▇▇▆▇▇▇█▆▇▇█▇▇▆▇▆▇▆</td></tr><tr><td>val_auc</td><td>▁▅▅▅▅▆▅▆▇▇▇▇▇▇▇█▇██▇▇▇▇█▇▇███▇███▇█▅█▇▇█</td></tr><tr><td>val_f1</td><td>▄▆▂▄▆▁▅▅▄▆▇▆▆▆▂▇▇▇▇▆▆▄▇▇▆▇▆▇▇▆▇▇█▇▇▆▇▅▆▆</td></tr><tr><td>val_loss_epoch</td><td>█▃▄▃▃▅▄▃▃▃▂▂▃▃▃▂▂▂▂▂▂▃▂▂▂▁▃▂▂▂▁▂▂▂▂▃▁▅▂▃</td></tr><tr><td>val_loss_step</td><td>▇▄▅▄▄▆▅▄▂▄▃▂▅▅▄▄▃▄▃▃▄▃▄▃▄▁▅▃▃▂▂▄▄▄▃▃▁█▄▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83766</td></tr><tr><td>train_auc</td><td>0.9134</td></tr><tr><td>train_f1</td><td>0.83283</td></tr><tr><td>train_loss_epoch</td><td>0.36638</td></tr><tr><td>train_loss_step</td><td>0.34033</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.79669</td></tr><tr><td>val_auc</td><td>0.89092</td></tr><tr><td>val_f1</td><td>0.80543</td></tr><tr><td>val_loss_epoch</td><td>0.44816</td></tr><tr><td>val_loss_step</td><td>0.59316</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/svyt8nq9' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/svyt8nq9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240101_051950-svyt8nq9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a99fefdd4ce4550a255e2eca97b71e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240101_055346-1bibt07h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1bibt07h' target=\"_blank\">GINConv_4_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1bibt07h' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1bibt07h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 2.4 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "2.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.8 K     Total params\n",
      "0.011     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2a44c29b9f14f7ca88957ed2765ee1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██████▇▇██████████</td></tr><tr><td>train_auc</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇█▇███████████</td></tr><tr><td>train_f1</td><td>▁▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇████████████████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▃▃▃▃▃▃▂▃▃▂▂▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▂▁▂▂▂</td></tr><tr><td>train_loss_step</td><td>▇▇▅▄▃▄▃▇▅▄▆▄▆▃▄▄▄█▅▃▄▃▁▅▃▃▂▃▃▂▄▄▃▂▄▅▃▃▄▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▆▅▇▄▇▇▆▇▇▆▇▇█▇▇█▇█▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇██</td></tr><tr><td>val_auc</td><td>▁▇▇▇▇▇▇█▇██████▇████▇█▇▇██▇██▇▇▇▇████▇██</td></tr><tr><td>val_f1</td><td>▄▇▅▃▆▁▇▆▄▆▆▅▅▇█▆▆█▆█▆▇▇▆▇▇▆▆▇▇▇▆▆▇▇▅█▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▅▃▆▂▃▄▂▂▃▃▂▂▃▃▂▂▁▃▂▃▂▂▂▂▂▂▂▂▃▃▂▁▃▁▄▁▃</td></tr><tr><td>val_loss_step</td><td>█▆▃▅▄▇▃▄▄▁▄▄▆▃▃▅▄▄▂▂▃▃▃▃▄▄▃▂▃▅▃▅▃▂▁▄▂▇▁▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83884</td></tr><tr><td>train_auc</td><td>0.90817</td></tr><tr><td>train_f1</td><td>0.83485</td></tr><tr><td>train_loss_epoch</td><td>0.38142</td></tr><tr><td>train_loss_step</td><td>0.336</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.81797</td></tr><tr><td>val_auc</td><td>0.89013</td></tr><tr><td>val_f1</td><td>0.82774</td></tr><tr><td>val_loss_epoch</td><td>0.46652</td></tr><tr><td>val_loss_step</td><td>0.6065</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1bibt07h' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/1bibt07h</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240101_055346-1bibt07h\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "decf97ef5afc4dfb89999a6949f0c882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240101_062811-qevyyw02</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qevyyw02' target=\"_blank\">GINConv_4_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qevyyw02' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qevyyw02</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 8.3 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "8.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.8 K     Total params\n",
      "0.035     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b77945883c47d393d96e6304e511bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▄▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇████▇▇▇▇▇██</td></tr><tr><td>train_auc</td><td>▁▅▅▅▅▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇█▇███████████████</td></tr><tr><td>train_f1</td><td>▁▅▅▅▅▆▆▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇█▇████▇██▇▇██</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▅▅▄▄▄▃▃▃▃▃▃▃▃▂▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▂▂▂▂▂▂▁</td></tr><tr><td>train_loss_step</td><td>▅▅▅▄▆▅▄▄▃▄▄▃█▃▅▅▃▅▂▃▃▅▂▃▂▄▃▁▃▄▂▂▂▃▃▂▂▂▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▂▅▅▇▆▆▆▆▅▆▇▃▆█▃▇▅▇▆▇█▁▄▇▆▆▅▆▅▃▆▆▁▅▅▆▅█▇</td></tr><tr><td>val_auc</td><td>▁▄▄▆▆▆▆▇▆▇▆▇▇█▇▇▅▆▅▆▆▇▇▆▇▇▆▇▇▆▇▇▇▆▄▇▆▆▇▇</td></tr><tr><td>val_f1</td><td>▂▂▆▆▇▆▇▇▇▅▆▇▃▆█▃█▆▇▇▇▇▁▅▇▇▆▅▇▅▄▇▆▁▆▆▇▅█▇</td></tr><tr><td>val_loss_epoch</td><td>▆█▃▂▂▂▂▂▁▂▂▂▅▂▂▃▃▄▃▂▃▃▇▃▂▁▆▄▂▅▅▃▂▇▃▅▂▄▂▃</td></tr><tr><td>val_loss_step</td><td>▃█▃▄▃▃▄▄▂▁▃▃▆▄▄▃▆▅▄▃▄▅▇▃▄▁▇▄▃▅▃▄▁▇▃▇▃▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87662</td></tr><tr><td>train_auc</td><td>0.94141</td></tr><tr><td>train_f1</td><td>0.87356</td></tr><tr><td>train_loss_epoch</td><td>0.3018</td></tr><tr><td>train_loss_step</td><td>0.31264</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.80851</td></tr><tr><td>val_auc</td><td>0.8906</td></tr><tr><td>val_f1</td><td>0.81798</td></tr><tr><td>val_loss_epoch</td><td>0.46977</td></tr><tr><td>val_loss_step</td><td>0.46719</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qevyyw02' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/qevyyw02</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240101_062811-qevyyw02\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77543199aa70413eb488b6eb50462bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240101_070202-viti0bjb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/viti0bjb' target=\"_blank\">GINConv_4_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/viti0bjb' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/viti0bjb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 8.3 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "8.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.8 K     Total params\n",
      "0.035     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba9ec471a6ed4363b6ef42345e21a553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇▇████▇█▇▇████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████████████</td></tr><tr><td>train_f1</td><td>▁▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████▇████▇███████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▃▂▂▁▂▂▁▁▁▁▂▁▂▁▂▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>▇▆▅▄▆▅▄▅▄▅▄▄█▄▄▅▄▃▄▄▅▅▁▄▂▃▃▃▄▄▄▂▂▄▃▂▃▂▃▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▅▇▇▇▇▇▅▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇</td></tr><tr><td>val_auc</td><td>▁▅▆▇▆▇▆▇▇▇▇▇▇▇█▇▇█████▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>val_f1</td><td>▁▆▆▇▇▇▇▇▆█▇█▇▇▇▇█▇███████▇██▇██▇██▇▇█▇██</td></tr><tr><td>val_loss_epoch</td><td>█▆▄▃▃▂▂▂▄▁▂▂▂▁▂▁▁▂▁▁▁▂▂▂▁▂▂▂▂▂▂▂▁▂▂▃▁▂▂▁</td></tr><tr><td>val_loss_step</td><td>▆█▅▄▄▃▂▄▄▁▃▂▃▂▄▂▃▄▃▃▃▅▃▃▃▂▅▁▄▄▃▄▁▅▄▆▁▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85773</td></tr><tr><td>train_auc</td><td>0.92717</td></tr><tr><td>train_f1</td><td>0.85022</td></tr><tr><td>train_loss_epoch</td><td>0.3536</td></tr><tr><td>train_loss_step</td><td>0.51531</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82979</td></tr><tr><td>val_auc</td><td>0.89896</td></tr><tr><td>val_f1</td><td>0.84549</td></tr><tr><td>val_loss_epoch</td><td>0.3818</td></tr><tr><td>val_loss_step</td><td>0.3074</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/viti0bjb' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/viti0bjb</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240101_070202-viti0bjb\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6abbc64c2e1d427abdf6f9d6bf067a04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333332417533, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240101_073808-jjadnj4a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jjadnj4a' target=\"_blank\">GINConv_4_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jjadnj4a' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jjadnj4a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 8.3 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "8.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.8 K     Total params\n",
      "0.035     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba4223d4fb2546cc8f928bb693b8812e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▆▆▆▆▆▇▆▆▇▆▇▆▇▇▇▇▆▇▇▇▇▇███▇████▇███▇█</td></tr><tr><td>train_auc</td><td>█▅▂▁▁▂▂▂▃▃▄▄▃▃▃▃▄▂▃▃▄▅▃▃▂▄▄▄▄▄▄▄▆▄▅▅▂▁▂▂</td></tr><tr><td>train_f1</td><td>▁▄▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████▇███▇█</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▃▂▂▂▂▂▂▂▃▂▂▂▂▂▁▂▂▂▁▂▁▂▂▂▂▂▂▁▁▂▂▁▁▁▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▆▆▇▆▇▇▆▇▇█▇█▇▇█▆▇▇█▇██▆▆█▆▇▇▇▇▆▆▇▆▇▇▆▇</td></tr><tr><td>val_auc</td><td>█▂▂▂▂▁▁▁▂▂▂▂▁▁▁▁▂▁▁▂▁▁▁▁▁▁▂▁▁▁▁▁▂▁▃▁▂▁▁▁</td></tr><tr><td>val_f1</td><td>▁▂▄▄▅▄▄▅▄▆▆▇▆▇▇▆█▃▅▇▇▇▇▇▃▄▇▄▅▇▅▆▄▃▆▃▆▇▃▄</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▂▂▂▂▂▂▁▁▁▂▂▁▁▁▃▂▂▁▂▂▁▂▂▂▃▂▂▂▂▂▃▂▃▂▁▄▂</td></tr><tr><td>val_loss_step</td><td>█▅▄▃▃▃▂▄▃▁▃▂▃▃▃▂▃▄▄▃▃▄▃▂▄▃▄▃▃▃▃▄▁▅▄▅▃▃▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84652</td></tr><tr><td>train_auc</td><td>0.28406</td></tr><tr><td>train_f1</td><td>0.84487</td></tr><tr><td>train_loss_epoch</td><td>0.35431</td></tr><tr><td>train_loss_step</td><td>0.36047</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.78723</td></tr><tr><td>val_auc</td><td>0.10618</td></tr><tr><td>val_f1</td><td>0.78365</td></tr><tr><td>val_loss_epoch</td><td>0.4595</td></tr><tr><td>val_loss_step</td><td>0.38864</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jjadnj4a' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/jjadnj4a</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240101_073808-jjadnj4a\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e279a8bb9c314fd0a58a3b74b6c613ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240101_081057-fs885l0j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fs885l0j' target=\"_blank\">GINConv_4_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fs885l0j' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fs885l0j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 8.3 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "8.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.9 K     Total params\n",
      "0.036     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe6b57482fbc440a89b6487271c18d67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▅▆▆▆▆▆▆▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇██▇▇▇███▇▇████▇</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇█▇▇███▇█▇██████████</td></tr><tr><td>train_f1</td><td>▁▆▆▆▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇███▇▇████▇</td></tr><tr><td>train_loss_epoch</td><td>█▄▄▄▄▃▃▃▂▃▃▂▃▂▂▃▂▂▂▂▁▁▂▂▁▁▁▂▂▂▁▂▁▂▂▁▁▂▁▂</td></tr><tr><td>train_loss_step</td><td>▆▆▄▅▄▇▄█▅▄▄▅▆▂▂▃▃▇▃▅▂▃▅▃▂▂▄▁▁▂▃▆▄▂▂▄▅▁▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▆▆▅▇▇▇█▃▆▅█▆▄▆▆▆▇▆▅▆▆▇█▄▆▇▇▇▆▇▇▇▆▆▆▅▆▆█</td></tr><tr><td>val_auc</td><td>▁▄▅▅▅▆▇▇▆▆▆▇▇▇█▇▇▇█▆█▇▇▇▇██▇▇▇▇▇▆█▅█▇█▆▇</td></tr><tr><td>val_f1</td><td>▁▆▇▆▇███▄▆▆█▆▄▆▆▆▇▆▅▆▆▇█▄▆▆▇▇▆▇▇█▆▇▆▆▇▆█</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▃▄▂▃▁▅▄▃▁▂▅▄▃▂▃▂▅▄▂▃▂▆▃▂▃▄▃▂▂▂▃▂▄▄▂▃▃</td></tr><tr><td>val_loss_step</td><td>▆▂▄▂▇▃▅▃▅▆▂▃▂▄▇▆▂▄▄▆▇▁▆▃▅▃▂▆▇▅▂▂▁▄▂█▄▃▄▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.85006</td></tr><tr><td>train_auc</td><td>0.92422</td></tr><tr><td>train_f1</td><td>0.84417</td></tr><tr><td>train_loss_epoch</td><td>0.35087</td></tr><tr><td>train_loss_step</td><td>0.29847</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82742</td></tr><tr><td>val_auc</td><td>0.89981</td></tr><tr><td>val_f1</td><td>0.83885</td></tr><tr><td>val_loss_epoch</td><td>0.43104</td></tr><tr><td>val_loss_step</td><td>0.58764</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fs885l0j' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/fs885l0j</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240101_081057-fs885l0j\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeea0e594c7d486e81c505cf73ce1fc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240101_084511-o43zzzt9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/o43zzzt9' target=\"_blank\">GINConv_4_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/o43zzzt9' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/o43zzzt9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 8.3 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "9.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "9.9 K     Total params\n",
      "0.040     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df785bb0efc4fd084c8604aa086205b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▆▇▇▇▇▇▇█▇▇▇▇▇▇▇▇█▇██▇██</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇█▇▇▇▇▇███████</td></tr><tr><td>train_f1</td><td>▁▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇█▇██▇██</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▄▄▃▄▄▃▃▃▃▃▃▃▃▃▃▃▂▃▂▂▃▂▂▂▂▂▂▂▁▂▁▁▂▂▂</td></tr><tr><td>train_loss_step</td><td>▇▇▆▆▃▅▄▅▅▆▄▃▃▄▃▄▄▃▅▃▅▅▃▃▁▃▃▃▁▃▂▂▄▂▂▃▄▂▃█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▅▆▆▇▇▆▇▆▆█▆▇█▇▇▆▇▇█▇▇▆▇▅▇▇▆▇▇▇▇▇▇▇▇▇▇▇▆</td></tr><tr><td>val_auc</td><td>▂▂▅▅▇▆▆▇▆▅▇▇▇█▇▇█▆▆▇▇▆█▇▁▇▇▇█▇▇▇█▆█▇█▇▆▆</td></tr><tr><td>val_f1</td><td>▁▆▇▇█▇▇█▇▇█▇███▇▆▇▇███▇▇▆▇█▇▇▇▇███▇▇█▇█▇</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▂▁▂▂▁▄▃▁▃▁▂▂▂▃▃▂▁▁▃▂▃▄▂▃▂▁▃▂▂▁▂▁▂▃▂▃▃</td></tr><tr><td>val_loss_step</td><td>█▄▄▁▁▃▂▃▆▅▂▃▂▄▄▂▃▅▁▂▂▅▃▃▃▄▆▁▃▆▄▄▂▄▂▁▇▁▆▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.87603</td></tr><tr><td>train_auc</td><td>0.93578</td></tr><tr><td>train_f1</td><td>0.87574</td></tr><tr><td>train_loss_epoch</td><td>0.34415</td></tr><tr><td>train_loss_step</td><td>0.57712</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.78014</td></tr><tr><td>val_auc</td><td>0.88977</td></tr><tr><td>val_f1</td><td>0.77698</td></tr><tr><td>val_loss_epoch</td><td>0.45238</td></tr><tr><td>val_loss_step</td><td>0.41328</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/o43zzzt9' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/o43zzzt9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240101_084511-o43zzzt9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f14dada95d384750ab515c5247ce0a9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333332417533, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240101_092148-47q5fnot</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/47q5fnot' target=\"_blank\">GINConv_4_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/47q5fnot' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/47q5fnot</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 30.9 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "33.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "33.1 K    Total params\n",
      "0.132     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad7778039e164f94b6f652f0a87db16e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▄▄▄▅▅▅▅▅▅▆▅▆▆▆▆▇▆▆▆▆▆▆▇▇▆▇▇▇▇█▆▇▇████</td></tr><tr><td>train_auc</td><td>▁▄▄▅▅▄▅▅▅▄▄▆▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇███▇██████</td></tr><tr><td>train_f1</td><td>▁▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▆▆▆▆▆▆▇▆▆▇▇▇▇▇▆█▇████</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▅▅▄▄▄▄▅▄▄▄▃▃▃▃▂▃▃▃▃▃▃▂▃▂▂▂▂▂▁▂▁▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>▇▇▇█▆▄▅▃▆▅▄▅█▅▄▃▇▄▅▁▄▂▆▄▄▃▃▂▃▄▃▂▂▂▂▂▃▁▁▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▅▃▅▅▄▃▅▄▅▅▅█▄▃▆▄▅▆▆▄▆▅▃▅▆▇▆▅▇▅▅▅▆▇▁▆▅▆▆▂</td></tr><tr><td>val_auc</td><td>▄▅▅▆▅▄▆▅▇▆▇▇▁▅▇▅▇█▇▆▇▆▁▆▇▇▇▇▇▅▆█▆▆▅▄▆▆▃▅</td></tr><tr><td>val_f1</td><td>▆▄▅▅▅▄▅▆▆▆▅█▅▆▆▅▅▇▆▄▆▅▆▅▆▇▆▆▇▆▆▅▆▇▁▆▅▆▆▅</td></tr><tr><td>val_loss_epoch</td><td>▄▄▃▄▃▃▃▅▁▂▂▃▅▄▁▄▄▃▃▃▂▄▅▄▄▂▄▄▃▅▇▄▅▂▇▅▅▄██</td></tr><tr><td>val_loss_step</td><td>▄▄▃▄▃▃▄▅▂▂▁▅▄▃▁▄▅▄▃▃▄▄▃▄▆▂▄▂▃▅▆▂▃▂▃▄▃▁█▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.89906</td></tr><tr><td>train_auc</td><td>0.95622</td></tr><tr><td>train_f1</td><td>0.89617</td></tr><tr><td>train_loss_epoch</td><td>0.26416</td></tr><tr><td>train_loss_step</td><td>0.34191</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.76359</td></tr><tr><td>val_auc</td><td>0.8773</td></tr><tr><td>val_f1</td><td>0.80315</td></tr><tr><td>val_loss_epoch</td><td>0.59175</td></tr><tr><td>val_loss_step</td><td>0.51311</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/47q5fnot' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/47q5fnot</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240101_092148-47q5fnot\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf15bc27854e4dde97316b12048b1a1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240101_095717-te751ent</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/te751ent' target=\"_blank\">GINConv_4_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/te751ent' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/te751ent</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 30.9 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "33.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "33.1 K    Total params\n",
      "0.132     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▅▅▅▆▆▆▅▆▆▆▇▆▇▆▇▇▆▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇██▇█</td></tr><tr><td>train_auc</td><td>▁▄▅▅▅▅▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇██▇████</td></tr><tr><td>train_f1</td><td>▁▄▅▅▅▅▆▆▆▆▅▆▆▆▇▆▇▆▆▇▆▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇██▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▅▅▄▄▃▃▄▃▄▃▃▃▃▃▃▃▃▂▃▂▃▂▃▂▂▂▂▂▂▂▂▂▁▂▂▁</td></tr><tr><td>train_loss_step</td><td>▆▆▅▇▅▄▄▄▅▅▄▄▇▄▃▄▄▂▄▂▃▂█▃▃▃▄▄▃▃▄▂▂▃▆▃▄▁▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▁▁▄▃▃▅▆▅▅▆▄▆▇▇▆▇▃▆█▅▄█▅▆▇▅▆▆▄█▃▃▇▅▆▆▆▆▂▆</td></tr><tr><td>val_auc</td><td>▁▅▅▆▆▅▇▇▇▇▆▆▇██▇▇▇█▇▆█▆▇▇▆▆▆▆█▅▅▇▇▇▇▇▇▆▇</td></tr><tr><td>val_f1</td><td>▂▁▅▃▃▆▆▆▆▇▃▇▇█▇▇▆▆▇▆▅▇▆▇▇▆▇▇▅█▃▆▇▄▆▆▇▇▂▇</td></tr><tr><td>val_loss_epoch</td><td>▇▆▄▄▅▅▃▃▃▂▃▃▂▂▂▃▇▄▃▂▄▁▂▁▇▃▃▂▄▃██▂▄▆▃▄▄▅▃</td></tr><tr><td>val_loss_step</td><td>▅▅▃▃▄▃▃▄▂▂▂▃▄▄▂▅█▆▅▁▅▂▁▂▇▃▂▂▃▆█▅▁▂▅▄▃▂▆▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.88843</td></tr><tr><td>train_auc</td><td>0.9491</td></tr><tr><td>train_f1</td><td>0.88454</td></tr><tr><td>train_loss_epoch</td><td>0.27587</td></tr><tr><td>train_loss_step</td><td>0.21539</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.82979</td></tr><tr><td>val_auc</td><td>0.90294</td></tr><tr><td>val_f1</td><td>0.85</td></tr><tr><td>val_loss_epoch</td><td>0.4192</td></tr><tr><td>val_loss_step</td><td>0.27163</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/te751ent' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/te751ent</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240101_095717-te751ent\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef614998fc2b4adc8286f36c3f1c8f99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333332417533, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240101_103316-mp2torg2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/mp2torg2' target=\"_blank\">GINConv_4_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/mp2torg2' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/mp2torg2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 30.9 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "33.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "33.1 K    Total params\n",
      "0.132     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▆▆▆▆▆▆▆▆▇▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇███▇███▇████</td></tr><tr><td>train_auc</td><td>▆▆▇▇▆▄▄▄▄▃▄▃▅▄▃▅▇▇▅▄▄▇█▇█▇▅▄▂▃▆▆▅▅▅▄▅▃▂▁</td></tr><tr><td>train_f1</td><td>▁▃▅▆▆▆▆▆▆▆▆▇▇▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇███▇███▇████</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▃▄▃▃▃▂▃▂▂▃▃▂▂▂▄▂▂▁▂▂▃▂▃▂▂▂▂▂▁▁▂▁▁▂▁▁▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▃▄▆▆▆▆▇▇▆▆▆▆▅▇▇▆▇▆▇▅▇▇██▆▅▇█▆▇█▇▅▇▁▆█▇▅▇</td></tr><tr><td>val_auc</td><td>▄▇██▆▂▅▆▃▂▃▂▃▂▂▅██▂▁▆██▇▇█▇▁▁▂█▅▇▅▇▇▁▁▁▁</td></tr><tr><td>val_f1</td><td>▄▄▆▆▆▇▇▇▇▇▆▆▆▇▇▇▇▆▇▇█▇██▆▅▇█▇▇█▇▅▇▁▆██▅█</td></tr><tr><td>val_loss_epoch</td><td>▅▂▂▂▂▁▁▁▂▂▂▂▂▂▁▁▁▃▁▂▂▁▁▁▃▂▂▁▂▂▂▂▄▁█▃▂▁▆▃</td></tr><tr><td>val_loss_step</td><td>▄▄▃▂▃▃▃▂▃▃▂▂▃▄▂▃▄▆▂▂▃▃▃▂▆▄▂▂▃▄▃▂▄▂▅▅▂▁█▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8719</td></tr><tr><td>train_auc</td><td>0.28539</td></tr><tr><td>train_f1</td><td>0.86951</td></tr><tr><td>train_loss_epoch</td><td>0.30859</td></tr><tr><td>train_loss_step</td><td>0.50096</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.79905</td></tr><tr><td>val_auc</td><td>0.11984</td></tr><tr><td>val_f1</td><td>0.83034</td></tr><tr><td>val_loss_epoch</td><td>0.53647</td></tr><tr><td>val_loss_step</td><td>0.60877</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/mp2torg2' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/mp2torg2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240101_103316-mp2torg2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2576139a50ac412ea4d8026cc0495b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333332417533, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240101_111059-y0xyq96i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/y0xyq96i' target=\"_blank\">GINConv_4_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/y0xyq96i' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/y0xyq96i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 30.9 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "33.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "33.1 K    Total params\n",
      "0.132     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▄▄▄▅▅▅▆▅▅▅▅▆▆▆▆▆▇▆▆▇▇▆▆▇▇▆▇▇▇▇▇▇▆███▇</td></tr><tr><td>train_auc</td><td>▁▄▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇</td></tr><tr><td>train_f1</td><td>▁▃▄▄▄▃▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▆▆▇▇▆▇▇▇▇▇▇▆███▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▅▅▅▄▄▄▃▄▄▄▄▃▃▃▄▃▃▄▃▃▃▂▃▃▃▃▂▂▂▂▂▂▃▂▁▁▂</td></tr><tr><td>train_loss_step</td><td>▅▅▄▄▅▅▄▅▄▄▆▄█▃▃▄▃▆▄▄▅▄█▄▃▂▄▇▃▃▂▃▂▂▂▁▃▂▁▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▅▂▁▆▅▆▅▅▇▇▅▅▃▅▆█▆▆▇▆▃▇▇▆▇▇▂▇▅▆▇▇▇▆▄▇▆▇▆▅</td></tr><tr><td>val_auc</td><td>▁▄▄▅▅▆▃▆█▇▄▇▇▇▆▇▇▇▇▆▅▇▆▅█▇▁▄▆▇▇▅▆▆▆▇▆▇▅▇</td></tr><tr><td>val_f1</td><td>▇▂▁▇▅▇▆▅█▇▆▇▇▆▇█▇▅█▇▃██▇▇▇▃█▅▆█▇█▅▄█▇▇▇▅</td></tr><tr><td>val_loss_epoch</td><td>▄▅▆▃▂▁▃▂▁▂▂▄▄▂▂▁▁▄▁▃▄▂▂▃▁▁█▄▅▄▂▄▂▃▅▃▄▆▆▆</td></tr><tr><td>val_loss_step</td><td>▅▃▆▅▃▃▄▄▄▅▃▅▃▄▃▂▄▅▃▆▅▄▂▅▃▃█▆▄▆▄▄▁▄▅▄▃▆▅▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.88253</td></tr><tr><td>train_auc</td><td>0.94987</td></tr><tr><td>train_f1</td><td>0.88062</td></tr><tr><td>train_loss_epoch</td><td>0.2962</td></tr><tr><td>train_loss_step</td><td>0.42914</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.78251</td></tr><tr><td>val_auc</td><td>0.89448</td></tr><tr><td>val_f1</td><td>0.78404</td></tr><tr><td>val_loss_epoch</td><td>0.54923</td></tr><tr><td>val_loss_step</td><td>0.60361</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/y0xyq96i' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/y0xyq96i</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240101_111059-y0xyq96i\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d1734ac10349f792405128bbcba791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20240101_114516-vw5nbu70</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/vw5nbu70' target=\"_blank\">GINConv_4_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/vw5nbu70' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/vw5nbu70</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 30.9 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "37.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "37.3 K    Total params\n",
      "0.149     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98047449b6094de6bd5fda6b44af3bc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▄▄▄▅▅▅▄▅▅▅▅▆▆▆▆▆▆▆▆▆▆▆▇▆▇▇▆▇▇▇▆▇▇▇▇▇█</td></tr><tr><td>train_auc</td><td>▁▄▄▄▅▅▆▆▆▆▆▆▆▆▇▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇██████</td></tr><tr><td>train_f1</td><td>▁▃▄▄▄▄▅▅▅▄▅▅▅▅▆▆▆▆▆▆▅▆▆▆▆▆▆▇▇▆▇▇▇▆▇▇▇▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▅▅▅▄▄▅▄▄▄▄▄▃▄▃▃▃▃▄▃▃▃▃▂▃▂▂▃▂▂▃▂▂▂▁▂▂▁</td></tr><tr><td>train_loss_step</td><td>▅▅▅▅▃▃▃▃▃▃▃▅█▃▂▄▄▂▄▄▄▃▃▃▄▃▃▃▃▃▃▃▃▂▃▂▁▂▄▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▁▁▂▂▃▃▃▂▂▂▂▂▄▄▄▅▅▂▂▂▂▂▆▆▆▆▆▃▃▃▃▃███</td></tr><tr><td>val_acc</td><td>▅▅▅▆▇▇█▇█▆▇▇▆▆▆▆▆██▅▅▇▇▅█▇▅▇▇▇▄▅▄▁▄▆▅▅▆▆</td></tr><tr><td>val_auc</td><td>▃▄▅▅▇▇▇▆█▆▇▇▇▇▆▆▇▇▇▄█▇▇▇▇█▆▇██▁▃▆▆▅▇▅▇▆▄</td></tr><tr><td>val_f1</td><td>▇▆▆▇▇▇█▇▇▇▇█▇▇▇▆▆█▇▇▅▇▇▅█▇▅▆▇▇▅▆▅▁▇▅▆▅▇▇</td></tr><tr><td>val_loss_epoch</td><td>▂▂▂▂▂▂▁▂▁▂▂▂▁▁▂▁▁▃▂▅▂▁▁▃▂▃▃▃▁▁▅▅▃█▆▄▄▄▃▆</td></tr><tr><td>val_loss_step</td><td>▃▂▃▃▃▃▃▃▃▃▃▄▃▂▄▂▂▃▃█▂▂▁▄▄▄▂▄▂▃▃▅▃▇▄▄▆▄▂▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.90732</td></tr><tr><td>train_auc</td><td>0.96752</td></tr><tr><td>train_f1</td><td>0.90468</td></tr><tr><td>train_loss_epoch</td><td>0.23119</td></tr><tr><td>train_loss_step</td><td>0.29684</td></tr><tr><td>trainer/global_step</td><td>1119</td></tr><tr><td>val_acc</td><td>0.78723</td></tr><tr><td>val_auc</td><td>0.86224</td></tr><tr><td>val_f1</td><td>0.81707</td></tr><tr><td>val_loss_epoch</td><td>0.62139</td></tr><tr><td>val_loss_step</td><td>0.67394</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/vw5nbu70' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_13PPI_Kfold/runs/vw5nbu70</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240101_114516-vw5nbu70\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k_folds = 5\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_ids, valid_ids) in enumerate(kfold.split(dataset_filtered)):\n",
    "    train_subset = dataset_filtered.index_select(train_ids.tolist())\n",
    "    val_subset = dataset_filtered.index_select(valid_ids.tolist())\n",
    "    for NUM_LAYERS, HIDDEN_CHANNELS, pool, in list(itertools.product(*[num_layers, hiddens, pools])):\n",
    "            # Path to the folder where the pretrained models are saved\n",
    "        # CHECKPOINT_PATH = checkpoint_folder / f'GAT_{NUM_LAYERS}_{HIDDEN_CHANNELS}_onehot_{fold}' / pool\n",
    "        CHECKPOINT_PATH = checkpoint_folder / f'GIN_{NUM_LAYERS}_{HIDDEN_CHANNELS}_onehot_{fold}' / pool\n",
    "        CHECKPOINT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Skip already trained kfold and pool\n",
    "        checkpoint = CHECKPOINT_PATH / f\"GraphLevel{model}\" / f\"GraphLevel{model}.ckpt\" \n",
    "        if checkpoint.exists():\n",
    "            print(checkpoint)\n",
    "            continue\n",
    "\n",
    "        # Run training\n",
    "        run = wandb.init(project=project_name, name=f'{model}_{NUM_LAYERS}_{HIDDEN_CHANNELS}_onehot_{fold}', \n",
    "                        group=f'{model}_{pool}', \n",
    "                        # mode=\"disabled\"\n",
    "                        )\n",
    "        PPIGraph.train_graph_classifier_kfold(model, \n",
    "                                                train_subset, \n",
    "                                                val_subset, \n",
    "                                                dataset, \n",
    "                                                CHECKPOINT_PATH, \n",
    "                                                AVAIL_GPUS, \n",
    "                                                in_channels=13,\n",
    "                                                hidden_channels=HIDDEN_CHANNELS, \n",
    "                                                out_channels = HIDDEN_CHANNELS,\n",
    "                                                num_layers=NUM_LAYERS, \n",
    "                                                epochs=epochs,\n",
    "                                                embedding=False,\n",
    "                                                batch_size=128,\n",
    "                                                graph_pooling=pool)\n",
    "        run.finish()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snowflake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
