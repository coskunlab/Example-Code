{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.io\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import trange, tqdm, tqdm_notebook\n",
    "from joblib import Parallel, delayed\n",
    "import re\n",
    "import h5py\n",
    "import tifffile as tiff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = (Path().cwd().parents[0] / 'data').absolute()\n",
    "data_processed = data_dir / 'processed'\n",
    "data_raw = r'Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\VP drug effect on HCC827 cells'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    " \n",
    "os.environ['JDK_HOME'] = \"C:\\Program Files\\Java\\jdk-17\"\n",
    "os.environ['JAVA_HOME'] = \"C:\\Program Files\\Java\\jdk-17\"\n",
    "\n",
    "os.environ['PATH'] += ';C:\\\\Program Files\\\\Java\\\\jdk-17\\\\jre\\\\bin\\\\server\\\\;C:\\\\Program Files\\\\Java\\\\jdk-17\\\\bin\\\\;C:\\\\Program Files\\\\Java\\\\jdk-17\\\\bin\\\\jar.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_dir = (Path().cwd().parents[0]).absolute()\n",
    "\n",
    "module_path = str(p_dir / \"src\")\n",
    " \n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers_map = {\n",
    "    'cycle1': {\n",
    "        1: 'DNA', \n",
    "        4: 'TEAD1/YAP',\n",
    "    },\n",
    "    'cycle2': {\n",
    "        1: 'DNA', \n",
    "        3: 'EGFR/Grb2',\n",
    "        4: 'Trail/DR5',\n",
    "    },\n",
    "    'cycle3': {\n",
    "        1: 'DNA', \n",
    "        4: 'Sox2/Oct4',\n",
    "    },\n",
    "    'cycle4': {\n",
    "        1: 'DNA', \n",
    "        4: 'E-cadherin/b-catenin',\n",
    "    },\n",
    "    'cycle5': {\n",
    "        1: 'DNA', \n",
    "        2: 'P-EGFR',\n",
    "        3: 'Phalloidin', \n",
    "        4: 'KI67',\n",
    "    },\n",
    "}\n",
    "\n",
    "def get_info(data_raw, marker_dict):\n",
    "    conditions = []\n",
    "    fovs = []\n",
    "    cycles = []\n",
    "    channels = []\n",
    "    markers = []\n",
    "    paths = [] \n",
    "    \n",
    "    # Loop through image folder\n",
    "    for (dirpath, dirnames, filenames) in os.walk(data_raw):\n",
    "        if 'after nuclease' in dirpath or 'Test' in dirpath or 'wrong' in dirpath:\n",
    "            continue\n",
    "        \n",
    "        for name in sorted(filenames):\n",
    "            if \"tif\" in name and \"sti\" in name \\\n",
    "            and 'overlay' not in name \\\n",
    "            and 'Composite' not in name:\n",
    "                # Get information from image name\n",
    "                \n",
    "                d_split = dirpath.split('\\\\')\n",
    "                condition = d_split[-1].split('_')[1]\n",
    "                n_split = name.split('_')\n",
    "                ch = int(n_split[-1][-5])\n",
    "\n",
    "                cycle = 'cycle' + d_split[-1].split('_')[2][-1]\n",
    "                try: marker = marker_dict[cycle][ch] \n",
    "                except: continue\n",
    "        \n",
    "                conditions.append(condition)\n",
    "                fovs.append('FW1')\n",
    "                cycles.append(cycle)\n",
    "                channels.append(ch)\n",
    "                markers.append(marker)\n",
    "                paths.append(os.path.join(dirpath, name))\n",
    "                \n",
    "    info = {\n",
    "            \"Condition\": conditions,\n",
    "            'FOV': fovs, \n",
    "            \"Cycle\": cycles,\n",
    "            \"Channels\": channels,\n",
    "            \"Markers\": markers,\n",
    "            \"Path\": paths\n",
    "        }\n",
    "\n",
    "    df = pd.DataFrame(info)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created df\n"
     ]
    }
   ],
   "source": [
    "df_meta_path = data_dir / 'VP_drug2' / 'metadata' / 'info.csv'\n",
    "df_meta_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_exist = df_meta_path.is_file()\n",
    "\n",
    "if not df_exist:\n",
    "    print('Created df')\n",
    "    df = get_info(data_raw, markers_map)\n",
    "    df.to_csv(df_meta_path, index=False)\n",
    "else:\n",
    "    print('Loaded df')\n",
    "    df = pd.read_csv(df_meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Condition\n",
       "10uM    13\n",
       "1uM     13\n",
       "ctrl    13\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Condition').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "def save_hdf5(\n",
    "    path: str, name: str, data: np.ndarray, attr_dict=None, mode: str = \"a\"\n",
    ") -> None:\n",
    "    # Read h5 file\n",
    "    hf = h5py.File(path, mode)\n",
    "    # Create z_stack_dataset\n",
    "    if hf.get(name) is None:\n",
    "        data_shape = data.shape\n",
    "        data_type = data.dtype\n",
    "        max_shape = (data_shape[0],) + data_shape[1:]\n",
    "        dset = hf.create_dataset(\n",
    "            name,\n",
    "            shape=data_shape,\n",
    "            maxshape=max_shape,\n",
    "            chunks=True,\n",
    "            dtype=data_type,\n",
    "            compression=\"gzip\",\n",
    "        )\n",
    "        dset[:] = data\n",
    "        if attr_dict is not None:\n",
    "            for attr_key, attr_val in attr_dict.items():\n",
    "                dset.attrs[attr_key] = attr_val\n",
    "    else:\n",
    "        print(f\"Dataset {name} exists\")\n",
    "\n",
    "    hf.close()\n",
    "\n",
    "def joblib_loop(task, pics):\n",
    "    return Parallel(n_jobs=20)(delayed(task)(i) for i in pics)\n",
    "\n",
    "def read_img(path):\n",
    "    return skimage.io.imread(path, as_gray=True)\n",
    "\n",
    "def get_min(imgs):\n",
    "    shapes = np.array([np.array(img.shape) for img in imgs])\n",
    "    return np.min(shapes, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created df\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c91ff3d08c043c984641ffb90e60332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_imgs_path = data_dir /  'VP_drug2' / 'metadata' / 'imgs.csv'\n",
    "df_imgs_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "temp_path = data_dir  / 'VP_drug2' /  'hdf5' / 'raw'\n",
    "temp_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_exist = df_imgs_path.is_file()\n",
    "\n",
    "\n",
    "if not df_exist:\n",
    "    print('Created df')\n",
    "    \n",
    "    group = df.groupby(['Condition'])\n",
    "    rows = []\n",
    "\n",
    "    for name, df_group in tqdm(group, total=len(group)):\n",
    "        file_name = name + '.hdf5'\n",
    "        file_path = temp_path / file_name\n",
    "        rows.append([name]+[file_path])\n",
    "        \n",
    "        channels = df_group.Channels.to_list()\n",
    "        cycles = df_group.Cycle.to_list()\n",
    "        markers = df_group.Markers.to_list()\n",
    "        paths = df_group.Path.to_numpy()\n",
    "            \n",
    "        imgs = joblib_loop(read_img, paths)\n",
    "        min_shape = get_min(imgs)\n",
    "        imgs_cropped = np.array([img[:min_shape[0], :min_shape[1]] for img in imgs])\n",
    "        info = {\"Cycle\": cycles, \"Channel\": channels, \"Marker\": markers}\n",
    "            \n",
    "            # hdf5 as Channel -> Z mapping\n",
    "        save_hdf5(file_path, 'imgs', imgs_cropped, info)\n",
    "    df_imgs = pd.DataFrame(rows, columns=['Condition', 'Path'])        \n",
    "    df_imgs.to_csv(df_imgs_path, index=False)\n",
    "else:\n",
    "    print('Loaded df')\n",
    "    df_imgs = pd.read_csv(df_imgs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Registration ImageJ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile as tf\n",
    "from PIL import Image\n",
    "import PIL.Image\n",
    "PIL.Image.MAX_IMAGE_PIXELS = 933120000\n",
    "import shutil\n",
    "from datetime import date, datetime\n",
    "import skimage.io \n",
    "from skimage import util\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure, util\n",
    "\n",
    "def contrast_str(img, n_min=0.1, n_max=100):\n",
    "    p2, p98 = np.percentile(img, (n_min, n_max))\n",
    "    img_rescale = exposure.rescale_intensity(img, in_range=(p2, p98))\n",
    "    img_rescale = util.img_as_ubyte(img_rescale)\n",
    "    return img_rescale\n",
    "\n",
    "def make_imgs_same_dim(imgs):\n",
    "    # Get max dimensions\n",
    "    shapes = np.array([img.shape[1:] for img in imgs])\n",
    "    min_x, min_y = shapes.min(axis=0)\n",
    "    imgs_cropped = [img[:, :min_x, :min_y] for img in imgs]\n",
    "    # imgs_cropped[0] = contrast_str(imgs_cropped[0])\n",
    "    return imgs_cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "regSavePath = data_dir / 'VP_drug2' /'imgs' / 'registered_imagej'\n",
    "regSavePath.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "chs = [1, 2, 3, 4]\n",
    "group = df.groupby(['Condition', 'FOV'])\n",
    "for name, df_group in group:\n",
    "    path = df_group.iloc[0].Path\n",
    "    \n",
    "    for cycle, df_cycle in df_group.groupby(['Cycle']):\n",
    "        cycle = cycle[-1]\n",
    "        channel = df_cycle.Channels.tolist()\n",
    "        imgs = [cv2.imread(f, cv2.IMREAD_GRAYSCALE) for f in df_cycle.Path.tolist()]\n",
    "        \n",
    "        for ch in chs: \n",
    "            # Save path per Channel\n",
    "            folderPath = os.path.join(regSavePath, '_'.join(name), 'Original', 'CH' + str(ch)) # 1 index\n",
    "            if not os.path.exists(folderPath):\n",
    "                os.makedirs(folderPath, exist_ok = True)\n",
    "            \n",
    "            fileOut = 'CH' + str(ch) + '_Cycle' + str(cycle).zfill(2) + '.tif'\n",
    "            fileOut = os.path.join(folderPath, fileOut)\n",
    "            if os.path.exists(fileOut):\n",
    "                continue\n",
    "\n",
    "            if ch in channel:\n",
    "                if ch == 1:\n",
    "                    img = contrast_str(imgs[list(channel).index(ch)], n_min=0.1, n_max=99.9)\n",
    "                else:\n",
    "                    img = imgs[list(channel).index(ch)]\n",
    "                tf.imwrite(fileOut, img, photometric = 'minisblack', bigtiff = True)\n",
    "\n",
    "            else:\n",
    "                emptyImage = np.zeros(imgs[0].shape, np.uint8)\n",
    "                # print('Dont exist create empty image', cycle, ch)\n",
    "                tf.imwrite(fileOut, emptyImage, photometric = 'minisblack', bigtiff = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runMacro(\"y:/coskun-lab/Thomas/23_PLA_revision/data/VP_drug2/imgs/registered_imagej/10uM_FW1/Original/CH1/20Jan2024_register_transforms.ijm\");\n",
      "runMacro(\"y:/coskun-lab/Thomas/23_PLA_revision/data/VP_drug2/imgs/registered_imagej/1uM_FW1/Original/CH1/20Jan2024_register_transforms.ijm\");\n",
      "runMacro(\"y:/coskun-lab/Thomas/23_PLA_revision/data/VP_drug2/imgs/registered_imagej/ctrl_FW1/Original/CH1/20Jan2024_register_transforms.ijm\");\n"
     ]
    }
   ],
   "source": [
    "group = df.groupby(['Condition', 'FOV'])\n",
    "chs = [1, 2, 3, 4]\n",
    "\n",
    "for name, channels in group:\n",
    "    name = '_'.join(name)\n",
    "    '''\n",
    "    run(\"Register Virtual Stack Slices\", \"source=[Y:/coskun-lab/Nicky/07 Temp/register large stitch] output=[Y:/coskun-lab/Nicky/07 Temp/register output] feature=Rigid registration=[Rigid                -- translate + rotate                  ] advanced shrinkage save save_dir=[Y:/coskun-lab/Nicky/07 Temp/register output] initial_gaussian_blur=1.60 steps_per_scale_octave=3 minimum_image_size=64 maximum_image_size=1024 feature_descriptor_size=8 feature_descriptor_orientation_bins=8 closest/next_closest_ratio=0.92 maximal_alignment_error=25 inlier_ratio=0.05 feature_extraction_model=Rigid registration_model=[Rigid                -- translate + rotate                  ] interpolate\");\n",
    "    run(\"Transform Virtual Stack Slices\", \"source = [Y:/coskun-lab/Nicky/07 Temp/other channels/original] output = [Y:/coskun-lab/Nicky/07 Temp/other channels/original] transforms = [Y:/coskun-lab/Nicky/07 Temp/register output] interpolate\");\n",
    "    '''\n",
    "    # folder to save registered images separated by channel to apply transforms\n",
    "    # create all folder\n",
    "    for ii, ch in enumerate(chs): # all channels\n",
    "        os.makedirs(os.path.join(regSavePath, name, 'Original', 'CH' + str(ch)), exist_ok = True)\n",
    "        os.makedirs(os.path.join(regSavePath, name, 'Registered', 'CH' + str(ch)), exist_ok = True)\n",
    "    \n",
    "    os.chdir(os.path.join(regSavePath, name, 'Original', 'CH1'))\n",
    "    now = datetime.now() # current date and time\n",
    "    date_time = now.strftime(\"%d%b%Y\")\n",
    "    macro = open(date_time + '_register_transforms.ijm', 'w')\n",
    "    \n",
    "    # register cycles on CH1\n",
    "    macro.write('run(\"Register Virtual Stack Slices\", \"source=[')\n",
    "    # original files\n",
    "    macro.write(os.path.join(regSavePath, name, 'Original', 'CH1').replace('\\\\', '/'))\n",
    "    macro.write('] output=[')\n",
    "    # registered output files\n",
    "    macro.write(os.path.join(regSavePath, name, 'Registered', 'CH1').replace('\\\\', '/'))\n",
    "    \n",
    "    # Rigid registration: translation + rotation\n",
    "    macro.write('] feature=Rigid registration=[Rigid                -- translate + rotate                  ] advanced shrinkage save save_dir=[')\n",
    "    # folder to save recorded transformations \n",
    "    macro.write('] initial_gaussian_blur=1.60 steps_per_scale_octave=3 minimum_image_size=64 maximum_image_size=1024 feature_descriptor_size=8 feature_descriptor_orientation_bins=8 closest/next_closest_ratio=0.92 maximal_alignment_error=25 inlier_ratio=0.05 feature_extraction_model=Rigid registration_model=[Rigid                -- translate + rotate                  ] interpolate\"); \\n')\n",
    "    \n",
    "    # # bigwrap registration\n",
    "    # macro.write('] feature=Similarity registration=[Elastic              -- bUnwarpJ splines                    ] advanced shrinkage save save_dir=[')\n",
    "    # # folder to save recorded transformations \n",
    "    # macro.write('] initial_gaussian_blur=1.60 steps_per_scale_octave=3 minimum_image_size=64 maximum_image_size=1024 feature_descriptor_size=8 feature_descriptor_orientation_bins=8 closest/next_closest_ratio=0.92 maximal_alignment_error=25 inlier_ratio=0.05 feature_extraction_model=Similarity registration_model=[[Elastic              -- bUnwarpJ splines                    ] interpolate registration=Mono image_subsample_factor=0 initial_deformation=[Very Coarse] final_deformation=Fine divergence_weight=0.1 curl_weight=0.1 landmark_weight=1 image_weight=0 consistency_weight=0 stop_threshold=0.01 shear=0.95 scale=0.95 isotropy=1\"); \\n')\n",
    "    \n",
    "    # Or use similarity: translation + rotation + isotropic scale\n",
    "    # macro.write('] feature=Similarity registration=[Similarity           -- translate + rotate + isotropic scale] advanced shrinkage save save_dir=[')\n",
    "    # # folder to save recorded transformations \n",
    "    # macro.write('] initial_gaussian_blur=1.60 steps_per_scale_octave=3 minimum_image_size=64 maximum_image_size=1024 feature_descriptor_size=25 feature_descriptor_orientation_bins=8 closest/next_closest_ratio=0.92 maximal_alignment_error=50 inlier_ratio=0.05 feature_extraction_model=Similarity registration_model=[Similarity           -- translate + rotate + isotropic scale] interpolate\"); \\n')\n",
    "    \n",
    "    macro.write('run(\"Close All\"); \\n\\n')\n",
    "    \n",
    "    # now apply transform to other channels\n",
    "    for ii, ch in enumerate([1,2,3,4]): # each other channel\n",
    "        \n",
    "        macro.write('run(\"Transform Virtual Stack Slices\", \"source=[')\n",
    "        # unregsitered folder\n",
    "        macro.write(os.path.join(regSavePath, name, 'Original', 'CH' + str(ch)).replace('\\\\', '/'))\n",
    "        macro.write('] output=[')\n",
    "        # registered folder\n",
    "        macro.write(os.path.join(regSavePath, name, 'Registered', 'CH' + str(ch)).replace('\\\\', '/'))\n",
    "        macro.write('] transforms=[')\n",
    "        macro.write(os.path.join(regSavePath, name, 'Original', 'CH1').replace('\\\\', '/')) # stored in original registration folder\n",
    "        macro.write('] interpolate\"); \\n')\n",
    "        macro.write('run(\"Close All\"); \\n\\n')\n",
    "    \n",
    "    macro.close()\n",
    "    \n",
    "    # print command to run macro\n",
    "    print('runMacro(\"' + os.path.join(regSavePath, name, 'Original', 'CH1', macro.name).replace('\\\\', '/') + '\");')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine all registered images into single folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "regSavePath = data_dir /  'VP_drug2' /'imgs' / 'registered_imagej'\n",
    "\n",
    "regSaveFinalPath = data_dir / 'VP_drug2' / 'imgs' / 'registered_imagej_final'\n",
    "regSaveFinalPath.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "regSaveCropPath = data_dir /  'VP_drug2' / 'imgs' /  'registered_crop'\n",
    "regSaveCropPath.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "630caa103059481a9474dd342d736b85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29a461ed985b4d2d87e13397de31ec85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c442e9234a54cfebb659c68a3146802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "group = df.groupby(['Condition', 'FOV'])\n",
    "\n",
    "for name, channels in group:\n",
    "    name = '_'.join(name)\n",
    "    for ii, cycle in enumerate(tqdm(channels['Cycle'].unique())): # each cycle\n",
    "    \n",
    "        dfCycle = channels.loc[channels['Cycle'] == cycle]\n",
    "        dfCycle.reset_index(drop = True, inplace = True) # index is channel - 1\n",
    "        cycle = cycle[5:]\n",
    "        for jj, ch in enumerate(dfCycle.Channels): # each channel\n",
    "            \n",
    "            # find registered file\n",
    "            tifPath = os.path.join(regSavePath, name, 'Registered', 'CH' + str(ch), 'CH' + str(ch)+ '_Cycle' + str(cycle).zfill(2) + '.tif')\n",
    "\n",
    "            # File out\n",
    "            fileOut = 'Cycle' + str(cycle).zfill(2) + \\\n",
    "            '_' + 'CH' + str(ch) + '.tif'\n",
    "            folder = regSaveFinalPath / name\n",
    "            folder.mkdir(parents=True, exist_ok=True)\n",
    "            fileOut = os.path.join(regSaveFinalPath, name, fileOut)\n",
    "            # print(tifPath)\n",
    "            # Copy\n",
    "            if os.path.exists(tifPath):\n",
    "                shutil.copyfile(tifPath, fileOut)\n",
    "            else:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Cropped image to smallest bounding box of non black region\n",
    "\n",
    "# Get channel list\n",
    "group = df.groupby(['Condition', 'FOV'])\n",
    "\n",
    "for name, df_group in group:\n",
    "    channels = df_group.Channels.tolist()\n",
    "    break\n",
    "\n",
    "# Crop\n",
    "for dir in os.listdir(regSaveFinalPath):\n",
    "\n",
    "    # Read imgs\n",
    "    imgs = []\n",
    "    paths = []\n",
    "    for file in os.listdir(regSaveFinalPath / dir):\n",
    "        if 'tif' in file:\n",
    "            path = regSaveFinalPath / dir/ file\n",
    "            imgs.append(tiff.imread(path))\n",
    "            paths.append(file)\n",
    "\n",
    "    # Get bboxs\n",
    "    bboxs = []\n",
    "    for i, img in enumerate(imgs):\n",
    "        if channels[i] != 1:\n",
    "            continue\n",
    "        bbox = skimage.measure.regionprops((img>0).astype(np.uint8))[0]['bbox']\n",
    "        bboxs.append(np.array(bbox))\n",
    "    bboxs = np.stack(bboxs)\n",
    "\n",
    "    bbox_final = [np.max(bboxs[:,0]),\n",
    "                np.max(bboxs[:,1]),\n",
    "                np.min(bboxs[:,2]),\n",
    "                np.min(bboxs[:,3])]\n",
    "\n",
    "    min_row, min_col, max_row, max_col = bbox_final\n",
    "\n",
    "    # Save cropped images\n",
    "    save_dir = regSaveCropPath / dir\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for i, img in enumerate(imgs):\n",
    "        save_path = save_dir / paths[i]\n",
    "        tiff.imwrite(save_path, img[min_row:max_row, min_col:max_col], bigtiff = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import util\n",
    "import h5py\n",
    "\n",
    "def get_info(data_raw, marker_dict):\n",
    "    conditions = []\n",
    "    fovs = []\n",
    "    cycles = []\n",
    "    channels = []\n",
    "    markers = []\n",
    "    paths = [] \n",
    "\n",
    "    # Loop through image folder\n",
    "    for (dirpath, dirnames, filenames) in os.walk(data_raw):\n",
    "        for name in sorted(filenames):\n",
    "            if \"tif\" in name:\n",
    "                # Get information from image name\n",
    "                n_split = name.split('_')\n",
    "                                \n",
    "                cond=dirpath.split('\\\\')[-1].split('_')[0]\n",
    "                fov=dirpath.split('\\\\')[-1].split('_')[1]\n",
    "                cycle='cycle'+str(int(n_split[0][-2:]))\n",
    "                ch = int(n_split[1][2])\n",
    "                try:\n",
    "                    marker = marker_dict[cycle][ch]\n",
    "                except:\n",
    "                    continue \n",
    "                    \n",
    "                conditions.append(cond)\n",
    "                fovs.append(fov)\n",
    "                cycles.append(cycle)\n",
    "                channels.append(ch)\n",
    "                markers.append(marker)\n",
    "                paths.append(os.path.join(dirpath, name))\n",
    "                \n",
    "    info = {\n",
    "            \"Condition\": conditions,\n",
    "            \"FOV\": fovs,\n",
    "            \"Cycle\": cycles,\n",
    "            \"Channels\": channels,\n",
    "            \"Markers\": markers,\n",
    "            \"Path\": paths\n",
    "        }\n",
    "\n",
    "    df = pd.DataFrame(info)\n",
    "    return df\n",
    "\n",
    "def save_hdf5(\n",
    "    path: str, name: str, data: np.ndarray, attr_dict=None, mode: str = \"a\"\n",
    ") -> None:\n",
    "    # Read h5 file\n",
    "    hf = h5py.File(path, mode)\n",
    "    # Create z_stack_dataset\n",
    "    if hf.get(name) is None:\n",
    "        data_shape = data.shape\n",
    "        data_type = data.dtype\n",
    "        max_shape = (data_shape[0],) + data_shape[1:]\n",
    "        dset = hf.create_dataset(\n",
    "            name,\n",
    "            shape=data_shape,\n",
    "            maxshape=max_shape,\n",
    "            chunks=True,\n",
    "            dtype=data_type,\n",
    "            compression=\"gzip\",\n",
    "        )\n",
    "        dset[:] = data\n",
    "        if attr_dict is not None:\n",
    "            for attr_key, attr_val in attr_dict.items():\n",
    "                dset.attrs[attr_key] = attr_val\n",
    "    else:\n",
    "        print(f\"Dataset {name} exists\")\n",
    "\n",
    "    hf.close()\n",
    "\n",
    "def read_img(path):\n",
    "    return skimage.io.imread(path, as_gray=True)\n",
    "\n",
    "def joblib_loop(task, pics):\n",
    "    return Parallel(n_jobs=20)(delayed(task)(i) for i in pics)\n",
    "\n",
    "def read_img(path):\n",
    "    return skimage.io.imread(path, as_gray=True)\n",
    "\n",
    "def get_min(imgs):\n",
    "    shapes = np.array([np.array(img.shape) for img in imgs])\n",
    "    return np.min(shapes, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder is already there\n",
      "Created df\n"
     ]
    }
   ],
   "source": [
    "data_raw = data_dir / 'VP_drug2'/ 'imgs' /  'registered_crop'\n",
    "df_meta_path = data_dir /  'VP_drug2'/ 'metadata' / 'info_sti.csv'\n",
    "\n",
    "try:\n",
    "    df_meta_path.parent.mkdir(parents=True, exist_ok=False)\n",
    "except FileExistsError:\n",
    "    print(\"Folder is already there\")\n",
    "\n",
    "df_exist = df_meta_path.is_file()\n",
    "\n",
    "if not df_exist:\n",
    "    print('Created df')\n",
    "    df = get_info(data_raw, markers_map)\n",
    "    df.to_csv(df_meta_path, index=False)\n",
    "else:\n",
    "    print('Loaded df')\n",
    "    df = pd.read_csv(df_meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Condition\n",
       "10uM    13\n",
       "1uM     13\n",
       "ctrl    13\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Condition').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created df\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9c12c0dc875489cb9f59eb2e51c6736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_imgs_path = data_dir /'VP_drug2'/ 'metadata' / 'imgs_reg.csv'\n",
    "temp_path =data_dir /'VP_drug2' / 'hdf5' / 'registered'\n",
    "try:\n",
    "    temp_path.mkdir(parents=True, exist_ok=False)\n",
    "except FileExistsError:\n",
    "    print(\"Folder is already there\")\n",
    "\n",
    "df_exist = df_imgs_path.is_file()\n",
    "\n",
    "if not df_exist:\n",
    "    print('Created df')\n",
    "    group = df.groupby(['Condition','FOV'])\n",
    "    rows = []\n",
    "\n",
    "    for name, df_group in tqdm(group, total=len(group)):\n",
    "        file_name = '_'.join(np.array(name).astype(str)) + '.hdf5'\n",
    "        file_path = temp_path / file_name\n",
    "        rows.append(list(name)+[file_path])\n",
    "        \n",
    "        # if file_path.exists():\n",
    "        #     continue\n",
    "        \n",
    "        channels = df_group.Channels.to_list()\n",
    "        cycles = df_group.Cycle.to_list()\n",
    "        markers = df_group.Markers.to_list()\n",
    "        paths = df_group.Path.to_numpy()\n",
    "            \n",
    "        imgs = joblib_loop(read_img, paths)\n",
    "        min_shape = get_min(imgs)\n",
    "        imgs_cropped = np.array([img[:min_shape[0], :min_shape[1]] for img in imgs])\n",
    "        info = {\"Cycle\": cycles, \"Channel\": channels, \"Marker\": markers}\n",
    "\n",
    "        imgs_cropped = util.img_as_ubyte(imgs_cropped)\n",
    "        \n",
    "        # hdf5 as Channel -> Z mapping\n",
    "        save_hdf5(file_path, 'imgs', imgs_cropped, info)\n",
    "    df_imgs = pd.DataFrame(rows, columns=['Condition', 'FOV', 'Path'])        \n",
    "    df_imgs.to_csv(df_imgs_path, index=False)\n",
    "else:\n",
    "    print('Loaded df')\n",
    "    df_imgs = pd.read_csv(df_imgs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Condition</th>\n",
       "      <th>FOV</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10uM</td>\n",
       "      <td>FW1</td>\n",
       "      <td>y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\VP_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1uM</td>\n",
       "      <td>FW1</td>\n",
       "      <td>y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\VP_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ctrl</td>\n",
       "      <td>FW1</td>\n",
       "      <td>y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\VP_d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Condition  FOV                                               Path\n",
       "0      10uM  FW1  y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\VP_d...\n",
       "1       1uM  FW1  y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\VP_d...\n",
       "2      ctrl  FW1  y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\VP_d..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari \n",
    "from skimage import exposure, util\n",
    "\n",
    "def contrast_str(img, n_min=0.1, n_max=99.9):\n",
    "    p2, p98 = np.percentile(img, (n_min, n_max))\n",
    "    img_rescale = exposure.rescale_intensity(img, in_range=(p2, p98))\n",
    "    img_rescale = util.img_as_ubyte(img_rescale)\n",
    "    return img_rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imgs_path = data_dir /'VP_drug2' /'metadata' / 'imgs_reg.csv'\n",
    "df_imgs = pd.read_csv(df_imgs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save combined images\n",
    "for row in df_imgs.itertuples():\n",
    "    # Read image\n",
    "    path = row.Path\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        imgs = f['imgs'][:]\n",
    "        markers = f['imgs'].attrs['Marker']\n",
    "\n",
    "    napari.view_image(imgs, name=markers, channel_axis=0, visible=False)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DNA', 'TEAD1/YAP', 'DNA', 'EGFR/Grb2', 'Trail/DR5', 'DNA',\n",
       "       'Sox2/Oct4', 'DNA', 'E-cadherin/b-catenin', 'DNA', 'P-EGFR',\n",
       "       'Phalloidin', 'KI67'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyto_markers = ['P-EGFR', 'Phalloidin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_seg_path = data_dir /  'VP_drug2' / 'imgs' / 'segmentation'\n",
    "whole_seg_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# Save combined images\n",
    "for row in df_imgs.itertuples():\n",
    "    # Read image\n",
    "    path = row.Path\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        imgs = f['imgs'][:]\n",
    "        markers = f['imgs'].attrs['Marker']\n",
    "\n",
    "    # Get dapi and cyto imgaes\n",
    "    indices = np.isin(markers, cyto_markers)\n",
    "    img_dapi = imgs[0]\n",
    "    imgs_cyto = imgs[indices,:]\n",
    "    \n",
    "    # Contrast streching and combine to rgb image\n",
    "    img_dapi = contrast_str(img_dapi, n_max=99.9)\n",
    "    imgs_cyto_scaled = [contrast_str(imgs_cyto[0], n_max=99.5), contrast_str(imgs_cyto[1], n_max=99.5)]\n",
    "    img_cyto = np.max(np.array(imgs_cyto_scaled), axis=0)\n",
    "    img_rgb = np.stack([np.zeros(img_dapi.shape),img_cyto, img_dapi], axis=0).astype(np.uint8)\n",
    "    \n",
    "    # Crop and save\n",
    "    file_name = f'{\"_\".join(row[1:3])}.tif'\n",
    "    file_path = whole_seg_path / file_name\n",
    "    tiff.imwrite(file_path, img_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QC masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import morphology, measure\n",
    "from skimage.segmentation import clear_border\n",
    "from collections import defaultdict\n",
    "   \n",
    "def count_pixel_label_mask(regionmask, intensity_image):\n",
    "    v,c = np.unique(intensity_image[regionmask], return_counts=True)\n",
    "    return dict(zip(v,c))\n",
    "    \n",
    "# Quality control of mask\n",
    "def qc_nuclei(mask_cyto, mask_nuclei, small_size=10000):\n",
    "    '''\n",
    "    Function to check if cell masks contain nuclei\n",
    "    '''\n",
    "    # Dictionnary storing nuclei and cyto label to cell id \n",
    "    nuclei2cell = {}\n",
    "    cyto2cell = {}\n",
    "    \n",
    "    # Filter out small objects\n",
    "    mask_cyto = morphology.remove_small_objects(mask_cyto,  min_size=small_size)\n",
    "    \n",
    "    # Filter out mask touching border\n",
    "    mask_cyto = clear_border(mask_cyto)\n",
    "    \n",
    "    # Filtered only cell mask region\n",
    "    cell_mask = np.where(mask_cyto > 0, 1, 0)\n",
    "    mask_nuclei_filtered = mask_nuclei * cell_mask\n",
    "    mask_nuclei_filtered =  morphology.remove_small_objects(mask_nuclei_filtered,  min_size=2000)\n",
    "    \n",
    "    nuclei_mask = np.where(mask_nuclei>0, 1, 0)\n",
    "    cyto = (mask_cyto - mask_cyto*nuclei_mask).astype(np.uint16)\n",
    "    \n",
    "    # Count pixel cell label in each nuclei region to assign each nuclei to cell\n",
    "    props = measure.regionprops(mask_nuclei_filtered, intensity_image=mask_cyto, \n",
    "                    extra_properties=(count_pixel_label_mask,))\n",
    "    nuclei_labels = []\n",
    "    cell_labels = []\n",
    "    for prop in props:\n",
    "        df = pd.DataFrame.from_dict(prop['count_pixel_label_mask'], orient='index').reset_index()\n",
    "        df.columns = ['Label', 'Count']\n",
    "        corresponding_label = df.iloc[df['Count'].argmax(axis=0)]['Label']\n",
    "        nuclei_labels.append(prop['Label'])\n",
    "        cell_labels.append(corresponding_label)\n",
    "    \n",
    "    df = pd.DataFrame({'Nuclei': nuclei_labels, 'Cyto': cell_labels})\n",
    "    return mask_cyto, mask_nuclei_filtered, cyto, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read masks paths \n",
    "mask_dir = data_dir /  'VP_drug2' / 'imgs' / 'masks'\n",
    "mask_filt_dir = data_dir /  'VP_drug2'  / 'imgs' / 'masks_filtered'\n",
    "mask_filt_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "masks_path = defaultdict(dict) \n",
    "for path in os.listdir(mask_dir):\n",
    "    name = path.split('.')[0]\n",
    "    if 'Nuclei' in name:\n",
    "        masks_path[name[7:]]['nuclei'] = mask_dir / path\n",
    "    else:\n",
    "        masks_path[name]['cyto'] = mask_dir / path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in df_imgs.itertuples():\n",
    "    # Read image\n",
    "    path = row.Path\n",
    "    name = '_'.join([row.Condition, row.FOV])\n",
    "    \n",
    "    # Read masks\n",
    "    mask_cyto_path = masks_path[name]['cyto']\n",
    "    mask_nuclei_path = masks_path[name]['nuclei']\n",
    "    \n",
    "    mask_cyto = skimage.io.imread(mask_cyto_path)\n",
    "    mask_nuclei = skimage.io.imread(mask_nuclei_path)\n",
    "    mask_nuclei = mask_nuclei[:mask_cyto.shape[0], :mask_cyto.shape[1]]\n",
    "    cell, nuclei, cyto, df = qc_nuclei(mask_cyto, mask_nuclei)\n",
    "    \n",
    "    file_path =  mask_filt_dir / f'Nuclei_{name}.tif'\n",
    "    tiff.imwrite(file_path, nuclei)\n",
    "    file_path =  mask_filt_dir / f'Cell_{name}.tif'\n",
    "    tiff.imwrite(file_path, cell)\n",
    "    file_path =  mask_filt_dir / f'Cyto_{name}.tif'\n",
    "    tiff.imwrite(file_path, cyto)\n",
    "    file_path =  mask_filt_dir / f'df_{name}.csv'\n",
    "    df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quanfitication PPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PLA\n",
    "\n",
    "PPI_save_path =  data_dir / 'VP_drug2' / 'PPI'\n",
    "PPI_save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "PPI_imgs_path =  data_dir / 'VP_drug2'  / 'PPI_imgs'\n",
    "PPI_imgs_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DNA' 'TEAD1/YAP' 'DNA' 'EGFR/Grb2' 'Trail/DR5' 'DNA' 'Sox2/Oct4' 'DNA'\n",
      " 'E-cadherin/b-catenin' 'DNA' 'P-EGFR' 'Phalloidin' 'KI67']\n",
      "['DNA' 'TEAD1/YAP' 'DNA' 'EGFR/Grb2' 'Trail/DR5' 'DNA' 'Sox2/Oct4' 'DNA'\n",
      " 'E-cadherin/b-catenin' 'DNA' 'P-EGFR' 'Phalloidin' 'KI67']\n",
      "['DNA' 'TEAD1/YAP' 'DNA' 'EGFR/Grb2' 'Trail/DR5' 'DNA' 'Sox2/Oct4' 'DNA'\n",
      " 'E-cadherin/b-catenin' 'DNA' 'P-EGFR' 'Phalloidin' 'KI67']\n"
     ]
    }
   ],
   "source": [
    "for row in df_imgs.itertuples():\n",
    "    path = row.Path\n",
    "    with h5py.File(path, 'r') as f:\n",
    "        markers = f['imgs'].attrs['Marker']\n",
    "    print(markers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Condition</th>\n",
       "      <th>FOV</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10uM</td>\n",
       "      <td>FW1</td>\n",
       "      <td>y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\VP_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1uM</td>\n",
       "      <td>FW1</td>\n",
       "      <td>y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\VP_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ctrl</td>\n",
       "      <td>FW1</td>\n",
       "      <td>y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\VP_d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Condition  FOV                                               Path\n",
       "0      10uM  FW1  y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\VP_d...\n",
       "1       1uM  FW1  y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\VP_d...\n",
       "2      ctrl  FW1  y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\VP_d..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPI_markers = ['TEAD1/YAP',  'EGFR/Grb2', 'Trail/DR5', 'Sox2/Oct4','E-cadherin/b-catenin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading image TEAD1/YAP\n",
      "Processing image TEAD1/YAP\n",
      "(array([0, 1], dtype=uint8), array([30726959,  1639081], dtype=int64))\n",
      "Reading image EGFR/Grb2\n",
      "Processing image EGFR/Grb2\n",
      "(array([0, 1], dtype=uint8), array([32218504,   147536], dtype=int64))\n",
      "Reading image Trail/DR5\n",
      "Processing image Trail/DR5\n",
      "(array([0, 1], dtype=uint8), array([32180475,   185565], dtype=int64))\n",
      "Reading image Sox2/Oct4\n",
      "Processing image Sox2/Oct4\n",
      "(array([0, 1], dtype=uint8), array([31747116,   618924], dtype=int64))\n",
      "Reading image E-cadherin/b-catenin\n",
      "Processing image E-cadherin/b-catenin\n",
      "(array([0, 1], dtype=uint8), array([32198025,   168015], dtype=int64))\n",
      "File exist. Deleted\n",
      "Reading image TEAD1/YAP\n",
      "Processing image TEAD1/YAP\n",
      "(array([0, 1], dtype=uint8), array([30001546,  2098002], dtype=int64))\n",
      "Reading image EGFR/Grb2\n",
      "Processing image EGFR/Grb2\n",
      "(array([0, 1], dtype=uint8), array([31902926,   196622], dtype=int64))\n",
      "Reading image Trail/DR5\n",
      "Processing image Trail/DR5\n",
      "(array([0, 1], dtype=uint8), array([31846796,   252752], dtype=int64))\n",
      "Reading image Sox2/Oct4\n",
      "Processing image Sox2/Oct4\n",
      "(array([0, 1], dtype=uint8), array([30947526,  1152022], dtype=int64))\n",
      "Reading image E-cadherin/b-catenin\n",
      "Processing image E-cadherin/b-catenin\n",
      "(array([0, 1], dtype=uint8), array([32016554,    82994], dtype=int64))\n",
      "Reading image TEAD1/YAP\n",
      "Processing image TEAD1/YAP\n",
      "(array([0, 1], dtype=uint8), array([30099224,  1894040], dtype=int64))\n",
      "Reading image EGFR/Grb2\n",
      "Processing image EGFR/Grb2\n",
      "(array([0, 1], dtype=uint8), array([31833323,   159941], dtype=int64))\n",
      "Reading image Trail/DR5\n",
      "Processing image Trail/DR5\n",
      "(array([0, 1], dtype=uint8), array([31789183,   204081], dtype=int64))\n",
      "Reading image Sox2/Oct4\n",
      "Processing image Sox2/Oct4\n",
      "(array([0, 1], dtype=uint8), array([30954196,  1039068], dtype=int64))\n",
      "Reading image E-cadherin/b-catenin\n",
      "Processing image E-cadherin/b-catenin\n",
      "(array([0, 1], dtype=uint8), array([31960813,    32451], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "for row in df_imgs.itertuples():\n",
    "    # Read image\n",
    "    path = row.Path\n",
    "    pla_detect = PLA.PLA_detection(path, name='imgs', m='Marker')\n",
    "    \n",
    "    with h5py.File(path, 'r') as f:\n",
    "        markers = f['imgs'].attrs['Marker']\n",
    "        \n",
    "    imgs_spots = []\n",
    "    imgs_wths = []\n",
    "    imgs_raw = []\n",
    "    for RNA in PPI_markers: \n",
    "        if RNA in markers:\n",
    "            img_spot, img_wth, _, img = pla_detect.detect_spot(RNA, thres=0.03, min_radius=2)\n",
    "            imgs_spots.append(img_spot)\n",
    "            imgs_wths.append(img_wth)\n",
    "            imgs_raw.append(img)\n",
    "\n",
    "    # Save imgs\n",
    "    file_path = PPI_imgs_path / (row[1] + '_raw.tiff')\n",
    "    tiff.imwrite(file_path, imgs_raw)\n",
    "    file_path = PPI_imgs_path / (row[1] + '_processed.tiff')\n",
    "    tiff.imwrite(file_path, imgs_wths)\n",
    "    file_path = PPI_imgs_path / (row[1] + '_detected.tiff')\n",
    "    tiff.imwrite(file_path, imgs_spots)\n",
    "\n",
    "    # Save PPI dict\n",
    "    name = row[1] +'.pkl'\n",
    "    pla_detect.save_pickle(PPI_save_path / name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract per cell PPI count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "def read_PPI(path):\n",
    "    with open(path, 'rb') as file:\n",
    "        PPI_dict = pickle.load(file)\n",
    "\n",
    "    return PPI_dict\n",
    "\n",
    "def create_PPI_df(PPI_labels, PPI_loc, name, cyto=True):\n",
    "    if cyto:\n",
    "        columns_name = ['Cyto', 'x', 'y']\n",
    "    else:\n",
    "        columns_name = ['Nuclei', 'x', 'y']\n",
    "    df = pd.DataFrame(np.hstack([PPI_labels[:,np.newaxis], PPI_loc]), \n",
    "                      columns=columns_name)\n",
    "    df['PPI'] = name\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_filt_dir = data_dir / 'VP_drug2' / 'imgs' / 'masks_filtered'\n",
    "PPI_save_path =  data_dir / 'VP_drug2' / 'PPI'\n",
    "\n",
    "masks_path = defaultdict(dict) \n",
    "for path in os.listdir(mask_filt_dir):\n",
    "    name = path.split('.')[0]\n",
    "    if 'Nuclei' in name:\n",
    "        masks_path[name[7:]]['nuclei'] = mask_filt_dir / path\n",
    "    elif 'Cyto' in name:\n",
    "        masks_path[name[5:]]['cyto'] =mask_filt_dir / path\n",
    "    elif 'Cell' in name:\n",
    "        masks_path[name[5:]]['cell'] =mask_filt_dir / path    \n",
    "    elif 'df' in name:\n",
    "        masks_path[name[3:]]['df'] =mask_filt_dir / path\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in df_imgs.itertuples():\n",
    "    name = '_'.join(row[1:3])\n",
    "    \n",
    "    # Read masks\n",
    "    mask_cyto_path = masks_path[name]['cell']\n",
    "    mask_nuclei_path = masks_path[name]['nuclei']\n",
    "    df_path =  masks_path[name]['df']\n",
    "    \n",
    "    mask_cyto = skimage.io.imread(mask_cyto_path)\n",
    "    mask_nuclei = skimage.io.imread(mask_nuclei_path)\n",
    "    df_cell_info = pd.read_csv(df_path)\n",
    "    nuclei2cell = dict(zip(df_cell_info.iloc[:,0], df_cell_info.iloc[:,1]))   \n",
    "    \n",
    "    # Read PPi\n",
    "    PPI_dict = read_PPI(PPI_save_path / f'{row[1]}.pkl')\n",
    "    dfs_PPI_cyto = []\n",
    "    dfs_PPI_nuclei = []\n",
    "    for k in PPI_dict.keys():\n",
    "        PPI_loc = PPI_dict[k][:, 1:3].astype(np.uint32)\n",
    "        \n",
    "        # Cyto\n",
    "        PPI_labels = mask_cyto[PPI_loc[:,0], PPI_loc[:,1]]\n",
    "        df_PPI = create_PPI_df(PPI_labels, PPI_loc, k)\n",
    "        dfs_PPI_cyto.append(df_PPI)\n",
    "        \n",
    "        # Nuclei\n",
    "        PPI_labels = mask_nuclei[PPI_loc[:,0], PPI_loc[:,1]]\n",
    "        df_PPI = create_PPI_df(PPI_labels, PPI_loc, k, cyto=False)\n",
    "        dfs_PPI_nuclei.append(df_PPI)\n",
    "    \n",
    "    # Combined DFs\n",
    "    df_PPI_cyto = pd.concat(dfs_PPI_cyto)\n",
    "    df_PPI_nuclei = pd.concat(dfs_PPI_nuclei)\n",
    "    df_PPI_nuclei['Nuclei_Cell'] = df_PPI_nuclei['Nuclei'].apply(lambda x: nuclei2cell.get(x,x))   \n",
    "    df_merged = df_PPI_cyto.merge(df_PPI_nuclei)\n",
    "    df_merged['Condition'] = row[1]\n",
    "    df_merged['FOV'] = row[2]\n",
    "    \n",
    "    # Save dataframe\n",
    "    path = PPI_save_path / f'{name}.csv'\n",
    "    df_merged.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coexpression between IF and PPI markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def read_mean_pixels(x, y, window_size, path):\n",
    "    x_min = np.clip(x-window_size,a_min=0, a_max=None)\n",
    "    x_max = x+window_size\n",
    "    y_min = np.clip(y-window_size, a_min=0, a_max=None)\n",
    "    y_max = y+window_size\n",
    "    \n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        pixels = f['imgs'][:, y_min:y_max, x_min:x_max]\n",
    "    mean_expression = pixels.mean(axis=(1,2))\n",
    "    return mean_expression\n",
    "    \n",
    "def extract(df, path, window_size=5):\n",
    "    x = df['x'].to_numpy()\n",
    "    y = df['y'].to_numpy()\n",
    "    \n",
    "    # Read markers name \n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        markers = f['imgs'].attrs['Marker']\n",
    "    \n",
    "    # Define partial and joblib\n",
    "    read_partial = partial(read_mean_pixels, window_size=window_size, path=path)\n",
    "    mean_expressions = Parallel(n_jobs=20)(delayed(read_partial)(i,j) for i,j in zip(y,x))\n",
    "    \n",
    "    # create dataframe\n",
    "    _, indices = np.unique(markers, return_index=True)\n",
    "    indices.sort()\n",
    "    marker_unique = markers[indices]\n",
    "    mean_expressions = np.stack(mean_expressions)\n",
    "    df_exp = pd.DataFrame(mean_expressions[:, indices], columns=marker_unique)\n",
    "    return df_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read PPI\n",
    "PPI_save_path =  data_dir / 'VP_drug2' / 'PPI'\n",
    "\n",
    "dfs = []\n",
    "for path in os.listdir(PPI_save_path):\n",
    "    if 'csv' in path:\n",
    "        df = pd.read_csv(PPI_save_path / path)\n",
    "        dfs.append(df)\n",
    "\n",
    "df = pd.concat(dfs)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df_fil = df[df.Cyto > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imgs_path = data_dir /'VP_drug2' /'metadata' / 'imgs_reg.csv'\n",
    "df_imgs = pd.read_csv(df_imgs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Co-expression data\n",
    "PPI_exp_path =  data_dir / 'VP_drug2' / 'PPI' / 'expression'\n",
    "PPI_exp_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "group = df_fil.groupby(['Condition', 'FOV'])\n",
    "\n",
    "for name, df_group in group:\n",
    "    path = df_imgs[(df_imgs.Condition == name[0]) & (df_imgs.FOV == name[1])].Path.item()\n",
    "    df_expression = extract(df_group, path)\n",
    "    \n",
    "    df_merged = pd.concat([df_group.reset_index().rename({'index':'Original Index'}, axis=1), \n",
    "                           df_expression], axis=1)\n",
    "    \n",
    "    # Save coexpression\n",
    "    file_name = '_'.join(name)\n",
    "    save_path = PPI_exp_path / f'{file_name}.csv'\n",
    "    df_merged.to_csv(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area quantification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import threshold_local, gaussian\n",
    "from skimage.filters import threshold_otsu, rank\n",
    "from skimage.morphology import disk\n",
    "from skimage import exposure, measure\n",
    "\n",
    "def threshold(img):\n",
    "    p2, p98 = np.percentile(img, (2, 99.9))\n",
    "    img_rescale = exposure.rescale_intensity(img, in_range=(p2, p98))\n",
    "\n",
    "    img_blur = gaussian(img_rescale , sigma=15, preserve_range=True).astype(np.uint8)\n",
    "    img_pro = cv2.subtract(img_rescale, img_blur)\n",
    "\n",
    "    thresh = 50\n",
    "    binary = img_pro >= thresh\n",
    "    return binary\n",
    "\n",
    "def custom(regionmask, intensity_image):\n",
    "    return np.sum(intensity_image[regionmask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_filt_dir = data_dir / 'VP_drug2' / 'imgs' / 'masks_filtered'\n",
    "PPI_save_path =  data_dir / 'VP_drug2' / 'PPI'\n",
    "\n",
    "masks_path = defaultdict(dict) \n",
    "for path in os.listdir(mask_filt_dir):\n",
    "    name = path.split('.')[0]\n",
    "    if 'Nuclei' in name:\n",
    "        masks_path[name[7:]]['nuclei'] = mask_filt_dir / path\n",
    "    elif 'Cyto' in name:\n",
    "        masks_path[name[5:]]['cyto'] =mask_filt_dir / path\n",
    "    elif 'Cell' in name:\n",
    "        masks_path[name[5:]]['cell'] =mask_filt_dir / path    \n",
    "    elif 'df' in name:\n",
    "        masks_path[name[3:]]['df'] =mask_filt_dir / path\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imgs_path = data_dir /'VP_drug2' /'metadata' / 'imgs_reg.csv'\n",
    "df_imgs = pd.read_csv(df_imgs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker = 'KI67'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for row in df_imgs.itertuples():\n",
    "    path = row.Path\n",
    "\n",
    "    # Read markers name \n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        markers = f['imgs'].attrs['Marker']\n",
    "        imgs = f['imgs'][:]\n",
    "\n",
    "    img = imgs[list(markers).index(marker)]\n",
    "    binary = threshold(img)\n",
    "\n",
    "    name = '_'.join(row[1:3])\n",
    "    \n",
    "    # Read masks\n",
    "    mask_cyto_path = masks_path[name]['cell']\n",
    "    mask_nuclei_path = masks_path[name]['nuclei']\n",
    "    df_path =  masks_path[name]['df']\n",
    "    mask_nuclei = skimage.io.imread(mask_nuclei_path)\n",
    "    df_cell_info = pd.read_csv(df_path)\n",
    "    nuclei2cell = dict(zip(df_cell_info.iloc[:,0], df_cell_info.iloc[:,1]))   \n",
    "    \n",
    "    # Get values\n",
    "    props = measure.regionprops_table(mask_nuclei, intensity_image=binary.astype(np.uint8),\n",
    "                                  properties=('label', 'area'),\n",
    "                                  extra_properties=(custom, ))\n",
    "    df = pd.DataFrame(props)\n",
    "    df.columns = ['Nuclei', 'Nuclei Area', 'Ki67 Area']\n",
    "    df['Nuclei_Cell'] = df['Nuclei'].apply(lambda x: nuclei2cell.get(x,x))   \n",
    "    df['Condition'] = row.Condition\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Co-expression data\n",
    "PPI_exp_path =  data_dir / 'VP_drug2' / 'PPI' / 'expression'\n",
    "PPI_exp_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df = pd.concat(dfs)\n",
    "df.to_csv(PPI_exp_path / 'Ki67.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ki67 Quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_filt_dir = data_dir / 'VP_drug2' / 'imgs' / 'masks_filtered'\n",
    "PPI_save_path =  data_dir / 'VP_drug2' / 'PPI'\n",
    "\n",
    "masks_path = defaultdict(dict) \n",
    "for path in os.listdir(mask_filt_dir):\n",
    "    name = path.split('.')[0]\n",
    "    if 'Nuclei' in name:\n",
    "        masks_path[name[7:]]['nuclei'] = mask_filt_dir / path\n",
    "    elif 'Cyto' in name:\n",
    "        masks_path[name[5:]]['cyto'] =mask_filt_dir / path\n",
    "    elif 'Cell' in name:\n",
    "        masks_path[name[5:]]['cell'] =mask_filt_dir / path    \n",
    "    elif 'df' in name:\n",
    "        masks_path[name[3:]]['df'] =mask_filt_dir / path\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imgs_path = data_dir /'VP_drug2' /'metadata' / 'imgs_reg.csv'\n",
    "df_imgs = pd.read_csv(df_imgs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker = 'KI67'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for row in df_imgs.itertuples():\n",
    "    path = row.Path\n",
    "\n",
    "    # Read markers name \n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        markers = f['imgs'].attrs['Marker']\n",
    "        imgs = f['imgs'][:]\n",
    "\n",
    "    img = imgs[list(markers).index(marker)]\n",
    "\n",
    "    name = '_'.join(row[1:3])\n",
    "    \n",
    "    # Read masks\n",
    "    mask_cyto_path = masks_path[name]['cell']\n",
    "    mask_nuclei_path = masks_path[name]['nuclei']\n",
    "    df_path =  masks_path[name]['df']\n",
    "    mask_cyto = skimage.io.imread(mask_cyto_path)\n",
    "\n",
    "    # Get values\n",
    "    props = measure.regionprops_table(mask_cyto, intensity_image=img,\n",
    "                                  properties=('label', 'area', 'mean_intensity'))\n",
    "    df = pd.DataFrame(props)\n",
    "    df.columns = ['Cell', 'Area', 'Ki67']\n",
    "    df['Condition'] = row.Condition\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Co-expression data\n",
    "PPI_exp_path =  data_dir / 'VP_drug2' / 'PPI' / 'expression'\n",
    "PPI_exp_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df = pd.concat(dfs)\n",
    "df = df[df.Area > 7000]\n",
    "df.to_csv(PPI_exp_path / 'Ki67_intensity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cell</th>\n",
       "      <th>Area</th>\n",
       "      <th>Ki67</th>\n",
       "      <th>Condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>38907.0</td>\n",
       "      <td>12.138278</td>\n",
       "      <td>10uM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>15708.0</td>\n",
       "      <td>7.348739</td>\n",
       "      <td>10uM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>10365.0</td>\n",
       "      <td>15.865027</td>\n",
       "      <td>10uM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>29638.0</td>\n",
       "      <td>3.150989</td>\n",
       "      <td>10uM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>26603.0</td>\n",
       "      <td>7.771454</td>\n",
       "      <td>10uM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>617</td>\n",
       "      <td>32728.0</td>\n",
       "      <td>2.413560</td>\n",
       "      <td>ctrl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>618</td>\n",
       "      <td>15838.0</td>\n",
       "      <td>6.887549</td>\n",
       "      <td>ctrl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>620</td>\n",
       "      <td>28077.0</td>\n",
       "      <td>11.681590</td>\n",
       "      <td>ctrl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>621</td>\n",
       "      <td>33493.0</td>\n",
       "      <td>1.594333</td>\n",
       "      <td>ctrl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>623</td>\n",
       "      <td>22736.0</td>\n",
       "      <td>3.121525</td>\n",
       "      <td>ctrl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1382 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cell     Area       Ki67 Condition\n",
       "0       8  38907.0  12.138278      10uM\n",
       "1      10  15708.0   7.348739      10uM\n",
       "2      11  10365.0  15.865027      10uM\n",
       "3      14  29638.0   3.150989      10uM\n",
       "4      15  26603.0   7.771454      10uM\n",
       "..    ...      ...        ...       ...\n",
       "508   617  32728.0   2.413560      ctrl\n",
       "509   618  15838.0   6.887549      ctrl\n",
       "510   620  28077.0  11.681590      ctrl\n",
       "511   621  33493.0   1.594333      ctrl\n",
       "513   623  22736.0   3.121525      ctrl\n",
       "\n",
       "[1382 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B-catenin mean expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from skimage import measure\n",
    "\n",
    "mask_filt_dir = data_dir / 'VP_drug2'/ 'imgs' / 'masks_filtered'\n",
    "PPI_save_path =  data_dir / 'VP_drug2'/ 'PPI'\n",
    "\n",
    "masks_path = defaultdict(dict) \n",
    "for path in os.listdir(mask_filt_dir):\n",
    "    name = path.split('.')[0]\n",
    "    if 'Nuclei' in name:\n",
    "        masks_path[name[7:]]['nuclei'] = mask_filt_dir / path\n",
    "    elif 'Cyto' in name:\n",
    "        masks_path[name[5:]]['cyto'] =mask_filt_dir / path\n",
    "    elif 'Cell' in name:\n",
    "        masks_path[name[5:]]['cell'] =mask_filt_dir / path    \n",
    "    elif 'df' in name:\n",
    "        masks_path[name[3:]]['df'] =mask_filt_dir / path\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imgs_path = data_dir / 'VP_drug2' /'metadata' / 'imgs_reg.csv'\n",
    "df_imgs = pd.read_csv(df_imgs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker = 'E-cadherin/b-catenin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for row in df_imgs.itertuples():\n",
    "    path = row.Path\n",
    "\n",
    "    # Read markers name \n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        markers = f['imgs'].attrs['Marker']\n",
    "        imgs = f['imgs'][:]\n",
    "\n",
    "    img = imgs[list(markers).index(marker)]\n",
    "\n",
    "    name = '_'.join(row[1:3])\n",
    "    \n",
    "    # Read masks\n",
    "    mask_cyto_path = masks_path[name]['cell']\n",
    "    mask_nuclei_path = masks_path[name]['nuclei']\n",
    "    df_path =  masks_path[name]['df']\n",
    "    mask_cyto = skimage.io.imread(mask_cyto_path)\n",
    "    \n",
    "    # Get values\n",
    "    props = measure.regionprops_table(mask_cyto, intensity_image=img,\n",
    "                                  properties=('label', 'area', 'mean_intensity'))\n",
    "    df = pd.DataFrame(props)\n",
    "    df.columns = ['Cell', 'Area', marker]\n",
    "    df['Condition'] = row.Condition\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Co-expression data\n",
    "PPI_exp_path =  data_dir /  'VP_drug2'/ 'PPI' / 'expression'\n",
    "PPI_exp_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df = pd.concat(dfs)\n",
    "df = df[df.Area > 7000]\n",
    "\n",
    "df.to_csv(PPI_exp_path / 'bcatenin_intensity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cell</th>\n",
       "      <th>Area</th>\n",
       "      <th>E-cadherin/b-catenin</th>\n",
       "      <th>Condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>38907.0</td>\n",
       "      <td>52.069036</td>\n",
       "      <td>10uM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>15708.0</td>\n",
       "      <td>41.231602</td>\n",
       "      <td>10uM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>10365.0</td>\n",
       "      <td>47.662808</td>\n",
       "      <td>10uM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>29638.0</td>\n",
       "      <td>11.676260</td>\n",
       "      <td>10uM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>26603.0</td>\n",
       "      <td>29.028756</td>\n",
       "      <td>10uM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>617</td>\n",
       "      <td>32728.0</td>\n",
       "      <td>8.806924</td>\n",
       "      <td>ctrl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>618</td>\n",
       "      <td>15838.0</td>\n",
       "      <td>26.462116</td>\n",
       "      <td>ctrl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>620</td>\n",
       "      <td>28077.0</td>\n",
       "      <td>34.124978</td>\n",
       "      <td>ctrl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>621</td>\n",
       "      <td>33493.0</td>\n",
       "      <td>6.475592</td>\n",
       "      <td>ctrl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>623</td>\n",
       "      <td>22736.0</td>\n",
       "      <td>13.688863</td>\n",
       "      <td>ctrl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1382 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cell     Area  E-cadherin/b-catenin Condition\n",
       "0       8  38907.0             52.069036      10uM\n",
       "1      10  15708.0             41.231602      10uM\n",
       "2      11  10365.0             47.662808      10uM\n",
       "3      14  29638.0             11.676260      10uM\n",
       "4      15  26603.0             29.028756      10uM\n",
       "..    ...      ...                   ...       ...\n",
       "508   617  32728.0              8.806924      ctrl\n",
       "509   618  15838.0             26.462116      ctrl\n",
       "510   620  28077.0             34.124978      ctrl\n",
       "511   621  33493.0              6.475592      ctrl\n",
       "513   623  22736.0             13.688863      ctrl\n",
       "\n",
       "[1382 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
