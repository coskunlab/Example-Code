{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e197f7b7-0e86-4a64-9d91-7f4e74d65b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.io\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import trange, tqdm, tqdm_notebook\n",
    "from joblib import Parallel, delayed\n",
    "import re\n",
    "import h5py\n",
    "import tifffile as tiff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a02f6d6-87a8-4214-9889-3c35d41d6f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5c8922a-18e2-4d8b-ba45-f979074a3b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = (Path().cwd().parents[0] / 'data').absolute()\n",
    "data_processed = data_dir / 'processed'\n",
    "data_raw = r'Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\Batch difference experiments'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d49ccd2b-f49f-4d34-8d35-d9d4cf478555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    " \n",
    "os.environ['JDK_HOME'] = \"C:\\Program Files\\Java\\jdk-17\"\n",
    "os.environ['JAVA_HOME'] = \"C:\\Program Files\\Java\\jdk-17\"\n",
    "\n",
    "os.environ['PATH'] += ';C:\\\\Program Files\\\\Java\\\\jdk-17\\\\jre\\\\bin\\\\server\\\\;C:\\\\Program Files\\\\Java\\\\jdk-17\\\\bin\\\\;C:\\\\Program Files\\\\Java\\\\jdk-17\\\\bin\\\\jar.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c23e1a-a24b-43d6-95a6-9828be235940",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Get info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "daf43503-f6a1-466e-b428-e30f8f327fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "markers_map = {\n",
    "    'cycle1': {\n",
    "        1: 'DNA', \n",
    "        3: 'Sox2/Oct4',\n",
    "        4: 'p-P90rsk/NF-Kb',\n",
    "    },\n",
    "    'cycle2': {\n",
    "        1: 'DNA', \n",
    "        3: 'Cyclin D1/CDK4',\n",
    "        4: 'Bim/Tom20',\n",
    "    },\n",
    "    'cycle3': {\n",
    "        1: 'DNA', \n",
    "        2: 'Concanavalin A',\n",
    "        3: 'Phalloidin',\n",
    "        4: 'WGA'\n",
    "    },\n",
    "}\n",
    "\n",
    "def get_info(data_raw, marker_dict):\n",
    "    conditions = []\n",
    "    fovs = []\n",
    "    cycles = []\n",
    "    channels = []\n",
    "    markers = []\n",
    "    paths = [] \n",
    "    \n",
    "    # Loop through image folder\n",
    "    for (dirpath, dirnames, filenames) in os.walk(data_raw):\n",
    "        if 'after nuclease' in dirpath or 'Test' in dirpath or 'wrong' in dirpath:\n",
    "            continue\n",
    "        \n",
    "            \n",
    "        for name in sorted(filenames):\n",
    "            if \"tif\" in name and \"sti\" in name \\\n",
    "            and 'overlay' not in name \\\n",
    "            and 'Composite' not in name:\n",
    "                # Get information from image name\n",
    "                row = filenames[-1][1] \n",
    "                if row == 'B':\n",
    "                    condition = 'Control'\n",
    "                elif row == 'E':\n",
    "                    condition = '100nM'\n",
    "                d_split = dirpath.split('\\\\')\n",
    "                \n",
    "                well = d_split[-2].split('_')[2].split(' ')[0]\n",
    "                n_split = name.split('_')\n",
    "                ch = int(n_split[-1][-5])\n",
    "                \n",
    "                cycle = well\n",
    "                try: marker = marker_dict[cycle][ch] \n",
    "                except: continue\n",
    "        \n",
    "                conditions.append(condition)\n",
    "                fovs.append(d_split[-2].split('_')[1])\n",
    "                cycles.append(cycle)\n",
    "                channels.append(ch)\n",
    "                markers.append(marker)\n",
    "                paths.append(os.path.join(dirpath, name))\n",
    "                \n",
    "    info = {\n",
    "            \"Condition\": conditions,\n",
    "            \"FOV\": fovs,\n",
    "            \"Cycle\": cycles,\n",
    "            \"Channels\": channels,\n",
    "            \"Markers\": markers,\n",
    "            \"Path\": paths\n",
    "        }\n",
    "\n",
    "    df = pd.DataFrame(info)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec93272b-5c43-44f6-b689-71a90d1b8e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created df\n"
     ]
    }
   ],
   "source": [
    "df_meta_path = data_dir / 'batch' / 'metadata' / 'info.csv'\n",
    "df_meta_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "df_exist = df_meta_path.is_file()\n",
    "\n",
    "if not df_exist:\n",
    "    print('Created df')\n",
    "    df = get_info(data_raw, markers_map)\n",
    "    df.to_csv(df_meta_path, index=False)\n",
    "else:\n",
    "    print('Loaded df')\n",
    "    df = pd.read_csv(df_meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6265da8f-b280-454d-a0b7-9f256d642dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Condition\n",
       "100nM      20\n",
       "Control    20\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Condition').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26b5f9d-2fe0-47db-9541-862466d3c6d1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Save HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5381dbe4-88d4-4da0-8835-d801fff9b518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "def save_hdf5(\n",
    "    path: str, name: str, data: np.ndarray, attr_dict=None, mode: str = \"a\"\n",
    ") -> None:\n",
    "    # Read h5 file\n",
    "    hf = h5py.File(path, mode)\n",
    "    # Create z_stack_dataset\n",
    "    if hf.get(name) is None:\n",
    "        data_shape = data.shape\n",
    "        data_type = data.dtype\n",
    "        max_shape = (data_shape[0],) + data_shape[1:]\n",
    "        dset = hf.create_dataset(\n",
    "            name,\n",
    "            shape=data_shape,\n",
    "            maxshape=max_shape,\n",
    "            chunks=True,\n",
    "            dtype=data_type,\n",
    "            compression=\"gzip\",\n",
    "        )\n",
    "        dset[:] = data\n",
    "        if attr_dict is not None:\n",
    "            for attr_key, attr_val in attr_dict.items():\n",
    "                dset.attrs[attr_key] = attr_val\n",
    "    else:\n",
    "        print(f\"Dataset {name} exists\")\n",
    "\n",
    "    hf.close()\n",
    "\n",
    "def read_img(path):\n",
    "    return skimage.io.imread(path, as_gray=True)\n",
    "\n",
    "def joblib_loop(task, pics):\n",
    "    return Parallel(n_jobs=20)(delayed(task)(i) for i in pics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58465cc6-c5d7-44d2-8be8-07b3453d07ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created df\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "665445ca8bad4ff2b38663e621c28517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_imgs_path = data_dir / 'batch' / 'metadata' / 'imgs.csv'\n",
    "df_imgs_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "temp_path = data_dir  /'batch' /  'hdf5' / 'raw'\n",
    "temp_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_exist = df_imgs_path.is_file()\n",
    "\n",
    "\n",
    "if not df_exist:\n",
    "    print('Created df')\n",
    "    \n",
    "    group = df.groupby(['Condition', 'FOV'])\n",
    "    rows = []\n",
    "\n",
    "    for name, df_group in tqdm(group, total=len(group)):\n",
    "        file_name = '_'.join(np.array(name).astype(str)) + '.hdf5'\n",
    "        file_path = temp_path / file_name\n",
    "        rows.append(list(name)+[file_path])\n",
    "        \n",
    "        group_cycle = df_group.groupby('Cycle')\n",
    "        for cycle, df_cycle in group_cycle:\n",
    "            channels = df_cycle.Channels.to_list()\n",
    "            markers = df_cycle.Markers.to_list()\n",
    "            paths = df_cycle.Path.to_numpy()\n",
    "    \n",
    "            imgs = joblib_loop(read_img, paths)\n",
    "            imgs = np.array(imgs)\n",
    "            info = {\"Channels\": channels, \"Markers\": markers}\n",
    "            \n",
    "            # hdf5 as Channel -> Z mapping\n",
    "            save_hdf5(file_path, cycle, imgs, info)\n",
    "    df_imgs = pd.DataFrame(rows, columns=['Condition', 'FOV', 'Path'])        \n",
    "    df_imgs.to_csv(df_imgs_path, index=False)\n",
    "else:\n",
    "    print('Loaded df')\n",
    "    df_imgs = pd.read_csv(df_imgs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32d5189c-d225-46a4-ae9b-99203055e879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Condition</th>\n",
       "      <th>FOV</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100nM</td>\n",
       "      <td>P10</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\batc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100nM</td>\n",
       "      <td>P21</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\batc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Control</td>\n",
       "      <td>P10</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\batc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Control</td>\n",
       "      <td>P21</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\batc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Condition  FOV                                               Path\n",
       "0     100nM  P10  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\batc...\n",
       "1     100nM  P21  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\batc...\n",
       "2   Control  P10  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\batc...\n",
       "3   Control  P21  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\batc..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc0eaca-cbde-4e05-8f1b-6d4a0f27e29f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Save Tiffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "662696e1-9800-4cbc-9cf9-fb1a5eaf2742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure, util\n",
    "\n",
    "def contrast_str(img, n_min=0.1, n_max=100):\n",
    "    p2, p98 = np.percentile(img, (n_min, n_max))\n",
    "    img_rescale = exposure.rescale_intensity(img, in_range=(p2, p98))\n",
    "    return img_rescale\n",
    "\n",
    "def make_imgs_same_dim(imgs):\n",
    "    # Get max dimensions\n",
    "    shapes = np.array([img.shape[1:] for img in imgs])\n",
    "    min_x, min_y = shapes.min(axis=0)\n",
    "    imgs_cropped = [img[:, :min_x, :min_y] for img in imgs]\n",
    "    # imgs_cropped[0] = contrast_str(imgs_cropped[0])\n",
    "    return imgs_cropped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e9582f7-091d-4ea1-a055-5c09821356ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_path = data_dir /  'batch' /'imgs' / 'raw'\n",
    "save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "group = df_imgs.groupby(['Condition', 'FOV'])\n",
    "for name, df_group in group:\n",
    "    path = df_group.iloc[0].Path\n",
    "             \n",
    "    # Read images\n",
    "    cycles = []\n",
    "    imgs_all = []\n",
    "    channels = []\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        for k in tqdm(f.keys(), total=len(f.keys()), leave=False):\n",
    "            cycle = k.split('_')[0]\n",
    "            channel = f[k].attrs['Channels']\n",
    "\n",
    "            imgs = f[k][:]\n",
    "            cycles.append(cycle)\n",
    "            channels.append(channel)\n",
    "            imgs[0] = contrast_str(imgs[0])\n",
    "            imgs_all.append(imgs)\n",
    "    \n",
    "    imgs_same_shape = make_imgs_same_dim(imgs_all)\n",
    "    \n",
    "    for i, imgs in enumerate(imgs_same_shape):\n",
    "        temp_path = save_path / '_'.join(np.array(name).astype(str))\n",
    "        temp_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        file_name = f'001_{cycles[i]}.tif'\n",
    "        file_path = temp_path / file_name\n",
    "\n",
    "        # Write image\n",
    "        tiff.imwrite(file_path, imgs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f38cd6-ca0e-4308-843c-fca6053d591e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Registration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aea897b2-b45a-4e4a-98ba-2b02ed9f4602",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ashlar import fileseries, thumbnail,reg\n",
    "import matplotlib.pyplot as plt\n",
    "from ashlar.scripts.ashlar import process_axis_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3fd5cc0e-8841-44c5-b883-bf6c6df82287",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c85e698de4434c2b8bb4fdae3d4811f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    assembling thumbnail 1/1\n",
      "    assembling thumbnail 1/1\n",
      "    estimated cycle offset [y x] = [ 24. -12.]\n",
      "    assembling thumbnail 1/1\n",
      "    estimated cycle offset [y x] = [-4. -1.]\n",
      "    assembling thumbnail 1/1\n",
      "    assembling thumbnail 1/1\n",
      "    estimated cycle offset [y x] = [17. 12.]\n",
      "    assembling thumbnail 1/1\n",
      "    estimated cycle offset [y x] = [  2. -15.]\n",
      "    assembling thumbnail 1/1\n",
      "    assembling thumbnail 1/1\n",
      "    estimated cycle offset [y x] = [  0. -17.]\n",
      "    assembling thumbnail 1/1\n",
      "    estimated cycle offset [y x] = [ 1. -5.]\n",
      "    assembling thumbnail 1/1\n",
      "    assembling thumbnail 1/1\n",
      "    estimated cycle offset [y x] = [-2. 18.]\n",
      "    assembling thumbnail 1/1\n",
      "    estimated cycle offset [y x] = [-3.  2.]\n"
     ]
    }
   ],
   "source": [
    "# Loop all images\n",
    "imgs_dir = data_dir / 'batch' /'imgs' / 'raw'\n",
    "save_dir = data_dir / 'batch' /'imgs' / 'registered'\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "imgs_dir_list = os.listdir(imgs_dir)\n",
    "\n",
    "for dir_path in tqdm(imgs_dir_list):\n",
    "    \n",
    "    # Create reader for each cycle\n",
    "    readers = []\n",
    "    for i in range(1, 4):\n",
    "        reader = fileseries.FileSeriesReader(\n",
    "            str(imgs_dir / dir_path),\n",
    "            pattern='{series}_'+f'cycle{i}.tif',\n",
    "            overlap=0.29,\n",
    "            width=1,\n",
    "            height=1,\n",
    "            layout='snake',\n",
    "            direction='horizontal',\n",
    "            pixel_size=0.18872, \n",
    "        )\n",
    "        readers.append(reader)\n",
    "    reader_1 = readers[0]\n",
    "    \n",
    "    # Run stitching\n",
    "    aligner0 = reg.EdgeAligner(reader_1, channel=0, filter_sigma=2, verbose=False,)\n",
    "    aligner0.run()\n",
    "    \n",
    "    # Generate merge image for 1 cycle\n",
    "    # Parramter\n",
    "    mosaic_args = {}\n",
    "    mosaic_args['verbose'] = False\n",
    "\n",
    "    mosaic = reg.Mosaic(\n",
    "            aligner0,aligner0.mosaic_shape,**mosaic_args\n",
    "        )\n",
    "    writer_class = reg.TiffListWriter\n",
    "    writer = writer_class(\n",
    "            [mosaic], str(save_dir / (dir_path + '_cycle1_ch{channel}.ome.tif'))\n",
    "    )\n",
    "    writer.run()\n",
    "    \n",
    "    # Loop through rest of cycles\n",
    "    aligners = list()\n",
    "    aligners.append(aligner0)\n",
    "\n",
    "    for j in range(1, len(readers)):\n",
    "        aligners.append(\n",
    "            reg.LayerAligner(readers[j], aligners[0], channel=0, filter_sigma=2, verbose=False)\n",
    "        )\n",
    "        aligners[j].run()\n",
    "        mosaic = reg.Mosaic(\n",
    "            aligners[j], aligners[0].mosaic_shape,**mosaic_args\n",
    "        )\n",
    "        writer = writer_class(\n",
    "                [mosaic], str(save_dir / (dir_path +'_cycle'+str(j+1)+'_ch{channel}.ome.tif'))\n",
    "        )\n",
    "        writer.run()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cc4ee3-d60f-4a22-b7bb-7a39d5f43ca3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "602c06cb-6bc6-4e0a-ade5-fd7a15ac1193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(data_raw, marker_dict):\n",
    "    conditions = []\n",
    "    fovs = []\n",
    "    cycles = []\n",
    "    channels = []\n",
    "    markers = []\n",
    "    paths = [] \n",
    "\n",
    "    # Loop through image folder\n",
    "    for (dirpath, dirnames, filenames) in os.walk(data_raw):\n",
    "        for name in sorted(filenames):\n",
    "            if \"tif\" in name:\n",
    "                # Get information from image name\n",
    "                n_split = name.split('_')\n",
    "                                \n",
    "                cond=n_split[0]\n",
    "                fov=n_split[1]\n",
    "                cycle=n_split[2]\n",
    "                ch = n_split[3][:3]\n",
    "                try:\n",
    "                    marker = marker_dict[cycle][ch]\n",
    "                except:\n",
    "                    continue \n",
    "                    \n",
    "                conditions.append(cond)\n",
    "                fovs.append(fov)\n",
    "                cycles.append(cycle)\n",
    "                channels.append(ch)\n",
    "                markers.append(marker)\n",
    "                paths.append(os.path.join(dirpath, name))\n",
    "                \n",
    "    info = {\n",
    "            \"Condition\": conditions,\n",
    "            \"FOV\": fovs,\n",
    "            \"Cycle\": cycles,\n",
    "            \"Channels\": channels,\n",
    "            \"Markers\": markers,\n",
    "            \"Path\": paths\n",
    "        }\n",
    "\n",
    "    df = pd.DataFrame(info)\n",
    "    return df\n",
    "\n",
    "def joblib_loop(task, pics):\n",
    "    return Parallel(n_jobs=20)(delayed(task)(i) for i in pics)\n",
    "\n",
    "def read_img(path):\n",
    "    return skimage.io.imread(path, as_gray=True)\n",
    "\n",
    "def get_min(imgs):\n",
    "    shapes = np.array([np.array(img.shape) for img in imgs])\n",
    "    return np.min(shapes, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2cb2fb22-5d00-49e5-92cc-408fc15ff349",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "markers_map_new = defaultdict(dict)\n",
    "for k,v in markers_map.items():\n",
    "    for i, (ch,marker) in enumerate(v.items()):\n",
    "        markers_map_new[k][f'ch{i}'] = marker\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea513195-d9a4-431b-a9da-9225bb20b91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder is already there\n",
      "Created df\n"
     ]
    }
   ],
   "source": [
    "data_raw = data_dir  / 'batch' /'imgs' / 'registered'\n",
    "df_meta_path = data_dir /  'batch' / 'metadata' / 'info_sti.csv'\n",
    "\n",
    "try:\n",
    "    df_meta_path.parent.mkdir(parents=True, exist_ok=False)\n",
    "except FileExistsError:\n",
    "    print(\"Folder is already there\")\n",
    "\n",
    "df_exist = df_meta_path.is_file()\n",
    "\n",
    "if not df_exist:\n",
    "    print('Created df')\n",
    "    df = get_info(data_raw, markers_map_new)\n",
    "    df.to_csv(df_meta_path, index=False)\n",
    "else:\n",
    "    print('Loaded df')\n",
    "    df = pd.read_csv(df_meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffeaad3f-7a6b-4aab-9b79-2d924e168ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder is already there\n",
      "Loaded df\n"
     ]
    }
   ],
   "source": [
    "df_imgs_path = data_dir / 'batch' /'metadata' / 'imgs_reg.csv'\n",
    "\n",
    "temp_path =data_dir /  'batch' /'hdf5' / 'registered'\n",
    "try:\n",
    "    temp_path.mkdir(parents=True, exist_ok=False)\n",
    "except FileExistsError:\n",
    "    print(\"Folder is already there\")\n",
    "\n",
    "df_exist = df_imgs_path.is_file()\n",
    "\n",
    "if not df_exist:\n",
    "    print('Created df')\n",
    "    group = df.groupby(['Condition','FOV'])\n",
    "    rows = []\n",
    "\n",
    "    for name, df_group in tqdm(group, total=len(group)):\n",
    "        file_name = '_'.join(np.array(name).astype(str)) + '.hdf5'\n",
    "        file_path = temp_path / file_name\n",
    "        rows.append(list(name)+[file_path])\n",
    "        \n",
    "        # if file_path.exists():\n",
    "        #     continue\n",
    "        \n",
    "        channels = df_group.Channels.to_list()\n",
    "        cycles = df_group.Cycle.to_list()\n",
    "        markers = df_group.Markers.to_list()\n",
    "        paths = df_group.Path.to_numpy()\n",
    "            \n",
    "        imgs = joblib_loop(read_img, paths)\n",
    "        min_shape = get_min(imgs)\n",
    "        imgs_cropped = np.array([img[:min_shape[0], :min_shape[1]] for img in imgs])\n",
    "        info = {\"Cycle\": cycles, \"Channel\": channels, \"Marker\": markers}\n",
    "            \n",
    "            # hdf5 as Channel -> Z mapping\n",
    "        save_hdf5(file_path, 'imgs', imgs_cropped, info)\n",
    "    df_imgs = pd.DataFrame(rows, columns=['Condition', 'FOV', 'Path'])        \n",
    "    df_imgs.to_csv(df_imgs_path, index=False)\n",
    "else:\n",
    "    print('Loaded df')\n",
    "    df_imgs = pd.read_csv(df_imgs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0e10f8c-4dde-49fd-9c25-d9d980594fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Condition</th>\n",
       "      <th>FOV</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100nM</td>\n",
       "      <td>P10</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\batc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100nM</td>\n",
       "      <td>P21</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\batc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Control</td>\n",
       "      <td>P10</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\batc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Control</td>\n",
       "      <td>P21</td>\n",
       "      <td>Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\batc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Condition  FOV                                               Path\n",
       "0     100nM  P10  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\batc...\n",
       "1     100nM  P21  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\batc...\n",
       "2   Control  P10  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\batc...\n",
       "3   Control  P21  Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\batc..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d1b1f5-a650-41a0-99fa-a1f2792e3da5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17349912-f4a0-4d0e-a0ad-f7d82fce3678",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.exposure import match_histograms, rescale_intensity\n",
    "import cv2\n",
    "from skimage import img_as_ubyte\n",
    "import tensorflow as tf \n",
    "from skimage import exposure, util, filters, restoration\n",
    "\n",
    "def random_crop(image, NEW_IMG_HEIGHT, NEW_IMG_WIDTH):\n",
    "    cropped_image = tf.image.random_crop(\n",
    "      image, size=[3, NEW_IMG_HEIGHT, NEW_IMG_WIDTH])\n",
    "\n",
    "    return cropped_image\n",
    "\n",
    "def make_color_overlay(input_data):\n",
    "    \"\"\"Create a color overlay from 2 channel image data\n",
    "    \n",
    "    Args:\n",
    "        input_data: stack of input images\n",
    "    \n",
    "    Returns:\n",
    "        numpy.array: color-adjusted stack of overlays in RGB mode\n",
    "    \"\"\"\n",
    "    RGB_data = np.zeros(input_data.shape[:3] + (3, ), dtype='float32')\n",
    "    \n",
    "    # rescale channels to aid plotting\n",
    "    for img in range(input_data.shape[0]):\n",
    "        for channel in range(input_data.shape[-1]):\n",
    "            # get histogram for non-zero pixels\n",
    "            percentiles = np.percentile(input_data[img, :, :, channel][input_data[img, :, :, channel] > 0],\n",
    "                                            [0, 100])\n",
    "            rescaled_intensity = rescale_intensity(input_data[img, :, :, channel],\n",
    "                                                       in_range=(percentiles[0], percentiles[1]),\n",
    "                                                       out_range='float32')\n",
    "            RGB_data[img, :, :, channel + 1] = rescaled_intensity\n",
    "        \n",
    "    # create a blank array for red channel\n",
    "    return RGB_data\n",
    "\n",
    "def contrast_str(img, n_min=10, n_max=100):\n",
    "    p2, p98 = np.percentile(img, (n_min, n_max))\n",
    "    img_rescale = rescale_intensity(img, in_range=(p2, p98))\n",
    "    img_rescale = util.img_as_ubyte(img_rescale)\n",
    "    return img_rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "783f7c67-387e-428f-abb0-f29f84eb06a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_imgs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[43mdf_imgs\u001b[49m\u001b[38;5;241m.\u001b[39mitertuples(), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(df_imgs)):\n\u001b[0;32m      2\u001b[0m     path \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39mPath\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Read images\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_imgs' is not defined"
     ]
    }
   ],
   "source": [
    "for row in tqdm(df_imgs.itertuples(), total=len(df_imgs)):\n",
    "    path = row.Path\n",
    "    \n",
    "    # Read images\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        \n",
    "        markers = f['imgs'].attrs['Marker']\n",
    "        imgs = f['imgs'][:]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b91eab18-81b1-4dba-a557-1b6784fd9864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Viewer(axes=Axes(visible=False, labels=True, colored=True, dashed=False, arrows=True), camera=Camera(center=(0.0, 1731.5, 2314.0), zoom=0.36283198614318707, angles=(0.0, 0.0, 90.0), perspective=0.0, interactive=True), cursor=Cursor(position=(1.0, 1.0), scaled=True, size=1, style=<CursorStyle.STANDARD: 'standard'>), dims=Dims(ndim=2, ndisplay=2, last_used=0, range=((0.0, 3464.0, 1.0), (0.0, 4629.0, 1.0)), current_step=(1732, 2314), order=(0, 1), axis_labels=('0', '1')), grid=GridCanvas(stride=1, shape=(-1, -1), enabled=False), layers=[<Image layer 'DNA' at 0x187107a5f30>, <Image layer 'Sox2/Oct4' at 0x187079a73d0>, <Image layer 'p-P90rsk/NF-Kb' at 0x18711eedbd0>, <Image layer 'DNA [1]' at 0x18711f9c5e0>, <Image layer 'Cyclin D1/CDK4' at 0x18712025f30>, <Image layer 'Bim/Tom20' at 0x187120d0af0>, <Image layer 'DNA [2]' at 0x18712156290>, <Image layer 'Concanavalin A' at 0x187121c8790>, <Image layer 'Phalloidin' at 0x1871223e080>, <Image layer 'WGA' at 0x18712313fd0>], scale_bar=ScaleBar(visible=False, colored=False, color=array([1., 0., 1., 1.], dtype=float32), ticks=True, position=<Position.BOTTOM_RIGHT: 'bottom_right'>, font_size=10.0, box=False, box_color=array([0. , 0. , 0. , 0.6], dtype=float32), unit=None), text_overlay=TextOverlay(visible=False, color=array([0.5, 0.5, 0.5, 1. ], dtype=float32), font_size=10.0, position=<TextOverlayPosition.TOP_LEFT: 'top_left'>, text=''), overlays=Overlays(interaction_box=InteractionBox(points=None, show=False, show_handle=False, show_vertices=False, selection_box_drag=None, selection_box_final=None, transform_start=<napari.utils.transforms.transforms.Affine object at 0x00000187073955A0>, transform_drag=<napari.utils.transforms.transforms.Affine object at 0x0000018707395600>, transform_final=<napari.utils.transforms.transforms.Affine object at 0x0000018707395660>, transform=<napari.utils.transforms.transforms.Affine object at 0x00000187073956C0>, allow_new_selection=True, selected_vertex=None)), help='', status='Ready', tooltip=Tooltip(visible=False, text=''), theme='dark', title='napari', mouse_over_canvas=False, mouse_move_callbacks=[<function InteractionBoxMouseBindings.initialize_mouse_events.<locals>.mouse_move at 0x000001870F74AE60>], mouse_drag_callbacks=[<function InteractionBoxMouseBindings.initialize_mouse_events.<locals>.mouse_drag at 0x000001870F077C70>], mouse_double_click_callbacks=[], mouse_wheel_callbacks=[<function dims_scroll at 0x000001870730DA20>], _persisted_mouse_event={}, _mouse_drag_gen={}, _mouse_wheel_gen={}, keymap={'Shift': <function InteractionBoxMouseBindings.initialize_key_events.<locals>.hold_to_lock_aspect_ratio at 0x000001870F074A60>, 'Control-Shift-R': <function InteractionBoxMouseBindings._reset_active_layer_affine at 0x000001870F790310>, 'Control-Shift-A': <function InteractionBoxMouseBindings._transform_active_layer at 0x000001870F790280>})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import napari \n",
    "\n",
    "napari.view_image(np.stack(imgs), name=markers, channel_axis=0, contrast_limits=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "456cfca5-9750-428d-91c7-cbb098d29161",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imgs['FOV'] = df_imgs['FOV'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c46aa7ef-45b5-4192-8288-4754ec760b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define markers to use for cytosolic segmentation\n",
    "cyto_markers = ['Concanavalin A', 'Phalloidin']\n",
    "\n",
    "# Define folder and create if don't exsit\n",
    "whole_seg_path = data_dir / 'batch' / 'imgs' / 'segmentation'\n",
    "whole_seg_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save combined images\n",
    "for row in df_imgs.itertuples():\n",
    "    # Read image\n",
    "    path = row.Path\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        imgs = f['imgs'][:]\n",
    "        markers = f['imgs'].attrs['Marker']\n",
    "\n",
    "    # Get dapi and cyto imgaes\n",
    "    indices = np.isin(markers, cyto_markers)\n",
    "    img_dapi =  imgs[-4]\n",
    "    imgs_cyto = imgs[indices,:]\n",
    "    \n",
    "    # Contrast streching and combine to rgb image\n",
    "    img_dapi = contrast_str(img_dapi, n_max=99.9)\n",
    "        \n",
    "    imgs_cyto_scaled = []\n",
    "    for img in imgs_cyto:\n",
    "        imgs_cyto_scaled = [contrast_str(img, n_max=99.9)]\n",
    "    img_cyto = np.max(np.array(imgs_cyto_scaled), axis=0)\n",
    "    img_rgb = np.stack([np.zeros(img_dapi.shape),img_cyto, img_dapi], axis=0).astype(np.uint8)\n",
    "    \n",
    "    # Crop and save\n",
    "    file_name = f'{\"_\".join(row[1:3])}.tif'\n",
    "    file_path = whole_seg_path / file_name\n",
    "    tiff.imwrite(file_path, img_rgb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed689bd-1b41-4b03-b4eb-a1250737d729",
   "metadata": {},
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d53d0331-0e28-4b29-b3e8-8e518a20a161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> GPU activated? YES\n"
     ]
    }
   ],
   "source": [
    "from skimage import exposure, util\n",
    "from cellpose import core, utils, io, models, metrics\n",
    "\n",
    "use_GPU = core.use_gpu()\n",
    "yn = ['NO', 'YES']\n",
    "print(f'>>> GPU activated? {yn[use_GPU]}')\n",
    "\n",
    "def contrast_str(img, n_min=0.01, n_max=99.95):\n",
    "    p2, p98 = np.percentile(img, (n_min, n_max))\n",
    "    img_rescale = exposure.rescale_intensity(img, in_range=(p2, p98))\n",
    "    img_rescale = util.img_as_ubyte(img_rescale)\n",
    "    return img_rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1354ac55-e707-4dd5-b72f-5d757aaad32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_seg_path = data_dir / 'batch'/ 'imgs' / 'segmentation'\n",
    "mask_path = data_dir  / 'batch'/ 'imgs' / 'masks'\n",
    "\n",
    "mask_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b79c70-6b6c-4724-8326-75080ae0fbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cyto segmentaion\n",
    "masks = []\n",
    "for p in os.listdir(whole_seg_path):\n",
    "    img = skimage.io.imread(whole_seg_path / p).transpose((2,0,1))\n",
    "    \n",
    "    # Cyto segmentation\n",
    "    model = models.CellposeModel(gpu=True, model_type='CP')\n",
    "    mask_cyto, flows, styles = model.eval(img, \n",
    "                                  channels=[2,3],\n",
    "                                  diameter=180,\n",
    "                                  flow_threshold=0.8,\n",
    "                                  cellprob_threshold=-3\n",
    "                                  )\n",
    "    \n",
    "    file_path = mask_path / p\n",
    "    tiff.imwrite(file_path, mask_cyto)\n",
    "    \n",
    "    # Nuclei segemtnation\n",
    "    model = models.CellposeModel(gpu=True, model_type='nuclei')\n",
    "    mask_nuclei, flows, styles = model.eval(img, \n",
    "                                  channels=[3,3],\n",
    "                                  diameter=80,\n",
    "                                  flow_threshold=0.4,\n",
    "                                  )\n",
    "    \n",
    "        \n",
    "    file_path = mask_path / f'Nuclei_{p}'\n",
    "    tiff.imwrite(file_path, mask_nuclei)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20364d3-1689-4636-a9bf-e52c877fbafa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
