{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test torch geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import networkx as nx \n",
    "import pickle \n",
    "import torch_geometric \n",
    "\n",
    "data_dir = r'Y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\graphs\\raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\torch_geometric\\utils\\convert.py:249: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:264.)\n",
      "  data[key] = torch.tensor(value)\n"
     ]
    }
   ],
   "source": [
    "for f in os.listdir(data_dir):\n",
    "    with open(os.path.join(data_dir, f), 'rb') as file:\n",
    "        G = pickle.load(file)\n",
    "    data = torch_geometric.utils.from_networkx(G)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.io\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import re\n",
    "import h5py\n",
    "import napari\n",
    "import tifffile as tiff\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.utils\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_dir = (Path().cwd().parents[0]).absolute()\n",
    "\n",
    "module_path = str(p_dir / \"src\")\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = (Path().cwd().parents[0] / 'data').absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import lightning.pytorch as pl\n",
    "import PPIGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Define condition mapping\n",
    "condition_mapping = {'HCC827Ctrl': 0, 'HCC827Osim': 1}\n",
    "\n",
    "# Load graph dataset and process if neede\n",
    "graph_path = data_dir / '9PPI' / 'graphs' \n",
    "\n",
    "dataset = PPIGraph.GraphDataset(graph_path, 'raw', 'pt', condition_mapping=condition_mapping, n_c=2)\n",
    "train_set, val_set, test_set = PPIGraph.train_test_val_split(dataset)\n",
    "\n",
    "# Create Dataloader\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: GraphDataset(1491):\n",
      "======================\n",
      "Number of graphs: 1491\n",
      "Number of features: 9\n",
      "Number of classes: 2\n",
      "Train set: 716, test set: 596, val set: 179\n",
      "Step 1:\n",
      "=======\n",
      "Number of graphs in the current batch: 32\n",
      "DataBatch(edge_index=[2, 51568], pos=[8792, 2], labels=[8792, 9], nuclei=[8792], weight=[51568], condition=[32], fov=[32], id=[32], train_mask=[8792], test_mask=[8792], edge_attr=[51568, 2], x=[8792, 9], y=[32], edge_weight=[51568], name=[32], batch=[8792], ptr=[33])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print some information on the dataset\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('======================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "print(f'Train set: {len(train_set)}, test set: {len(test_set)}, val set: {len(val_set)}')\n",
    "for step, data in enumerate(train_loader):\n",
    "\n",
    "    print(f'Step {step + 1}:')\n",
    "    print('=======')\n",
    "    print(f'Number of graphs in the current batch: {data.num_graphs}')\n",
    "    print(data)\n",
    "    print()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-fold on filter dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from lightning.pytorch.accelerators import find_usable_cuda_devices\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from torch.utils.data import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out by maximum number of counts per cell\n",
    "min_count = 100\n",
    "max_count = 400\n",
    "\n",
    "graph_path = data_dir / '9PPI' / 'graphs' \n",
    "dataset = PPIGraph.GraphDataset(graph_path, 'raw', 'pt', condition_mapping=condition_mapping, n_c=2)\n",
    "\n",
    "# Create Dataloader\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Get Indices\n",
    "indices = []\n",
    "for step, data in enumerate(loader):\n",
    "    if len(data.x) <= min_count:\n",
    "        continue \n",
    "    \n",
    "    if (data.x.sum(axis=0) >= max_count).any():\n",
    "        continue\n",
    "    indices.append(step)\n",
    "    \n",
    "# Get subset dataset\n",
    "dataset_filtered = dataset.index_select(indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1368"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = '9PPI_v3'\n",
    "condition = 'Kfold'\n",
    "checkpoint_folder = (Path().cwd().parents[0]).absolute() / 'data' / '9PPI' /\"saved_models\" / dataset_name / f\"Graph_GNNs_{condition}\" \n",
    "project_name = f'PLA_10152023_{dataset_name}_{condition}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "AVAIL_GPUS = [0]\n",
    "\n",
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "NUM_LAYERS = 2\n",
    "HIDDEN_CHANNELS = 16\n",
    "pools = ['mean', 'max', 'sum', 'attention', 'attention2']\n",
    "num_layers = [2,3,4]\n",
    "hiddens = [16, 32, 64]\n",
    "\n",
    "\n",
    "epochs = 80\n",
    "model = 'GINConv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mthoomas\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_132210-osy3rq6l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/osy3rq6l' target=\"_blank\">GINConv_2_16_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/osy3rq6l' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/osy3rq6l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py:397: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA RTX A2000 12GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_16_onehot_0\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:486: PossibleUserWarning: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:438: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\utilities\\data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:438: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:281: PossibleUserWarning: The number of training batches (9) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇█▇▇██▇▇</td></tr><tr><td>train_auc</td><td>▁▄▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇██████████</td></tr><tr><td>train_f1</td><td>▁▄▅▆▆▆▇▇▆▇▇▇▇▇▆█▇▇▇▇▇▇▇▆▆▇▆▇▇█▇█▇█▇▇██▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▃▄▃▃▂▃▃▃▂▂▂▂▃▃▂▂▂▂▂▂▂▂▁▂▂▂▁▁▂▂▂▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>▆█▆▅▂▃▆▄▆▃▅▂▅▄▅▃▃▄▃▅▅▂▄▂▂▄▂▃▅▅▄▁▂▆▃▃▂▄▁▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▃▅▅▅▅▅▅▄▅▄▄▆▆▆▅▆▆▆▆▆▃▇▅▄▇▅▆▆█▇▇▆▇█▇███</td></tr><tr><td>val_auc</td><td>▁▃▅▅▅▅▅▆▆▇▆▆▆▇▇▇▆▇▇▇▇▇▆▇▇▇▇▇▆▇█▇█▆██▇███</td></tr><tr><td>val_f1</td><td>▁▄▃▆▆▆▆▇▇█▇█▅▇█▇▆▇▇▇▇█▄█▆▅▇▆▇██▇█▇▇█▇█▇█</td></tr><tr><td>val_loss_epoch</td><td>▄▃▅▅▃▂▂▂▂▄▁█▄▂▁▂▆▂▂▃▃▁█▃▆▃▃▅▂▃▂▃▄▂▂▃▁▂▃▁</td></tr><tr><td>val_loss_step</td><td>▄▃▄▃▃▃▃▃▃▂▂▃▃▃▃▁▄▃▃▂▂▂▂▃▂▃▃▅▃▅█▂▁▃▂▁▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77788</td></tr><tr><td>train_auc</td><td>0.83439</td></tr><tr><td>train_f1</td><td>0.70617</td></tr><tr><td>train_loss_epoch</td><td>0.49395</td></tr><tr><td>train_loss_step</td><td>0.48606</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.74453</td></tr><tr><td>val_auc</td><td>0.77403</td></tr><tr><td>val_f1</td><td>0.66019</td></tr><tr><td>val_loss_epoch</td><td>0.55039</td></tr><tr><td>val_loss_step</td><td>0.53447</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/osy3rq6l' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/osy3rq6l</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_132210-osy3rq6l\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b09b1011d32435691a04e279635ff89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666592937, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_134254-id8yc1oo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/id8yc1oo' target=\"_blank\">GINConv_2_16_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/id8yc1oo' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/id8yc1oo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_16_onehot_0\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\torch_geometric\\utils\\scatter.py:93: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
      "  warnings.warn(f\"The usage of `scatter(reduce='{reduce}')` \"\n",
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▃▄▅▄▅▆▅▆▆▆▆▇▇▇▇▇▇█▇▇▇▇▇▇▇▇██▇▇▇▇▇▇▇███</td></tr><tr><td>train_auc</td><td>▁▁▁▂▃▃▄▄▄▅▅▅▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇██▇███▇▇████</td></tr><tr><td>train_f1</td><td>▄▁▁▃▅▄▅▇▅▆▆▇▇▇▇▇▇▇▇█▇▇█▇▇▇▇▇██▇▇▇██▇▇███</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▆▅▅▄▄▄▃▄▄▃▂▃▂▂▃▃▁▂▂▂▂▂▃▂▂▁▁▂▂▁▁▂▂▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>███▇▅▅▆▅▆▅▅▃▅▆▆▅▂▆▄▅▅▄▃▄▁▅▃▃▅▄▅▃▂▄▂▄▂▂▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▁▂▃▃▄▄▅▅▄▁▃▅▅▅▅▆▅▇▄▆▆▆▃▆▂▆▆▆▅▆█▆▆▃▆▇▄▇▆</td></tr><tr><td>val_auc</td><td>▁▃▄▄▅▆▆▆▅▅▅▅▆▆▇▇▇▆▇▇█▇▇▇▇▇▇▇▇▇██▇▇▇▇▇▇█▇</td></tr><tr><td>val_f1</td><td>▁▂▂▃▅▅▅▆▆▇▇▇▆▇▆██▇▇███▇████▇██████▄▆▇███</td></tr><tr><td>val_loss_epoch</td><td>▇▇▆▇▅▅▄▃▅▄▆▅▄▃▁▄▃▄▃▆▃▂▄█▄█▄▃▃▃▃▁▄▂▄▄▁▄▃▃</td></tr><tr><td>val_loss_step</td><td>▇▆▆▆▆▅▆▅▅▅▇▆▅▅▄▄▆▆▆▄▃▂▄▆▃▅▄▅▄▅▄▃▃█▄▂▄▂▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.75686</td></tr><tr><td>train_auc</td><td>0.80868</td></tr><tr><td>train_f1</td><td>0.69495</td></tr><tr><td>train_loss_epoch</td><td>0.52139</td></tr><tr><td>train_loss_step</td><td>0.46833</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.70803</td></tr><tr><td>val_auc</td><td>0.75507</td></tr><tr><td>val_f1</td><td>0.67213</td></tr><tr><td>val_loss_epoch</td><td>0.57704</td></tr><tr><td>val_loss_step</td><td>0.5287</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/id8yc1oo' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/id8yc1oo</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_134254-id8yc1oo\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_135535-efzrgg2b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/efzrgg2b' target=\"_blank\">GINConv_2_16_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/efzrgg2b' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/efzrgg2b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_16_onehot_0\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c91706f85b7445828fed30f067203246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▂▁▃▄▅▆▅▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇█▇▇▇▇██▇▇██▇▇▇████</td></tr><tr><td>train_auc</td><td>▂▁▁▄▄▅▅▇▆▆▇▆▆▅▅▅▆▅▇▇▆▅▇▇▇▇▇▇▇▆▆▇▇▆▇▇██▆▇</td></tr><tr><td>train_f1</td><td>▃▁▁▂▂▄▄▅▃▄▄▄▄▆▅▆▄▆▆▇▆▇▇▆▇▆▆██▇▇▇██▇▇▇█▇█</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▁▂▃▃▄▄▅▄▅▄▄▄▄▅▄▅▄▄▅▅▅▅▅▅▅▅▅▇▅▇▆▅▅▇▇▂▆▅█</td></tr><tr><td>val_auc</td><td>▄▁▄▆▆▇▆▇▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇█▇▇▇██▇█▇█</td></tr><tr><td>val_f1</td><td>▁▁▄▄▅▅▅▆▅▆▅▆▆▆▆▆▆▆▆▇▆▇▇▅▇▆▇▇▇▇▇▆▇▇█▇█▇▅█</td></tr><tr><td>val_loss_epoch</td><td>█▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁</td></tr><tr><td>val_loss_step</td><td>█▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.73766</td></tr><tr><td>train_auc</td><td>0.66313</td></tr><tr><td>train_f1</td><td>0.68565</td></tr><tr><td>train_loss_epoch</td><td>0.58176</td></tr><tr><td>train_loss_step</td><td>0.63486</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.69708</td></tr><tr><td>val_auc</td><td>0.74019</td></tr><tr><td>val_f1</td><td>0.62443</td></tr><tr><td>val_loss_epoch</td><td>0.60834</td></tr><tr><td>val_loss_step</td><td>0.61367</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/efzrgg2b' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/efzrgg2b</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_135535-efzrgg2b\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_140719-ro4fh76y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ro4fh76y' target=\"_blank\">GINConv_2_16_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ro4fh76y' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ro4fh76y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\torch_geometric\\deprecation.py:22: UserWarning: 'nn.glob.GlobalAttention' is deprecated, use 'nn.aggr.AttentionalAggregation' instead\n",
      "  warnings.warn(out)\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_16_onehot_0\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.1 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f91e914f99a948588d4a1af21c234edc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇▇█▇▇█▇██▇██▇███▇</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇██▇███████</td></tr><tr><td>train_f1</td><td>▁▄▆▆▆▆▇▇▇▇▇▇▇▇▇▆▆▇▇▇▇▇█▇██▇▇█▇▇▇▇█▇▇███▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▃▅▄▃▃▃▃▃▂▃▂▂▃▂▃▃▂▃▂▃▂▃▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▄▆▆▅▅▁▃▄▅▃▃▄▅▂▄▃▅▃▆▅▂▄▃▁▄▃▁▂▃▂▂▄▃▁▃▆▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▂▅▇▆▇▇▅▆▅▇▅▆█▇▇▆▇▇▅█▆▇█▇▅▇▇▇▇▆██▇▆▆▆▅▄</td></tr><tr><td>val_auc</td><td>▁▃▅▆▆▆▆▆▅▆▆▆▅▅▇▇▇▅▆▇▆▇▆▇▇▆▅▇█▇▇▆▇▇▇▆▇▇█▆</td></tr><tr><td>val_f1</td><td>▁▂▃▆▇▇▇▇▅▆▇▇▆▆▇▇▇▆▇▇▇█▆▇▇▇▆▇▇▆▇▇█▇▇▆▆▆█▄</td></tr><tr><td>val_loss_epoch</td><td>▅▆▆▃▂▄▄▃▆▇▃▃▅█▁▂▄█▃▅▅▃▄▁▄▇▅▂▃▄▂▃▂▄▁▃▅▅▆█</td></tr><tr><td>val_loss_step</td><td>▆█▄▄▄▅▁▄▅▅▅▄▅▄▄▄▂▆▅▆▂▆▃▃▃▇▂▅▃█▄▃▄▅▇▂▁▄▇▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77239</td></tr><tr><td>train_auc</td><td>0.84638</td></tr><tr><td>train_f1</td><td>0.70392</td></tr><tr><td>train_loss_epoch</td><td>0.47481</td></tr><tr><td>train_loss_step</td><td>0.42247</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.66788</td></tr><tr><td>val_auc</td><td>0.74245</td></tr><tr><td>val_f1</td><td>0.37241</td></tr><tr><td>val_loss_epoch</td><td>0.73594</td></tr><tr><td>val_loss_step</td><td>0.56512</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ro4fh76y' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ro4fh76y</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_140719-ro4fh76y\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a97b45f04e4b17acf1445050b27eca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_141914-ax1li46g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ax1li46g' target=\"_blank\">GINConv_2_16_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ax1li46g' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ax1li46g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_16_onehot_0\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.1 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "1.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.5 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "144d1fd227a640e3a2f0b4f9a0a38021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇██▇███▇█████▇█</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇███▇█▇█▇█▇██▇██████</td></tr><tr><td>train_f1</td><td>▁▁▅▆▆▇▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇█▇█▇▆▇▇▇██▇▇████▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▄▃▃▃▃▃▂▃▃▂▂▃▃▂▂▂▂▂▁▁▂▂▂▂▁▂▂▂▁▂▂▁▂▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▆▅▇▇▆▄▃▅▄▆▄▅▄▄▂▃▃▄▃▃▆▃▄▆▃▄▄▆▆▁▃▄▄▃▂▅▄▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▂▄▅▅▄▅▅▆▂▇▅▃▆▄▆▇▇▆▆▆▆▇▆▅▆▅▇▇▆▆▇▆▆▅▇▇█▇</td></tr><tr><td>val_auc</td><td>▁▄▆▆▆▆▇▆▆▇▆▇▇▆▇▆▇▇▇▇▇▆▆▇▆▆▇▇██▆▇▇▇▇▆▇▇██</td></tr><tr><td>val_f1</td><td>▁▂▂▅▇██▆▆▇██▆▄▇▅▆▇█▇█▇▇▇▇▆▇▆█▇▇▇▇▇▇▅█▇█▇</td></tr><tr><td>val_loss_epoch</td><td>▅▄▄▅▄▃▂▄▃▂▄▂▄▆▂▄▅▃▃▄▂▃▁▂▄▇▃▅▂▂▂▃▁▂▃█▁▂▃▁</td></tr><tr><td>val_loss_step</td><td>▅▅█▅▅▄▃▃▄▃▄▃▃█▅▇▄▃▃▅▁▄▄▃▂▃▃▃▃▃▃▄▃▆▃▄▃▆▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.78428</td></tr><tr><td>train_auc</td><td>0.84817</td></tr><tr><td>train_f1</td><td>0.71905</td></tr><tr><td>train_loss_epoch</td><td>0.47616</td></tr><tr><td>train_loss_step</td><td>0.45493</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.71533</td></tr><tr><td>val_auc</td><td>0.75843</td></tr><tr><td>val_f1</td><td>0.60204</td></tr><tr><td>val_loss_epoch</td><td>0.55311</td></tr><tr><td>val_loss_step</td><td>0.47648</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ax1li46g' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ax1li46g</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_141914-ax1li46g\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_143313-s90ioyt8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/s90ioyt8' target=\"_blank\">GINConv_2_32_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/s90ioyt8' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/s90ioyt8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_32_onehot_0\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 3.7 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "4.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.2 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c6d167f0d9442a89f1aab45a9671e1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇█▇▇████▇████████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇█▇▇██▇▇██▇██▇████████</td></tr><tr><td>train_f1</td><td>▁▅▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████▇█▇▇▇█▇███▇██████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▄▄▄▃▄▃▃▃▃▃▃▂▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂▁▂▂</td></tr><tr><td>train_loss_step</td><td>█▅▆▅▄▄▇▄▇▄▆▄▆▄▃▆▂▃▅▃▄▅▃▅▃▆▃▅▅▃▄▅▄▂▅▂▅▁▂▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▂▃▄▆▆▇▆█▂▆▆▇▄▆▇▃█▄▇▂▁▆▄▆▅▅▆█▇▇██▇▇▆▇█▃█▇</td></tr><tr><td>val_auc</td><td>▁▄▄▅▆▆▅▇▆▆▆▆▆▅▆▅▇▆▇▇▇▆▅▆▆▆▇▇█▇▆▆▆▇▆▇▇▄▇▆</td></tr><tr><td>val_f1</td><td>▁▃▄▆▇█▇███▇██▆▆▃██████▄▆█▅▆█▇▇██▇▆▆▇█▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>▄█▅▄▃▃▅▂▆▃▂▄▄▄▆█▁▃▁▅▆▃▃▇▄▅▄▄▂▂▂▃▄▅▇▃▄▆▃▂</td></tr><tr><td>val_loss_step</td><td>▅▆▆▅▄▄▄▅▅▅▅▄▆▆▆█▄▅▆▅▆▄▅▄▅▄▅▇▄▄▄▅▄▄▅▄▄▄▅▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.79799</td></tr><tr><td>train_auc</td><td>0.86251</td></tr><tr><td>train_f1</td><td>0.73969</td></tr><tr><td>train_loss_epoch</td><td>0.4627</td></tr><tr><td>train_loss_step</td><td>0.53501</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.69708</td></tr><tr><td>val_auc</td><td>0.73567</td></tr><tr><td>val_f1</td><td>0.56995</td></tr><tr><td>val_loss_epoch</td><td>0.56585</td></tr><tr><td>val_loss_step</td><td>0.4016</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/s90ioyt8' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/s90ioyt8</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_143313-s90ioyt8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_144441-ha9d894z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ha9d894z' target=\"_blank\">GINConv_2_32_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ha9d894z' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ha9d894z</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_32_onehot_0\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 3.7 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "4.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.2 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇</td></tr><tr><td>train_auc</td><td>▁▃▄▄▄▅▆▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇██████████</td></tr><tr><td>train_f1</td><td>▂▁▄▆▅▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇█▇██</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▄▃▄▃▃▃▃▂▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▂▁▂</td></tr><tr><td>train_loss_step</td><td>█▆▅▅▆▄▆▄▆▅▄▄▅▃▃▅▂▃▃▄▄▆▂▄▃▄▃▄▅▄▃▅▄▂▄▂▃▁▁▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▆▆▆▆▇▇▆▆▇█▇▇▆▇▆█▇▇▇▇██▅▇██▇▇▆▇▇█▇██▇██▇</td></tr><tr><td>val_auc</td><td>▁▄▆▅▅█▇▆█▇▇█▇▇▇▇▇▇▇█▇███▇█▇▇▇▇▇▇█▇▇█▇▇▇▇</td></tr><tr><td>val_f1</td><td>▆▂▁▃▄▆▄▁▇▇█▇▆▇▇▇▇▇▇▄▇██▇▇▇▇█▄▇▅▆█▇▇▇▅▅▇▃</td></tr><tr><td>val_loss_epoch</td><td>█▆▅▅▅▄▅▄▇▄▃▅▃█▅▅▂▅▃▅▃▃▁█▄▃▃▅▄▃▃▃▃▅▅▃▃▅▄▄</td></tr><tr><td>val_loss_step</td><td>█▆▅▆▅▄▅▆▆▅▄▅▅▆▅▄▅▆▅▅▄▄▄▄▅▄▄▅▆▅█▇▄▅▅▃▅▃▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.76965</td></tr><tr><td>train_auc</td><td>0.8246</td></tr><tr><td>train_f1</td><td>0.71429</td></tr><tr><td>train_loss_epoch</td><td>0.49554</td></tr><tr><td>train_loss_step</td><td>0.53095</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.67153</td></tr><tr><td>val_auc</td><td>0.73661</td></tr><tr><td>val_f1</td><td>0.42308</td></tr><tr><td>val_loss_epoch</td><td>0.59049</td></tr><tr><td>val_loss_step</td><td>0.44767</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ha9d894z' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ha9d894z</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_144441-ha9d894z\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_145738-9159mv7r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/9159mv7r' target=\"_blank\">GINConv_2_32_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/9159mv7r' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/9159mv7r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_32_onehot_0\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 3.7 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "4.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.2 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▁▃▅▅▅▅▆▅▇▆▆▆▆▆▆▇▇▇▆▇▇▇▇▆▇█▆▇▇▇▇▇▇███▇▇</td></tr><tr><td>train_auc</td><td>▆▅▂▆▆▅▅▅▅▇▅▅▅▆▃▆▅▇█▅▃▂▂▄▃▁▂▂▂▃▇▅▆▄▅▂▂▃▁▂</td></tr><tr><td>train_f1</td><td>▁▃▂▅▅▆▆▆▆▅▇▆▆▆▅▆▇▇▇▇▇▇▇▇▇▆█▇▇▇█▇▇▇▇███▇█</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▃▄▅▄▅▅▆▅▅▄▆▆▆▅▅▇▅▇▅▇▇▆▆▅▅█▆▅▇▆▆▇██▇█▄▆</td></tr><tr><td>val_auc</td><td>█▂▇▇▇▇▇██▆▇▇▇▇▅▆██▇▇▆█▆▇▅▅▄▃▅▆▇▇▇▆▃▂▁▃▅▂</td></tr><tr><td>val_f1</td><td>▁▃▄▆▆▇▇▇▇▇▇▇▇▇▇▇▆▇█▇▇▇██▇▇▇█▇▇▇▇▇█████▅▇</td></tr><tr><td>val_loss_epoch</td><td>██▃▂▂▂▂▁▂▂▁▂▂▂▂▂▂▁▁▂▁▁▁▂▁▂▁▁▂▁▂▁▂▂▂▁▁▂▂▁</td></tr><tr><td>val_loss_step</td><td>█▄▃▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▁▂▂▂▂▁▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.74589</td></tr><tr><td>train_auc</td><td>0.49389</td></tr><tr><td>train_f1</td><td>0.68973</td></tr><tr><td>train_loss_epoch</td><td>0.548</td></tr><tr><td>train_loss_step</td><td>0.63798</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.67883</td></tr><tr><td>val_auc</td><td>0.44924</td></tr><tr><td>val_f1</td><td>0.52174</td></tr><tr><td>val_loss_epoch</td><td>0.56005</td></tr><tr><td>val_loss_step</td><td>0.43178</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/9159mv7r' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/9159mv7r</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_145738-9159mv7r\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_151235-53f5swlc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/53f5swlc' target=\"_blank\">GINConv_2_32_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/53f5swlc' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/53f5swlc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_32_onehot_0\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 3.7 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "4.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.3 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▆▆▇▇▇▇▇▇▇▆▇▇▇▇▇█▇▇▇█▇▇▇▇▇▇█████▇███</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇███████████</td></tr><tr><td>train_f1</td><td>▁▅▅▆▆▆▅▆▇▆▆▇▆▇▆▆▆▇▇▇▇▇▇▆█▇▇▇▇▇▇▇▇███▇███</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▃▃▃▃▃▃▃▃▃▃▃▃▃▂▂▃▂▂▂▁▃▂▂▂▂▂▁▁▁▁▂▂▂▂▁</td></tr><tr><td>train_loss_step</td><td>███▄▆▃▅▄▄▄█▄▄▇▄▄▅▅▄▃▄▅▅▆▃▂▃▃▆▃▄▁▃▃▄▄▃▄▃▆</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▄▅▅▅▇▇▆▇▆▇▆▇▇█▃▇▆▆▇▇█▆█▅█▆▅▆▆▇▆▇▅▅▆█▇▄</td></tr><tr><td>val_auc</td><td>▁▄▄▅▅▅▇▇▇██▇█▇▇██▆▇█▇▇█▆▇▅▇▇▆▇▅▇▆▇▆▇▅▇▅▇</td></tr><tr><td>val_f1</td><td>▁▃▅▆▆▆▇▇▇▇█▇█▇▇██▇▆█▇█▇▇▇▆▇▇▅▆▆▇█▇▆█▆█▇█</td></tr><tr><td>val_loss_epoch</td><td>▃▃▄▆▃▁▂▂▃▁▅▁▂▃▂▂▂▂▅▄▂▂▃▂▂▃▄▂█▂▁▃▂▁▃▂▃▂▂▃</td></tr><tr><td>val_loss_step</td><td>▅█▄▄▃▄▁▁▄▃▂▃▃▄▂▃▄▄▃▅▇▃▁▃▄▃▂█▂▃▃█▃▃▃▆█▅▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.80073</td></tr><tr><td>train_auc</td><td>0.85951</td></tr><tr><td>train_f1</td><td>0.74651</td></tr><tr><td>train_loss_epoch</td><td>0.45972</td></tr><tr><td>train_loss_step</td><td>0.55918</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.66423</td></tr><tr><td>val_auc</td><td>0.75358</td></tr><tr><td>val_f1</td><td>0.64341</td></tr><tr><td>val_loss_epoch</td><td>0.62044</td></tr><tr><td>val_loss_step</td><td>0.55003</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/53f5swlc' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/53f5swlc</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_151235-53f5swlc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_152920-e4hw8mxf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/e4hw8mxf' target=\"_blank\">GINConv_2_32_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/e4hw8mxf' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/e4hw8mxf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_32_onehot_0\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 3.7 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "5.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.3 K     Total params\n",
      "0.021     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▅▅▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇▇█▇▇█▇▇█▇██▇▇█</td></tr><tr><td>train_auc</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇▇█▇▇██████████</td></tr><tr><td>train_f1</td><td>▁▆▆▆▇▇▇▇▇▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇█▇█▇▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▅▃▃▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▃▃▂▂▃▂▁▁▂▁▂▁▂▂▂▂</td></tr><tr><td>train_loss_step</td><td>█▇▇▆▅▇▆▄▇█▅▅▃▅▂▃▃▆▆▆▄▃▃▇▄▄▆▂▅▄▃▃▁▃▄▂▃▂▃▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▃▃▄▆▆▆▄▅▄▆▆▇▄▆▇▇▅▇▆▇▇▇▄▁▇▇▆▇▆▆█▆▆▃▇▆▄▅▆█</td></tr><tr><td>val_auc</td><td>▁▃▅▆▅▆▄▅▇▆▆▇▇▇▅▇▇▄▇▆▇▆▅▆▇█▅▇▆█▇▃▆▇▇▅▂▆▇█</td></tr><tr><td>val_f1</td><td>▁▁▃▇▆▇▃▄█▆▇▇█▅▆▇█▇█▇▇▇▂▇▆▇▇█▅██▅▆█▆▇▄▅▅█</td></tr><tr><td>val_loss_epoch</td><td>▃▇▅▁▂▄▃▄▄▂▅▁▄▄▁▃▃▃▂▂▂▃█▄▃▁▂▄▆▃▄▆▃▆▄▂█▆▂▃</td></tr><tr><td>val_loss_step</td><td>▃▆▆▂▃▃▆▅▄▂▁▄▃▄▃▄▁▂▄▁▃█▃▄▃▂▇▅▂▄▃▃▃▆▄▃▃▂▅▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.80622</td></tr><tr><td>train_auc</td><td>0.85326</td></tr><tr><td>train_f1</td><td>0.75964</td></tr><tr><td>train_loss_epoch</td><td>0.46837</td></tr><tr><td>train_loss_step</td><td>0.49034</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.72628</td></tr><tr><td>val_auc</td><td>0.75143</td></tr><tr><td>val_f1</td><td>0.64115</td></tr><tr><td>val_loss_epoch</td><td>0.61348</td></tr><tr><td>val_loss_step</td><td>0.66165</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/e4hw8mxf' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/e4hw8mxf</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_152920-e4hw8mxf\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_154441-hderrawj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/hderrawj' target=\"_blank\">GINConv_2_64_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/hderrawj' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/hderrawj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_64_onehot_0\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 13.5 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.7 K    Total params\n",
      "0.063     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29afbca07ce54951a79c10e39d7c80d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▅▆▅▆▆▆▆▆▆▆▆▆▆▇▆▇▇▇▆▇▆▇▇▇▇█▇██▇█▇█▇█▇█</td></tr><tr><td>train_auc</td><td>▁▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇███████</td></tr><tr><td>train_f1</td><td>▁▆▆▆▇▆▇▇▇▇▇▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇██▇██▇█▇█▇███</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▅▄▅▄▄▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▃▂▂▁▂▂▂▂▂▂▁▂▂</td></tr><tr><td>train_loss_step</td><td>█▆█▆▆█▆▅█▅▅▄▅█▆▇▅▇▅▅▆▅▃▅▄▆▅▄▅▆▆▆▄▅▄▂▄▅▄▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▃▃▆▃▇▇▇▆▆▆▆▅▇▆▆▆▇▄▃▆▇█▁▆▇█▅▆▃▇▃▆▆▆▇▇▅▆▇▄</td></tr><tr><td>val_auc</td><td>▁▃▅▆▆▇▇▃▅▅▄▃▆▆▇▄▆▆▇▆█▇▆▅▆▇█▇▆▆▆▃▄▅▆▆▇▆█▇</td></tr><tr><td>val_f1</td><td>▁▂▇██▇▇▇▇▇▇▅▇▇█▇█▃█▆▇██▇▇██▆█▆█▆▆▇▇█▅██▄</td></tr><tr><td>val_loss_epoch</td><td>▅▄▁▃▂▂▁▃▃▂▃▃▂▂▂▃▂█▃▂▁▁▃▃▂▁▃▅▄▃▃▂▃▃▂▂▅▂▂▃</td></tr><tr><td>val_loss_step</td><td>▆▇▂▂▂▁▂▁▃▂▂▄▂▂▁▂▃▆▃▃▂▂▅▄▃▃▃▂█▂▇▄▇▃▁▃▃▃▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.81444</td></tr><tr><td>train_auc</td><td>0.87938</td></tr><tr><td>train_f1</td><td>0.77217</td></tr><tr><td>train_loss_epoch</td><td>0.42896</td></tr><tr><td>train_loss_step</td><td>0.33087</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.64964</td></tr><tr><td>val_auc</td><td>0.7398</td></tr><tr><td>val_f1</td><td>0.37662</td></tr><tr><td>val_loss_epoch</td><td>0.73436</td></tr><tr><td>val_loss_step</td><td>0.79614</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/hderrawj' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/hderrawj</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_154441-hderrawj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "840e2cddb7114d7daa75bb2ba566acb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_155829-nrnqthx6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/nrnqthx6' target=\"_blank\">GINConv_2_64_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/nrnqthx6' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/nrnqthx6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_64_onehot_0\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 13.5 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.7 K    Total params\n",
      "0.063     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▅▆▆▅▆▆▇▇▆▇▇▆▇▇▇▇▇▇▇█▇▇▇▇▆▇████▇▇█▇█▇▇</td></tr><tr><td>train_auc</td><td>▁▄▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇█▇▇███████████</td></tr><tr><td>train_f1</td><td>▂▁▅▆▆▇▆▆▇▇▇▆▇▇▆▇▇▇▇▇▇▇█▇▇▇▇▇▇▇███▇██▇███</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▃▄▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▁▂▂▂▂▃▂▁▂▁▁▂▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>██▇▆▆▆▅▅▆▅▄▂▄▅▆▅▃▅▄▃▄▃▃▄▃▅▄▅▃▄▅▄▁▅▃▂▃▃▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▂▄▆▄▃▄▆▇▆▆▇▇▇▇▅▅▆▇█▇▇█▆▅▆▆▆▅▆▇▆▂▇▆▆▆▇▄</td></tr><tr><td>val_auc</td><td>▁▃▅▄▆▆▇▆▇▇▆▆▆▆▇▇▆▇▆▇█▆▇█▆▇▇▇▇▇▇▇▇▆▇▇█▇▇█</td></tr><tr><td>val_f1</td><td>▁▃▃▆██▄█▆█▇▇█▇▇▇█▆▇██▆▇██▅█▆██▆▇▇▇▇█▆▇▇█</td></tr><tr><td>val_loss_epoch</td><td>█▅▄▄▅▅▃▅▂▄▅▄▃▇▂▆▇▄▃▂▁▃▃▄▅▆▅█▅▅▇▁▂█▃▄▄▆▄▅</td></tr><tr><td>val_loss_step</td><td>▇▆█▄▅█▆▆▅▄▃▅▆▄▂▄▆▁▅▅▄▃▂▃▃█▇▂▆▃▃▅▄▄▃▃▁▅▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.78519</td></tr><tr><td>train_auc</td><td>0.85631</td></tr><tr><td>train_f1</td><td>0.73446</td></tr><tr><td>train_loss_epoch</td><td>0.45739</td></tr><tr><td>train_loss_step</td><td>0.3692</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.67518</td></tr><tr><td>val_auc</td><td>0.79977</td></tr><tr><td>val_f1</td><td>0.68551</td></tr><tr><td>val_loss_epoch</td><td>0.62756</td></tr><tr><td>val_loss_step</td><td>0.53739</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/nrnqthx6' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/nrnqthx6</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_155829-nrnqthx6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_161113-2uvzivow</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/2uvzivow' target=\"_blank\">GINConv_2_64_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/2uvzivow' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/2uvzivow</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_64_onehot_0\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 13.5 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.7 K    Total params\n",
      "0.063     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▂▁▃▄▄▄▅▆▅▆▆▆▆▆▆▆▇▇▇▇▇▆▆▆▇▇▇▇▆▇▇▇█▇▇▇▇██▇</td></tr><tr><td>train_auc</td><td>▄▅▂▃▃▃▄▄▃▂▂▃▃▁▃▃▂▂▄▆▅▄▅▅▅▄▅▄▆▅█▇▆▆▆▅▄▃▅▄</td></tr><tr><td>train_f1</td><td>▁▂▂▃▅▄▅▅▅▆▆▅▅▆▆▆▆▇▇▆▇▇▇▇▇▆▇▇▆▇▇██▇▇█▇██▇</td></tr><tr><td>train_loss_epoch</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▄▁▇▂▅▃▅▅▄▅▆▇▅▄▅▃▇▇▇▆▅▅▇▆▅▆▆▄▇▆▇▆█▆▆▅█▇</td></tr><tr><td>val_auc</td><td>▇█▅▅▄▅▅▄▁▂▂▃▃▂▄▁▂▁▆▆▇▆▇▆▆▄▃▆▆▅▇▇▆▆▆▄▅▁▆▇</td></tr><tr><td>val_f1</td><td>▁▂▅▂▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇█▆▇█▇▆▇▇▇▆▆▇▇▆</td></tr><tr><td>val_loss_epoch</td><td>█▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▆▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.72761</td></tr><tr><td>train_auc</td><td>0.60515</td></tr><tr><td>train_f1</td><td>0.68094</td></tr><tr><td>train_loss_epoch</td><td>0.57974</td></tr><tr><td>train_loss_step</td><td>0.76175</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.69343</td></tr><tr><td>val_auc</td><td>0.71737</td></tr><tr><td>val_f1</td><td>0.52809</td></tr><tr><td>val_loss_epoch</td><td>0.70482</td></tr><tr><td>val_loss_step</td><td>0.69695</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/2uvzivow' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/2uvzivow</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_161113-2uvzivow\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aeb2b1d1704455eacd19d4c4e30be51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_162250-ddo09t02</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ddo09t02' target=\"_blank\">GINConv_2_64_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ddo09t02' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ddo09t02</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_64_onehot_0\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 13.5 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "15.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.7 K    Total params\n",
      "0.063     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▅▅▅▅▆▆▅▆▅▆▅▆▆▆▆▆▇▆▇▆▇▆▇▇▆▇▇▇█▇▇██▇▇▇</td></tr><tr><td>train_auc</td><td>▁▄▅▅▆▆▆▆▆▇▆▇▆▇▆▇▇▆▇▇▇▇▇▇▇▆▇▇▇█▇▇██▇███▇█</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▆▆▇▇▆▇▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇███▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▄▄▄▄▃▄▃▄▃▄▃▄▃▃▃▃▃▃▃▂▃▃▂▃▂▂▂▁▁▂▁▁▂▂▂</td></tr><tr><td>train_loss_step</td><td>▅▆▅▅█▅▃▅▂▄▄▂▃▃▄▄▄▄▄▂▄▃▃▇▄▁▂▂▃▂▅▁▄▁▁▄▂▂▃▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▁▄▃▆▄▆▅▃▆▆▆▆▄▄▅▇▆▆▆▇▆▆▆▆▆▆█▅▇▁▄▇▇█▅▆▃▇▇</td></tr><tr><td>val_auc</td><td>▁▃▄▆▇▅█▅▇▆█▇▇▇▄▆▇▇█▇▆▆▇▆██▇▇▅▇▆█▇▇█▇▆▅▇▆</td></tr><tr><td>val_f1</td><td>▁▂▇▇▇▅█▅█▇█▇▆▅▅▆█▆█▇▇▆▇▇█▆▇▇▅▇▇█▇▇█▇▇▄▇▇</td></tr><tr><td>val_loss_epoch</td><td>▅█▂▂▂▃▃▃▃▂▄▂▂▄▄▄▁▂▃▃▂▃▃▁▃▃▃▁▅▄▃▃▃▃▂▄▃█▃▃</td></tr><tr><td>val_loss_step</td><td>██▃▂▂▄▂▃▅▃▂▂▂▆▇▃▃▃▄▇▅▂▄▁▆▁▄▂▁▃▆▅▂▅▅▂▅▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.81353</td></tr><tr><td>train_auc</td><td>0.88018</td></tr><tr><td>train_f1</td><td>0.76443</td></tr><tr><td>train_loss_epoch</td><td>0.42775</td></tr><tr><td>train_loss_step</td><td>0.51464</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.73358</td></tr><tr><td>val_auc</td><td>0.757</td></tr><tr><td>val_f1</td><td>0.66359</td></tr><tr><td>val_loss_epoch</td><td>0.59437</td></tr><tr><td>val_loss_step</td><td>0.56937</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ddo09t02' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ddo09t02</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_162250-ddo09t02\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_163548-t0o98xir</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/t0o98xir' target=\"_blank\">GINConv_2_64_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/t0o98xir' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/t0o98xir</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_64_onehot_0\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 13.5 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "19.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "19.8 K    Total params\n",
      "0.079     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▆▅▆▆▆▆▆▆▆▇▆▇▇▇▆▇▇▇▇▇▆▇▇▇▆▇▇▇▇▇▇▇██▇█</td></tr><tr><td>train_auc</td><td>▁▅▅▅▆▆▆▆▆▆▆▇▆▇▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇█</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▆▇▆▇▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▅▄▄▄▄▄▃▄▃▄▃▃▃▄▃▃▃▃▃▃▃▃▂▃▃▂▃▂▃▃▂▂▁▃▁</td></tr><tr><td>train_loss_step</td><td>▆█▇▇▅▅▅▅▇█▇▅▅▆▅▃▅▃▄▄▁▄▅▄▆▃▂▆▅▄▅▅▂▆▅▆▄▃▄▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▄▅▂▄▆▆▄▅▅▅▇▄▆▅▆▃▂▃▆▆▆▆▅▆▅█▆▆▆▅▇▆▆▆▃▇▃▅</td></tr><tr><td>val_auc</td><td>▁▃▃▅▄▄▄▅▅▅▄▅▇▇▆▆▆▆▇▆▆▇▅▆▇▆▅█▇▆██▇▇▆▆▇▆▄▅</td></tr><tr><td>val_f1</td><td>▁▄▅▇▇▅▇▇▇▅▆▇▇██▇█▇▃▇▇▇▆▇█▇██▆▇▇██▆▆█▇▇▄▇</td></tr><tr><td>val_loss_epoch</td><td>█▅▆▂▃▃▂▃▅▄▅▂▂▃▂▁▃▂▆▃▄▁▃▃▄▂▃▁▃▁▃▂▃▆▆▂▃▄▆▂</td></tr><tr><td>val_loss_step</td><td>▇▆▄▄▅█▄▂▄▃▅▄▃▄▄▂▂▅▅▄▅▅▂▄▄▄▄▇▆▄▅▄▄▅▆▄▃▄▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.81718</td></tr><tr><td>train_auc</td><td>0.88361</td></tr><tr><td>train_f1</td><td>0.77827</td></tr><tr><td>train_loss_epoch</td><td>0.4189</td></tr><tr><td>train_loss_step</td><td>0.39823</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.68978</td></tr><tr><td>val_auc</td><td>0.72889</td></tr><tr><td>val_f1</td><td>0.64435</td></tr><tr><td>val_loss_epoch</td><td>0.61413</td></tr><tr><td>val_loss_step</td><td>0.4758</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/t0o98xir' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/t0o98xir</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_163548-t0o98xir\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d48ec7c88da341ff93aaa7aa3feb3600",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_164854-y9v6skbk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/y9v6skbk' target=\"_blank\">GINConv_3_16_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/y9v6skbk' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/y9v6skbk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_16_onehot_0\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.7 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▇▆▇▇▇▇▇▇▇▇▇▇█▇██▇▇▇█▇█▇▇▇█▇█▇█▇▇█▇███</td></tr><tr><td>train_auc</td><td>▁▅▆▇▇▇▇▇▇▇▇▇▇▇██▇▇██▇▇██▇███████████████</td></tr><tr><td>train_f1</td><td>▁▃▄▆▅▅▆▆▅▆▅▆▆▆▆▇▆▇▇▆▆▇▇▇▇▆▆▆▇▇▇▆▇▆▆▇▆▆█▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▃▃▃▃▃▂▂▂▂▃▂▂▂▂▁▂▂▃▂▂▂▂▂▂▁▂▁▂▁▂▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>██▆▄▅▆▆▂▅▄▂▆▄▆▄▄▅▂▂▆▅▃▅▄▄▃▄▆▃▄▅▄▁▂▆▄▃▁▃▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▃▄▅▅▅▅▅▆▅▇▆▇▇▆▇▆▅▆▆▇▅█▆▇▅▇▅▄▇▄▇▇▆█▇▄▅▄</td></tr><tr><td>val_auc</td><td>▁▄▄▄▅▅▅▅▆▅▆▆▆▆▆▇▆▆▇▇▇▇▆▇▇▇▆▇▆▆▇▆▇▆▇█▇▆▇▆</td></tr><tr><td>val_f1</td><td>▁▃▃▄▆▆▅▆▅▆▅▆▆▇▆▆▇▇▅▆▆▆▅██▇▅▇▇▄▇▄█▇▆█▇▅█▅</td></tr><tr><td>val_loss_epoch</td><td>▄▄▃█▃▄▃▂▄▄▅▃▅▃▆▃▆▁▃▄▄▃▂▂▃▂▄▂▄▄▂▇▂▃▄▁▂▄▃▆</td></tr><tr><td>val_loss_step</td><td>▅▄▄▆▃▄▅▆▄▄▆▃▄▃▄▄▄▃▆▃▅▂▇▅▄▃▅▄▃▃▃▂▄▁▅▄▂▄▃█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.79525</td></tr><tr><td>train_auc</td><td>0.85657</td></tr><tr><td>train_f1</td><td>0.73397</td></tr><tr><td>train_loss_epoch</td><td>0.47908</td></tr><tr><td>train_loss_step</td><td>0.5287</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.67883</td></tr><tr><td>val_auc</td><td>0.74383</td></tr><tr><td>val_f1</td><td>0.44304</td></tr><tr><td>val_loss_epoch</td><td>0.77287</td></tr><tr><td>val_loss_step</td><td>0.85963</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/y9v6skbk' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/y9v6skbk</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_164854-y9v6skbk\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_170216-sx1xcmx3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/sx1xcmx3' target=\"_blank\">GINConv_3_16_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/sx1xcmx3' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/sx1xcmx3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_16_onehot_0\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.7 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73a752942747486aa9131f35ed89000a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▅▆▆▆▇▆▆▇▇▇▇█▇▇▇█▇▇▇▇▇█████████▇███▇██</td></tr><tr><td>train_auc</td><td>▁▂▄▅▆▆▆▆▆▇▇▇▇▇█▇▇▇█▇▇▇█▇█████████▇██████</td></tr><tr><td>train_f1</td><td>▂▁▃▄▅▅▅▇▅▅▇▇▆▇▇▇▆▆▇▆▆▇▆▆▇▇▇██▇▇▇▇▆▇▇▇▇█▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▅▄▄▄▃▄▃▂▃▃▂▂▂▂▃▁▂▂▂▂▂▂▁▁▂▁▂▂▁▂▂▂▂▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▆▅▄▇▅▃█▅▁▅▄▄▃▂▃▃▃▅▃▂▂▂▄▃▁▆▂▃▄▃▂▂▅▄▂▁▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▅▆▆▅▆▆▆▇▇▇▇▇▇▆██████▇█▆▇▇▇▇▇█▇▇▅▇██▇▆▇▇</td></tr><tr><td>val_auc</td><td>▁▃▄▅▅▅▆▆▆▇▇█▇▇▆█▇▇████▇█▇▇█▇▇▇█▇█▇▇▇██▇▇</td></tr><tr><td>val_f1</td><td>▆▁▃▃▆▆▇▅▆▇▇▇▆▆▇█▇██▇██▇█▇█▇▇▇▇█▇▇▇█▇▇▇▇▆</td></tr><tr><td>val_loss_epoch</td><td>█▆▅▅▅▅▅▂▅▂▃▃▃▃█▂▄▁▂▂▄▃▁▄▂▃▂▁▅▂▂▂▆▁▃▂▃▆▂▄</td></tr><tr><td>val_loss_step</td><td>█▅▆▅▅▅▆▅▄▄▅▄▃▃▃▃▃▄▃▂▅▃▄▃▅▄▆▄▃▃▃▃▅▁▄▄▄▇▂█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.75411</td></tr><tr><td>train_auc</td><td>0.81434</td></tr><tr><td>train_f1</td><td>0.6511</td></tr><tr><td>train_loss_epoch</td><td>0.5235</td></tr><tr><td>train_loss_step</td><td>0.50041</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.72628</td></tr><tr><td>val_auc</td><td>0.76797</td></tr><tr><td>val_f1</td><td>0.58101</td></tr><tr><td>val_loss_epoch</td><td>0.61389</td></tr><tr><td>val_loss_step</td><td>0.73361</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/sx1xcmx3' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/sx1xcmx3</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_170216-sx1xcmx3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f53c2432d8a43478319caa6bb1a7144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_171420-vcd24izh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/vcd24izh' target=\"_blank\">GINConv_3_16_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/vcd24izh' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/vcd24izh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_16_onehot_0\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.7 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▂▄▄▅▄▅▅▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇██████</td></tr><tr><td>train_auc</td><td>▁▂▂▃▄▄▃▄▄▄▅▅▅▆▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇█▇▇▇▇████</td></tr><tr><td>train_f1</td><td>▁▂▃▄▃▃▂▄▄▄▅▆▅▇▆▇▆▆▆▆▆▇▇▇▇▇▆█▇▇▇▇▇▇▇█▇▇█▇</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▂▃▃▂▂▃▄▅▅▄▆▇▅▆▇▇▆▆▇▅▅▆▅▇▇▅▇█▇▆▄█▆▆██▇▆</td></tr><tr><td>val_auc</td><td>▃▂▁▂▂▃▃▃▃▄▄▄▆▅▅▆▆▆▆▆▆▅▅▆▆▇▆▅▆▆▇▆▆▇▆▆██▇▇</td></tr><tr><td>val_f1</td><td>▁▄▆▄▅▃▄▅▆▆▆▆▆▇▆▆▇▇▆▇▇▇▇▇▇█▇▆▇▇▇▆█▇▇▆▇▇█▅</td></tr><tr><td>val_loss_epoch</td><td>█▇▃▃▂▃▂▂▂▂▂▃▂▂▃▂▃▁▁▂▂▁▂▂▂▁▂▃▃▂▂▂▅▃▃▁▁▂▁▄</td></tr><tr><td>val_loss_step</td><td>▅█▃▃▁▁▂▂▂▁▂▁▁▁▂▁▁▁▂▁▂▁▂▂▁▁▂▂▂▂▃▁▂▂▂▂▁▂▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.75229</td></tr><tr><td>train_auc</td><td>0.76298</td></tr><tr><td>train_f1</td><td>0.68525</td></tr><tr><td>train_loss_epoch</td><td>0.54074</td></tr><tr><td>train_loss_step</td><td>0.58291</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.67153</td></tr><tr><td>val_auc</td><td>0.75061</td></tr><tr><td>val_f1</td><td>0.43038</td></tr><tr><td>val_loss_epoch</td><td>0.79433</td></tr><tr><td>val_loss_step</td><td>0.79567</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/vcd24izh' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/vcd24izh</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_171420-vcd24izh\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_172704-z5llhudc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/z5llhudc' target=\"_blank\">GINConv_3_16_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/z5llhudc' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/z5llhudc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_16_onehot_0\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.7 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇▇███▇██▇████▇███████</td></tr><tr><td>train_auc</td><td>▁▄▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇███▇█████████████▇</td></tr><tr><td>train_f1</td><td>▂▁▅▆▇▆▆▇▆▆▆▇▇▆▇▆▆▅▇▇▇▇▇▇▆▇▇▇▇▇██▇█▇▇▇▇█▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▄▃▃▃▃▂▃▃▃▃▂▃▃▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▇▇▅▅▅▃▃▄▆▄▂▅▄▅▄▃▅▁▁▄▃▂▂▃▄▃▅▄▃▄▄▁▃▃▄▁▁▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▂▃▄▅▅▇▄▆▇▄▆▅▁▆▇▆▆▇▇▅▆▇▇▇▅▇▇▇▇▆▇▇▇▇▇▇█▇▆▇</td></tr><tr><td>val_auc</td><td>▁▃▅▅▆▆▅▆▆▆▇▆▇▆▇▆▆█▇▆▇▇▇▇█▇▇▇█▇███▇▇▇███▇</td></tr><tr><td>val_f1</td><td>▁▃▄▆▆▆▄▅▇▃▆█▇▆▆▆▇▇▇▅▆▇█▆█▇▇▇▇▅▇█▇▇▇▇█▇▆▇</td></tr><tr><td>val_loss_epoch</td><td>▅▄▄▄▄▂▅▄▂▄▅▄▄▃▂▃▃▃▂█▃▁▂▄▄▄▂▂▃▃▂▃▂▂▂▃▂▄▄▄</td></tr><tr><td>val_loss_step</td><td>▆▅▅▃▄▄▇█▅▇▄▅▅▅▃▄▃▂▃▄▃▂▄▃▃▃▄▄▂▄▂▄▄▁▃▄▄▄▃▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77879</td></tr><tr><td>train_auc</td><td>0.83301</td></tr><tr><td>train_f1</td><td>0.69975</td></tr><tr><td>train_loss_epoch</td><td>0.49312</td></tr><tr><td>train_loss_step</td><td>0.41739</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.72628</td></tr><tr><td>val_auc</td><td>0.76587</td></tr><tr><td>val_f1</td><td>0.59459</td></tr><tr><td>val_loss_epoch</td><td>0.65174</td></tr><tr><td>val_loss_step</td><td>0.74434</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/z5llhudc' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/z5llhudc</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_172704-z5llhudc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_174001-b1otb5fy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/b1otb5fy' target=\"_blank\">GINConv_3_16_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/b1otb5fy' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/b1otb5fy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_16_onehot_0\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.7 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "2.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇███▇█▇████▇█████▇███</td></tr><tr><td>train_auc</td><td>▁▅▆▇▇▇▇▇▇▇▇█▇▇██▇███████████████████████</td></tr><tr><td>train_f1</td><td>▁▃▆▅▆▆▆▇▆▆▆▇▇▆▇▇▇▇▆▆▇▆█▇▇▆▇▇▆▇▆▆▇▇▇▇▅▇▇▆</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▂▁▂▂▁▂▁▂▂▂▁▂▂▁▁▂▁▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>██▇▅▃▆▃▄▅▅▅▃▄▃▃▂▂▂▃▃▁▂▂▄▃▁▃▂▃▄▄▄▄▂▂▂▃▄▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▂▅▅▆▄▅▆▆▆▄▅▆▆▃▆▆▆▇█▅▆▅▆▆▇▆▆▄▄▇█▇▇▆▄▇▇▅</td></tr><tr><td>val_auc</td><td>▁▄▅▆▅▆▅▆▇▇▇▆▇▇▇██▇▆▇█▇▇▇█▇▇▇▇▆▇██▇▇▇▇▇▇▇</td></tr><tr><td>val_f1</td><td>▁▂▂▆▅▇▅▆▇▆▇▅▆▆▆█▆▇▇██▆▆▅▇▇▇▇▇▅▄▇█▇█▇▅▇▇▆</td></tr><tr><td>val_loss_epoch</td><td>▅▅█▃▅▂▇▃▃▃▁▅▄▅▃▃▃▄▃▃▂▃▄▃▄▅▅▃▃▇▄▂▂▄▁▂▇▃▃▃</td></tr><tr><td>val_loss_step</td><td>▅▄█▄▄▃▇▂▁▄▃▇▄▄▃▃▃▃▄▃▄▂▄▅▃▃▃▄▃▂▃▂▂▃▄▃▃▂▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77514</td></tr><tr><td>train_auc</td><td>0.83783</td></tr><tr><td>train_f1</td><td>0.69853</td></tr><tr><td>train_loss_epoch</td><td>0.48435</td></tr><tr><td>train_loss_step</td><td>0.4717</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.69343</td></tr><tr><td>val_auc</td><td>0.77745</td></tr><tr><td>val_f1</td><td>0.49398</td></tr><tr><td>val_loss_epoch</td><td>0.5946</td></tr><tr><td>val_loss_step</td><td>0.48488</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/b1otb5fy' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/b1otb5fy</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_174001-b1otb5fy\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_175409-f0o4zo2v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/f0o4zo2v' target=\"_blank\">GINConv_3_32_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/f0o4zo2v' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/f0o4zo2v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_32_onehot_0\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 5.9 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "6.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.5 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dcfd3180e334d2996333116c544562b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▆▆▆▆▆▇▆▆▇▆▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇█▇▇▇█▇▇▇███</td></tr><tr><td>train_auc</td><td>▁▅▅▆▆▆▆▆▇▇▆▆▇▆▇▇▇▇▇▇▆▇▇▇▇▇▇███▇▇███▇████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▆▆▇▆▆▆▇▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇██</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▅▄▄▄▄▄▄▄▄▄▄▃▃▃▄▃▄▃▃▃▃▃▂▂▂▂▃▂▂▃▂▂▂▂▁▂</td></tr><tr><td>train_loss_step</td><td>▇█▇▆▅▄▄▃▂▅▄▄▄▂▄▅▅▄▆▆▂▃▃▄▃▃▁▅▂▃▃▃▅▃▄▂▄▃▃▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▁▆▆▅▅▆▆▇▆▃▂▆▃▆▅▅▇▅▂▆█▅▅▄▄▆▇▆▆▃▇▄▅▆▇▇▄▄▇</td></tr><tr><td>val_auc</td><td>▁▃▅▅▅▅▄▅▆▆▆▆▅▅▅▅▆▇▃▅▇█▅▇▇▆▆▇▇▆▆▇▅▃▇▇▅▅▆▇</td></tr><tr><td>val_f1</td><td>▁▂▆▇▇▇▆▆▇▇█▃▆▄▆▆▅▇▆▃▆▇▅█▅▅▆▇▆▆▄▇▄▆▆█▇▅▄▇</td></tr><tr><td>val_loss_epoch</td><td>▄▆▂▁▁▃▃▃▂▂▃▃▃▃▂▃▂▃▃▅▃▁▃▂▂▄▄▂▃▂▃▂█▅▂▂▄▄▅▄</td></tr><tr><td>val_loss_step</td><td>▃▄▃▂▂▃▂▂▁▂▂▃▃▃▂▂▃▂▂▄▂▁▂▄▅▂▂▁▁█▂▁▂▂▃▂▁▂▂▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.80896</td></tr><tr><td>train_auc</td><td>0.87348</td></tr><tr><td>train_f1</td><td>0.76331</td></tr><tr><td>train_loss_epoch</td><td>0.43974</td></tr><tr><td>train_loss_step</td><td>0.46231</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.71898</td></tr><tr><td>val_auc</td><td>0.76009</td></tr><tr><td>val_f1</td><td>0.57459</td></tr><tr><td>val_loss_epoch</td><td>0.77319</td></tr><tr><td>val_loss_step</td><td>0.97685</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/f0o4zo2v' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/f0o4zo2v</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_175409-f0o4zo2v\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_181055-kdf5x2t7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/kdf5x2t7' target=\"_blank\">GINConv_3_32_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/kdf5x2t7' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/kdf5x2t7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_32_onehot_0\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 5.9 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "6.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.5 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b53b823852594a0a8e6b02d100c4e276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▄▅▅▆▇▆▆▆▆▇▇▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇</td></tr><tr><td>train_auc</td><td>▁▃▄▄▅▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇███▇███▇▇███████</td></tr><tr><td>train_f1</td><td>▁▄▅▅▆▆▆▇▆▆▅▆▇▇▇▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▆▇▇▇█▇█▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▅▄▄▃▃▃▄▄▃▃▃▃▃▂▃▂▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂</td></tr><tr><td>train_loss_step</td><td>▇██▆▄▅▅▅▂▄▄▃▃▃▃█▆▄▃▄▁▃▁▄▃▁▃▃▃▂▃▃▃▂▂▃▂▃▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▁▁▂▁▂▅▆▅▃▅▆▇▅█▄▅▆▇▄▆▇▆▆▄▅▆▆▆▅▆▆▇▃▅▇▆▅▆▅</td></tr><tr><td>val_auc</td><td>▁▁▁▁▂▃▃▄▅▅▃▅▆▇▇▆▅▅▇▇▇▇▇▇▆█▆▇▇▇▅▇█▇▆▇▆▇▆▆</td></tr><tr><td>val_f1</td><td>▁▂▃▃▂▄▆▇█▇▆▇█▇█▅█▇▇█▇███▅█▇█▇█▆▆██▇███▇█</td></tr><tr><td>val_loss_epoch</td><td>█▇▆▆▃▆▆▅▄▆▇▄▄▃▃▇▆▆▃▄▄▄▂▅▃▅▅▄▄▅▅▄▇▆▂▃▇▄▁▄</td></tr><tr><td>val_loss_step</td><td>█▅▆▇▇▇▅▄▅▆▅▆▆▅▅▄█▄▂▆▂▁▆▆▅▄▃▂▂█▄▁▁▂▄▃▂▃▇▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.75229</td></tr><tr><td>train_auc</td><td>0.82287</td></tr><tr><td>train_f1</td><td>0.70055</td></tr><tr><td>train_loss_epoch</td><td>0.49257</td></tr><tr><td>train_loss_step</td><td>0.49686</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.70438</td></tr><tr><td>val_auc</td><td>0.75006</td></tr><tr><td>val_f1</td><td>0.67729</td></tr><tr><td>val_loss_epoch</td><td>0.59275</td></tr><tr><td>val_loss_step</td><td>0.54151</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/kdf5x2t7' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/kdf5x2t7</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_181055-kdf5x2t7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_182305-bj3qvhoq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/bj3qvhoq' target=\"_blank\">GINConv_3_32_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/bj3qvhoq' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/bj3qvhoq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_32_onehot_0\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 5.9 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "6.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.5 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c3a4986b2a94d6abae6e9b24c61f5ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▂▁▃▃▅▅▆▆▆▆▆▆▇▆▇▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇█▇█▇▇████</td></tr><tr><td>train_auc</td><td>█▆▅▂▁▂▄▆▄▄▂▃▄▆▅▄▅▃▂▂▅▄▄▅▃▃▁▄▃▂▅▄▃▂▄▃▆▆▄▄</td></tr><tr><td>train_f1</td><td>▁▁▃▄▅▅▇▆▅▆▇▆▆▆▆▆▆▆▇▇▇▇▆▇▇▇▇▇█▇▇█▇▇█▇▇███</td></tr><tr><td>train_loss_epoch</td><td>█▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▄▄▅▄▄▄▅▅▄▄▄▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▇▅▆█▇▇▅▆▆█▅▅</td></tr><tr><td>val_auc</td><td>█▇▅▁▁▂▃▃▄▄▄▄▅▅▆▆▇▄▃▅▄▄▆▆▅▄▃▂▂▂▂▄▁▂▄▄▅▄▄▅</td></tr><tr><td>val_f1</td><td>▁▃▆▇▆▆▆▆▇▆▇▇▆▇▇▇▇▇▆▇▇▇▇▇▆▇▇▇▇▆▇█▇█▆▇▇█▆▆</td></tr><tr><td>val_loss_epoch</td><td>█▅▂▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.76143</td></tr><tr><td>train_auc</td><td>0.50544</td></tr><tr><td>train_f1</td><td>0.70575</td></tr><tr><td>train_loss_epoch</td><td>0.52642</td></tr><tr><td>train_loss_step</td><td>0.5985</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.67883</td></tr><tr><td>val_auc</td><td>0.56823</td></tr><tr><td>val_f1</td><td>0.46341</td></tr><tr><td>val_loss_epoch</td><td>0.72355</td></tr><tr><td>val_loss_step</td><td>0.72458</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/bj3qvhoq' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/bj3qvhoq</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_182305-bj3qvhoq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_183502-qptpyi9i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qptpyi9i' target=\"_blank\">GINConv_3_32_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qptpyi9i' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qptpyi9i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_32_onehot_0\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 5.9 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "6.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.5 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "998d7b38ef8d48859b50e802834ffd81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▅▆▆▆▆▇▇▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇███</td></tr><tr><td>train_auc</td><td>▁▅▅▆▆▆▆▆▆▇▇▇▆▇▇▆▇▇▇▇▇▇▇▇▇█▇█▇▇█▇▇▇██████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▇▆▆▇▇▇▇▆▇▆▆▆▇▇▇▇▇▇▇▇▇█▇▇▇▇▇███▇▇███</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▄▄▄▄▃▄▄▄▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁▃▃▃▁▂▂▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▇▆▆▆▅▇▇▂▃▅▄▃▄▄▃▄▄▃▆▃▂▂▄▃▂▆▅▂▂▁▂▄▅▃▂▃▃▄▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▃▂▅▆▆▅▆▇▆▅▁▅▅█▂█▅▆▆▃▇▇█▄▅▇▅▅▆▅▅▅▇▆▆█▆▄</td></tr><tr><td>val_auc</td><td>▂▃▁▃▂▅▅▅▆▇▃▄▄▆▃▆▅▅▅▅▇▅▅▅▇▄▇█▇▇▇▄▅▆▆▆▅▇▅▅</td></tr><tr><td>val_f1</td><td>▁▃▄▃▆▆▆▆▆█▆▆▂▅▆▇▃▇▅▇▆▄▇▇▇▄▅█▅▅▆▆▅▅▇▆▆▇▆▅</td></tr><tr><td>val_loss_epoch</td><td>▄▃▄▅▃▂▃▂▄▂▅▂█▂▃▃█▂▇▂▂▆▄▂▁▆▆▂▄▄▅▃▃▆▄▅▄▄▄▇</td></tr><tr><td>val_loss_step</td><td>▂▃▃▃▁▁▂▃▁▂▂▂▆▃▂▂▂▁▂▃▃▂▃▄▃█▂▂▅▄▃▂▂▁▄▁▄▂▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8053</td></tr><tr><td>train_auc</td><td>0.8778</td></tr><tr><td>train_f1</td><td>0.74852</td></tr><tr><td>train_loss_epoch</td><td>0.43865</td></tr><tr><td>train_loss_step</td><td>0.4331</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.66788</td></tr><tr><td>val_auc</td><td>0.73677</td></tr><tr><td>val_f1</td><td>0.40523</td></tr><tr><td>val_loss_epoch</td><td>0.82528</td></tr><tr><td>val_loss_step</td><td>0.85724</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qptpyi9i' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qptpyi9i</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_183502-qptpyi9i\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_184706-4wd3w9j2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/4wd3w9j2' target=\"_blank\">GINConv_3_32_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/4wd3w9j2' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/4wd3w9j2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_32_onehot_0\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 5.9 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "7.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.6 K     Total params\n",
      "0.030     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▅▆▆▆▆▆▆▇▇▇▇▇▇▆▇▇▇▇▇▇█▇█▇███▇▇███▇██</td></tr><tr><td>train_auc</td><td>▁▅▅▅▆▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇██████</td></tr><tr><td>train_f1</td><td>▁▅▆▇▆▆▆▆▆▆▇▇▇▇▇▇█▇▇▆▇▇▇▇▇▇██████▇▇███▇██</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▃▃▂▂▃▂▂▁▁▃▃▂▁▁▂▂▁</td></tr><tr><td>train_loss_step</td><td>▇▄▅▆█▅▄▆▅▄▆▄▆▅▅▄▆▂▄▂▃▅▆▄▃▃▄▄▆▂▄▄▃▅▂▂▂▁▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▁▄▄▄▅▅▅▆▃▆▆▅▆█▆▃▄▇▆▅▅▇▅▅▄▅▆▇▅▆▆▃▆▇▅▆▇▇▃</td></tr><tr><td>val_auc</td><td>▁▃▄▄▅▅▄▄▅▅▆▆▆▇█▇▅▅█▇▆▅▅▇▆▅▇▅▇▇▄▅▆█▇▅▆▄▅▄</td></tr><tr><td>val_f1</td><td>▁▂▅▅▅▆▇▆▆▃▇▆▇▇█▆▃▅▇▆▅▅▇▅▅▄█▆▇█▆▆▄▆▇▅▆▇▇▄</td></tr><tr><td>val_loss_epoch</td><td>▅▅▃▄▃▂▂▁▂▇▂▁▂▂▂▁█▃▃▃▂▄▂▁▄▇▂▁▃▄▅▁▇▂▂▄▂▁▂▇</td></tr><tr><td>val_loss_step</td><td>▃▄▃▃▂▃▃▂▂▄▂▂▁▁▁▂▅▄▂▄▂▂▁▃▂▃▄▃▃▄▁▄█▂▂▄▆▁▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.81993</td></tr><tr><td>train_auc</td><td>0.88703</td></tr><tr><td>train_f1</td><td>0.77066</td></tr><tr><td>train_loss_epoch</td><td>0.41047</td></tr><tr><td>train_loss_step</td><td>0.36201</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.64964</td></tr><tr><td>val_auc</td><td>0.72911</td></tr><tr><td>val_f1</td><td>0.32394</td></tr><tr><td>val_loss_epoch</td><td>0.83229</td></tr><tr><td>val_loss_step</td><td>0.66412</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/4wd3w9j2' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/4wd3w9j2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_184706-4wd3w9j2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_185929-6odg6jbt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/6odg6jbt' target=\"_blank\">GINConv_3_64_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/6odg6jbt' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/6odg6jbt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_64_onehot_0\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 22.1 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "24.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.2 K    Total params\n",
      "0.097     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▆▆▆▆▆▆▆▆▆▆▇▆▆▆▇▇▆▇▇▆▇▇▇▇▆█▇▇▇▇▇▇███▇</td></tr><tr><td>train_auc</td><td>▁▄▅▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇█▇▇▇█▇██▇█</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▆▆▇▇▆▆▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇█▇▇▇▇█▇███▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▅▅▄▅▄▄▄▄▄▄▃▄▃▄▃▃▄▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▁▂▂</td></tr><tr><td>train_loss_step</td><td>█▅▆▄▆▅▃▅▅▅▆▅▅▆▄▄▅▄▄▄▅▄▃▃▄▃▄▅▄▃▄▄▁▃▅▂▂▁▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▂▃▆█▄▅▆▆█▇█▆▅█▁▅▆▇▂▂▇▅▅▇█▄█▇▅▇▆▅▇▇▇▇▄▅▅▇</td></tr><tr><td>val_auc</td><td>▁▁▅▇▆▇▇▇▆▇█▆▄▇▆▆▆▆▄▄▅▅█▆▅▆▇▇▇▄▇▅▇▇▆▆▇▅▃▇</td></tr><tr><td>val_f1</td><td>▁▃▇▇█▄█▆▇██▆▄▇█▄▇▇██▇▆▆▇█▄█▇▅▇▆▆▇▆▆▆█▆▄▇</td></tr><tr><td>val_loss_epoch</td><td>▄▄▂▁▂▃▂▂▂▁▂▂▄▁▄▄▃▂▃▃▂▂▁▂▂▄▂▄▃▂▃▄▂▂▄▄▂▃█▂</td></tr><tr><td>val_loss_step</td><td>█▅▂▂▃▃▂▄▂▂▂▂▃▂▄█▅▂▃▄▃▃▂▂▂▂▂▃▃▅▃▃▄▂▃▅▄▄▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.81901</td></tr><tr><td>train_auc</td><td>0.8991</td></tr><tr><td>train_f1</td><td>0.77852</td></tr><tr><td>train_loss_epoch</td><td>0.39579</td></tr><tr><td>train_loss_step</td><td>0.40954</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.71168</td></tr><tr><td>val_auc</td><td>0.75474</td></tr><tr><td>val_f1</td><td>0.54857</td></tr><tr><td>val_loss_epoch</td><td>0.59782</td></tr><tr><td>val_loss_step</td><td>0.48308</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/6odg6jbt' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/6odg6jbt</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_185929-6odg6jbt\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_191217-r5dkmcla</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/r5dkmcla' target=\"_blank\">GINConv_3_64_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/r5dkmcla' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/r5dkmcla</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_64_onehot_0\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 22.1 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "24.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.2 K    Total params\n",
      "0.097     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▆▇▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇▇▇█▇▇▇▇█████</td></tr><tr><td>train_auc</td><td>▁▃▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇█▇██▇███████</td></tr><tr><td>train_f1</td><td>▁▂▆▅▆▆▇▆▆▆▆▇▇▇▇▇▇▇▇▇▇██▇█▇▇▇▇▇█▇▆▇█▇████</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▃▃▄▃▃▃▃▂▃▃▂▂▂▂▂▂▂▁▂▂▂▂▁▂▂▁▁▂▂▂▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▆▆▅▆▄▅▄▄▅▅▄▇▃▂▅▅▅▄▅▄▃▃▅▂▃▄▁▂▁▃▃▂▄▃▂▁▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▃▄▃▅▇▇▇▇▇▇▇▆▇█▇█▆▆█▇▁█▇█▆▇▇▇▇█▆▄█▇▅▄▇▆▅▇</td></tr><tr><td>val_auc</td><td>▁▃▅▅▆▆█▆▇▇▆▇▆█▆█▆▆█▇▆▇▇▇█▆▇▇█▇▇▆▇▇▆▇▇▆█▇</td></tr><tr><td>val_f1</td><td>▁▄▂▆▆▇▇▇▇██▆▇█▆▇▆███▇█▇█▆▇▇▇▇██▄██▇▇▇▆▅▇</td></tr><tr><td>val_loss_epoch</td><td>▅▄█▂▅▃▃▃▂▅▄▂▃▃▅▃▂▃▁▃█▄▃▂▃▃▄▆▄▁▅▇▂▂▅▅▄▄▄▃</td></tr><tr><td>val_loss_step</td><td>▆▄█▄▃▃▃▄▃▃▂▃▁▂▃▄▆▃▁▃▃▇▂▂▄▆▅▇▃▄▄▆▄▃▄▄▄▄▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.7925</td></tr><tr><td>train_auc</td><td>0.86759</td></tr><tr><td>train_f1</td><td>0.75353</td></tr><tr><td>train_loss_epoch</td><td>0.45226</td></tr><tr><td>train_loss_step</td><td>0.47118</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.71533</td></tr><tr><td>val_auc</td><td>0.7478</td></tr><tr><td>val_f1</td><td>0.58065</td></tr><tr><td>val_loss_epoch</td><td>0.59333</td></tr><tr><td>val_loss_step</td><td>0.541</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/r5dkmcla' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/r5dkmcla</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_191217-r5dkmcla\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_192454-0a9np5ky</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/0a9np5ky' target=\"_blank\">GINConv_3_64_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/0a9np5ky' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/0a9np5ky</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_64_onehot_0\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 22.1 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "24.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.2 K    Total params\n",
      "0.097     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▃▃▄▅▄▅▆▅▆▆▅▆▅▇▇▇▇▇▆▇▇▇█▇▇▇▇████▇▇▇████</td></tr><tr><td>train_auc</td><td>█▅▄▄▂▁▁▃▄▄▄▂▃▂▃▃▄▄▆▅▄▃▃▄▄▄▃▃▃▃▃▄▃▃▄▄▂▄▄▄</td></tr><tr><td>train_f1</td><td>▂▁▄▂▃▄▃▄▆▆▅▆▆▆▅▇▇▇▇▇▆▇▇▇▇▇█▇▇████▇█▇████</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▃▂▂▁▂▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▃▄▃▄▅▅▅▃▅█▅▅▆▆▇▆▆▇▅▇▇▆▇▇▇▆▇▆▆▆▅▆▇▆▆▆▇▆</td></tr><tr><td>val_auc</td><td>█▄▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▄▂▁▁▁▁▁▁▁▁▂▁▁▂▂▁▁▁▁▁▂▁</td></tr><tr><td>val_f1</td><td>▁▄▅▅▅▄▅▅▆▄▆█▆▅▆▇▇▇▇▇▇▇█▇▇▇▇▇██▆▇▇▇▇▇▆▇▇▆</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▁▁▃▂▂▃▁▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▃▂▂▁▄▃▂▂▁▁▁▁▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77057</td></tr><tr><td>train_auc</td><td>0.40692</td></tr><tr><td>train_f1</td><td>0.72326</td></tr><tr><td>train_loss_epoch</td><td>0.52941</td></tr><tr><td>train_loss_step</td><td>0.54076</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.71168</td></tr><tr><td>val_auc</td><td>0.22162</td></tr><tr><td>val_f1</td><td>0.51534</td></tr><tr><td>val_loss_epoch</td><td>0.56332</td></tr><tr><td>val_loss_step</td><td>0.4557</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/0a9np5ky' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/0a9np5ky</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_192454-0a9np5ky\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30479f0d198f4054a62a250d93f8a643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_193741-rnwm56ie</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/rnwm56ie' target=\"_blank\">GINConv_3_64_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/rnwm56ie' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/rnwm56ie</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_64_onehot_0\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 22.1 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "24.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.3 K    Total params\n",
      "0.097     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▅▆▆▅▆▆▆▆▇▆▇▇▇▆▆▇▇▇▇▇▇▇▇▇█▇▇▆█▇█▆▇▇▇▇█</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇███▇███▇█████</td></tr><tr><td>train_f1</td><td>▁▆▆▆▇▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇█▇█▇▇█▇██</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▅▄▄▄▄▄▄▄▃▄▃▃▃▃▃▃▃▂▂▃▂▂▂▂▂▂▂▃▂▂▁▃▂▁▂▂▁</td></tr><tr><td>train_loss_step</td><td>▆▅▄▅█▄▄▆▃▅▅▅▅▅▅▄▄▃▄▅▃▃▅▆▄▁▄▂▂▅▁▃▂▁▅▂▁▁▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▅▇▅▅▅▇▃▅▅▇▇▄▆█▆▆▇█▇▆▆▆▅▄▄█▅▄▅▄▆▇▅▇▅█▄▇</td></tr><tr><td>val_auc</td><td>▁▄▆▇▆▅▅▇▅▆▇▆▇▅▅█▇█▇▇▇▇██▄▇███▆█▆▇▇▆▇▄▇▆▇</td></tr><tr><td>val_f1</td><td>▁▃▇▇▅▇▆▇▄▇▆▇▇▅▆█▆█▇█▇▇▇▇▆▅▇█▆▄▅▅█▇▅▇▆█▅█</td></tr><tr><td>val_loss_epoch</td><td>▆▇▄▂▆▄▄▄▅▄▅▁▄▅▅▃▂▃▄▄▂▃▂▅▅▆▄▂▆▆▄█▃▂▄▁▆▄▆▄</td></tr><tr><td>val_loss_step</td><td>█▇▃▁▅▂▃▂▅▃▂▃▁▇▃▃▅▄▂▁▂▄▅▃▃▂▅▅▆▆▃▇▆▅▄▅▄▄▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.82633</td></tr><tr><td>train_auc</td><td>0.8922</td></tr><tr><td>train_f1</td><td>0.7836</td></tr><tr><td>train_loss_epoch</td><td>0.40033</td></tr><tr><td>train_loss_step</td><td>0.38094</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.74453</td></tr><tr><td>val_auc</td><td>0.76312</td></tr><tr><td>val_f1</td><td>0.66981</td></tr><tr><td>val_loss_epoch</td><td>0.61695</td></tr><tr><td>val_loss_step</td><td>0.62242</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/rnwm56ie' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/rnwm56ie</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_193741-rnwm56ie\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_195004-hj4fcgft</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/hj4fcgft' target=\"_blank\">GINConv_3_64_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/hj4fcgft' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/hj4fcgft</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_64_onehot_0\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 22.1 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "28.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "28.4 K    Total params\n",
      "0.114     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9dd2fa66f0446ac83e3fd5dd1a36304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▅▅▆▆▆▇▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇▇██</td></tr><tr><td>train_auc</td><td>▁▄▅▆▆▅▆▆▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇███████</td></tr><tr><td>train_f1</td><td>▁▄▅▅▆▅▅▆▆▆▇▆▆▅▆▆▇▆▇▇▇▇▇▆▇▇▇▇▇▇▆▇▇█▇▇█▇██</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▅▄▄▃▄▃▄▃▃▄▄▃▃▃▃▃▂▂▂▂▂▂▃▂▂▂▁▂▁▂▁▂▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▆▆▆▄▅▆▅▄▃▅▄▄▄▃▄▅▆▄▂█▃▃▅▄▄▄▅▅▂▂▃▂▃▁▂▂▂▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▆▇▆▄▄▆▇▇▇▅▃▇▅▆▆▄▄▅▆▆▄▅▅▇▄▄▅▅▅▇█▆▃▇▄▄▃▅</td></tr><tr><td>val_auc</td><td>▁▅▅▅▅▅▅▅▇▆▇▄▆▇▄▇▇▅▅▆▅▅▆▇▇█▆▆▃▅▅██▆▆▇▆▆▇▃</td></tr><tr><td>val_f1</td><td>▁▂█▇▇▄▇▆█▇▇▇▄█▆▇▇▅█▆▇▇▄▅▆█▅▄▇▇▇▇█▇▄▇█▅▄▇</td></tr><tr><td>val_loss_epoch</td><td>▅▅▂▂▃▂▂▂▁▂▁▂▄▂▃▁▄▂▂▂▃▄█▅▄▁▆▄▄▃▄▃▂▃▆▄▃▆▇▃</td></tr><tr><td>val_loss_step</td><td>▇▇▁▃▂▇▃▂▃▁▃▅▇▃▃▂▃▄▄▅▂▁▄▅▁▃▃█▂▃▂▁▅█▆▄▄▃▄▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83729</td></tr><tr><td>train_auc</td><td>0.89907</td></tr><tr><td>train_f1</td><td>0.7991</td></tr><tr><td>train_loss_epoch</td><td>0.4041</td></tr><tr><td>train_loss_step</td><td>0.52175</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.68248</td></tr><tr><td>val_auc</td><td>0.69709</td></tr><tr><td>val_f1</td><td>0.57561</td></tr><tr><td>val_loss_epoch</td><td>0.73547</td></tr><tr><td>val_loss_step</td><td>0.85105</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/hj4fcgft' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/hj4fcgft</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_195004-hj4fcgft\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e1c87cc61f4af19a43056865b13ff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_200244-ovbday7j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ovbday7j' target=\"_blank\">GINConv_4_16_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ovbday7j' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ovbday7j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_16_onehot_0\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 2.3 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61cb5615135448acb3db808067810c10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▆▆▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇██▇▇▇█▇▇▇████▇███▇███</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇██▇▇█▇█▇█▇███████</td></tr><tr><td>train_f1</td><td>▁▅▇▆▆▇▇▇▇▇▇█▇▇█▇▇▇████▇▇█▇██████▇██▇████</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▄▄▃▃▃▃▂▃▃▂▃▂▂▂▃▂▂▂▃▁▁▂▂▂▁▁▂▁▁▂▂▁▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▄▅▅▄▄▃▄▄▃▄▃▄▂▄▄▄▃▄▅▃▅▃▅▅▆▄▃▄▅▃▁▄▄▂▄▄▅▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▄▅▅▄▆▅▃▆▇▆▅▆▆▇▆▆▅█▄▇▇▆▆▇▆▅▆▅▆▇▇▆▇▇▅█▄▅</td></tr><tr><td>val_auc</td><td>▁▃▆▅▆▆▇▆▇▇▇▆▇▇▇▇▇▇▇█▇█▇██▇▇▇█▇▇██▇█▇▇█▅█</td></tr><tr><td>val_f1</td><td>▁▂▄▆▅▅▇▆▄▇▇▇▆▆▇█▇▇▆█▅▇▇▇▆▇▇▆▆▆▇█▇▆█▇▆█▄▆</td></tr><tr><td>val_loss_epoch</td><td>▅█▇▅▄▆▃▄▆▄▃▂▆▄▂▃▁▂▆▁▆▃▃▂▃▃▄▆▁▂▅▂▄▃▁▃▄▂▇▄</td></tr><tr><td>val_loss_step</td><td>▅█▆▅▄▃▁▄▅▃▃▃▅▄▃▃▄▃▇▂▄▃▂▂▇▁▂▃▅▅▂▁▃▂▂▆▂▄▅▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77057</td></tr><tr><td>train_auc</td><td>0.82603</td></tr><tr><td>train_f1</td><td>0.6994</td></tr><tr><td>train_loss_epoch</td><td>0.48902</td></tr><tr><td>train_loss_step</td><td>0.49162</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.67883</td></tr><tr><td>val_auc</td><td>0.78356</td></tr><tr><td>val_f1</td><td>0.45</td></tr><tr><td>val_loss_epoch</td><td>0.66673</td></tr><tr><td>val_loss_step</td><td>0.77043</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ovbday7j' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ovbday7j</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_200244-ovbday7j\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_201602-06ycn91m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/06ycn91m' target=\"_blank\">GINConv_4_16_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/06ycn91m' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/06ycn91m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_16_onehot_0\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 2.3 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c27078ccffa3461cbc42774bb1a59eff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▃▃▅▅▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████▇▇███▇</td></tr><tr><td>train_auc</td><td>▁▂▃▄▅▅▆▆▆▆▆▇▇▇▇▇▇██▇██▇█▇▇▇█▇█████▇█████</td></tr><tr><td>train_f1</td><td>▂▁▃▃▅▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▆▇▇▇▇▇█████▇▇████</td></tr><tr><td>train_loss_epoch</td><td>█▇▆▅▅▄▃▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁▂▁▂▁▂▁</td></tr><tr><td>train_loss_step</td><td>██▇▇▆▆▄▄▇▆▄▄▄▆▄▄▆▆▃▅▆▅▇▅▆▆█▃▄▆▆▄▁▅▆▄▅▅▄▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▃▃▄▄▅▅▁▆▅▅▆▆▅▇▆▆▅▅▇▆▆▇▄▇█▇▇▇▆███▇████▇██</td></tr><tr><td>val_auc</td><td>▁▃▃▃▅▅▅▅▅▆▆▆▅▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇█▇▇</td></tr><tr><td>val_f1</td><td>▁▁▂▄▆▅▇▅▅▇▆▇▅▇▆▆▆▇▇▆▆▇▇██▆▇▇▇▇█▇▇█▇▇█▇▇█</td></tr><tr><td>val_loss_epoch</td><td>█▇▇▅▄▆█▆▄▆▅▃▆▆▄▅▁▅▃▁▅▄▆▄▃▃▆▅▃▁▄▂▆▄▁▅▁▁▅▃</td></tr><tr><td>val_loss_step</td><td>▆▆▆▅▄▄█▄▄▅▅▄▅▅▄▄▅▅▄▅▄▅▅▄▅▄▄▄▅▄▃▂▄▄▁▄▃▃▆▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.74406</td></tr><tr><td>train_auc</td><td>0.78798</td></tr><tr><td>train_f1</td><td>0.66265</td></tr><tr><td>train_loss_epoch</td><td>0.52175</td></tr><tr><td>train_loss_step</td><td>0.50445</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.72993</td></tr><tr><td>val_auc</td><td>0.764</td></tr><tr><td>val_f1</td><td>0.69672</td></tr><tr><td>val_loss_epoch</td><td>0.58724</td></tr><tr><td>val_loss_step</td><td>0.56169</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/06ycn91m' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/06ycn91m</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_201602-06ycn91m\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_202837-b94rnhcm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/b94rnhcm' target=\"_blank\">GINConv_4_16_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/b94rnhcm' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/b94rnhcm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_16_onehot_0\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 2.3 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▂▂▂▃▃▅▄▆▅▆▆▆▆▆▆▆▇▆▆▇▇▇▇▇▇███▇█▇█▇████▇</td></tr><tr><td>train_auc</td><td>▆██▇▅▄▄▆▅█▆▄▅▅▆▆▆▆▅▃▅▄▄▅▅▅▆▄▅▅▄▄▄▂▃▃▁▂▃▃</td></tr><tr><td>train_f1</td><td>▁▃▃▃▂▃▂▄▂▄▄▅▆▅▅▆▆▆▆▆▆▆▇▇▇▇▇█▇█▇█▇█▇▇█▇█▇</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▁▂▂▃▂▃▃▃▄▃▅▄▅▄▅▅▅▅▅▅▄▆▄▆▅▅▆█▅▇██▇█▅▅▆▇▆</td></tr><tr><td>val_auc</td><td>███▇▆▆█▇▇█▇▇██▇██▇▄▂▃▄▇█▇▆█▇▅▂▄▄▁▁▁▁▁▁▁▁</td></tr><tr><td>val_f1</td><td>▁▁▂▂▄▂▄▅▃▅▅▆▆▆▆▆▆▆▆▆▆▆▇▆▇▆▆▆█▅▇▇███▅▆▆▇▆</td></tr><tr><td>val_loss_epoch</td><td>█▃▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.72669</td></tr><tr><td>train_auc</td><td>0.4687</td></tr><tr><td>train_f1</td><td>0.6575</td></tr><tr><td>train_loss_epoch</td><td>0.55782</td></tr><tr><td>train_loss_step</td><td>0.55702</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.68248</td></tr><tr><td>val_auc</td><td>0.23275</td></tr><tr><td>val_f1</td><td>0.43137</td></tr><tr><td>val_loss_epoch</td><td>0.63435</td></tr><tr><td>val_loss_step</td><td>0.70913</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/b94rnhcm' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/b94rnhcm</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_202837-b94rnhcm\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_204133-oebc8iv9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/oebc8iv9' target=\"_blank\">GINConv_4_16_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/oebc8iv9' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/oebc8iv9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_16_onehot_0\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 2.3 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "2.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▆▇▆▆▆▆▆▆▇▇▇▇▇█▇▇▇▇▇█▇▇▇▇▇▆▇██▇█▇▇▇███</td></tr><tr><td>train_auc</td><td>▁▃▆▆▇▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇█▇█████▇▇████</td></tr><tr><td>train_f1</td><td>▁▄▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇█▇▇▇█▇▆█████▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▄▃▃▄▄▃▃▃▃▃▃▂▂▂▂▃▂▁▂▁▂▂▂▂▁▃▂▁▁▁▂▂▂▁▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▇▅▃▆▄▅▄▄▅▆▃▅▅▃▄▃▅▃▄▃▂▆▅▄▄▂▃▆▃▁▂▃▄▆▃▃▂▃▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▃▃▄▄▅▄▃▇▆▆▆▆▆▄▅▆▆▆▄▆▆█▆▆▆▆▄▆▅▆▆▆▆▅▆▆▇▅</td></tr><tr><td>val_auc</td><td>▁▁▃▄▄▅▅▆▅▇▆▇▇▆▆▅▇▇▇▇▆▇▇█▇█▇▇▆▇▇▇▇▆▅▇▆▇▇▇</td></tr><tr><td>val_f1</td><td>▁▂▅▃▅▅▇▅▅▇▇▇▇▇▇▅▆▇▇▇▆▇▇█▇▇▆▆▅▇▆▇▇▇▇▆▇▇█▆</td></tr><tr><td>val_loss_epoch</td><td>▅▅▆▆█▇▃▄▄▄▄▃▁▄▃▃▃▂▃▃▆▃▅▂▄▄▃▄▆▄▆▄▃▂▃▅▃▃▃▅</td></tr><tr><td>val_loss_step</td><td>▄▄▄▅▄▂▂▃▃▁▂▂▂▂▂▂▃▂▂▂▁▁█▃▃▂▁▃▂▂▂▂▃▁▁▇▃▄▁▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.78885</td></tr><tr><td>train_auc</td><td>0.8434</td></tr><tr><td>train_f1</td><td>0.73108</td></tr><tr><td>train_loss_epoch</td><td>0.47726</td></tr><tr><td>train_loss_step</td><td>0.50169</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.69343</td></tr><tr><td>val_auc</td><td>0.76196</td></tr><tr><td>val_f1</td><td>0.4878</td></tr><tr><td>val_loss_epoch</td><td>0.65217</td></tr><tr><td>val_loss_step</td><td>0.70254</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/oebc8iv9' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/oebc8iv9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_204133-oebc8iv9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_205417-f5xanryy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/f5xanryy' target=\"_blank\">GINConv_4_16_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/f5xanryy' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/f5xanryy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_16_onehot_0\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 2.3 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "2.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.7 K     Total params\n",
      "0.011     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▆▆▆▆▇▆▆▇▇▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▆▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇█▇▇████</td></tr><tr><td>train_f1</td><td>▁▄▅▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇██▇▇█▇▇█▇██▇██</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▄▃▃▃▃▃▃▂▃▃▃▂▃▃▃▃▃▂▂▂▃▂▂▃▂▂▃▃▂▃▂▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▇▆▇▇▆▆▅▇▃▃▆▄▅▇▇▅▇▄▅▂▄▅▆▅▃▄▃▅▃▄▅▁▄▂▆▃▂▃▇</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▂▄▅▅▅▅▃▇▆▅▅▆▆▇▄▂▇▆▆▆▅▆█▆▇▆▇▄▆▅▅▆█▇▇▃▇▆</td></tr><tr><td>val_auc</td><td>▁▄▅▆▆▇▇▆▆▇▇▆▇█▇▇▆▆▇▇▇▇▇▇█▇▇█▇▇▇▆▇▇█▇█▇█▇</td></tr><tr><td>val_f1</td><td>▁▂▂▄▆▅▇▆▄▇▆▅▆▇▇▇▅▃▆▇▇▇▆▆█▆▇▆▇▅▇▆▅▆█▇█▄▇▆</td></tr><tr><td>val_loss_epoch</td><td>▃▄▇▅▄▃▂▃▅▂▂▃▄▁▁▂▃█▂▁▂▂▄▃▂▆▂▁▂▅▂▅▃▁▃▄▁▃▂▃</td></tr><tr><td>val_loss_step</td><td>▄▅▅▅▃▃▃▃▅▂▂▃▅▂▂▃▆█▄▂▂▃▅▂▄▂▄▄▂▁▂▃▂▃▃▃▃▅▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.78428</td></tr><tr><td>train_auc</td><td>0.82688</td></tr><tr><td>train_f1</td><td>0.7122</td></tr><tr><td>train_loss_epoch</td><td>0.48697</td></tr><tr><td>train_loss_step</td><td>0.58162</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.70073</td></tr><tr><td>val_auc</td><td>0.76835</td></tr><tr><td>val_f1</td><td>0.5</td></tr><tr><td>val_loss_epoch</td><td>0.63597</td></tr><tr><td>val_loss_step</td><td>0.66281</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/f5xanryy' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/f5xanryy</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_205417-f5xanryy\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_210705-6q4u9wa3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/6q4u9wa3' target=\"_blank\">GINConv_4_32_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/6q4u9wa3' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/6q4u9wa3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_32_onehot_0\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 8.2 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "8.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.7 K     Total params\n",
      "0.035     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▅▆▆▆▇▆▆▇▇▇▇▇▇▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇██▇█▇██▇</td></tr><tr><td>train_auc</td><td>▁▅▆▅▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇██▇█▇███</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▅▆▇▇▆▇▇▇▇▇▆▆▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇█▇▇█▇██▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▅▄▄▄▄▃▃▄▃▃▃▃▃▃▃▃▃▃▃▃▂▂▃▂▃▂▂▃▂▁▂▂▂▂▂▁▁</td></tr><tr><td>train_loss_step</td><td>██▄▆██▅▃▃▆▂▄▆▄▃▂▅▅▇█▂▄▃▂▆▄▃▃▂▁▃▅▄▅▂▁▂▃▄▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▄▄▅▆▅▆▅▇▇▅█▅▆▄▂▃█▆▅▃▃▄▆▅▃▇▅▃▃▆▄▃▆▅▆▆▃▄</td></tr><tr><td>val_auc</td><td>▂▂▅▄▆▇▇▇█▇▇█▇▆▅▅▄▆▆▅▅▄▇▅▆▄▃▆█▂▃▇▄▁▄▄▇▅▃▂</td></tr><tr><td>val_f1</td><td>▁▃▅▅▇▆▆▇▅▆▇██▅▆▅▃▄█▇▆▃█▅▆▆▄▇▅▃▄▇▄▄▆▆▆▇▄▄</td></tr><tr><td>val_loss_epoch</td><td>▄▇▂▃▃▁▁▁▂▁▂▃▃▅▁▃▆▂▂▄▃▅▅▂▁▃▇▂▄▇▄▃█▄▅▃▃▄▇▇</td></tr><tr><td>val_loss_step</td><td>▃▅▂▂▂▂▃▂▁▂▂▄▁▃▄▂▇▄▂▃▄▂▂▂▂▃▂▂▄▄▃▃▆▃▂█▃▃▂▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.80622</td></tr><tr><td>train_auc</td><td>0.88133</td></tr><tr><td>train_f1</td><td>0.75406</td></tr><tr><td>train_loss_epoch</td><td>0.41688</td></tr><tr><td>train_loss_step</td><td>0.43586</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.64964</td></tr><tr><td>val_auc</td><td>0.70321</td></tr><tr><td>val_f1</td><td>0.35135</td></tr><tr><td>val_loss_epoch</td><td>0.90659</td></tr><tr><td>val_loss_step</td><td>0.97107</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/6q4u9wa3' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/6q4u9wa3</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_210705-6q4u9wa3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_211936-acvp4rph</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/acvp4rph' target=\"_blank\">GINConv_4_32_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/acvp4rph' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/acvp4rph</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_32_onehot_0\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 8.2 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "8.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.7 K     Total params\n",
      "0.035     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▅▆▆▆▇▆▇▆▆▇▇▇▇▇▇█▇▇▇▇█▇▇█▇▇██▇▇███▇▇</td></tr><tr><td>train_auc</td><td>▁▄▅▅▅▆▆▆▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇▇█▇▇███▇█</td></tr><tr><td>train_f1</td><td>▁▄▅▆▆▅▆▆▇▇▇▇▇▇▇▆▇█▇▇█▇▇▇▇█▇▇█▇███▇▇███▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▄▃▃▃▃▃▂▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▂▂▁▁▂▁▁▂▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▇▆▇▆▇▅▂▄▅▄▅▅▄▂▂▅▄▅▅▅▄▂▃▅▄▄▂▃▁▃▄▂▅▂▄▂▄▅▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▃▃▃▄▄▅▄▃▆▇▅▅▆▅▆▇▆▇▁▄▇▆▇▄█▆▅▇▇▇▆▆▅▆▆▆▆▆▇▆</td></tr><tr><td>val_auc</td><td>▁▁▁▅▄▄▄▃▅▆▆▄▆▆▆▇▆▆▇▇▅▆▇▅▇▆▆▇█▆▅▅▆▅█▄▇▄█▆</td></tr><tr><td>val_f1</td><td>▇▁▃▅▅▇▇▇▆▇▆▇█▅▇█▇█▇▇▇▇▇▇█▆▅█▇█▇▆▇▇▆▇██▇█</td></tr><tr><td>val_loss_epoch</td><td>██▄▅▅▄▃▆▁▂▄▆▅▃▂▄▂▂▇▅▃▃▄▃▂▂▅▁▃▃▂▃▄▅▄▄▅▆▃▂</td></tr><tr><td>val_loss_step</td><td>▄▄▃▂▃▃▃▃▂▃▄▄▂▃▃▂▃▃▅▃▃▃▃▂▂▄▂▂▃▄▃▂█▃▃▃▃▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77239</td></tr><tr><td>train_auc</td><td>0.83015</td></tr><tr><td>train_f1</td><td>0.7018</td></tr><tr><td>train_loss_epoch</td><td>0.47503</td></tr><tr><td>train_loss_step</td><td>0.41438</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.72628</td></tr><tr><td>val_auc</td><td>0.74851</td></tr><tr><td>val_f1</td><td>0.66667</td></tr><tr><td>val_loss_epoch</td><td>0.55184</td></tr><tr><td>val_loss_step</td><td>0.45375</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/acvp4rph' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/acvp4rph</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_211936-acvp4rph\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_213204-bktmhw3j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/bktmhw3j' target=\"_blank\">GINConv_4_32_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/bktmhw3j' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/bktmhw3j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_32_onehot_0\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 8.2 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "8.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.7 K     Total params\n",
      "0.035     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▂▂▄▅▅▅▆▇▆▇▆▆▆▇▆▇▇▇█▇▇▇▇▇▇▇█▇████▇█████</td></tr><tr><td>train_auc</td><td>▂▂▁▃▄▅▄▅▅▅▅▆▆▆▆▇▆▆▇▇▆▇▇▇█▇▇▇▇▇▇█▇▇▆▇▆▆▆▅</td></tr><tr><td>train_f1</td><td>▁▃▃▃▃▅▅▅▆▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▆▇▆▇▇▇▇▇▇▇█▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▃▄▄▅▄▅▅▅▄▆▆▅▅▅▆▆▅▆▆▆▇▆▇▆▆▇▅▆▆▆▆▆▅▇▆▅█▇</td></tr><tr><td>val_auc</td><td>▄▁▂▃▆▅▅▅▅▅▆▆▅▆▆▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇█▇███▇</td></tr><tr><td>val_f1</td><td>▁▃▄▆▅▆▆▅▅▆▆▇▇▆▆▆▇▇▆▇▇▆▇▇▆▆▇▇▅▆▆▆▇▆▅▇▆▅▇█</td></tr><tr><td>val_loss_epoch</td><td>█▃▂█▃▁▂▄▂▂▁▁▂▂▁▂▁▁▂▁▁▁▁▂▁▂▂▃▂▁▁▁▁▁▂▁▁▂▁▁</td></tr><tr><td>val_loss_step</td><td>█▂▂▂▃▁▂▃▂▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.7532</td></tr><tr><td>train_auc</td><td>0.63773</td></tr><tr><td>train_f1</td><td>0.70264</td></tr><tr><td>train_loss_epoch</td><td>0.56168</td></tr><tr><td>train_loss_step</td><td>0.47726</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.72263</td></tr><tr><td>val_auc</td><td>0.7786</td></tr><tr><td>val_f1</td><td>0.66667</td></tr><tr><td>val_loss_epoch</td><td>0.5342</td></tr><tr><td>val_loss_step</td><td>0.53292</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/bktmhw3j' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/bktmhw3j</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_213204-bktmhw3j\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_214444-oh4iq5h4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/oh4iq5h4' target=\"_blank\">GINConv_4_32_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/oh4iq5h4' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/oh4iq5h4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_32_onehot_0\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 8.2 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "8.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.8 K     Total params\n",
      "0.035     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▆▇▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇█████▇██▇█</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇███▇████▇█████</td></tr><tr><td>train_f1</td><td>▁▆▅▆▆▆▇▇▇▆▆▇▇▆▇▇▇▇▇▇▇██▇▇▇█▇█▇████▇▇████</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▄▄▄▄▄▃▃▄▃▃▃▃▃▃▃▄▃▂▂▂▃▂▃▂▂▃▂▂▂▂▃▂▂▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>██▅▆▅▇▄▆▆▇▅▄▅▄▆▄▃▅▄▂▄▄▅▅▃▄▅▃▂▃▅▂▄▃▂▃▁▂▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▃▄▂▅▇▂▇▅▄▆█▅▇▇▅▄▄▇▆▅▇▄█▇▆▇▄▆▄▆▅▆▆▇▆▅▄▄</td></tr><tr><td>val_auc</td><td>▁▁▂▄▃▅▅▄▅▅▂▅▅▅▄▅▅▅▇▇▆█▇▅▆▄▅▆▆▆▆▄▄▄▅▆▆▆▃▆</td></tr><tr><td>val_f1</td><td>▁▃▄▅▃▆▇▂▇▆▅▆█▆▇▇▅▅▄▇▇▅█▅█▇▇▇▅▇▅▇▆▇▇▇▇▆▅▅</td></tr><tr><td>val_loss_epoch</td><td>▃█▄▄▅▃▂▇▂▄▄▃▁▃▃▃▃▃▃▄▂▅▂▆▁▂▂▄▃▃▅▃▃▁▂▂▃▂▆▇</td></tr><tr><td>val_loss_step</td><td>▄▅▆▄▅▂▁▆▄▆▅▂▁▅▃▁▅▄▄▃▆▄▄▂▁▂▄▄▂▃▃▃▄▃▆▂▃▄▄█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.80987</td></tr><tr><td>train_auc</td><td>0.88199</td></tr><tr><td>train_f1</td><td>0.76991</td></tr><tr><td>train_loss_epoch</td><td>0.4251</td></tr><tr><td>train_loss_step</td><td>0.36037</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.67153</td></tr><tr><td>val_auc</td><td>0.75761</td></tr><tr><td>val_f1</td><td>0.3662</td></tr><tr><td>val_loss_epoch</td><td>0.86834</td></tr><tr><td>val_loss_step</td><td>0.97388</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/oh4iq5h4' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/oh4iq5h4</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_214444-oh4iq5h4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_215720-hfesbbq1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/hfesbbq1' target=\"_blank\">GINConv_4_32_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/hfesbbq1' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/hfesbbq1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_32_onehot_0\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 8.2 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "9.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "9.8 K     Total params\n",
      "0.039     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▇▇▇▇▇▇▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇▇█▇█▇███▇█</td></tr><tr><td>train_auc</td><td>▁▆▆▆▆▆▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇▇██▇██▇██</td></tr><tr><td>train_f1</td><td>▁▆▆▆▇▇▇▇▇▆▆▇▆▇▇▇▇▇▇▇▇▇▇██▇███▇████▇███▇█</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▄▃▄▄▃▃▄▄▃▃▃▃▃▃▃▂▃▃▂▂▂▂▂▂▂▃▂▂▂▂▂▂▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▇▆▄▅▅▆▄▆▅▅▄▂▄▄▄▃▅▄▄▅▂▆▄▄▅▃▃▇▃▅▄▃▄▅▅▅▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▄▃▅▅▄▆▅▃▆▇▇▆▆▇▇▄▅▆▅▆▇▄▆▇▄▆▄▃▆▆▅█▄▇▅▆▇▇</td></tr><tr><td>val_auc</td><td>▁▃▃▄▃▄▄▅▄▄▄▇▆▆▅▆▅▄▅▆▆▄▆▆▆▆▄▅▄▅▇▆▇█▆▇▄▆▆▅</td></tr><tr><td>val_f1</td><td>▁▃▅▄▆▆▅▇▆▃▇▇▇▆▇▇▇▅▆▇▅▆▇▅▆▇▅▆▅▃█▆▅█▅▇▆▆█▇</td></tr><tr><td>val_loss_epoch</td><td>▃▅▄▃▃▃▃▄▃█▃▂▂▂▂▂▂█▃▁▃▂▂▃▂▂▆▂▃▄▃▂▅▂▅▃▄▄▃▁</td></tr><tr><td>val_loss_step</td><td>▅▇▆▇▄▅▄▄▅▆▅▄▅▄▄▅▄▆▄▅▄▅▆▄▅▄▆▄▇▆▄▅▅█▆▅▅▅█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.81444</td></tr><tr><td>train_auc</td><td>0.88194</td></tr><tr><td>train_f1</td><td>0.75513</td></tr><tr><td>train_loss_epoch</td><td>0.42163</td></tr><tr><td>train_loss_step</td><td>0.33865</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.71898</td></tr><tr><td>val_auc</td><td>0.74818</td></tr><tr><td>val_f1</td><td>0.59259</td></tr><tr><td>val_loss_epoch</td><td>0.51357</td></tr><tr><td>val_loss_step</td><td>0.28709</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/hfesbbq1' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/hfesbbq1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_215720-hfesbbq1\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_221151-igl38ktl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/igl38ktl' target=\"_blank\">GINConv_4_64_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/igl38ktl' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/igl38ktl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_64_onehot_0\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 30.7 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "32.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "32.8 K    Total params\n",
      "0.131     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27308b85253941d98f61b4ec9627d215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▅▆▆▆▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇█▇█▇▇█▇▇▇▇██▇██</td></tr><tr><td>train_auc</td><td>▁▅▅▅▅▅▆▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇██▇██</td></tr><tr><td>train_f1</td><td>▁▆▆▆▆▆▇▆▇▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇█▇██▇█▇▇█▇██▇██</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▅▅▄▅▄▄▄▄▄▄▄▃▄▃▄▃▄▃▃▂▂▃▃▂▃▃▂▃▂▃▃▂▂▃▂▁</td></tr><tr><td>train_loss_step</td><td>█▅▆▅▇▆▄▆█▅▄▇▅▇▅▄▄▆▅▆▄▅▄▅▆▃▇▄▆▅▅▆▄▄▄▃▂▃▅▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▃▆▅▄▄▅▅▆▅▇▆▆▇▄▇▆▄▁▄▆▅▄▆█▅▅▄▇▆▆▆▇▆▆██▅▇▆▆</td></tr><tr><td>val_auc</td><td>▁▄▄▃▄▅▅▄▄▅▆▇▆▅█▆▅▅▆▄▄▅▅▇▄▅▆▇▆▆▇▇▆▅▆█▄▆▅▅</td></tr><tr><td>val_f1</td><td>▁▆▆▇▃▇▅▇▇▇▇█▇▄▇▇▅▇▄▇▅▄▇█▇▆▄▇█▇█▇▇▇██▆▇█▇</td></tr><tr><td>val_loss_epoch</td><td>▆▄▃▃▃▃▄▂▂▃▂▂▁▄▂▂▂█▄▂▅▄▄▁▃▂▃▂▂▃▂▄▅▄▁▁▃▂▅▇</td></tr><tr><td>val_loss_step</td><td>▃▂▃▃▃▂▃▂▁▁▁▂▁▃▁▂▂▃▃▃▁▁▂▂▂▁▃▂▂▂▁▂▂▅▂▂▃▄▃█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83547</td></tr><tr><td>train_auc</td><td>0.90452</td></tr><tr><td>train_f1</td><td>0.78923</td></tr><tr><td>train_loss_epoch</td><td>0.36307</td></tr><tr><td>train_loss_step</td><td>0.27477</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.71168</td></tr><tr><td>val_auc</td><td>0.73694</td></tr><tr><td>val_f1</td><td>0.59067</td></tr><tr><td>val_loss_epoch</td><td>0.93712</td></tr><tr><td>val_loss_step</td><td>1.4082</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/igl38ktl' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/igl38ktl</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_221151-igl38ktl\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_222654-991gl6w7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/991gl6w7' target=\"_blank\">GINConv_4_64_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/991gl6w7' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/991gl6w7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_64_onehot_0\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 30.7 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "32.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "32.8 K    Total params\n",
      "0.131     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▆▆▆▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇███▇███▇██</td></tr><tr><td>train_auc</td><td>▁▄▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇███▇██████</td></tr><tr><td>train_f1</td><td>▁▅▅▆▆▆▇▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇▇███▇███▇██</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▃▃▃▃▃▃▂▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▂▂▁▁▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▆▆▅▅▇▃▄▆▄▄▅▃▄▃▃▂▃▄▄▁▅▂▆▄▂▇▄▆▄▃▅▂▃▂▃▂▁▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▃▃▅▆▆▇▇▅▆▇▇▇▇▆▇▆▁▆▆▅▆████▅▆▆▆█▇▇██▇▆▇▄▆▃</td></tr><tr><td>val_auc</td><td>▁▅▅▅▆▆▇▇▆▇▇▇▇▆▇▇▇▇▇▅▆███▇▇▇█▆███▇▇▇▇▇▅▆▇</td></tr><tr><td>val_f1</td><td>▂▁▄▇▅▇▇▄▆▇▇▇█▇▇█▇▅▆▇▇█▇█▇▇▆█▇██████▇▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>▄█▄▂▂▃▃▄▃▃▂▁▃▃▃▄▅▃▃▂▃▃▂▂▃▃▃▃▃▃▂▄▃▃▂▃▂▃▄█</td></tr><tr><td>val_loss_step</td><td>▃▄▂▂▂▂▂▂▂▁▂▂▂▂▁▃▃▂▂▃▁▂▂▂▂▂▂▂▂▂▁▃▃▁▂▂▂▃▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.80622</td></tr><tr><td>train_auc</td><td>0.87592</td></tr><tr><td>train_f1</td><td>0.75176</td></tr><tr><td>train_loss_epoch</td><td>0.43727</td></tr><tr><td>train_loss_step</td><td>0.37292</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.60949</td></tr><tr><td>val_auc</td><td>0.7484</td></tr><tr><td>val_f1</td><td>0.63481</td></tr><tr><td>val_loss_epoch</td><td>0.88207</td></tr><tr><td>val_loss_step</td><td>1.18255</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/991gl6w7' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/991gl6w7</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_222654-991gl6w7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_224217-qxd4u1jc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qxd4u1jc' target=\"_blank\">GINConv_4_64_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qxd4u1jc' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qxd4u1jc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_64_onehot_0\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 30.7 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "32.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "32.8 K    Total params\n",
      "0.131     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1d4c675026747b3b90b9e75df82a15a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▂▃▅▄▄▅▆▆▆▅▆▆▆▆▆▆▇▇▇▇▇▇█▇▇█▇▇▇▇██▇█████</td></tr><tr><td>train_auc</td><td>▄▆▂▁▃▂▄▅▅▆▆▄▅▅▅▄▅▅▅▆▅▅▃▄▅▅▅▇▆▆▄▅▇▇▅▃▆▅██</td></tr><tr><td>train_f1</td><td>▁▃▂▃▄▄▄▆▆▆▅▅▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▆██▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▃▃▃▃▃▃▅▃▄▄▄▅▆▅▄▆▆▇▅▆▅▇▇▅▆▆▇▇▇▇█▇▇▅▆▆▇▆</td></tr><tr><td>val_auc</td><td>▇▆▁▁▅▅▆▆▆▆▆▅▆▆▆▆▇▇▇▇▇▇▇█▇▇▇█▇▇▇▇█▇▇█▇▇██</td></tr><tr><td>val_f1</td><td>▁▄▅▅▆▅▅▆▆▆▆▆▆▆▇▆▅▇▇▇▆▇▆▇▇▇▇▇▇▇▇▇█▇▇▅█▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▆▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▇▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃▁▁▁▂▁▁▂▁▁▁▁▁▁▂▁▁▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77697</td></tr><tr><td>train_auc</td><td>0.69789</td></tr><tr><td>train_f1</td><td>0.72523</td></tr><tr><td>train_loss_epoch</td><td>0.47982</td></tr><tr><td>train_loss_step</td><td>0.39246</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.70073</td></tr><tr><td>val_auc</td><td>0.7748</td></tr><tr><td>val_f1</td><td>0.54945</td></tr><tr><td>val_loss_epoch</td><td>0.6466</td></tr><tr><td>val_loss_step</td><td>0.77791</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qxd4u1jc' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qxd4u1jc</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_224217-qxd4u1jc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_225734-47efm0k7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/47efm0k7' target=\"_blank\">GINConv_4_64_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/47efm0k7' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/47efm0k7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_64_onehot_0\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 30.7 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "32.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "32.9 K    Total params\n",
      "0.131     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▅▆▅▅▆▆▅▆▆▆▆▆▆▇▆▆▆▇▆▇▇▇▇▇▇▇▇█▇▇█▆█▇██▇</td></tr><tr><td>train_auc</td><td>▁▅▅▅▆▆▆▆▆▆▆▇▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇█████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▅▆▆▇▅▇▆▆▆▇▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇█▇▇█▇████▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▅▄▄▄▄▃▃▃▃▃▄▃▃▃▃▃▃▃▂▃▂▃▃▃▂▂▂▂▂▃▁▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▅▃▄▄▅▃▃▄▃▃▂▃▃▄▃▃▆▂▄▂▃▂▃▅▁▁▆▃▂▂▂▁▃▅▁▁▃▄▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▄▅▃▆▆▇▇▇▂▇▆▆▇█▅▂▆▇██▄▅▇▄▇▆▅▅▆▄▃▅▂▄█▃▆▆▇</td></tr><tr><td>val_auc</td><td>▁▅▅▄▅▆▆▇▆▅▆▇█▇▆▇▇▅███▇▇▆▅▇▆▆▆▆▂▃█▆▆▇▅▅▇▇</td></tr><tr><td>val_f1</td><td>▁▅▇▄▇▇▇▇▇▄█▆█▇█▆█▇▇▇█▅▅▇▅█▇▆▆█▅▄▅▇▄█▄▇▆▇</td></tr><tr><td>val_loss_epoch</td><td>▇▃▁▄▃▂▁▂▂▄▁▄▂▃▃▂▃▆▂▂▂▃▅▃▃▂▃▃▄▅▆▅▄▅█▃▆▄▆▆</td></tr><tr><td>val_loss_step</td><td>▄▃▂▃▂▂▂▂▂▃▂▂▂▂▂▂▂▂▁▂▂▂▂▃▂▃▃▃▃▄▃▄▂▂▃▅▂▄█▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.81901</td></tr><tr><td>train_auc</td><td>0.88704</td></tr><tr><td>train_f1</td><td>0.76029</td></tr><tr><td>train_loss_epoch</td><td>0.41545</td></tr><tr><td>train_loss_step</td><td>0.45926</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.72263</td></tr><tr><td>val_auc</td><td>0.76279</td></tr><tr><td>val_f1</td><td>0.6</td></tr><tr><td>val_loss_epoch</td><td>0.75875</td></tr><tr><td>val_loss_step</td><td>1.01731</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/47efm0k7' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/47efm0k7</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_225734-47efm0k7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e7536c967314aecba6e90562ffd90ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_231211-97reahm8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/97reahm8' target=\"_blank\">GINConv_4_64_onehot_0</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/97reahm8' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/97reahm8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_64_onehot_0\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 30.7 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "37.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "37.0 K    Total params\n",
      "0.148     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e6360d6b8b43f990ed932e2bf1c0a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▅▆▆▆▆▆▆▆▇▇▇▆▇▇▆▇▆▇▇▇▇▇▆▇▇▇▇███▇█▇████</td></tr><tr><td>train_auc</td><td>▁▅▆▅▆▆▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇█▇██▇▇█████▇████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▇▆▆▇▆▆▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇█▇▇██████▇████</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▄▄▄▄▄▄▄▃▃▄▃▃▃▃▃▃▃▃▃▂▃▂▂▃▂▁▂▁▂▂▂▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆█▆▆▅▄▆▅▆▃▄▃▅▃▃▃▅▄▂▃▂▄▆▁▄▅▂▆▅▅▃▂▃▄▂▅▂▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▂▂▆▅▆▇▇▇▆▆▇█▇▆▇▆▇█▆█▇▅▇▆▆▄▇▅▅▂▄▆▅▆▄▄▁▇▄▅</td></tr><tr><td>val_auc</td><td>▁▁▄▂▃▆▇▅▆▆▆█▆▄▆▅▆▄▅▇▄▅▅▅▃▄▆▆▆▆▁▃▄▄▄▄▅▆▄▅</td></tr><tr><td>val_f1</td><td>▁▁▆▆▇▇▇█▆▇▇█▇▆▆▆▇▇██▇▄▇▆▇▄█▆▅█▆▇▆▆█▅█▇▄▇</td></tr><tr><td>val_loss_epoch</td><td>█▅▁▂▁▁▂▁▂▁▁▁▂▄▃▂▂▂▁▂▁▄▂▂▂▃▁▁▂▃▄▂▂▁▂▃▄▂▅▂</td></tr><tr><td>val_loss_step</td><td>█▆▃▂▂▂▂▂▂▂▂▁▂▅▃▃▂▂▃▁▂▁▃▃▂▂▆▃▃▃▃▃▄▃▃▂▄▃▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.82541</td></tr><tr><td>train_auc</td><td>0.89275</td></tr><tr><td>train_f1</td><td>0.78121</td></tr><tr><td>train_loss_epoch</td><td>0.39788</td></tr><tr><td>train_loss_step</td><td>0.41613</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.66058</td></tr><tr><td>val_auc</td><td>0.74035</td></tr><tr><td>val_f1</td><td>0.61411</td></tr><tr><td>val_loss_epoch</td><td>0.65972</td></tr><tr><td>val_loss_step</td><td>0.69945</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_0</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/97reahm8' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/97reahm8</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_231211-97reahm8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_232730-84aj7c58</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/84aj7c58' target=\"_blank\">GINConv_2_16_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/84aj7c58' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/84aj7c58</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_16_onehot_1\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▇▆▇▇▇▇▆▇▇▇▇▇█▇▇▇█▇▇▇▇▇█▇▇█▇████▇▇███</td></tr><tr><td>train_auc</td><td>▁▄▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇██▇▇██████▇████</td></tr><tr><td>train_f1</td><td>▁▃▅▆▇▆▆▇▇▇▆▇▆▇▇▇▇▇▇▇█▇▇▇▇▇█▆▇█▇█▇██▇▇███</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▄▃▃▃▃▃▃▂▂▃▂▂▂▂▂▂▂▃▂▃▂▂▂▃▂▂▁▂▂▂▃▁▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▆▅▃▅▃▅▆▄▄▆▃▄▄▃▄▃▅▄▅▄▄▄▂▅▂▂▅▂▁▅▂▄▄▆▂▂▄▁▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▄▄▃▅▅▆▆▇▆▅▇▇▆▆▇▇█▇▇▇▇▇▇▇▇▆▇█▇▆▆▇▄▆▇▇▇▇▇</td></tr><tr><td>val_auc</td><td>▁▄▅▅▆▇▆▇▇▇▇▇▇▇▇▇█▇█▇█▇▇▇▇▇▇▇█▇█▇▇▆▇█▇▇▇█</td></tr><tr><td>val_f1</td><td>▁▆▅▄▆▆▇▇█▇▆███▆▇███▇██▇██▇█▇███▇██▇▇▇▇▇█</td></tr><tr><td>val_loss_epoch</td><td>▅▅▄█▃▅▃▃▃▃▅▃▃▃▂▁▂▂▃▃▂▃▃▃▂▄▄▃▂▂▄▄▂▅▃▁▂▂▁▂</td></tr><tr><td>val_loss_step</td><td>█▄▆▇▄▃▄▂▃▄▄▄▄▅▄▂▂▂▃▃▂▂▃▄▆▃▆▆▂▇▃▂▆▄▂▂█▅▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77879</td></tr><tr><td>train_auc</td><td>0.83453</td></tr><tr><td>train_f1</td><td>0.7119</td></tr><tr><td>train_loss_epoch</td><td>0.48683</td></tr><tr><td>train_loss_step</td><td>0.50683</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.76642</td></tr><tr><td>val_auc</td><td>0.82606</td></tr><tr><td>val_f1</td><td>0.69811</td></tr><tr><td>val_loss_epoch</td><td>0.49306</td></tr><tr><td>val_loss_step</td><td>0.46261</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/84aj7c58' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/84aj7c58</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_232730-84aj7c58\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_234253-zmfip8b9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/zmfip8b9' target=\"_blank\">GINConv_2_16_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/zmfip8b9' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/zmfip8b9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_16_onehot_1\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▃▄▄▄▅▆▆▆▇▇▇▇▇▇▆▇▇▇▇▇▇▇██▇▇▇██████▇█▇█▇</td></tr><tr><td>train_auc</td><td>▁▁▁▂▃▄▅▆▆▆▇▆▇▇▇▇▇▇██▇▇▇█▇█▇▇█████████▇██</td></tr><tr><td>train_f1</td><td>▅▂▁▂▃▄▅▆▇▆▇▇▇█▇▇▆▇▇▇▇▇▇▇█▇▇▇▇██████▇███▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▆▅▅▄▄▃▄▃▃▂▂▂▂▃▂▂▂▂▁▂▂▂▁▂▂▁▁▁▁▁▁▂▂▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▇▇▆▅▇▆▅▆█▃▄▅▂▅▃▄▂▅▅▄▂▃▃▁▄▅▃▂▅▁▂▄▆▃▁▅▂▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▁▁▂▃▂▃▆▄▆▅▃▇▆▄▆█▇▃▇▇▄▆▅▅▆▃▃▅▄▅▄▇▇▇██▆▇▅</td></tr><tr><td>val_auc</td><td>▁▃▄▄▅▇▅▇▆▇▆▇█▇▇▇██▇▇▇▇█▇▇▆▇▇▇▇▇▇▇▇▇█████</td></tr><tr><td>val_f1</td><td>▁▁▂▃▄▄▃▇████████▇▇██████████████▇██▇████</td></tr><tr><td>val_loss_epoch</td><td>▇▇▇▇▆▅▆▄▆▄▆▆▃▄▅▂▃▃▆▃▃▄▄▅▄▅█▅▅▇▅▇▃▂▃▁▃▃▂▄</td></tr><tr><td>val_loss_step</td><td>█▇▇▆▆▄▆▃▆▄▇▇▄▄▆▃▂▂▇▃▃▄▂▃▃▅▅▃▆▇▃▁▄▆▁▁█▃▅▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.72395</td></tr><tr><td>train_auc</td><td>0.78512</td></tr><tr><td>train_f1</td><td>0.62716</td></tr><tr><td>train_loss_epoch</td><td>0.54754</td></tr><tr><td>train_loss_step</td><td>0.61635</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.66058</td></tr><tr><td>val_auc</td><td>0.78235</td></tr><tr><td>val_f1</td><td>0.65428</td></tr><tr><td>val_loss_epoch</td><td>0.59032</td></tr><tr><td>val_loss_step</td><td>0.54599</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/zmfip8b9' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/zmfip8b9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_234253-zmfip8b9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231215_235819-twhi20z0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/twhi20z0' target=\"_blank\">GINConv_2_16_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/twhi20z0' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/twhi20z0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_16_onehot_1\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81e4b47382e34007b73acb7d58dcb829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▄▄▅▅▅▅▅▅▆▆▇▆▆▇▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████</td></tr><tr><td>train_auc</td><td>▃▂▂▁▂▃▂▄▄▅▅▆▆▅▇▆▆▆▆▆▆▇▇▆▇▇▆▆▇▆▇▇▇▇▇█▇▆▆▆</td></tr><tr><td>train_f1</td><td>▂▁▂▃▃▁▁▂▃▂▄▄▅▄▅▆▅▆▅▆▇▆▆▆▆▇▇▆▇█▇▇▇▇▇███▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▅▆▆▅▆▆▆▆▆▆▇▆▇▇▆▇▇▆▇▇▇▇██▇▇▇█▇▇█▇██▇█▇█</td></tr><tr><td>val_auc</td><td>▄▁▁▃▅▅▆▆▆▇▇▇▇▇▇▇▇▇█▇▇███████████████████</td></tr><tr><td>val_f1</td><td>▁▃▅▆▆▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇██▇████▇███▇████▇█▇█</td></tr><tr><td>val_loss_epoch</td><td>█▄▂▁▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▂▂▁▁▁▁▁▁▁▂▂▁▁▁▁▁▂▁▁▁▁▁▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.72121</td></tr><tr><td>train_auc</td><td>0.6302</td></tr><tr><td>train_f1</td><td>0.6312</td></tr><tr><td>train_loss_epoch</td><td>0.56248</td></tr><tr><td>train_loss_step</td><td>0.57872</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.74453</td></tr><tr><td>val_auc</td><td>0.79503</td></tr><tr><td>val_f1</td><td>0.68182</td></tr><tr><td>val_loss_epoch</td><td>0.58018</td></tr><tr><td>val_loss_step</td><td>0.49955</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/twhi20z0' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/twhi20z0</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231215_235819-twhi20z0\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_001647-3dg2xpw5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/3dg2xpw5' target=\"_blank\">GINConv_2_16_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/3dg2xpw5' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/3dg2xpw5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_16_onehot_1\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.1 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇▆▇▇██▇█▇█▇▇▇██▇█▇▇███</td></tr><tr><td>train_auc</td><td>▁▄▅▆▆▆▇▇▆▇▇▇▇▇▇█▇▇▇▇▇███▇█▇██▇███▇██████</td></tr><tr><td>train_f1</td><td>▁▃▅▆▆▆▇▆▆▇▇▆▇▇▇▆▇▇▆▅▆▇██▇▇██▇▇▇▇▇▇▇▇▇█▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▄▄▄▃▃▃▃▃▃▃▃▂▂▃▃▃▃▃▂▂▂▂▂▂▂▃▃▂▁▂▃▂▂▂▂▂▁</td></tr><tr><td>train_loss_step</td><td>██▆▅▇▅▅▄▄▅▆▄▄▁▅▂▅▃▆▄▄▆▄▅▁▁▄▃▁▄▃▃▇▂▂▃▃▃▄▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▃▅▅▆▄▆▇▆▇▇▇▆▆▇▅▇▇▇▇▆█▇▇▇▇▇▆▇▇▇▇█▆▇█▇▆▆</td></tr><tr><td>val_auc</td><td>▁▄▅▆▇▆▇▇▇▆▇▇▇▇█▇▇▇█▇█▇██▇██▇▇█████▇████▇</td></tr><tr><td>val_f1</td><td>▁▃▄▆▆▇▅▆▇▇█████▇▆███████▇██████████████▆</td></tr><tr><td>val_loss_epoch</td><td>▇▆▆▆▅▄▅▅▅▂▃▃▃▂▆▃█▂▃▃▄▅▄▂▂▄▃▂▃▁▁▃▂▁▆▅▃▂▁▅</td></tr><tr><td>val_loss_step</td><td>█▆▅▅▄▅▄▄▃▄▄▄▅▄▃▄█▅▅▄▂▂▂▅▃▄▃▃▃▇▃▁▃▃▂▅▆▃▃▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.78336</td></tr><tr><td>train_auc</td><td>0.84304</td></tr><tr><td>train_f1</td><td>0.7148</td></tr><tr><td>train_loss_epoch</td><td>0.48926</td></tr><tr><td>train_loss_step</td><td>0.50098</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.72628</td></tr><tr><td>val_auc</td><td>0.82529</td></tr><tr><td>val_f1</td><td>0.5614</td></tr><tr><td>val_loss_epoch</td><td>0.57517</td></tr><tr><td>val_loss_step</td><td>0.60652</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/3dg2xpw5' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/3dg2xpw5</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_001647-3dg2xpw5\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_003527-tjne4hhy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/tjne4hhy' target=\"_blank\">GINConv_2_16_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/tjne4hhy' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/tjne4hhy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_16_onehot_1\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.1 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "1.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.5 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▆▆▆▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇███▇█████▇▇█</td></tr><tr><td>train_auc</td><td>▁▃▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▆█▇██████████</td></tr><tr><td>train_f1</td><td>▁▁▅▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇█▇▇▇▇█▇▇▆▆▇██▇█████▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▄▄▃▃▃▂▃▃▃▃▂▂▃▂▂▃▂▂▂▂▂▂▂▂▃▁▁▁▁▁▁▁▁▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▄▆▆▄▆▆▄▄▆▃▃▃▂▂▂▅▆▄▃▅▅▅▃▂▂▃▁▃▃▄▂▄▄▁▂▅▄▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▄▃▄▆▆▇▆▆▆▅▇▇▇▇█▆▇▇▇▇▇▆▇▇▇█▇▆█▆▇▇▇▇█▇▆▇▄</td></tr><tr><td>val_auc</td><td>▁▄▅▅▆▇▆▆▇▇▅▇▇▇▇▇▇▇▇▇▇▇▇▆▇▇█▇▇█▆▇▇▇█▇██▇█</td></tr><tr><td>val_f1</td><td>▁▄▄▄▇▇▇▇▇▇█▇▇██▇▇█▇▇▇█▇████▇▇██▇▇▇▇█▇███</td></tr><tr><td>val_loss_epoch</td><td>█▅▄▆▄▄▄▃▃▃▅▂▃▄▅▅▃▃▁▃▃▄▂▆▅▂▃▄▄▃▅▃▃▂▆▂▄▅▄▅</td></tr><tr><td>val_loss_step</td><td>▇▆██▄▄▅▂▅▃▅▃▃▅▅▄▂▄▂▃▄▅▁▅▃▁▆▁▄▁█▃▃▆▂▁▃▄▄▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.78519</td></tr><tr><td>train_auc</td><td>0.82061</td></tr><tr><td>train_f1</td><td>0.71306</td></tr><tr><td>train_loss_epoch</td><td>0.50183</td></tr><tr><td>train_loss_step</td><td>0.49314</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.67518</td></tr><tr><td>val_auc</td><td>0.82881</td></tr><tr><td>val_f1</td><td>0.6899</td></tr><tr><td>val_loss_epoch</td><td>0.58409</td></tr><tr><td>val_loss_step</td><td>0.4764</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/tjne4hhy' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/tjne4hhy</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_003527-tjne4hhy\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_005329-lfif0b4y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/lfif0b4y' target=\"_blank\">GINConv_2_32_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/lfif0b4y' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/lfif0b4y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_32_onehot_1\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 3.7 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "4.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.2 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇█▇▇▇▇██▇▇█</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇██▇▇▇███████▇████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇██▇▇█▇█▇█▇█▇▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▄▃▄▄▃▃▂▂▂▂▂▂▂▃▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▄▄▄▃▅▅█▆▆▄▃▃▂▇█▅▄▃▅▄▄▅▄▂▂▂▅▄▁▄▄▂▄▁▂▇▄▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▅▅▅▇▇▇▇▇▇▇▇▇█████▇█▁▆▇▇▇▆▇██▅█▁██▇███▇▇█</td></tr><tr><td>val_auc</td><td>▁▅▅▅▇▆▇▆▆▇▇▇▇▆▇▇▆▆█▆▇█▇▇▇▇██▇█▅▇▇██▇▇▇█▆</td></tr><tr><td>val_f1</td><td>▁▂▁▆▇▇█▆██████▇▇▇▅█▆██▆▆██▇█▇▇▆████▇▇▇█▇</td></tr><tr><td>val_loss_epoch</td><td>▃▃▄▁▂▂▂▂▂▂▂▁▂▂▁▁▄▂▁█▂▂▂▂▂▂▁▂▃▂▇▁▂▂▁▂▂▁▂▂</td></tr><tr><td>val_loss_step</td><td>▃▃▃▃▁▂▃▃▂▂▂▂▂▃▃▂▁▃▁█▂▂▂▂▃▂▁▂▂▂▁▁▂▄▂▂▁▆▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.78611</td></tr><tr><td>train_auc</td><td>0.84961</td></tr><tr><td>train_f1</td><td>0.73041</td></tr><tr><td>train_loss_epoch</td><td>0.47986</td></tr><tr><td>train_loss_step</td><td>0.50221</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.75182</td></tr><tr><td>val_auc</td><td>0.80677</td></tr><tr><td>val_f1</td><td>0.67925</td></tr><tr><td>val_loss_epoch</td><td>0.5441</td></tr><tr><td>val_loss_step</td><td>0.55841</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/lfif0b4y' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/lfif0b4y</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_005329-lfif0b4y\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_011332-clyn5zll</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/clyn5zll' target=\"_blank\">GINConv_2_32_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/clyn5zll' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/clyn5zll</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_32_onehot_1\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 3.7 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "4.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.2 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9660cdb7609d452ab6fc96355652bfba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.013 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.080676…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▅▆▆▆▆▆▇▇▇▇█▇▇▇▇▇▇█▇█▇▇████▇▇█▇▇▇██▇██</td></tr><tr><td>train_auc</td><td>▁▃▃▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████▇▇█▇▇████▇█</td></tr><tr><td>train_f1</td><td>▁▁▃▄▆▆▇▇▆▆▇▇▇▇▇▇▇▇▇█▇▇█▇▇██▇█▇███▇▇▇█▇██</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▄▄▄▃▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▂▂▂▁▁▂▁▂</td></tr><tr><td>train_loss_step</td><td>█▆▆▄▄▃▆▅█▅▃▃▃▂▃▃▃▄▃▂▄▄▃▄▃▁▂▁▃▃▃▃▃▂▃▂▁▄▄▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▆▆█▇▆▇██▆▇▆▇▇▆▆▇█▆█▇▇█▅▇▇█▅███▇▇▇▆▆▇▇██</td></tr><tr><td>val_auc</td><td>▁▆▆▆▇▇▇▇▇▇▇▇█▇▇▇▇███▇▇█▇▇▇▇▇▇███▇▇▇▇▇▇▇▇</td></tr><tr><td>val_f1</td><td>▆▁▂▆▇▇▅▆▇▇▇▇▆█▇▇▇██▆▇██▇█▇▇▇▇██▇▅▇▇▇▇▆█▇</td></tr><tr><td>val_loss_epoch</td><td>▅▄▃▂▃▃▂▂▃▃▃▃▃▄▄▄▅▃▄▂▃▃▃▅▂▂▂█▂▂▁▁▃▃▃▅▄▂▃▂</td></tr><tr><td>val_loss_step</td><td>█▅▃▅▃▄▄▅▂▅▄▅▁▄█▃▁▄▆▅▃▃▃▃▃█▁▅▄▁▃▇▃▄▁▁▅▅▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77148</td></tr><tr><td>train_auc</td><td>0.81741</td></tr><tr><td>train_f1</td><td>0.71264</td></tr><tr><td>train_loss_epoch</td><td>0.51383</td></tr><tr><td>train_loss_step</td><td>0.57017</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.71898</td></tr><tr><td>val_auc</td><td>0.76091</td></tr><tr><td>val_f1</td><td>0.66953</td></tr><tr><td>val_loss_epoch</td><td>0.57688</td></tr><tr><td>val_loss_step</td><td>0.52634</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/clyn5zll' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/clyn5zll</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_011332-clyn5zll\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_013248-cv9chqld</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/cv9chqld' target=\"_blank\">GINConv_2_32_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/cv9chqld' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/cv9chqld</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_32_onehot_1\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 3.7 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "4.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.2 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af915541b4104fe1b0bb89bba9c39fa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▃▄▄▂▆▅▅▆▆▆▆▇▆▇▇▆▆█▇▇█▇██▇▇▇▇▇▇█▇█████▇</td></tr><tr><td>train_auc</td><td>▄▅▄▅▄▄▆▇▆▅▆▂▃▁▃▃▄▅▄▅▄▃▃▂▁▄▅▄▂▂▄▆▇▇█▇██▇▇</td></tr><tr><td>train_f1</td><td>▁▂▄▄▃▄▇▆▅▅▆▅▆▇▅▆▇▆▆█▇▆█▇██▇▇█▆█▇█▇█▇▇██▇</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>▇█▂▁▂▁▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▂▆▆▇▆▇▇▇▇▇▆▇▇▇▆▇▇▇▇█▆▇▇▇▇▇█▇▁▇▇▇▆▇▆▆▇▇█▆</td></tr><tr><td>val_auc</td><td>▇▅▆▆▆▇▇▇▇▇▇▆▆▃▄▆▇▆▅▆▆▆▄▁▁▆▇▆▁▁▇█▇▇██████</td></tr><tr><td>val_f1</td><td>▁▆▆▇▇█▇▇██▇▇▇█▆▇████▇▇██████▇▇▇██▇██▇▇██</td></tr><tr><td>val_loss_epoch</td><td>█▂▂▁▁▁▂▁▁▁▁▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▂▂▁▁▁▂▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▁▂▁▁▁▁▂▁▁▁▁▂▂▁▁▁▁▁▁▁▂▁▁▂▁▁▁▂▁▁▁▁▁▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.72029</td></tr><tr><td>train_auc</td><td>0.62747</td></tr><tr><td>train_f1</td><td>0.64419</td></tr><tr><td>train_loss_epoch</td><td>0.59619</td></tr><tr><td>train_loss_step</td><td>0.69005</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.71898</td></tr><tr><td>val_auc</td><td>0.78621</td></tr><tr><td>val_f1</td><td>0.68571</td></tr><tr><td>val_loss_epoch</td><td>0.59711</td></tr><tr><td>val_loss_step</td><td>0.53335</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/cv9chqld' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/cv9chqld</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_013248-cv9chqld\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_015352-9ciu1ocz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/9ciu1ocz' target=\"_blank\">GINConv_2_32_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/9ciu1ocz' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/9ciu1ocz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_32_onehot_1\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 3.7 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "4.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.3 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9e2e4159630488c86dab55588c199f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.013 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.080211…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▇▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇██▇▇▇▇██▇██▇▇██▇▇█▇█</td></tr><tr><td>train_auc</td><td>▁▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇███▇███▇███████</td></tr><tr><td>train_f1</td><td>▁▃▅▆▆▆▆▆▇▆▆▇▆▇▇▆█▇▇█▇█▇▆▇▇██▆██▇▇██▇▇█▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▄▄▄▄▃▃▃▃▂▃▃▃▁▂▂▂▂▂▂▂▂▁▁▂▂▂▁▂▁▁▂▂▁▂▁</td></tr><tr><td>train_loss_step</td><td>▇▆▇▄▄▆▄▅▆▅▄▄▅▅▅▅▄▃▅▂▄▃▄▅█▃▂▃▄▃▃▅▄▃▃▄▁▂▂▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▅▆▆▆▅▇▆▇█▆▆▇▇▆▆▇▇▇▇▇▆▇▆▇▇█▇▇▇▅█▆█▇▇▇▇█</td></tr><tr><td>val_auc</td><td>▁▄▅▅▅▆▆▆▆▇▇▆▆▇▇▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█</td></tr><tr><td>val_f1</td><td>▁▃▆▆█▇█▇▇▇▇█▇▇▇██▇▇█▇▇███▇██▇██████▇██▇█</td></tr><tr><td>val_loss_epoch</td><td>█▆▄▃▅▃▅▄▇▇▂▂▄▆▆▆▂▅▁▆▆▃█▁▄▄▇▂▄▄▆▇▂▃▁▇▃▆▅▇</td></tr><tr><td>val_loss_step</td><td>▅▅▂▂▃▃▄▁▂▁▁▂▃▃▂▂▃▂▂▂▃▂▂▁▂▃▂▂▂▁▃▂▃▅▃▂▂▃▃█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.79799</td></tr><tr><td>train_auc</td><td>0.84346</td></tr><tr><td>train_f1</td><td>0.74091</td></tr><tr><td>train_loss_epoch</td><td>0.47411</td></tr><tr><td>train_loss_step</td><td>0.52491</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.77372</td></tr><tr><td>val_auc</td><td>0.83394</td></tr><tr><td>val_f1</td><td>0.73504</td></tr><tr><td>val_loss_epoch</td><td>0.61965</td></tr><tr><td>val_loss_step</td><td>0.87191</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/9ciu1ocz' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/9ciu1ocz</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_015352-9ciu1ocz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_021235-kt8iflwa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/kt8iflwa' target=\"_blank\">GINConv_2_32_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/kt8iflwa' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/kt8iflwa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_32_onehot_1\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 3.7 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "5.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.3 K     Total params\n",
      "0.021     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇███▇▇▇▇▇▇██▇██▇█████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇████▇▇▇▇▇█████▇█████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▇▇▇▇▆▇▇▇▇▆▇▇▇█▇▇█▇▇▇▆▆▇▆█▇▇██▇▇▇███</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▃▃▂▂▂▁▂▂▂▃▂▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>██▇▆▄▄▆▆▅█▄█▅▅▄▄▃▆▄▆▂▁▆▄▃▄▅▄▄▄▆▃▃▂█▅▂▄▄▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▂▁▃▄▆▆▇▆▅█▆▇▅▆▇▆▄▅▆▆▇▄▄▆█▇█▇▇█▃▇▁█▄▇▄▇▆▅</td></tr><tr><td>val_auc</td><td>▁▄▃▅▆▆▇▆▆█▇▇▇▅▇█▅▆▆▇▇▇▇█▆▆▇▇▇▇▇▇▆█▇█▆█▆▇</td></tr><tr><td>val_f1</td><td>▁▁▄▄▆▇██▇█▆▇▆▇▇▇▇▆█▇▇████▇██▇█▇▇▇█▄███▇▇</td></tr><tr><td>val_loss_epoch</td><td>▆▆▆▃▂▂▂▂▂▂▅▁▅▃▁▄▄▂▃▂▂▇▄▂▄▃▁▄▁▂▃▂█▁▄▂▄▃▄▂</td></tr><tr><td>val_loss_step</td><td>▅▇▄▃▂▂▃▂▃▂▃▂▁▃▂▂▄▂▃▂▂▃▅▅▁▄▁▅▃█▃▁▂▄▄▃▁▃▅▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.78336</td></tr><tr><td>train_auc</td><td>0.84039</td></tr><tr><td>train_f1</td><td>0.7215</td></tr><tr><td>train_loss_epoch</td><td>0.47946</td></tr><tr><td>train_loss_step</td><td>0.45361</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.71898</td></tr><tr><td>val_auc</td><td>0.81911</td></tr><tr><td>val_f1</td><td>0.67511</td></tr><tr><td>val_loss_epoch</td><td>0.51581</td></tr><tr><td>val_loss_step</td><td>0.49189</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/kt8iflwa' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/kt8iflwa</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_021235-kt8iflwa\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a82079536f44c6dbf2961c334e5345a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_023212-jwe2d5c7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/jwe2d5c7' target=\"_blank\">GINConv_2_64_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/jwe2d5c7' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/jwe2d5c7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_64_onehot_1\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 13.5 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.7 K    Total params\n",
      "0.063     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▆▆▆▆▆▇▆▆▇▇▆▆▇▇▇▆▆▆▇▇█▇▇▇█▇██▇█▇▇████</td></tr><tr><td>train_auc</td><td>▁▄▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇█▇▇▇██████</td></tr><tr><td>train_f1</td><td>▁▆▆▆▆▆▇▆▇▇▇▆▇▇▆▇▇▇▇▆▇▇▇▇█▇▇▇█▇████▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▅▅▄▄▄▄▃▄▄▃▃▄▃▃▂▃▃▃▄▂▂▂▂▃▂▂▂▁▂▂▂▁▂▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>▇▄█▄▆▇▃▄▄▄▅▅▅▆▄▃▃▃▂▆▂▂▂▃▅▃▅▃▁▅▄▂▃▄▆▁▁▁▄▇</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▄▆▇▆▇▆▅▄▆▄▇▁▄▂▅▅▇▅▇▇▅▆▆▇█▇▅▇▇▅▅▆▆▆▄▇▆▇</td></tr><tr><td>val_auc</td><td>▂▄▁▆▇▇▆▆▄▆▇▆▆▅▆▆▆▆▆▆▇▆▄▇▆▆█▅▆▇▇▅▇▅▅▄▆▅▆▆</td></tr><tr><td>val_f1</td><td>▁▃█████████▄█▇█▇▆▇▇▆█▇███▇███████▇▆▇█▇█▇</td></tr><tr><td>val_loss_epoch</td><td>▅▄▃▂▁▃▃▂▃▆▃█▃▇▄▄▃▂▁▆▁▁▃▃▃▁▂▂▂▁▂▃▂▂▄▂▅▂▄▄</td></tr><tr><td>val_loss_step</td><td>▄▄▃▂▂▁▁▂▄▂▂▄▂▅▂▄▃▂▁▅▆▁▂▅▂▃▁▁▂▂▂▂█▂▂▅▃▁▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.79799</td></tr><tr><td>train_auc</td><td>0.86156</td></tr><tr><td>train_f1</td><td>0.75526</td></tr><tr><td>train_loss_epoch</td><td>0.4641</td></tr><tr><td>train_loss_step</td><td>0.58722</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.75182</td></tr><tr><td>val_auc</td><td>0.81669</td></tr><tr><td>val_f1</td><td>0.6383</td></tr><tr><td>val_loss_epoch</td><td>0.64712</td></tr><tr><td>val_loss_step</td><td>0.82716</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/jwe2d5c7' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/jwe2d5c7</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_023212-jwe2d5c7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_025126-urovw1nh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/urovw1nh' target=\"_blank\">GINConv_2_64_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/urovw1nh' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/urovw1nh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_64_onehot_1\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 13.5 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.7 K    Total params\n",
      "0.063     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▃▅▅▅▅▆▇▆▇▆▆▇▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇█▇█▇▇█▇█▇█▇</td></tr><tr><td>train_auc</td><td>▁▂▄▅▅▆▆▆▇▇▇▇▇▇▆▇▇▇▇▇█▇▇█▇██▇██▇█████████</td></tr><tr><td>train_f1</td><td>▁▁▃▅▅▆▆▆▇▆▇▇▇▇▆▇▇▇▆▇▇▇█▇▇▇▇▇██▇█▇██████▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▄▄▄▃▃▃▃▃▃▄▃▂▂▃▂▂▂▂▂▂▂▂▂▂▁▂▁▂▁▁▂▁▂▁▂</td></tr><tr><td>train_loss_step</td><td>█▆▇▅▇▅▄▅▆▅▅▅▄▅▆▄▄▅▃▅▂▆▃▃▃▅▅▃▃▅▄▃▂▄▄▂▁▃▄▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▃▇▆▇▇▅▇▅█▆▅▇▃▆▆▇▆▇▆▇▇▆▇▆▇█▇▆▇▇▇▅▇▅▇█▇▇</td></tr><tr><td>val_auc</td><td>▁▃▄▆▅▆▆▇▇▇▇▆▇▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▅▇█▇▇▆██▇▇</td></tr><tr><td>val_f1</td><td>▁▃▄▆▇▇▇█▇████▇▇██▆████▇████▇██▇█████▇██▇</td></tr><tr><td>val_loss_epoch</td><td>▇▅▄▄▃▄▃▂▂▇▁▆█▂▅▃▃▃▂▂▂▂▁▃▅▂▂▃▃▂▃▂▂▅▄▇▁▁▄▄</td></tr><tr><td>val_loss_step</td><td>▆▅▅▄▄▃▂▄▃▃▄▂▅▃▄▃▂▃▄▅▇▄▁▃▃▂▇▁▄▃▃▃▃▂█▄▄▁▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77879</td></tr><tr><td>train_auc</td><td>0.85408</td></tr><tr><td>train_f1</td><td>0.72248</td></tr><tr><td>train_loss_epoch</td><td>0.47267</td></tr><tr><td>train_loss_step</td><td>0.55449</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.72628</td></tr><tr><td>val_auc</td><td>0.79112</td></tr><tr><td>val_f1</td><td>0.65753</td></tr><tr><td>val_loss_epoch</td><td>0.60805</td></tr><tr><td>val_loss_step</td><td>0.73789</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/urovw1nh' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/urovw1nh</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_025126-urovw1nh\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_031109-x61ewxbd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/x61ewxbd' target=\"_blank\">GINConv_2_64_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/x61ewxbd' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/x61ewxbd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_64_onehot_1\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 13.5 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.7 K    Total params\n",
      "0.063     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▃▃▃▅▅▅▅▅▅▅▆▆▅▆▆▆▇▆▆▇▇▇▇▆▆▆▇▇▆▇▆▇▇▇▇█▇▇</td></tr><tr><td>train_auc</td><td>▃▂▄▄▄▂▂▂▂▂▁▁▂▃▃▄▂▄▄▄▆▇▆▆▅▄▅▄▅▆▆▇█▇▅▆▇█▆▇</td></tr><tr><td>train_f1</td><td>▁▂▄▂▄▄▅▄▄▅▄▄▆▆▄▆▆▆▆▅▆▆▇▆▆▆▆▆▇▆▇▇▇▇▇█▇█▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▄▅▇▇▇█▇▇▇▇█▇▇▇▇████▇▇▇█▇▄▇▆▇▇▇█▆▇▇▇▆█▇</td></tr><tr><td>val_auc</td><td>▅▆▆▆▅▄▁▁▂▄▃▂▄▅▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇██████▇</td></tr><tr><td>val_f1</td><td>▁▄▆▇█▇▇█▇▇▇▇█▇▇█▇████▇▇▇███▇██▇▇▇██▇██▇█</td></tr><tr><td>val_loss_epoch</td><td>█▄▂▁▁▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▆▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.71938</td></tr><tr><td>train_auc</td><td>0.7023</td></tr><tr><td>train_f1</td><td>0.65467</td></tr><tr><td>train_loss_epoch</td><td>0.56685</td></tr><tr><td>train_loss_step</td><td>0.62687</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.72263</td></tr><tr><td>val_auc</td><td>0.78759</td></tr><tr><td>val_f1</td><td>0.696</td></tr><tr><td>val_loss_epoch</td><td>0.62813</td></tr><tr><td>val_loss_step</td><td>0.61947</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/x61ewxbd' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/x61ewxbd</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_031109-x61ewxbd\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_032935-ahkc9j3n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ahkc9j3n' target=\"_blank\">GINConv_2_64_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ahkc9j3n' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ahkc9j3n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_64_onehot_1\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 13.5 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "15.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.7 K    Total params\n",
      "0.063     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab12b3e643e5426db63106d92ed06d97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▅▄▄▆▅▆▆▆▆▆▅▄▆▆▇▇▆▇▇▆▆█▇▇▆▇▇█▆██▇██▇█▇</td></tr><tr><td>train_auc</td><td>▁▅▅▅▅▅▆▆▆▆▇▇▇▆▆▆▇▇▇▇▇▇▇▇▇▇█▆▇██▇███████▇</td></tr><tr><td>train_f1</td><td>▁▅▅▆▅▅▇▅▇▇▇▇▇▇▄▇▆▇▇▇▇█▆▇█▇▇▆▇██▇███████▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▅▅▅▄▄▄▃▃▃▃▄▅▄▃▂▃▂▃▃▃▃▂▂▂▄▂▂▂▃▂▁▂▁▂▁▁▃</td></tr><tr><td>train_loss_step</td><td>▅▄▅█▆▄▂▄▂▃▂▂▃▄▄▄▂▅▅▄▁▃▃▃▄▂▁▂▂▃▃▃▂▃▂▄▂▂▂▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▇▇▇▇▆▇▅▇▇▆▆▆▆▇▅▂▇▁▂▇▇▇▇▇██▆██▇█▇▇▅██▇█</td></tr><tr><td>val_auc</td><td>▁▃▃▆▇▄▇▆▇▆▇▇▅▆▆▅▆▇▆▄▆▆▅▆█▇▆▇▇▇▇▆▇█▇▆▆▆▆▇</td></tr><tr><td>val_f1</td><td>▁▄██▇▇▆▇███▇▇▆▆▇█▇▇▇▇▇█▇██▇▇▆██▇██▇█▇███</td></tr><tr><td>val_loss_epoch</td><td>▆█▄▃▂▃▂▂▃▄▁▂▃▃▂▂▄▅▁▇▇▂▄▃▂▃▂▁▃▃▂▂▂▆▂▄▃▁▂▂</td></tr><tr><td>val_loss_step</td><td>█▆▄▃▄▃▄▃▆▂▄▃▄▃▄▃▄▆▃▇▅▅▂▃▅▄▇▄▃▅▃▃▅▃▃▂▂▄▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77514</td></tr><tr><td>train_auc</td><td>0.83892</td></tr><tr><td>train_f1</td><td>0.70146</td></tr><tr><td>train_loss_epoch</td><td>0.4886</td></tr><tr><td>train_loss_step</td><td>0.55914</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.77737</td></tr><tr><td>val_auc</td><td>0.82832</td></tr><tr><td>val_f1</td><td>0.73593</td></tr><tr><td>val_loss_epoch</td><td>0.49844</td></tr><tr><td>val_loss_step</td><td>0.4106</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ahkc9j3n' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ahkc9j3n</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_032935-ahkc9j3n\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_034923-j39t4sev</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/j39t4sev' target=\"_blank\">GINConv_2_64_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/j39t4sev' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/j39t4sev</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_64_onehot_1\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 13.5 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "19.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "19.8 K    Total params\n",
      "0.079     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65e1d0e381f64ed1ba911b14f7ed773f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.013 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.080226…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▄▅▆▆▆▆▆▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇████▇█▇███</td></tr><tr><td>train_auc</td><td>▁▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇████████▇█</td></tr><tr><td>train_f1</td><td>▁▅▅▄▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████▇█▇███</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▆▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▃▃▂▃▂▃▃▂▂▂▂▂▁▂▂▁▂▁</td></tr><tr><td>train_loss_step</td><td>██▇▅▆▄▅▅▃▆▂▅▄▄▄▄▂▃▂▂▄▂▆▃▂▂▅▄▄▁▂▄▃▁▂▄▂▃▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▄▆▇▇▇▇▇█▇▆▇▆▆████▆▇▆▇█▇▇█▇▇▇▃▇▇▇▇▇▆▅▆██</td></tr><tr><td>val_auc</td><td>▁▄▄▄▇▆▆▆█▇▆██▇▆▆▆▇▆▆▃▅▇▆▇▇▆▄▆▆▇▆▅▅▆▅▇▆▆▅</td></tr><tr><td>val_f1</td><td>▁▄▇▇▇█▇▇█▇███▆████▆▇█▇█████▇████▇▇██████</td></tr><tr><td>val_loss_epoch</td><td>█▄▂▃▄▃▂▃▁▃▃▃▃▂▄▁▂▃▇▂▄▂▃▃▂▁▂▄▂▅▂▃▃▂▂▅▅▃▄▄</td></tr><tr><td>val_loss_step</td><td>█▅▂▃▃▄▄▃▃▄▅▃▃▄▂▄▃▃▇▇▃▁▅▃▇▂▃▁▄▃▆▂▃▅▄▂▅▅▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.80987</td></tr><tr><td>train_auc</td><td>0.88661</td></tr><tr><td>train_f1</td><td>0.76837</td></tr><tr><td>train_loss_epoch</td><td>0.41273</td></tr><tr><td>train_loss_step</td><td>0.38552</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.76277</td></tr><tr><td>val_auc</td><td>0.80302</td></tr><tr><td>val_f1</td><td>0.70852</td></tr><tr><td>val_loss_epoch</td><td>0.59326</td></tr><tr><td>val_loss_step</td><td>0.61875</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/j39t4sev' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/j39t4sev</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_034923-j39t4sev\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_040715-q2cnfk7e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/q2cnfk7e' target=\"_blank\">GINConv_3_16_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/q2cnfk7e' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/q2cnfk7e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_16_onehot_1\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.7 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▆▆▇▇▇▇▇▇▇▇▇▇██▇▇▇███▇███▇███▇▇█▇▇█████</td></tr><tr><td>train_auc</td><td>▁▄▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇███▇███████▇███▇█████</td></tr><tr><td>train_f1</td><td>▂▁▆▅▅▆▇▆▅▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇█▇███▇▇▇▇▆▇▇█▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▂▂▂▂▁▂▂▂▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>██▇▇▆▅▄▅▅▅▃▄▃▅▆▅▃▆▄▃▃▅▇▃▄▃▅▆▆█▄▃▂▃▄▅▁▃▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▅▆▅▆▅▄▆▅▇█▅▅▇█▇█▆▇▇▇▇▅█▆▆▆▆▇▅██▇▇▇▇▆▆▆</td></tr><tr><td>val_auc</td><td>▁▄▅▆▆▆▆▆▆▆▆▇▇▇▇█▆▇▇▇▇▇█▇█▇▇▇▇▇▇▇▇▇▇▇█▇▇▇</td></tr><tr><td>val_f1</td><td>▁▁▆▆▅▆▅▅▆▅▇█▆█▇█▇█▆█▇▇▇▅▇█▆▆▇▇▅██▇▇██▇█▆</td></tr><tr><td>val_loss_epoch</td><td>█▆▅▄▄▇▅▅▃▃▃▃▂▅▃▂▆▁▁▃▂▂▁█▂▅▃▆▃▄▅▂▃▂▃▂▃▇▄▇</td></tr><tr><td>val_loss_step</td><td>▆▅▄▄▃▂▅▅▆▃▃▂▄▄▂▂▄▃▃▃▂▃▄▅▂▃▁▃▃▃▂▅▇▅▂▂▃▅▄█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.78519</td></tr><tr><td>train_auc</td><td>0.85031</td></tr><tr><td>train_f1</td><td>0.72057</td></tr><tr><td>train_loss_epoch</td><td>0.48538</td></tr><tr><td>train_loss_step</td><td>0.48944</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.74088</td></tr><tr><td>val_auc</td><td>0.81305</td></tr><tr><td>val_f1</td><td>0.62032</td></tr><tr><td>val_loss_epoch</td><td>0.62531</td></tr><tr><td>val_loss_step</td><td>0.75229</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/q2cnfk7e' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/q2cnfk7e</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_040715-q2cnfk7e\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_042427-1dkxgl3d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/1dkxgl3d' target=\"_blank\">GINConv_3_16_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/1dkxgl3d' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/1dkxgl3d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_16_onehot_1\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.7 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▅▅▅▆▆▆▆▆▇▆▇▇▇▇▇▇█▇█▇▇█▇███▇▇█████████▇</td></tr><tr><td>train_auc</td><td>▁▂▃▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇█▇█▇██████████████████</td></tr><tr><td>train_f1</td><td>▃▁▄▅▅▆▆▅▅▅▆▅▇█▆▆▇▇▇▇▇▆▇▇▆▇██▇▇▇▇▇▇▇▇▇█▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▇▅▅▄▄▄▄▃▃▃▃▂▃▂▃▃▂▁▂▁▂▁▁▂▂▂▁▂▁▁▂▁▂▁▁▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>██▆▇█▆▅▅▅▆▃▅▄▇▅▅▄▄▄▃▄▅▅▄▄▃▃▇▅▆▄▄▂▄▃▄▁▄▄▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▇▇▆███▄▆▆▇▆▄▇▇▆▆▇█▇▇▇▄▇▇▆▇▇█▇▅▇▇▇▅█▆▇▇▇</td></tr><tr><td>val_auc</td><td>▁▄▅▆▇▆▆▆▆▇▇▇▇▆▇█▇▇▇▇▇▅█▆▇▇▇▆▇▇█▇▆▆▆██▇▇▇</td></tr><tr><td>val_f1</td><td>▅▆▃▁▆▆▇▆▇▇▇▇▆▆▇▇▇█▇▇█▆▆▇▇▇▇█▇▆▇▇▇▆▇█▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>▆▄▄▃▂▄▃▄▃▃▃▃▄▂▂▃▄▃▂▁▂▂█▂▂▄▂▃▂▃▄▂▂▁▅▂▅▃▂▂</td></tr><tr><td>val_loss_step</td><td>█▅▄▄▃▂▄▅▄▅▄▄▆▃▂▃▅▄▃▂▂▃▂▃▅▆▁▃▂▃▆▃▄▃█▂▆▂▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.72212</td></tr><tr><td>train_auc</td><td>0.78609</td></tr><tr><td>train_f1</td><td>0.61224</td></tr><tr><td>train_loss_epoch</td><td>0.54924</td></tr><tr><td>train_loss_step</td><td>0.56687</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.71533</td></tr><tr><td>val_auc</td><td>0.78489</td></tr><tr><td>val_f1</td><td>0.65487</td></tr><tr><td>val_loss_epoch</td><td>0.57173</td></tr><tr><td>val_loss_step</td><td>0.6008</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/1dkxgl3d' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/1dkxgl3d</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_042427-1dkxgl3d\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_044208-5r86hbmk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/5r86hbmk' target=\"_blank\">GINConv_3_16_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/5r86hbmk' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/5r86hbmk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_16_onehot_1\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.7 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▁▂▃▃▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▅▆▆▆▆▆▇▇▆▆▆▇▆▇▇▇▇█</td></tr><tr><td>train_auc</td><td>▁▂▂▁▃▃▃▃▄▄▅▅▅▅▅▆▅▆▆▆▆▇▆▇▇▇▇▇█▇▇▇▇▇▇█▇███</td></tr><tr><td>train_f1</td><td>▁▂▄▄▃▄▃▃▂▃▃▄▃▅▄▅▅▅▆▆▆▆▆▇▆▆▆▆▇▇▆▆▆▆▇▇▇▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇██████████████████</td></tr><tr><td>val_auc</td><td>▁▄▂▃▃▄▅▅▅▅▅▅▆▅▆▆▅▆▆▆▆▆▆▆▇▇▇▇█▇▇██▇▇▇▇███</td></tr><tr><td>val_f1</td><td>▄▁▅▆▂▄▂▂▂▂▄▃▃▅▄▄▄▅▅▆▇▆████▆█▇█▆▇█▇▆▇█▆▆▇</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▃▁▃▂▂▂▂▁▃▁▂▂▁▃▂▂▂▂▂▂▂▁▃▂▂▁▅▁▁▂▁▂▁▂▂▁▂</td></tr><tr><td>val_loss_step</td><td>█▅▂▂▂▂▂▂▂▂▂▁▂▁▁▁▃▃▂▃▃▂▂▃▁▁▁▂▂▁▂▁▃▂▁▁▁▁▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.7468</td></tr><tr><td>train_auc</td><td>0.76186</td></tr><tr><td>train_f1</td><td>0.68701</td></tr><tr><td>train_loss_epoch</td><td>0.56266</td></tr><tr><td>train_loss_step</td><td>0.60576</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.74453</td></tr><tr><td>val_auc</td><td>0.80437</td></tr><tr><td>val_f1</td><td>0.6789</td></tr><tr><td>val_loss_epoch</td><td>0.64179</td></tr><tr><td>val_loss_step</td><td>0.77518</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/5r86hbmk' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/5r86hbmk</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_044208-5r86hbmk\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d1654f57e6a41e1aad1ca93c7ae4448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_045959-vzxlnesg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/vzxlnesg' target=\"_blank\">GINConv_3_16_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/vzxlnesg' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/vzxlnesg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_16_onehot_1\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.7 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▇▇▇▆▇▇▇▇█▇█▇▇█▇▇█████████▇██▇▇█▇███</td></tr><tr><td>train_auc</td><td>▁▄▅▆▆▇▇▇▆▇▇▇▇█▇▇▇▇█▇▇█▇███▇█████████▇███</td></tr><tr><td>train_f1</td><td>▂▁▄▄▆▆▅▆▄▅▅▆▆▇▆▇▆▆▇▇▅▇▇▇▇▇▇█▇▇▇▇█▆▆▇▆██▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▂▂▁▂▂▂▁▂▂▁▁▁▁▂▁▁▂</td></tr><tr><td>train_loss_step</td><td>██▆▅▄▅▂▄▄▅▃▅▄▄▃▄▃▂▂▄▅▅▃▄▄▃▃▅▁▃▄▄▄▃▄▂▄▅▄▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▃▁▂▅▆▆▃▆▅▅▂▅▆▇▆▆▇▅█▅▇▅█▆█▆▇▆▇▆▆█▇▅▇▇▆▇▆▇</td></tr><tr><td>val_auc</td><td>▁▄▅▆▆▇▇▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇██▇██▇█▇▇▇███▇█▇</td></tr><tr><td>val_f1</td><td>▄▁▂▅▇█▃▆▅▅▃▅▆▇▇█▇▆█▅▇▅█▆▇▇█▅█▆▆██▆▆▇▆▇▆▇</td></tr><tr><td>val_loss_epoch</td><td>▆▅▃▄▃▄▅▃▃▃█▃▄▂▃▄▃▃▁▃▂▂▃▃▃▃▄▃▃▃▄▂▁▄▄▁▂▄▅▂</td></tr><tr><td>val_loss_step</td><td>█▆▇▄▄▁▄▄▃▃▇▇▂▄▂▅▃▂▄▄▃▄▁▄▁▄▂▃▃▄▂▃▃▆▄▂▄▃▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77605</td></tr><tr><td>train_auc</td><td>0.83913</td></tr><tr><td>train_f1</td><td>0.70085</td></tr><tr><td>train_loss_epoch</td><td>0.50121</td></tr><tr><td>train_loss_step</td><td>0.50083</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.74818</td></tr><tr><td>val_auc</td><td>0.81966</td></tr><tr><td>val_f1</td><td>0.63874</td></tr><tr><td>val_loss_epoch</td><td>0.51444</td></tr><tr><td>val_loss_step</td><td>0.47471</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/vzxlnesg' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/vzxlnesg</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_045959-vzxlnesg\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_051700-qn16jat5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qn16jat5' target=\"_blank\">GINConv_3_16_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qn16jat5' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qn16jat5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_16_onehot_1\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.7 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "2.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇██▇▇█████▇█████████</td></tr><tr><td>train_auc</td><td>▁▄▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇█▇█▇██▇█████████</td></tr><tr><td>train_f1</td><td>▂▁▅▅▅▅▆▇▇▆▅▇▇▇▇▇▇▇▆▆▆▇█▆▆▇▇▇▆▇▆▆▇▇▇▇▇▇▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▃▃▃▃▃▃▂▃▂▂▂▃▃▂▁▂▂▂▂▂▂▂▂▂▂▃▁▂▂▂▁▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▆▅▆▃▅▅▅▅▃▇▃▆▃▄▆▃▄▄▃▄▃▅▆▅▄▅▂▃▃▃▅▃▃▃▃▃▃▅▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▃▇▄▆▆▅▇▄▅▇▇▇▇▆▅███▄█▆▅█▄████▆▆██▇▇▆▇▇▇</td></tr><tr><td>val_auc</td><td>▁▄▆▇▇▇▇▆██▇▇▇▇▇▇▇███▇██▇█▇█▇▇▇▇█▇█▇██▇█▇</td></tr><tr><td>val_f1</td><td>▁▃▄▇▄▆▆▅▇▅▅▇▇██▆▆███▅▇▆▇█▅████▆▆████▆▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>▆▅▄▃▅▃▃▂▁▆▄▂▄▃▄▃▆▂▁▁▃▅█▃▃▇▁▃▃▄▃▃▃▂▁▂▂▃▃▃</td></tr><tr><td>val_loss_step</td><td>▇▆█▅▅▅▄▄▂▆▆▄▅▂▁▅▃▃▄▂▆▄▃▂▇▅▃▁▂▅▃▃▅▄▅▃▃▅▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77605</td></tr><tr><td>train_auc</td><td>0.84339</td></tr><tr><td>train_f1</td><td>0.69865</td></tr><tr><td>train_loss_epoch</td><td>0.49075</td></tr><tr><td>train_loss_step</td><td>0.38289</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.74453</td></tr><tr><td>val_auc</td><td>0.80864</td></tr><tr><td>val_f1</td><td>0.64286</td></tr><tr><td>val_loss_epoch</td><td>0.54806</td></tr><tr><td>val_loss_step</td><td>0.51461</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qn16jat5' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qn16jat5</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_051700-qn16jat5\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_053408-i79soiyz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/i79soiyz' target=\"_blank\">GINConv_3_32_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/i79soiyz' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/i79soiyz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_32_onehot_1\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 5.9 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "6.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.5 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▆▆▇▇▇▆▆▆▆▆▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█</td></tr><tr><td>train_auc</td><td>▁▅▅▅▆▆▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇█</td></tr><tr><td>train_f1</td><td>▁▅▅▆▆▆▆▆▇▆▆▆▆▆▆▆▆▇▇▇▆▆▇▇▇▇▇▇▇█▇▇▆▇█▇▇▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▅▅▄▄▄▄▄▄▄▄▃▄▄▃▃▃▄▃▃▃▄▃▃▃▂▂▂▂▃▂▂▂▂▂▂▁</td></tr><tr><td>train_loss_step</td><td>▇▇█▆▅▇▄▅▅▅▄▅▅▅▄▅▅▅▄▄▄▃▅▅▆▅▄▄▃▅▃▄▆▄▄▂▅▅▄▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▆▆▇▇▆▇▆▅▇▇▇▇▄▅▇█▇▆▇▇▆▇▅▆▇▆▇▆▅▆▇▆▇▇▇▆▆▆</td></tr><tr><td>val_auc</td><td>▁▁▂▅▆▅▅▆▆▄▆▇▆█▅▅▇█▅▇▇▇▆▅▃▆▅▆▅▅▄▄▅█▇▆▇▇▆▆</td></tr><tr><td>val_f1</td><td>▁▂▇▇▇█▇█▆▆▇▇██▅▆▇█▇▇▇▇▆█▆██▆▇▆▆▇▇▇██▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>▄▇▂▂▁▂▂▂▂▂▂▁▂▂█▂▂▂▂▂▁▁▃▃▂▂▂▃▂▄▄▂▁▂▂▁▂▄▂▃</td></tr><tr><td>val_loss_step</td><td>▅▇▄▃▃▃▃▂▂▅▃▂▂▁█▄▃▁▃▂▃▃▅▂▃▃▁▃▃▆▃▄▃▁▃▄▄▄▄▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.81993</td></tr><tr><td>train_auc</td><td>0.88879</td></tr><tr><td>train_f1</td><td>0.77278</td></tr><tr><td>train_loss_epoch</td><td>0.4104</td></tr><tr><td>train_loss_step</td><td>0.3035</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.72993</td></tr><tr><td>val_auc</td><td>0.81371</td></tr><tr><td>val_f1</td><td>0.61053</td></tr><tr><td>val_loss_epoch</td><td>0.6428</td></tr><tr><td>val_loss_step</td><td>0.74715</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/i79soiyz' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/i79soiyz</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_053408-i79soiyz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "033fb781cb4c4dbdb99868d326e36c6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_055043-q3dqc6qy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/q3dqc6qy' target=\"_blank\">GINConv_3_32_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/q3dqc6qy' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/q3dqc6qy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_32_onehot_1\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 5.9 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "6.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.5 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▆▆▆▆▇▆▆▆▇▇▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇█▇▇▇█</td></tr><tr><td>train_auc</td><td>▁▄▅▆▆▆▆▇▇▇▇▇▇▇▇▇█▇█▇▇▇██▇▇▇█████▇███████</td></tr><tr><td>train_f1</td><td>▁▂▄▆▆▆▆▇▇▆▆▇▇▆▇▇▆▆█▇▇▇▇▇▇▇▇██▇▇▇▇▇▇▇▇▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▄▃▃▃▃▃▃▃▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▂▂▁▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▇▆▆▅▄▅▄▅▃▄▅▄▃▄▅▄▅▄▃▄▃▂▃▄▃▃▂▂▂▃▆▄▄▂▃▅▅▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▂▇▅▄▅▅▃▇▇▅▇▃▅█▂▇▇▄▄▇▅▄▇▅▇▇▅▆▆▅▃▅██▃▇▇█</td></tr><tr><td>val_auc</td><td>▃▁▁▅▆▅▄▆▅▆▇▅▆▄▅█▅▅▆▆▆▆▆▆▆▅▇▆▆▅▅▅▅▆▆▇▅▇▇▆</td></tr><tr><td>val_f1</td><td>▁▂▃▇▆▇▇▇▇▇▇▇█▇▇█▇▇▇███████▇██▇▇█▇███▇███</td></tr><tr><td>val_loss_epoch</td><td>▆▅▄▄▂▄▄▃▄▂▃▃▂▅▄▁█▃▂▅▄▃▅▄▇▃▃▄▄▄▅▄▄▂▂▁▇▃▅▃</td></tr><tr><td>val_loss_step</td><td>▅▄▅▃▃▃▂▂▅▃▃▃▁▄▃▂█▂▂▅▃▂▆▂▅▂▂▃▄▄▁▃▂▂▃▃▆▃▆▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.78611</td></tr><tr><td>train_auc</td><td>0.82677</td></tr><tr><td>train_f1</td><td>0.72854</td></tr><tr><td>train_loss_epoch</td><td>0.49777</td></tr><tr><td>train_loss_step</td><td>0.42679</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.74818</td></tr><tr><td>val_auc</td><td>0.78516</td></tr><tr><td>val_f1</td><td>0.70638</td></tr><tr><td>val_loss_epoch</td><td>0.58456</td></tr><tr><td>val_loss_step</td><td>0.60969</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/q3dqc6qy' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/q3dqc6qy</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_055043-q3dqc6qy\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f4555da86b54cc881a09c5c9d8db9c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_060301-1ulkj4o9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/1ulkj4o9' target=\"_blank\">GINConv_3_32_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/1ulkj4o9' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/1ulkj4o9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_32_onehot_1\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 5.9 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "6.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.5 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d569c0a18b840c0a144a0f4a50d07fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▃▂▃▄▅▆▆▆▇▆▆▆▆▆▇▇▇▇▇▇▇█▇▇▇▇▇▇▆▇█▇█▇▇█▇█</td></tr><tr><td>train_auc</td><td>▄▃▁▁▄▂▅▄▄▂▃▁▃▅▂▄▂▄▄▄▅▅▆█▅▂▃▃▆▅▄▆▆▄▆▆▆▆▆▆</td></tr><tr><td>train_f1</td><td>▁▂▂▂▄▅▄▅▆▅▆▅▆▆▆▆▆▇▇▇▇▆▇█▇▇▇▇█▇▆▇▇▆█▇▇▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>██▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▄▆▄▆▆▆▇▆▇▇▇▇█▇▇██▇▇█▆███████▇▇▇▇▇▇███▆</td></tr><tr><td>val_auc</td><td>▅▅▁▂▄▄▆▆▆▄▅▄▄▅▆▆▆▅▇▆▆▆▆█▇▇▅▆▇▇▇▇▇▇█▇█▇▇▇</td></tr><tr><td>val_f1</td><td>▁▃▆▆▅▇▆▆▇▆▇▇▇▇█▇▇█████▆███████▇▇▇▇▇▇███▇</td></tr><tr><td>val_loss_epoch</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.75229</td></tr><tr><td>train_auc</td><td>0.64123</td></tr><tr><td>train_f1</td><td>0.68815</td></tr><tr><td>train_loss_epoch</td><td>0.53093</td></tr><tr><td>train_loss_step</td><td>0.39958</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.71168</td></tr><tr><td>val_auc</td><td>0.78368</td></tr><tr><td>val_f1</td><td>0.52121</td></tr><tr><td>val_loss_epoch</td><td>0.61519</td></tr><tr><td>val_loss_step</td><td>0.65984</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/1ulkj4o9' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/1ulkj4o9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_060301-1ulkj4o9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa9cb786c0c849af9231f961edbdf01b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666592937, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_061405-6b6jyv65</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/6b6jyv65' target=\"_blank\">GINConv_3_32_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/6b6jyv65' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/6b6jyv65</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_32_onehot_1\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 5.9 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "6.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.5 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▆▆▇▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█████▇█▇████▇█</td></tr><tr><td>train_auc</td><td>▁▅▅▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇█▇████▇▇</td></tr><tr><td>train_f1</td><td>▁▆▅▆▆▅▇▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇█▇▇█▇▇█▇█▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▅▄▄▄▄▄▃▄▃▃▃▃▃▃▃▃▂▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂▂</td></tr><tr><td>train_loss_step</td><td>▇▇▆▇▇▇▅█▄▄▅▄▃▆▅▂▆▅▅▄▃▂▃█▃▄▃▃▂▂▄▆▃▃▁▃▅▂▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▆▆▇▇▆▇▇▇▄▆▇▆██▇▆▇▇▆█▇▇▆▇█▆▇▇▇▆▆█▇█▇█▇▇</td></tr><tr><td>val_auc</td><td>▁▃▅▅▆▆▅▆█▇▇▆▇▆▅█▆▆▅▆▅▅▇▇▆▆▇▆▇▇▆▆▇██▆▆▆▄▆</td></tr><tr><td>val_f1</td><td>▁▂▆▆▇▇▇█▇▇▄▇█▆██▇▇▇█▇██▇█▇█▇▇▇██▆█▇█▇█▇▇</td></tr><tr><td>val_loss_epoch</td><td>▇▇▂▅▃▅▃▃▁▃█▂▂▆▆▅▅▂▃▃▂▆▄▃▅▂▂▄▁▃▅▄▃▃▃▆▂▄▄▄</td></tr><tr><td>val_loss_step</td><td>▅█▄▄▃▂▄▄▂▄▅▄▃▃▁▃▅▄▅▅▆▄▄▃▄▅▅▃▃▄▃▂▄▄▃▃▄▆▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.79616</td></tr><tr><td>train_auc</td><td>0.85143</td></tr><tr><td>train_f1</td><td>0.73229</td></tr><tr><td>train_loss_epoch</td><td>0.45804</td></tr><tr><td>train_loss_step</td><td>0.39288</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.74088</td></tr><tr><td>val_auc</td><td>0.80875</td></tr><tr><td>val_f1</td><td>0.61202</td></tr><tr><td>val_loss_epoch</td><td>0.57062</td></tr><tr><td>val_loss_step</td><td>0.62346</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/6b6jyv65' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/6b6jyv65</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_061405-6b6jyv65\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_062630-n27x51pf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/n27x51pf' target=\"_blank\">GINConv_3_32_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/n27x51pf' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/n27x51pf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_32_onehot_1\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 5.9 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "7.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.6 K     Total params\n",
      "0.030     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53bfa4d4eb2643ac889f20cf0d592308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.013 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.080249…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▆▆▆▆▆▇▇▇▆▇█▇▆▇▇▇█▇▇▇▇▇▇████▇██▇███▇</td></tr><tr><td>train_auc</td><td>▁▄▅▆▆▆▆▆▆▆▇▆▇▆▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇██▇███████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▇▆▇▆▆▇▇▇▇▇▇█▇▆▇▇▇█▇█▇▇▇████▇▇██▇██▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▄▄▄▃▄▃▄▄▃▃▂▂▃▃▃▂▂▂▃▂▄▃▂▂▂▁▁▂▁▁▂▁▂▂▁</td></tr><tr><td>train_loss_step</td><td>▆▇▆▆▇▆▅▆▅▄▇▄▆▄▄▂▃▅▃▆▄▃█▃▅▄▃▂▅▄▂▄▄▁▄▃▂▇▃▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▅▇▇▇▇▆▇▅▇▇▇▇▇▅▆▆▇▇▇▆▆▇▇██▅▅▆▇▆▇█▇▆█▇▇▆</td></tr><tr><td>val_auc</td><td>▁▂▅▄▅▇▄▇▆▅▆▇▇▆█▆▆▇█▇▇▆▆▇█▇▇▆▆▆▇▅█▇█▇▇▆▇█</td></tr><tr><td>val_f1</td><td>▁▂▆█▇▇█▆▇▆▇█▇▇█▆▇▆▇▇▇█▆▇▇██▆▆▆▇█▇██▆██▇▆</td></tr><tr><td>val_loss_epoch</td><td>█▇▃▃▅▂▂▁▂▂▂▂▂▄▃▅▃▃▃▂▂▅▆▂▄▃▂▄▄█▅▅▅▂▃█▁▂▅▇</td></tr><tr><td>val_loss_step</td><td>▄▅▂▂▂▂▄▃▂▃▂▂▃▂▃▄▃▂▃▃▂▂▄▃▂▂▂▁▇▂▄▃▄▁▂▃▃▂▃█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.78702</td></tr><tr><td>train_auc</td><td>0.8599</td></tr><tr><td>train_f1</td><td>0.72229</td></tr><tr><td>train_loss_epoch</td><td>0.4519</td></tr><tr><td>train_loss_step</td><td>0.50092</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.71898</td></tr><tr><td>val_auc</td><td>0.82666</td></tr><tr><td>val_f1</td><td>0.57459</td></tr><tr><td>val_loss_epoch</td><td>0.72565</td></tr><tr><td>val_loss_step</td><td>0.87285</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/n27x51pf' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/n27x51pf</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_062630-n27x51pf\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8452e7a3c3eb40e3bcc5cbf541974d9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666592937, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_063956-hska5b1s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/hska5b1s' target=\"_blank\">GINConv_3_64_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/hska5b1s' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/hska5b1s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_64_onehot_1\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 22.1 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "24.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.2 K    Total params\n",
      "0.097     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab27283b24c74986aa3f97b66bffd358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▆▅▆▅▆▆▆▆▅▆▆▆▆▆▇▇▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇█▇█</td></tr><tr><td>train_auc</td><td>▁▄▅▆▅▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇███</td></tr><tr><td>train_f1</td><td>▁▃▅▆▆▆▇▆▆▇▆▆▆▇▆▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▅▄▄▄▄▄▄▄▅▃▄▄▄▃▃▃▃▄▃▃▃▂▃▂▃▂▂▂▂▃▂▂▂▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▆▅▄▅▅▃▅▄▄▄▆▆▅▃▃▅▂▂▂▄▂▅▅▆▄▄▃▃▃▅▄▄▂▄▃▃▂▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▆▆▅▆▆▇▇█▇▇▇██▇▇▇▅▇█▇▇█▇██▇▇▇▇▇▆▇▆▅▆▇█▆</td></tr><tr><td>val_auc</td><td>▁▃▃▅▆▆▄▅▆▅▆▆▇▆▇▅▆▆▇▆█▇▅██▆█▇▅▆▆▆▄▆▂▇▅▄▆▁</td></tr><tr><td>val_f1</td><td>▁▃▇█▆█▇▇██▇███▇▇▇▇▆███▇█▇██▇▇█▇█▇█▇█▇▇█▇</td></tr><tr><td>val_loss_epoch</td><td>█▆▄▄▃▃▃▂▃▂▃▄▃▃▂▂▄▁▅▂▄▃▂▃▄▂▃▄▄▂▄▃▂▄▂▆▅▄▇▄</td></tr><tr><td>val_loss_step</td><td>█▃▃▃▃▄▂▂▃▂▁▃▃▃▄▂▂▂▅▁▅▃▂▂▁▃▂▂▂▃▂▆▃▂▂▄▄▃▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.82815</td></tr><tr><td>train_auc</td><td>0.89413</td></tr><tr><td>train_f1</td><td>0.78924</td></tr><tr><td>train_loss_epoch</td><td>0.3984</td></tr><tr><td>train_loss_step</td><td>0.32749</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.71533</td></tr><tr><td>val_auc</td><td>0.77778</td></tr><tr><td>val_f1</td><td>0.58065</td></tr><tr><td>val_loss_epoch</td><td>0.58553</td></tr><tr><td>val_loss_step</td><td>0.48566</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/hska5b1s' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/hska5b1s</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_063956-hska5b1s\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_065237-3a079582</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/3a079582' target=\"_blank\">GINConv_3_64_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/3a079582' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/3a079582</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_64_onehot_1\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 22.1 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "24.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.2 K    Total params\n",
      "0.097     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▅▅▅▆▆▇▆▇▇▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇██▇█▇▇██▇████</td></tr><tr><td>train_auc</td><td>▁▃▄▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇█▇▇██▇▇███</td></tr><tr><td>train_f1</td><td>▁▁▄▅▅▅▆▆▆▆▇▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇█▇▇▇▇▇██▇████</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▅▅▄▄▃▃▃▃▃▃▃▃▃▃▃▂▂▃▃▂▂▂▂▂▂▂▂▁▂▂▁▁▂▂▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▇▆▆▅▄▄▄▅▃▇▄▅▃▄▆▂▃▂▄▃▅▄▅▅▄▃▄▃▅▄▄▃▃▃▄▃▄▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▄▃█▇▇▇▇█▇▇██▃██▆█▅█▅██▆▇▃▇█▇▇▇▇▇▇▄▆▆▆▇▇</td></tr><tr><td>val_auc</td><td>▁▃▄▅▆▆▇▇▇▇▆▇███▇▇▆▇▇▇▇▆▇█▇▇▇▇▇▇▇▇▆▅▇▇▆▆▇</td></tr><tr><td>val_f1</td><td>▁▅▃▇▇▆█▆██▇██▇▇█▆████▇██▇▇██▇█▇██▇▇██▇█▇</td></tr><tr><td>val_loss_epoch</td><td>▆▅█▃▃▄▄▂▂▃▄▄▂█▁▃▄▁▅▃▇▂▃▅▃▇▆▅▄▂▃▄▃▅▅▄▇▃▇▂</td></tr><tr><td>val_loss_step</td><td>▇▆▇▄▅▃▅▅▄▄▁▅▃▇▄▄▃▄█▃▂▃▅▄▃▄█▅▃▆▂▅▃▃▄▄▄▇▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.80256</td></tr><tr><td>train_auc</td><td>0.85893</td></tr><tr><td>train_f1</td><td>0.76471</td></tr><tr><td>train_loss_epoch</td><td>0.45547</td></tr><tr><td>train_loss_step</td><td>0.33788</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.72263</td></tr><tr><td>val_auc</td><td>0.79095</td></tr><tr><td>val_f1</td><td>0.62745</td></tr><tr><td>val_loss_epoch</td><td>0.5212</td></tr><tr><td>val_loss_step</td><td>0.46804</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/3a079582' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/3a079582</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_065237-3a079582\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_070438-zc3l5c2o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/zc3l5c2o' target=\"_blank\">GINConv_3_64_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/zc3l5c2o' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/zc3l5c2o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_64_onehot_1\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 22.1 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "24.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.2 K    Total params\n",
      "0.097     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▅▄▅▅▆▅▆▆▆▇▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇███</td></tr><tr><td>train_auc</td><td>▃▁▂▅▇▅▅▅▅▆▆▇▇▆▅▆▅▆▆▄▄▆▄▆▆▇▅▆▇█▇▇▇▇▇█▇▇██</td></tr><tr><td>train_f1</td><td>▁▁▃▅▃▃▄▅▅▅▆▆▇▅▆▆▇▇▇▆▇▇▇▆▆▇▇▇▇▇▇▇▇██▇▇███</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▅▅▆▅▆▇▇▇▇▇▆▇▇▇▆▇▆▇▆▆▇▇▆▇█▇▅▆▄▇▇▆▆▇▇▆█▅</td></tr><tr><td>val_auc</td><td>▆▁▄▇██▇█████████████▇▇█▇▇██▇████████████</td></tr><tr><td>val_f1</td><td>▁▄▆▇▇▆▇▇██▇▇▇▇▇█▇▇▇▇▇▇██▇▇██▆▇▅▇█▇▇██▇█▆</td></tr><tr><td>val_loss_epoch</td><td>█▅▂▃▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▂▁▁▂▂▂▁</td></tr><tr><td>val_loss_step</td><td>█▂▃▃▁▂▁▂▂▁▁▁▂▁▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.76965</td></tr><tr><td>train_auc</td><td>0.65786</td></tr><tr><td>train_f1</td><td>0.71749</td></tr><tr><td>train_loss_epoch</td><td>0.50531</td></tr><tr><td>train_loss_step</td><td>0.46759</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.68978</td></tr><tr><td>val_auc</td><td>0.76819</td></tr><tr><td>val_f1</td><td>0.47853</td></tr><tr><td>val_loss_epoch</td><td>0.70415</td></tr><tr><td>val_loss_step</td><td>0.56428</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/zc3l5c2o' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/zc3l5c2o</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_070438-zc3l5c2o\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c22affc545a74293870aab095ff050d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666592937, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_071659-04332ufu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/04332ufu' target=\"_blank\">GINConv_3_64_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/04332ufu' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/04332ufu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_64_onehot_1\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 22.1 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "24.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.3 K    Total params\n",
      "0.097     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c60b0ba59e2462a843233f27e3eac5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▆▆▆▆▆▆▆▆▆▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇▇██</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇██▇██</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▇▆▇▇▇▇▇▆▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇████▇█▇▇██</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▅▄▅▄▄▄▃▃▄▄▃▄▃▃▃▃▃▃▃▂▂▃▂▂▂▂▂▂▂▂▁▂▂▁▁</td></tr><tr><td>train_loss_step</td><td>▇█▇▆▇▆▆▆▆▇▅▇▅▆▅▅▄▄▅█▆▄▆▆▇▄▅▄▅▇▄▅▅▆▅▅▅▅▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▂▅▇▇▆▇▇▇▇▇▆█▇▄▆██▇▇▁▆▇▇▇▅█▆▇█▇▇█▆▆▅▅▄▇▇█</td></tr><tr><td>val_auc</td><td>▁▆▇▇█▇█▆█▇▇▇▇▅▆▇▇▇▇▃▇▇▆▇▆▇▇▅▆▅▇▇▇▆▅▅▅█▅█</td></tr><tr><td>val_f1</td><td>▁▆▇▇▆█▇▇▇████▅████▇▇▆▇▇██▇▆██▇▇█▇█▆▆▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>▄▂▂▂▃▃▂▂▂▃▂▃▂▆▃▃▂▃▅█▄▂▂▂▄▂▅▄▁▃▃▅▄▃▂▄▅▂▂▂</td></tr><tr><td>val_loss_step</td><td>▆▄▄▂▄▃▂▄▂▃▄▁▅▅▄▃▂▅▅█▄▄▁▃▇▅▄▄▇▄▄▇▃▄▄▆▅▄▆▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8245</td></tr><tr><td>train_auc</td><td>0.89321</td></tr><tr><td>train_f1</td><td>0.77358</td></tr><tr><td>train_loss_epoch</td><td>0.38951</td></tr><tr><td>train_loss_step</td><td>0.25451</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.75912</td></tr><tr><td>val_auc</td><td>0.8238</td></tr><tr><td>val_f1</td><td>0.68269</td></tr><tr><td>val_loss_epoch</td><td>0.51131</td></tr><tr><td>val_loss_step</td><td>0.40735</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/04332ufu' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/04332ufu</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_071659-04332ufu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_072857-kwzdsbhx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/kwzdsbhx' target=\"_blank\">GINConv_3_64_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/kwzdsbhx' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/kwzdsbhx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_64_onehot_1\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 22.1 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "28.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "28.4 K    Total params\n",
      "0.114     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd95f9da149f4f4c854d3ca80370dcb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▅▅▆▆▅▆▆▆▆▆▆▆▇▆▇▆▆▆▆▆▇▇▆▇▆▇▇▇▇▇▇▇▇▇▇█</td></tr><tr><td>train_auc</td><td>▁▅▅▅▆▅▆▆▆▆▆▆▆▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇█▇█▇█▇▇██</td></tr><tr><td>train_f1</td><td>▁▄▅▅▆▆▆▆▆▆▇▆▆▆▇▆▇▆▇▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▄▃▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▃▃▂▁</td></tr><tr><td>train_loss_step</td><td>█▅▇▄▇▅▅▆▅▄▅▅▄▄▃▂▇▆▄▅▃▄▅▄▂▄▃▅▅▃▄▂▃▃▃▁▃▃▄▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▄▆▇▆▇▇█▇▆▇▆▇▆▆▇▇▆▄▇█▇▆▇▇▇▇▇▆█▇█▅▇▆▇▆▆▆▇</td></tr><tr><td>val_auc</td><td>▁▃▅▅▅▅▇▇▅▆▆▆▇▅▆▇▆▅▅▇▇▅▇▇▅▅▅▇▆█▇▆▄▅▅▇▆▇▆▇</td></tr><tr><td>val_f1</td><td>▁▅▇██▇██▇▇▇▆██▇▇▇▇█▇█▇█▇████▆█▇██▇▆▇▆▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>▇▄▂▂▂▄▃▁▂▂▂▁▂▃▅▁▃▂▅▂▂▁▂▆▃▂▃▃▃▁▃▄▅▃▃█▆▃▅▆</td></tr><tr><td>val_loss_step</td><td>█▃▃▂▄▁▁▂▄▃▁▂▂▂▄▃▂▅▅▂▂▂▄▁▂▅▄▄▂▄▃▁▂▃▂▃▂▂▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.84552</td></tr><tr><td>train_auc</td><td>0.89994</td></tr><tr><td>train_f1</td><td>0.80686</td></tr><tr><td>train_loss_epoch</td><td>0.38215</td></tr><tr><td>train_loss_step</td><td>0.41794</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.72993</td></tr><tr><td>val_auc</td><td>0.81669</td></tr><tr><td>val_f1</td><td>0.58427</td></tr><tr><td>val_loss_epoch</td><td>0.76151</td></tr><tr><td>val_loss_step</td><td>0.65573</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/kwzdsbhx' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/kwzdsbhx</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_072857-kwzdsbhx\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_074104-w9d99vab</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/w9d99vab' target=\"_blank\">GINConv_4_16_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/w9d99vab' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/w9d99vab</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_16_onehot_1\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 2.3 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇████▇████████</td></tr><tr><td>train_auc</td><td>▁▃▅▆▇▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇██████████████</td></tr><tr><td>train_f1</td><td>▁▄▅▆▇▇▇▇▇▇▇█▇▇▇▇█▇▇▇██▇▇█▇▇█████████████</td></tr><tr><td>train_loss_epoch</td><td>█▇▅▄▃▄▃▃▃▃▃▃▂▃▂▂▂▂▃▂▂▂▂▂▂▂▁▂▁▂▂▁▁▂▁▂▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▅▅▅▅▅▆▄▃▄▄▄▄▅▃▄▃▃▃▃▂▇▃█▅▄▅▃▆▄▄▁▂▆▃▃▄▃▆</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▂▄▅▃▄▆▅▇▄▆▅██▇▆▆█▇▇▅▇▆█▅▆▇▆▇▇█▇▇▆▇▇█▇▅</td></tr><tr><td>val_auc</td><td>▁▃▅▆▆▆▆▇▆▇▇▇▇█▇▇▇▆▇██▇▇▇█▇▇█▇▇▇█▆▇▇▇▇▇▆█</td></tr><tr><td>val_f1</td><td>▁▂▃▅▆▅▅▇██▅▇▆██▇▇▇▇█▇▆▇▇█▆▇█▆▇██▇▇▇▇███▆</td></tr><tr><td>val_loss_epoch</td><td>▅▅█▅▃▆▆▃▆▃▅▂▄▂▂▂▃▃▂▃▁▃▃▃▃▂▆▄▄▂▃▃▄▂▃▅▁▃▃▆</td></tr><tr><td>val_loss_step</td><td>▄▄▇▃▁▂▄▂▃▂▃▃▅▂▁▂▂▅▂▁▂▂▂▁▃▂▃▂▁▃▃▂▂▃▃▂▃▂▂█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.76965</td></tr><tr><td>train_auc</td><td>0.81456</td></tr><tr><td>train_f1</td><td>0.69268</td></tr><tr><td>train_loss_epoch</td><td>0.50979</td></tr><tr><td>train_loss_step</td><td>0.63604</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.70438</td></tr><tr><td>val_auc</td><td>0.81928</td></tr><tr><td>val_f1</td><td>0.50307</td></tr><tr><td>val_loss_epoch</td><td>0.74535</td></tr><tr><td>val_loss_step</td><td>0.89925</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/w9d99vab' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/w9d99vab</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_074104-w9d99vab\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_075311-10nb4m13</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/10nb4m13' target=\"_blank\">GINConv_4_16_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/10nb4m13' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/10nb4m13</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_16_onehot_1\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 2.3 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40781e5609834dae87a55195b8c21ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▃▃▅▆▆▆▆▆▆▆▆▇▇▆▇▇▆▆▇▇▇▇▇▇▇▇▇██▇███████▇</td></tr><tr><td>train_auc</td><td>▁▁▃▃▄▆▅▆▆▆▆▆▇▇▇▆▇▆▇▇▇▇█▇▇▇▇▇▇█▇▇█████▇█▇</td></tr><tr><td>train_f1</td><td>▃▁▃▃▅▇▇▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇██████████▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▆▄▄▄▄▃▃▄▄▂▂▃▃▃▃▃▃▂▃▂▃▃▃▃▂▁▂▂▂▂▂▁▂▂▂▁▂</td></tr><tr><td>train_loss_step</td><td>██▆▆▆▄▅▅▅▄▄▄▄▄▄▄▃▃▂▄▂▂▆▃▆▅▃▃▁▇▅▄▂▁▄▂▂▄▃▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▃▃▄▇▇█▆▆▆▂▁▇▇▇▃▇▇▇▇██▇▆███▇▆█▄▆▆▆▇▅▇▇▇▄▄</td></tr><tr><td>val_auc</td><td>▁▂▃▅▆▇▅▅▆█▄▇▇▇▄▇█▇███▇▇▇▇▇▆▆▇▇▇▇▇█▇▆█▇▇▇</td></tr><tr><td>val_f1</td><td>▁▁▃▆▆▇▇▆█▇▇▇▇▇█▆██▇▇█▇████▇██▇█████▇█▇██</td></tr><tr><td>val_loss_epoch</td><td>▇▆▆▅▄▃▄▃▇▇█▃▃▂█▅▄▄▂▃▂▄▅▃▃▂▄▄▆▇▄▅▄▃▆▄▁▃▆▄</td></tr><tr><td>val_loss_step</td><td>▆▆▆▅▂▂▅▄▅▆▇▃▃▂▆▂▃▆▁▁▄▂▃▂▄▄▆▂▆▄▆▄█▅▁▄▃▅▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.71481</td></tr><tr><td>train_auc</td><td>0.72247</td></tr><tr><td>train_f1</td><td>0.61951</td></tr><tr><td>train_loss_epoch</td><td>0.56601</td></tr><tr><td>train_loss_step</td><td>0.62093</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.63504</td></tr><tr><td>val_auc</td><td>0.7726</td></tr><tr><td>val_f1</td><td>0.65035</td></tr><tr><td>val_loss_epoch</td><td>0.61728</td></tr><tr><td>val_loss_step</td><td>0.58184</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/10nb4m13' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/10nb4m13</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_075311-10nb4m13\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_080511-6356kjou</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/6356kjou' target=\"_blank\">GINConv_4_16_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/6356kjou' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/6356kjou</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_16_onehot_1\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 2.3 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c64beb7e399c45c38003dd207918a73a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▂▁▂▃▃▃▃▄▅▅▄▅▅▅▅▅▅▅▆▆▆▇▆▇▆▆▆▆▆█▇██▇█▇████</td></tr><tr><td>train_auc</td><td>▁▂▁▂▂▃▃▄▄▄▄▅▅▅▅▆▅▅▆▆▇▇▆▇▆▆▇▆▇▇▇█▇▇██▇███</td></tr><tr><td>train_f1</td><td>▂▃▃▃▃▁▃▁▁▁▂▂▂▂▃▄▃▄▄▄▅▆▅▆▅▅▅▅▆▇▇▇▇▇█▇█▇█▇</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▁▃▃▄▃▃▃▃▃▃▃▃▄▅▆▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▆█▇▇████</td></tr><tr><td>val_auc</td><td>▁▂▃▃▃▃▄▃▄▄▄▄▅▅▅▅▅▅▆▅▆▆▆▆▆▇▇▇▆▇▇▇███▇████</td></tr><tr><td>val_f1</td><td>▁▃▄▃▄▄▄▃▃▃▄▄▄▄▆▆▆▆▆▆▆▇▇▆▆▇▆▇▆▇▇▇▇█▇▇████</td></tr><tr><td>val_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.73492</td></tr><tr><td>train_auc</td><td>0.75627</td></tr><tr><td>train_f1</td><td>0.64806</td></tr><tr><td>train_loss_epoch</td><td>0.56522</td></tr><tr><td>train_loss_step</td><td>0.52139</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.73358</td></tr><tr><td>val_auc</td><td>0.80418</td></tr><tr><td>val_f1</td><td>0.5731</td></tr><tr><td>val_loss_epoch</td><td>0.65354</td></tr><tr><td>val_loss_step</td><td>0.7215</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/6356kjou' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/6356kjou</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_080511-6356kjou\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_081731-fu9mizxo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/fu9mizxo' target=\"_blank\">GINConv_4_16_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/fu9mizxo' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/fu9mizxo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_16_onehot_1\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 2.3 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "2.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0375fd78b944666b556d6f82391e682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▆▆▆▆▆▇▇▆▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇███▇▇▇████</td></tr><tr><td>train_auc</td><td>▁▄▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇▇█▇█▇▇▇████</td></tr><tr><td>train_f1</td><td>▁▄▅▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇▇▇█▇▇█▇▇▇█████▇████</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▅▄▄▄▄▃▃▃▃▂▃▃▃▃▃▂▃▃▃▂▂▂▂▂▂▂▁▂▂▂▂▂▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>██▇▆▄▄▅▆▆▄▅▄▅▄▄▄▄▄▄▆▃▄▆▄▅▄▅▄▄▄▆▄▅▄▅▃▆▅▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▁▂▆▅▄▅▇▇▆▅▅▇▇▆▇▇▇▆▆▇▆▅▇▆▆▅▇▅▆▆▆▇▅▇▅█▆▇▇</td></tr><tr><td>val_auc</td><td>▁▃▅▆▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇▆▇▇█▇▇▆▇▇▇▇▇▇▇█▇▇▇▆█▆</td></tr><tr><td>val_f1</td><td>▁▂▂▇▆▅▆█▇▆▆▅█▇▇██▇██▇█▆█▆███▆▆███▆▇▆█▇▇█</td></tr><tr><td>val_loss_epoch</td><td>▇▇▇▄▄▇▃▅▃▃▅█▂▄▄▄▃▄▃▁▁▅▅▂▄▅▅▁█▆▆▄▁▄▂▆▂▄▆▃</td></tr><tr><td>val_loss_step</td><td>▆▇█▄▄▄▅▄▃▄▄▃▃▅▃▄▄▂▄▆▂▁▅▄▅▅█▃▃▃▅▄▂▄▃▂▃▄▄▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77331</td></tr><tr><td>train_auc</td><td>0.82067</td></tr><tr><td>train_f1</td><td>0.70686</td></tr><tr><td>train_loss_epoch</td><td>0.50297</td></tr><tr><td>train_loss_step</td><td>0.36652</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.75182</td></tr><tr><td>val_auc</td><td>0.80495</td></tr><tr><td>val_f1</td><td>0.68224</td></tr><tr><td>val_loss_epoch</td><td>0.51517</td></tr><tr><td>val_loss_step</td><td>0.46002</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/fu9mizxo' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/fu9mizxo</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_081731-fu9mizxo\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_082934-1b57pf19</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/1b57pf19' target=\"_blank\">GINConv_4_16_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/1b57pf19' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/1b57pf19</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_16_onehot_1\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 2.3 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "2.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.7 K     Total params\n",
      "0.011     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "764cb0e2a5e24cb5ba62a4ad01fac9b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▆▇▆▇▇▇▇▇▆▇▇▇▇▇██▇▇▇▇█▇█▇█▇▇▇▇██▇▇█▇▇</td></tr><tr><td>train_auc</td><td>▁▄▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇▇▇█▇▇████▇██▇████</td></tr><tr><td>train_f1</td><td>▁▅▆▇▇▇▇▇▇▇██▇█▇▇▇▇██▇▇███▇█▇█▇█████▇▇██▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▄▃▃▄▄▃▃▂▃▂▂▂▃▃▂▂▂▂▃▂▂▂▂▃▁▂▂▂▃▂▁▂▂▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▆▇▄▇▃▆▇▄▅▃▆▃▆▄▅▅▃▁▄▇▄▄▄▁▁▄▄▃▃▅▆▃▃▆▂▁▄▄▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▁▅▄▅▇▇▄▇▇█▇▇█▅▇▇█▇▆▆██▇▅█▇▆█▇▇▇██▇▆▇▇▇▇</td></tr><tr><td>val_auc</td><td>▁▄▅▇▆█▇▆▇▇▇▇▆▇▆▇▇▇▆▇▇▇█▇▆▇█▇█▇▇▇██▇▇██▆▇</td></tr><tr><td>val_f1</td><td>▁▂▅▅▆▇▇▅▇▇█▇▇█▆▇███▆▇██▇▆█▇▇█████▇█▇▇██▇</td></tr><tr><td>val_loss_epoch</td><td>▆▆▆▃▄▄▂▅▂▃▃▃▄▅▃▃▃▁▅▃▆▃▄▄█▃▄▄▃▂▂▃▁▄▃▅▆▃▂▁</td></tr><tr><td>val_loss_step</td><td>▇█▅▇▆▅▄▆▆▅▄▅▅▄▆▄▅▆▄▅▄▅▅▇▅▅▅▆▅▅▄▅▅▅▆▆▆▅▅▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.76508</td></tr><tr><td>train_auc</td><td>0.82595</td></tr><tr><td>train_f1</td><td>0.67093</td></tr><tr><td>train_loss_epoch</td><td>0.49789</td></tr><tr><td>train_loss_step</td><td>0.46329</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.75547</td></tr><tr><td>val_auc</td><td>0.813</td></tr><tr><td>val_f1</td><td>0.65641</td></tr><tr><td>val_loss_epoch</td><td>0.46094</td></tr><tr><td>val_loss_step</td><td>0.29591</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/1b57pf19' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/1b57pf19</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_082934-1b57pf19\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_084130-81zo4h4h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/81zo4h4h' target=\"_blank\">GINConv_4_32_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/81zo4h4h' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/81zo4h4h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_32_onehot_1\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 8.2 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "8.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.7 K     Total params\n",
      "0.035     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▅▆▇▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇██▇██▇█</td></tr><tr><td>train_auc</td><td>▁▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇█▇████</td></tr><tr><td>train_f1</td><td>▁▆▆▆▇▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▅▄▄▃▄▃▄▄▃▄▃▃▃▃▃▃▃▃▃▃▂▂▂▃▂▂▂▂▂▂▂▁▂▂▁▂▁</td></tr><tr><td>train_loss_step</td><td>▇█▆▄▅▆▄▆▃▇▂▆▄█▄▅▅▆▂▆▄▄▄▂▇▂▇▄▃█▃▄▃▂▁▄▂▂▄▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▆▄▇▇▇▄▆█▇▇▅▆▇█▅▇▇▇█▇▆▇▇▇▇▇▅█▆▇▆▇▇▅██▅▇</td></tr><tr><td>val_auc</td><td>▁▃▄▃▅▇▆▄▆▇▆▇▄▇▇▇▅▆▇▆▇█▇▅▆▆▆▇▅▆▆▅▅▆▇▇██▇█</td></tr><tr><td>val_f1</td><td>▁▃█▄▇▇▇▇▇▇▇█▆▆▇█▆▇▇▇▇▇▇▇█▇█▇▆█▇▇█▇▇▆██▆█</td></tr><tr><td>val_loss_epoch</td><td>▅█▅▃▂▁▃▇▂▂▂▁▄▃▂▁▁▁▂▂▁▂▂▂▂▂▃▂▄▂▅▃▅▃▄▄▃▂▃▄</td></tr><tr><td>val_loss_step</td><td>▃▇▄▄▁▂▃▅▂▁▂▃▅▄▃▁▃▁▃▂▆▄▁▆▁▂▂▄▄▃▂▄▃▂▅▃▃█▂█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.81353</td></tr><tr><td>train_auc</td><td>0.86295</td></tr><tr><td>train_f1</td><td>0.75</td></tr><tr><td>train_loss_epoch</td><td>0.45075</td></tr><tr><td>train_loss_step</td><td>0.48264</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.75182</td></tr><tr><td>val_auc</td><td>0.82975</td></tr><tr><td>val_f1</td><td>0.72358</td></tr><tr><td>val_loss_epoch</td><td>0.64445</td></tr><tr><td>val_loss_step</td><td>0.8154</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/81zo4h4h' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/81zo4h4h</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_084130-81zo4h4h\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52d58b5aa0e348f98cc71f23b325a7d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_085315-qz4hcg7j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qz4hcg7j' target=\"_blank\">GINConv_4_32_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qz4hcg7j' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qz4hcg7j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_32_onehot_1\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 8.2 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "8.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.7 K     Total params\n",
      "0.035     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▅▆▆▆▆▆▆▇▇▇▆▆█▇▇▇▇▇▇▇█▇▇▇█▇▇▇██▇█▇███▇</td></tr><tr><td>train_auc</td><td>▁▄▄▅▅▆▆▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇▇█▇█████████</td></tr><tr><td>train_f1</td><td>▁▃▅▅▆▆▇▆▇▆▇▇▇▇▆█▇▇▇▇▇█▇▇▇█▇█▇▇▇████▇▇▇█▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▄▄▃▃▃▃▃▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>██▆▅▅▅▄▄▄▆▂▅▄▆▄▃▅▄▄▅▃▅▃▃▅▄▇▄▃▅▄▄▃▂▁▄▃▄▅▆</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▆▃▅▆█▇▆▄▅▆▅▁█▇▇▆▆▇▂▂▇▄▇▃▆▅▇▇▇▇▇▇▄▇▃█▄▄█▆</td></tr><tr><td>val_auc</td><td>▁▄▅▄▆█▇▆▇▆▅▅▇▇▇▅▆▇▅▆▆▆▆▅▅▇▆▆▆▇▆▅▆▆▆▇▆▅▇▇</td></tr><tr><td>val_f1</td><td>▅▁▄▅▇█▄▇▇▆▇▇███▇▅▇▇▇▇▇█▇▇████▇█▇█▇▇██▇██</td></tr><tr><td>val_loss_epoch</td><td>▆▄▃▃▃▃▄▅▄▃▄▆▂▃▃▃▁▂▇▆▂█▄▅▃▃▄▃▂▂▄▂▇▂▇▂▅▄▂▅</td></tr><tr><td>val_loss_step</td><td>▅▃▁▃▂▃▂▄▂▂▁▆▂▃▁▃▂▁▆▇▃▂▁▂▄▁▂▂▄▅▂▄▂█▅▁▃▃▄▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.75868</td></tr><tr><td>train_auc</td><td>0.80841</td></tr><tr><td>train_f1</td><td>0.67407</td></tr><tr><td>train_loss_epoch</td><td>0.51154</td></tr><tr><td>train_loss_step</td><td>0.5881</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.70803</td></tr><tr><td>val_auc</td><td>0.79018</td></tr><tr><td>val_f1</td><td>0.69466</td></tr><tr><td>val_loss_epoch</td><td>0.64091</td></tr><tr><td>val_loss_step</td><td>0.72903</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qz4hcg7j' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qz4hcg7j</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_085315-qz4hcg7j\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_090521-2xmc9ogm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/2xmc9ogm' target=\"_blank\">GINConv_4_32_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/2xmc9ogm' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/2xmc9ogm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_32_onehot_1\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 8.2 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "8.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.7 K     Total params\n",
      "0.035     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06d7a7c3dac549659048532e720614d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▁▃▃▅▅▅▅▆▆▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▆▆▇▇▇▇▇▇▇█▇█▇</td></tr><tr><td>train_auc</td><td>█▃▂▆▄▄▃▃▃▃▄▃▁▃▁▃▅▃▄▃▁▄▄▂▃▄▄▃▆▄▅▅▄▅▆▅▅▅▇▆</td></tr><tr><td>train_f1</td><td>▁▂▄▃▄▅▅▅▄▆▆▆▆▆▇▆▇▇▇▆▇▇▇▇▇█▇▆▇▇▇▇█▇▇██▇█▇</td></tr><tr><td>train_loss_epoch</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▄▆▆▆▆▆▆▇▇▇▇▇▆▇▇▆▇▇▇▇▆█▇▇▆▇▇▆▇▆▇▇▇█▆▇▇▆▇</td></tr><tr><td>val_auc</td><td>█▄▅▅▃▂▂▁▁▁▁▁▁▁▁▂▂▁▁▁▂▂▂▁▂▃▂▁▁▃▄▄▂▅▄▆▅▅▇▄</td></tr><tr><td>val_f1</td><td>▁▄▇▇▇▇▇▇▇█▇▇▇▇█▇▇▇██▇██▇█▇▇▇██▇▇█▇█▇█▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▂▁▃▅▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▂▁▂▂</td></tr><tr><td>val_loss_step</td><td>█▃▂▃▂▂▂▂▄▂▁▁▂▂▁▁▂▁▂▁▂▂▁▂▂▃▃▁▂▂▂▂▂▁▃▂▂▃▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.73035</td></tr><tr><td>train_auc</td><td>0.49271</td></tr><tr><td>train_f1</td><td>0.66817</td></tr><tr><td>train_loss_epoch</td><td>0.56286</td></tr><tr><td>train_loss_step</td><td>0.69738</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.73723</td></tr><tr><td>val_auc</td><td>0.44566</td></tr><tr><td>val_f1</td><td>0.63636</td></tr><tr><td>val_loss_epoch</td><td>0.75986</td></tr><tr><td>val_loss_step</td><td>0.90394</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/2xmc9ogm' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/2xmc9ogm</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_090521-2xmc9ogm\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_091708-7j3fhhdv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/7j3fhhdv' target=\"_blank\">GINConv_4_32_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/7j3fhhdv' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/7j3fhhdv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_32_onehot_1\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 8.2 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "8.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.8 K     Total params\n",
      "0.035     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3db632e0916e4192b6991771a2c1bc10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▆▆▆▇▇▆▆▆▆▇▇▇▇▇▇▇▇▇▆▇▇██▇▇▇█▇▇▇▇▇████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▇▆▇▇▇▇▇▇▇▇██▇▇▇███▇▇█████▇███████▇██</td></tr><tr><td>train_f1</td><td>▁▅▅▆▇▆▇▇▇▆▆▆▆▆▇▇▆▇▇▇▇▇▆▆▆██▇▇▇▇▇██▇▇▇███</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▃▂▂▂▂▁▃▂▂▂▁▁▁▂▁▁▂▁▂▂▁▂▂▂</td></tr><tr><td>train_loss_step</td><td>██▅█▇▅▅▆▆▅▅▄▄▃▅▃▄▃▃▄▃▄▅▄▂▆▄▂▃▅▃▂▁▁▃▄▂▃▂▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▄▇▆▇▆▆▇▇▆▇▄▇▆▆▆▅▇▆▅▆▆▇██▆▇▇▇██▆▆▄▇▇▇█▇</td></tr><tr><td>val_auc</td><td>▁▃▄▇▄▆▃▅▇▅▆▆▅█▆▂▃▇▅▄▆▄▄▆██▃▅▆▇█▇▅▇▃▅▇▄▆▆</td></tr><tr><td>val_f1</td><td>▁▃▅▇▇▇▆▇█▇▇▇▅██▇▇██▇▆▇▇███▇▇▇▇▇██▇▅██▇█▇</td></tr><tr><td>val_loss_epoch</td><td>▄▇▄▂▂▂▂▂▂▂▁▁▄▁▂▂▃▂▂▃▅▂▃▁▁▁▄▃▃▂▂▂▂▃█▁▄▂▃▄</td></tr><tr><td>val_loss_step</td><td>▄▅▃▂▂▁▄▃▂▃▂▂▄▂▂▃▂▃▂▂▃▃▂▃▂▁▂▃▂▃▂▃▂▂▃▃▄▁▂█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.81261</td></tr><tr><td>train_auc</td><td>0.86368</td></tr><tr><td>train_f1</td><td>0.76888</td></tr><tr><td>train_loss_epoch</td><td>0.46857</td></tr><tr><td>train_loss_step</td><td>0.47212</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.74453</td></tr><tr><td>val_auc</td><td>0.81024</td></tr><tr><td>val_f1</td><td>0.63542</td></tr><tr><td>val_loss_epoch</td><td>0.66647</td></tr><tr><td>val_loss_step</td><td>0.97152</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/7j3fhhdv' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/7j3fhhdv</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_091708-7j3fhhdv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_092907-3hbt6xcv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/3hbt6xcv' target=\"_blank\">GINConv_4_32_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/3hbt6xcv' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/3hbt6xcv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_32_onehot_1\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 8.2 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "9.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "9.8 K     Total params\n",
      "0.039     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▆▇▇▆▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇███████████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▇▇▇▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇█▇████████████</td></tr><tr><td>train_f1</td><td>▁▆▆▆▆▆▇▆▇▆█▇▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇███▇███████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▅▄▄▃▃▃▄▃▃▃▄▃▃▃▂▂▃▂▂▂▃▂▂▂▂▂▁▂▂▂▁▁▂▂▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▇█▇█▃▅▃▆▆▇▄▅▂▆▅▃▄▄▅▅▄▂▇▁▂▅▃▄▅▆▂▄▃▄▂▄▂▄▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▅▆█▇█▇▇▅▇▇███▇█▇▇█▇▄▇█▇▇██▇█▆▇▆█▆▇▇▆▇▆</td></tr><tr><td>val_auc</td><td>▁▂▄▆█▇█▅▇▇▇▆▅▆▇▆▇▇▇▆▅█▇▅▆▄▇▆▆▄▆▅▅▆▅▇▅▅▅▆</td></tr><tr><td>val_f1</td><td>▁▄▅▆█▇▇▇█▅▇████▇█▇▇█▇▅▇█▇▇██▇▇▆▇█▇▇▇▇▇▇█</td></tr><tr><td>val_loss_epoch</td><td>▄▄▃▂▁▂▁▃▁▄▂▂▂▁▂▂▃▂▃▃▃█▂▁▂▃▄▂▃▃▄▁▂▃▃▄▂▄▂▃</td></tr><tr><td>val_loss_step</td><td>▆▅█▄▂▄▅▃▃▃▂▂▃▃▃▃▄▃▄▃▄▄▂▄▃▄▂▄▁▂▅▄▄▆▄▆▄▄▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.81536</td></tr><tr><td>train_auc</td><td>0.8624</td></tr><tr><td>train_f1</td><td>0.75306</td></tr><tr><td>train_loss_epoch</td><td>0.43344</td></tr><tr><td>train_loss_step</td><td>0.39276</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.72263</td></tr><tr><td>val_auc</td><td>0.80737</td></tr><tr><td>val_f1</td><td>0.70312</td></tr><tr><td>val_loss_epoch</td><td>0.6176</td></tr><tr><td>val_loss_step</td><td>0.6529</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/3hbt6xcv' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/3hbt6xcv</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_092907-3hbt6xcv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_094106-lkj4bti3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/lkj4bti3' target=\"_blank\">GINConv_4_64_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/lkj4bti3' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/lkj4bti3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_64_onehot_1\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 30.7 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "32.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "32.8 K    Total params\n",
      "0.131     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▅▆▆▆▆▆▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇█▇█▇▇█</td></tr><tr><td>train_auc</td><td>▁▄▅▅▆▆▆▆▆▆▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇█▇███▇█</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▆▆▇▇▆▇▆▇▇▇▆▇▇▇▇▇▇██▇▇██▇▇▇▇████▇██</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▅▄▄▄▄▄▄▄▄▃▄▃▄▃▃▃▃▃▃▃▂▃▃▃▂▂▂▃▂▁▂▁▁▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▆▇▄█▆▃▄▂▅▅▄▅▃▇▅▄▂▅▄▃▄▄▆▃▄▄▄▃▃▃▃▃▃▂▃▄▁▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▃▄▁▆▇▇▆▆▇▆▇▇▇▇▄▆▇▇▇▆▇▇█▅▇▆▆▇▇▇▇▇█▂▇▇▇▆▇▇</td></tr><tr><td>val_auc</td><td>▁▃▂▂▆▅▃▄▅▅▆▅▅▅▃▅▅▆▅▅▆▅▆▆█▄▁▇█▆▇▆▇▂▄█▇▅▅▅</td></tr><tr><td>val_f1</td><td>▁▃▇▇██▇█▇▇▇▇█▇▇█▇██▇▇▇█▇▇█▇██▇▇██▇▇▇█▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>▆▄▆▃▁▂▂▂▂▂▁▂▂▁▆▂▁▂▃▁▁▃▃▅▄▃▃▁▃▂▁▂▂█▂▁▁▃▁▂</td></tr><tr><td>val_loss_step</td><td>▅▄▅▂▂▂▂▂▂▁▁▃▂▃▅▃▁▂▂▃▂▂▃▃▄▂▂▃▂▂▁▃▁▂▂▃▂█▄▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.82358</td></tr><tr><td>train_auc</td><td>0.88967</td></tr><tr><td>train_f1</td><td>0.77688</td></tr><tr><td>train_loss_epoch</td><td>0.40175</td></tr><tr><td>train_loss_step</td><td>0.34419</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.76277</td></tr><tr><td>val_auc</td><td>0.81873</td></tr><tr><td>val_f1</td><td>0.65608</td></tr><tr><td>val_loss_epoch</td><td>0.55742</td></tr><tr><td>val_loss_step</td><td>0.51671</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/lkj4bti3' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/lkj4bti3</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_094106-lkj4bti3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_095311-lqb7ptyz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/lqb7ptyz' target=\"_blank\">GINConv_4_64_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/lqb7ptyz' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/lqb7ptyz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_64_onehot_1\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 30.7 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "32.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "32.8 K    Total params\n",
      "0.131     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "670fb4bbca8d4a3c89c9e4cb6d0735c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▄▄▅▅▅▅▆▆▅▆▇▆▆▆▆▆▇▆▆▆▆▇▇▇▇▇▇▇▇█▇▇▇███▇▇</td></tr><tr><td>train_auc</td><td>▁▃▅▄▅▆▅▅▅▆▅▆▇▆▇▇▇▆▇▇▇▇▆▇▇█▇▇▇▇█▇█▇▇▇████</td></tr><tr><td>train_f1</td><td>▁▃▄▄▅▆▅▅▆▆▅▆▇▆▆▇▆▇▇▆▇▇▆▇▇▇▇▇▇▇▇█▇▇▇███▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▄▄▄▃▃▅▃▃▃▃▃▃▃▂▃▂▃▃▂▃▂▂▃▂▂▂▂▂▂▂▂▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▇█▆▇▆▆▄▅▄▆▅▆▄▆▅▅▃▄▄▄▅▄▆▆▄▆▅▅▄▄▅▄▅▄▄▄▄▄▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▅▄▇▇▃▆▇▇▇▅▇▇▇▆▅▇▇█▇▁▇█▆▆▇▆▇▇▃▇▇▆▇█▇██▆██</td></tr><tr><td>val_auc</td><td>▁▄▆▆▃▃▄▆▇▆▅▆▇▆▅█▅▇▆▆▆▇▄▆▆▅▇▇▅▆▆▇▇██▆█▅▇▇</td></tr><tr><td>val_f1</td><td>▂▁▅▅▇▇▇▇█▇▇▆█▇▇█▇▇▇▆▇█▇▇▆▇█▇▇▆▇▇▇█▇▇█▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>▃▅▂▃▅▃▂▂▁▄▂▂▂▁▄▁▂▁▃▆▂▂▅▃▃▆▃▁█▂▁▄▃▂▁▁▂▃▁▁</td></tr><tr><td>val_loss_step</td><td>▄▅▂▃▆▅▃▂▃▄▃▄▃▄▄▃▃▃▂█▃▃▂▃▅▃▂▄▁▃▄▄▂▃▅▃▄▄▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.7925</td></tr><tr><td>train_auc</td><td>0.82534</td></tr><tr><td>train_f1</td><td>0.74466</td></tr><tr><td>train_loss_epoch</td><td>0.44555</td></tr><tr><td>train_loss_step</td><td>0.30432</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.73358</td></tr><tr><td>val_auc</td><td>0.79078</td></tr><tr><td>val_f1</td><td>0.67265</td></tr><tr><td>val_loss_epoch</td><td>0.53899</td></tr><tr><td>val_loss_step</td><td>0.49296</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/lqb7ptyz' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/lqb7ptyz</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_095311-lqb7ptyz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9724a606ae64302b001d719b1e068c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_100614-hux08wmk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/hux08wmk' target=\"_blank\">GINConv_4_64_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/hux08wmk' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/hux08wmk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_64_onehot_1\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 30.7 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "32.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "32.8 K    Total params\n",
      "0.131     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8630ebfd83aa4d00846c1a3312191810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▂▂▄▄▃▄▅▅▄▅▆▅▆▆▅▆▇▆▆▇▆▇▇▇▇▇█▇▇█▇▇███▇▇▇</td></tr><tr><td>train_auc</td><td>▄▆▆▅▄▄▅▇▇▇██▇▅▆▆▅▃▃▃▃▁▁▃▂▃▃▄▄▃▄▄▅▆▅▄▄▃▄▃</td></tr><tr><td>train_f1</td><td>▁▃▁▃▃▂▂▃▅▅▄▅▆▆▆▆▄▆▇▆▆▇▆▇▇▇▇▇█▆▇▇▇▇███▇▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>▄█▂▂▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▄▆▆▇▆▅▆▆▇▇▇▇▇▇▆▇▇▇▆▆▆▅▆▇▇▆▆▇▇▆▇▆▇▇▇▇▆█▆</td></tr><tr><td>val_auc</td><td>█▇▇▇▆▇▇██████████▇▆▅▃▁▁▁▃▆▆▆▆▅▆█████▇▃▆▆</td></tr><tr><td>val_f1</td><td>▃▁▅▄▇▅▂▆▅▆▆▆▆▆▆▅▆▆▆▅▄▅▁▆▆▆▄▆▇▇▅▇▄▇▆▇▆▃█▄</td></tr><tr><td>val_loss_epoch</td><td>▂█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▄▅▁▁▁▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.75868</td></tr><tr><td>train_auc</td><td>0.50944</td></tr><tr><td>train_f1</td><td>0.69794</td></tr><tr><td>train_loss_epoch</td><td>0.4992</td></tr><tr><td>train_loss_step</td><td>0.38286</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.69343</td></tr><tr><td>val_auc</td><td>0.6552</td></tr><tr><td>val_f1</td><td>0.48148</td></tr><tr><td>val_loss_epoch</td><td>0.84491</td></tr><tr><td>val_loss_step</td><td>0.62905</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/hux08wmk' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/hux08wmk</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_100614-hux08wmk\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ee4b4a63bd48ae97fb984f81eb513d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_101846-1gq9p840</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/1gq9p840' target=\"_blank\">GINConv_4_64_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/1gq9p840' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/1gq9p840</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_64_onehot_1\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 30.7 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "32.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "32.9 K    Total params\n",
      "0.131     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▅▅▆▆▆▆▆▇▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇█▆▇▇▇▇█▇█▇▇██</td></tr><tr><td>train_auc</td><td>▁▅▅▅▆▅▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇▇▇█▇█████</td></tr><tr><td>train_f1</td><td>▁▆▅▆▅▅▆▆▇▇▆▇▆▇▇▇▇▆▇▇▇▇▇▇██▇█▇▇▇▇▇█▇██▇██</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▅▄▅▄▄▃▃▃▃▄▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▃▂▂▂▂▁▃▁▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>▆▅▇▄▅▃▄▅▇▃▄▃▄▃▄▄▂▃▅▃▃▂▄▃▅▄▃▄▄▆▃▃▃▄▅▁▂▂▄█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▇▅▆▇▆▇▇▆▆▇▇▂▆▇▅▇▇▅▅▇▅▇▇▇▆█▇▆▆▆▇▆█▇▇▇▇▆▅</td></tr><tr><td>val_auc</td><td>▂▄▁▇▇▆▇▆▇▅▆▆▂▂▃▄▆▅▇▅▆▇▆▇▆▆▇▇▇▅▅▆▆█▇▇▃▇▇▇</td></tr><tr><td>val_f1</td><td>▁▇▇▇▇▇▇██▇▇▇▇▇█▆█▇█▆█▆██▇▇█▇▆▇▇█▇████▇▆▆</td></tr><tr><td>val_loss_epoch</td><td>█▄▅▃▂▂▃▃▃▃▃▃▅▃▄▆▃▂▃▆▂▅▄▁▃▇▅▃▁▄▁▂▃▂▃▁▂▃▂▅</td></tr><tr><td>val_loss_step</td><td>█▄▆▂▂▄▂▁▁▃▃▃▇▄▆▃▆▃▄▅▄▃▄▄▄▄▃▃▄▄▄▇▃▆▂▆▆▄▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.82541</td></tr><tr><td>train_auc</td><td>0.88587</td></tr><tr><td>train_f1</td><td>0.78071</td></tr><tr><td>train_loss_epoch</td><td>0.43253</td></tr><tr><td>train_loss_step</td><td>0.67256</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.71168</td></tr><tr><td>val_auc</td><td>0.82148</td></tr><tr><td>val_f1</td><td>0.54335</td></tr><tr><td>val_loss_epoch</td><td>0.6167</td></tr><tr><td>val_loss_step</td><td>0.51296</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/1gq9p840' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/1gq9p840</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_101846-1gq9p840\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_103041-pktn3nzw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/pktn3nzw' target=\"_blank\">GINConv_4_64_onehot_1</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/pktn3nzw' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/pktn3nzw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_64_onehot_1\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 30.7 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "37.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "37.0 K    Total params\n",
      "0.148     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f1561818455437782e7c8978c47519f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▆▅▆▆▆▆▆▆▆▆▆▇▇▇▆▇▇▇▆▆▇▇▇▇▇▇▇█▇█▇▇▇███▇</td></tr><tr><td>train_auc</td><td>▁▄▅▅▆▆▆▆▆▆▆▆▆▆▇▇▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇█▇██████</td></tr><tr><td>train_f1</td><td>▁▅▄▆▅▆▆▆▆▆▇▆▆▆▇▇▆▆▇█▇▆▆▇▇▇▇▇█▇█▇███████▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▅▄▄▄▄▄▃▄▄▃▃▃▃▃▃▃▃▃▃▃▃▃▂▃▃▃▂▂▂▃▂▂▁▂▂▂</td></tr><tr><td>train_loss_step</td><td>█▆▇▆▅▇▆▄▆▆▅▆▅▃▄▂▅▆▄█▃▄▇▄▇▄▃▆▄▄▄▁▅▄▄▄▄▃▃▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▄▆▇▄▇▇▁▇▇▇▇▆▇▅▇▇▇▇█▇▆▇█▇█▇▇▇▇▆▇█▇▇▇▇█▃▇▇</td></tr><tr><td>val_auc</td><td>▂▂▅▆▆█▁▃▃▆▅▁▃▅▆▅▆▆▇▅▄▆▅▂▇▄█▆▆▄█▅▆▅▅▄▆▂▂▅</td></tr><tr><td>val_f1</td><td>▁▅█▇██▇▇▇██▇▇██▆▆██▇▆████▇█▇▇▆███▇█▆▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>▅▃▂▆▂▁█▂▃▁▂▂▂▄▂▂▂▂▃▂▂▂▃▂▂▃▂▂▁▂▁▂▂▂▃▂▁▅▂▂</td></tr><tr><td>val_loss_step</td><td>▄▅▃▄▁▂█▂▃▂▂▂▂▄▃▂▂▂▂▃▂▂▁▂▂▁▂▂▃▂▃▂▂▂▂▃▃▂▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.81261</td></tr><tr><td>train_auc</td><td>0.88471</td></tr><tr><td>train_f1</td><td>0.76135</td></tr><tr><td>train_loss_epoch</td><td>0.4183</td></tr><tr><td>train_loss_step</td><td>0.44855</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.72628</td></tr><tr><td>val_auc</td><td>0.80291</td></tr><tr><td>val_f1</td><td>0.59016</td></tr><tr><td>val_loss_epoch</td><td>0.58308</td></tr><tr><td>val_loss_step</td><td>0.53925</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_1</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/pktn3nzw' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/pktn3nzw</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_103041-pktn3nzw\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f191fc5cb8a9493f9d5bc6f251a13dd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_104250-l0j6x9jg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/l0j6x9jg' target=\"_blank\">GINConv_2_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/l0j6x9jg' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/l0j6x9jg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_16_onehot_2\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3c65c8812c1417c8168228df0d649f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▇▇▇▇▇▇█▇▇▇██▇▇█▇▇██▇███▇▇▇█▇█▇███▇█</td></tr><tr><td>train_auc</td><td>▁▄▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇▇▇█▇█▇▇█▇▇███▇▇</td></tr><tr><td>train_f1</td><td>▁▄▆▆▆▆▇▆▇▇▇█▇▇▇█▇▇▇█▇▇█▇▇█▇▇▆▇▇█▇█▇▇▇█▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▄▄▃▃▃▃▃▃▂▃▃▃▂▃▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂</td></tr><tr><td>train_loss_step</td><td>█▇▅▅▄▅▅▆▅▄▃▅▄▄▆▂▃▄▁▇▃▆▄▅▄▂▅▅▅▃▇▃▄▅▄▃▃▅▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▃▅▅▆▇▇█▇▇▇▇▇▇▅▇█▇▇▆▇▅▇▇▁▆▇▆███▇▇█▆▇█▆▂▆▇</td></tr><tr><td>val_auc</td><td>▁▃▄▆▆▇▇▅▆▆▇▆▇▆▆▆▆▆▆▆▆▆▆▅▇▆▅██▇▇▆▆▆▆▆▆▄▃▇</td></tr><tr><td>val_f1</td><td>▁▅▄▅▇▇██▇▇▇▇██▇█▇██▇▄▇█▇▅██▇▇█▇█▇▇███▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>▃▂▂▂▂▁▂▂▁▁▁▁▂▃▂▁▂▂▂▁▃▂▃█▂▂▂▂▂▂▂▂▂▂▂▁▂▆▂▂</td></tr><tr><td>val_loss_step</td><td>▆▃▄▂▄▃▂▄▃▃▂▂▃▅▃▂▂▃▄▄▆▃▅▂▄▃▂▃▃▄▄▃▄█▂▆▃▁▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.76143</td></tr><tr><td>train_auc</td><td>0.81282</td></tr><tr><td>train_f1</td><td>0.68132</td></tr><tr><td>train_loss_epoch</td><td>0.50844</td></tr><tr><td>train_loss_step</td><td>0.49941</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.72263</td></tr><tr><td>val_auc</td><td>0.82949</td></tr><tr><td>val_f1</td><td>0.66957</td></tr><tr><td>val_loss_epoch</td><td>0.53096</td></tr><tr><td>val_loss_step</td><td>0.55961</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/l0j6x9jg' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/l0j6x9jg</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_104250-l0j6x9jg\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f521c55e8fd6408fa05f0aef37b66999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_105452-50rn4tiv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/50rn4tiv' target=\"_blank\">GINConv_2_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/50rn4tiv' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/50rn4tiv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_16_onehot_2\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f61bd740b2d430eabd8a03d327f74ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▃▃▄▄▄▅▅▅▅▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█▇▇</td></tr><tr><td>train_auc</td><td>▄▄▄▄▃▂▂▁▂▁▂▂▂▁▃▃▄▅▅▆▅▄▄▄▅▆▇▅▆▆▆▇▇▇▆▇▇▇▇█</td></tr><tr><td>train_f1</td><td>▅▂▁▃▃▄▄▅▆▅▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇█▇███▇███</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▃▃▁▁▂▂▂▁▁▁▂▂▂▁▂▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▇▇▇▇▇▇▆▅▅▅▅▄▄▆▃▄▅▁▅▂▄▄▅▅▂▅▅▃▂▅▃▃▅▃▃▃▅▂▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▁▁▂▄▆▆▅▇▄▆▆▇█▇▅▇▃▇▅▆▃▅▆▅▆▆▇▆▅▇▇▆▆▇▇▇▅▆▇</td></tr><tr><td>val_auc</td><td>▆▆▆▃▁▁▁▁▁▁▁▁▁▁▂▄██████▆█████████████████</td></tr><tr><td>val_f1</td><td>▁▁▁▃▄▇▆▇▆▇▅█▇████▇███▇██▇██████████▇███▇</td></tr><tr><td>val_loss_epoch</td><td>██▇▇▇▆▆▇▃▅▄▄▄▄▃▄▅▅▃▃▄▆▅▄▃▄▂▂▃▄▂▄▄▃▄▁▂▅▃▄</td></tr><tr><td>val_loss_step</td><td>▆▆▆▅▅▅▅▅▃▅▃▄▃▃▃▃▃▅▃▃▄▂▂▂▂▃▂▂▃▂▂▂▂▄▄▁▃▁▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.71481</td></tr><tr><td>train_auc</td><td>0.7137</td></tr><tr><td>train_f1</td><td>0.64626</td></tr><tr><td>train_loss_epoch</td><td>0.55999</td></tr><tr><td>train_loss_step</td><td>0.57955</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.74818</td></tr><tr><td>val_auc</td><td>0.8049</td></tr><tr><td>val_f1</td><td>0.65672</td></tr><tr><td>val_loss_epoch</td><td>0.58778</td></tr><tr><td>val_loss_step</td><td>0.73228</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/50rn4tiv' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/50rn4tiv</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_105452-50rn4tiv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_110725-rpm2ame7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/rpm2ame7' target=\"_blank\">GINConv_2_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/rpm2ame7' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/rpm2ame7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_16_onehot_2\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▃▃▅▅▅▅▅▇▆▆▆▆▆▆▆▆▇▆▇▇▇▇▆▇▇▇▇▇▇█▇▇▇▇█▇▇</td></tr><tr><td>train_auc</td><td>▇▆▂▂▁▅▃▁▄▅▅███▃▂▆▄▃▂▄▃▄▁▃▁▁▂▅▄▄▄▃▂▄▆▅▅▄▃</td></tr><tr><td>train_f1</td><td>▃▄▄▃▂▅▃▁▂▂▆▄▅▄▅▆▅▅▅▆▆▆▇▇▇▆▇▇▆█▇█▇██▇▇███</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▅▆▆▅▄▄▅▅▅▅▅▄▅▆▅▅▅▅▆▆▆▆▆▇▆▇▆▇▇██▇█▇█▇█▆</td></tr><tr><td>val_auc</td><td>█▄▃▃▃▂▂▂▂▄▆▇▇▇▅▅▄▄▃▂▂▂▂▁▁▁▂▂▄▃▂▂▂▄▃▄▅▄▄▃</td></tr><tr><td>val_f1</td><td>▁▃▆▆▇▇▆▅▆▆▇▆▇▆▆▇▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇██████▇</td></tr><tr><td>val_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.70567</td></tr><tr><td>train_auc</td><td>0.4661</td></tr><tr><td>train_f1</td><td>0.64537</td></tr><tr><td>train_loss_epoch</td><td>0.58888</td></tr><tr><td>train_loss_step</td><td>0.49664</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.71898</td></tr><tr><td>val_auc</td><td>0.37075</td></tr><tr><td>val_f1</td><td>0.64186</td></tr><tr><td>val_loss_epoch</td><td>0.5477</td></tr><tr><td>val_loss_step</td><td>0.6213</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/rpm2ame7' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/rpm2ame7</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_110725-rpm2ame7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_112017-2oxtb2i4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/2oxtb2i4' target=\"_blank\">GINConv_2_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/2oxtb2i4' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/2oxtb2i4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_16_onehot_2\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.1 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▇▇▇▇▇▇██▇▇▇▇██▇▇▇█▇███▇██▇▇███▇█████</td></tr><tr><td>train_auc</td><td>▁▄▅▆▆▇▇▇▇▇▇▇▇▇█▇██▇▇▇█▇█▇█▇██▇▇█████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▇▇▇▆▇█▇▇▅▇▆▇▇▇▇▇██▇██▇▇▇▇▇▇▇█▇███▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▃▄▄▃▃▃▂▂▃▃▂▂▂▂▃▂▂▂▃▂▂▂▂▂▂▂▃▂▂▁▂▂▂▁▂▂</td></tr><tr><td>train_loss_step</td><td>█▆▆▅▅▆▄▆▂▄▅▇▄▃▄▆▆▃▄▃▃▄▂▁▃▂▃▃▅▄▃▄▅▄▄▂▅▅▅▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▃▅▆▅▅▆▆▆▆▇▇▇▇▆▇▇▇▇▇▆▆▆▅▆▇▆▇█▇█▆▇▇▇▆▇▆▇</td></tr><tr><td>val_auc</td><td>▁▄▆▅▇▅▅▅▇▇▆▆▇▇▇▆▇▇▆█▇▆▆▆▆▇▇▆▆▆▇██▆▆▆▅▆▅▆</td></tr><tr><td>val_f1</td><td>▁▃▃▆▇▆██▆█▇▇▇██████▇▇███▅█▇█▇███▇█▇▇██▇▇</td></tr><tr><td>val_loss_epoch</td><td>▆▄▆▃▃▃▄▃▃▃▂▂▄▂▂▃▃▂▂▃▂▂▃▁█▂▁▄▁▄▂▂▄▂▃▂▂▂▃▂</td></tr><tr><td>val_loss_step</td><td>█▆▇▄▅▅▆▅▄▄▄▅▃▄▂▃▃▄▂▂▄▃▅▄▄▂▆▄▄▃▅▄▃▄▄▇▅▄▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.76051</td></tr><tr><td>train_auc</td><td>0.82597</td></tr><tr><td>train_f1</td><td>0.69535</td></tr><tr><td>train_loss_epoch</td><td>0.52069</td></tr><tr><td>train_loss_step</td><td>0.46407</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.75547</td></tr><tr><td>val_auc</td><td>0.82159</td></tr><tr><td>val_f1</td><td>0.63784</td></tr><tr><td>val_loss_epoch</td><td>0.4953</td></tr><tr><td>val_loss_step</td><td>0.4271</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/2oxtb2i4' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/2oxtb2i4</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_112017-2oxtb2i4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b75cd6b22e094d9bae2b3ce9df8120bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_113339-dctayyh8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/dctayyh8' target=\"_blank\">GINConv_2_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/dctayyh8' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/dctayyh8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_16_onehot_2\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.1 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "1.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.5 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▆▆▆▆▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇█████▇██▇▇█████▇█</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇█████▇███████████</td></tr><tr><td>train_f1</td><td>▂▁▄▅▆▆▇▆▆▇▇▇▇▇▆▇▆▇█▇▇▇███▇▇█▇▇█▇▇█▇██▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▃▃▃▃▃▃▂▂▃▂▂▂▂▂▃▂▂▂▂▁▂▂▂▂▂▁▁▂▁▁▂▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▇▆▆▄▃▄▆▅▃▄▄▃▅▅▃▅▃▄▅▃▄▆▅▅▅▂▄▃▂▅▄▃▃▅▁▅▇▄▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▅▃▆▇▆▇▆▇▇▅▄▆▆█▇▇▅▅▅▃▇▇▇▇▇██▇█▇▇▇▄▆▆▇█▇▇</td></tr><tr><td>val_auc</td><td>▁▄▆▆█▄▆▆█▇▅▄█▆█▇▇▆▅▄▅▇▆▇▆▇██▇█▇▇▇▅▆▆▇▇▇▇</td></tr><tr><td>val_f1</td><td>▁▅▄▆▇█▇█▇▇██▆▇██▇█▇▇▇▇▇██▇█▇▇▇▇█▇█▇▆▇▇▇█</td></tr><tr><td>val_loss_epoch</td><td>▇▄▄▄▃▃▂▄▃▃▄▆▄▃▄▁▂█▃▃▅▂▁▄▆▁▄▅▂▄▂▄▂▄▄▂▁▂▂▂</td></tr><tr><td>val_loss_step</td><td>▅▃▄▃▂▃▃▃▂▂▄▅▂▃▂▃▂▃▂▃▂▃▄▃▃▃▅▃▃▂█▂▂▂▃▂▃▃▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77239</td></tr><tr><td>train_auc</td><td>0.81628</td></tr><tr><td>train_f1</td><td>0.71013</td></tr><tr><td>train_loss_epoch</td><td>0.51446</td></tr><tr><td>train_loss_step</td><td>0.54922</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.73723</td></tr><tr><td>val_auc</td><td>0.82562</td></tr><tr><td>val_f1</td><td>0.71654</td></tr><tr><td>val_loss_epoch</td><td>0.51671</td></tr><tr><td>val_loss_step</td><td>0.42164</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/dctayyh8' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/dctayyh8</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_113339-dctayyh8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_114659-lpehyapz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/lpehyapz' target=\"_blank\">GINConv_2_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/lpehyapz' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/lpehyapz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_32_onehot_2\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 3.7 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "4.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.2 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▇▇▇▇▇▇▇▇▇█▇▇▇▇██▇▇█▇█▇██▇▇██████████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇████▇███▇█▇█████████</td></tr><tr><td>train_f1</td><td>▁▆▆▆▇▇▇▇▇▇▇▇▇█▇▆▇▇█▇█▇█▇▇▆█▇▇▇███▇██████</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▄▄▃▄▃▃▃▃▃▂▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▆▃▅▄▆▄▄▄▅▆▄▃▂▃▅▄▂▃▃▃▁▄▃▂▁▁▃▄▂▃▃▁▃▃▂▁▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▆▅▅▇▄▃▇▇▆▇▇█▇▇▇██▆█▄▇▇▆█▇█▇█▇█▇▆▁▆▇▆▇▇▆▇</td></tr><tr><td>val_auc</td><td>▁▅▇▇▅▅▅▇▇▇██▇▆▆██▆▆▄▇▇▂▆▆▇▆▇▇▇▅▄▄▄█▇▆▅▄▆</td></tr><tr><td>val_f1</td><td>▃▂▁▆▇▇▇██▆▅█▇▇█▇▇█▇▇██▇▇█▆█▇▇█▅▇▆▇█▃▇▇▆▆</td></tr><tr><td>val_loss_epoch</td><td>▅▄▃▃▅▆▂▃▄▂▂▂▂▃▂▂▃▄▁▇▃▄▄▅▃▂▂▁▁▅▃▄█▃▁▅▃▂▄▄</td></tr><tr><td>val_loss_step</td><td>▂▂▂▁▂▃▂▁▂▂▁▁▁▁▂▂▂▂▁▃▃▂▂▂█▁▃▂▁▁▂▂▁▂▂▁▂▂▁▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77788</td></tr><tr><td>train_auc</td><td>0.84695</td></tr><tr><td>train_f1</td><td>0.72101</td></tr><tr><td>train_loss_epoch</td><td>0.47344</td></tr><tr><td>train_loss_step</td><td>0.47141</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.73358</td></tr><tr><td>val_auc</td><td>0.81153</td></tr><tr><td>val_f1</td><td>0.62944</td></tr><tr><td>val_loss_epoch</td><td>0.60912</td></tr><tr><td>val_loss_step</td><td>0.79238</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/lpehyapz' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/lpehyapz</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_114659-lpehyapz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_120006-o8pynss9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/o8pynss9' target=\"_blank\">GINConv_2_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/o8pynss9' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/o8pynss9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_32_onehot_2\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 3.7 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "4.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.2 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeac3a669cc5416887a1bd10732b3233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▅▅▅▆▅▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██</td></tr><tr><td>train_auc</td><td>▁▃▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇█▇█▇██</td></tr><tr><td>train_f1</td><td>▂▁▄▅▆▆▇▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇██▇▇██▇███</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▄▄▄▃▃▃▃▃▂▃▃▃▂▂▃▂▂▂▂▂▂▂▂▁▂▂▁▂▂▁▂▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▆▄▅▅▅▄▆▅▅▄▄▄▃▃▃▅▂▃▃▃▁▃▄▂▂▃▃▃▂▂▄▂▂▁▁▃▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▇▆█▇███▇▇██▇▇▆▇█▇███▇█▇▆▇▇▆█▇▇▇▇▇▇█▇▆▇▆</td></tr><tr><td>val_auc</td><td>▁▇▇▇▇██████████▇▇██▇██████▇▇▇▇▇▇▇▇█████▇</td></tr><tr><td>val_f1</td><td>▅▃▁█▇▅▇▆▇▇██▆▇▇▇███▇▇▇█▇▇▇█▇▇▇▇▇▇▇▇██▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▅▄▄▃▄▁▃▂▂▂▂▂▂▃▃▄▃▁▂▁▃▂▅▅▂▂▅▂▅▄▂▄▂▁▁▅▂▅▆</td></tr><tr><td>val_loss_step</td><td>▆▄▃▄▄▃▃▂▃▃▃▂▂▁▄▃▃▂▂▃▂▃▂▃▄▃▂▃▂▃▅▅▂▃▂▂▅▃▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.78245</td></tr><tr><td>train_auc</td><td>0.8401</td></tr><tr><td>train_f1</td><td>0.70833</td></tr><tr><td>train_loss_epoch</td><td>0.49469</td></tr><tr><td>train_loss_step</td><td>0.51102</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.66423</td></tr><tr><td>val_auc</td><td>0.79174</td></tr><tr><td>val_f1</td><td>0.66423</td></tr><tr><td>val_loss_epoch</td><td>0.68062</td></tr><tr><td>val_loss_step</td><td>0.84132</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/o8pynss9' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/o8pynss9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_120006-o8pynss9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_121239-66l037rl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/66l037rl' target=\"_blank\">GINConv_2_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/66l037rl' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/66l037rl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_32_onehot_2\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 3.7 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "4.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.2 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45859e8ba63e42808235a26828a7f5db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▂▃▆▆▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▆▇▇▇▇▇▇▆▇▆▇█▇█▇▇▇█▇</td></tr><tr><td>train_auc</td><td>█▆▅▅▇█▇▇▇▆▄▃▁▂▂▂▂▂▄▃▅▅▆▅▂▄▃▄▅▄▃▂▃▅▃▂▂▃▃▄</td></tr><tr><td>train_f1</td><td>▁▂▃▄▆▅▅▅▆▅▅▅▅▇▇▆▆▆▆▇▇▆▇▇▆▆█▆▆▆▇▇█▇█▇▇▆█▇</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▄▂▁▂▄▄▃▄▅▄▄▅▆▇▅▃▄▇▅▂▆▄█▄▅▆▅▅▆▆▅▆▄▇▅▂█▅</td></tr><tr><td>val_auc</td><td>█▄▄▄▆▇▇▇▇▅▃▂▁▁▁▁▁▁▁▁▃▁▃▂▁▂▁▁▃▂▁▁▂▃▂▁▁▁▂▂</td></tr><tr><td>val_f1</td><td>▁▃▆▄▅▅▆▅▆▇▆█▆▆▆▇▆▇▅▇▆█▆▇█▇▆█▆▆▇▆▆▇▇█▆▇▆▇</td></tr><tr><td>val_loss_epoch</td><td>█▃▁▂▂▂▁▂▁▁▁▁▁▁▁▁▁▂▁▁▁▂▁▂▁▁▁▂▁▂▁▁▁▂▁▁▁▁▂▁</td></tr><tr><td>val_loss_step</td><td>█▂▂▂▁▁▂▁▂▂▁▂▁▁▁▂▂▂▁▂▂▂▁▁▂▁▁▁▁▁▂▁▁▁▁▁▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.72852</td></tr><tr><td>train_auc</td><td>0.45626</td></tr><tr><td>train_f1</td><td>0.66441</td></tr><tr><td>train_loss_epoch</td><td>0.55914</td></tr><tr><td>train_loss_step</td><td>0.54925</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.72628</td></tr><tr><td>val_auc</td><td>0.32073</td></tr><tr><td>val_f1</td><td>0.64789</td></tr><tr><td>val_loss_epoch</td><td>0.54169</td></tr><tr><td>val_loss_step</td><td>0.54369</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/66l037rl' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/66l037rl</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_121239-66l037rl\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41706d4be43c4b9e9b091e32705dfbda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_122536-f5yy4tpx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/f5yy4tpx' target=\"_blank\">GINConv_2_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/f5yy4tpx' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/f5yy4tpx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_32_onehot_2\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 3.7 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "4.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.3 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▇▇▇▇▇▇▆▇▇▇▇▇▇█▇▇█▇▇▇▇▇█▇███████▇███</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇█▇▇▇██▇▇▇██▇▇█████████████</td></tr><tr><td>train_f1</td><td>▁▅▆▅▆▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇▇▆██▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▇▅▅▃▅▃▃▅▆▄▅▃▃▅▅▅▅▅▅▇▄▅▇▅▂▄▃▃▂▆▁▄▄▁▂▂▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▄▂▆▄▄▆▄▇▇▄▇▆▆▆▇▇▇▆▆▆▆▆▆▆▇█▆▆▇▇▆▅▆▇▆▆▆▆▆</td></tr><tr><td>val_auc</td><td>▁▃▇▆▁▄▆▄▆▇▄▇▆▆▄█▆▅▇▅▆▅▆▆▆█▆▅▅▇▆▄▃▇▅▇▅▆▄▆</td></tr><tr><td>val_f1</td><td>▁▄▃▆▇█▆█▇▇███████▇▆▇█▇▆█▇████▇▇▇██▇▆▆█▇█</td></tr><tr><td>val_loss_epoch</td><td>▆▃█▄▄▄▂▅▃▃▃▄▁▄▂▁▂▅▃▄▁▂▆▂▁▂▂▄▂▁▂▂▄▂▃▆▃▄▅▂</td></tr><tr><td>val_loss_step</td><td>▇▆▇▃▇▄▄▅▃▅▆▅▄▄▄▃▂▅▄▄▄▆▄▁▄▅▅▇▅▄▄▂▅▄▆▆▃▄█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.78245</td></tr><tr><td>train_auc</td><td>0.84216</td></tr><tr><td>train_f1</td><td>0.71934</td></tr><tr><td>train_loss_epoch</td><td>0.47285</td></tr><tr><td>train_loss_step</td><td>0.42466</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.74088</td></tr><tr><td>val_auc</td><td>0.82043</td></tr><tr><td>val_f1</td><td>0.69528</td></tr><tr><td>val_loss_epoch</td><td>0.49099</td></tr><tr><td>val_loss_step</td><td>0.41068</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/f5yy4tpx' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/f5yy4tpx</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_122536-f5yy4tpx\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e2cc9544f6d47a090a9a7b743b441b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_123757-6zvlpnrx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/6zvlpnrx' target=\"_blank\">GINConv_2_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/6zvlpnrx' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/6zvlpnrx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_32_onehot_2\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 3.7 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "5.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.3 K     Total params\n",
      "0.021     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█▇██████▇█▇█████</td></tr><tr><td>train_auc</td><td>▁▅▅▆▆▇▆▇▇▆▇▇▇▇▇▇▇█▇▇▇▇█▇▇▇██████▇███████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▇▇▇▆▆▇█▇▇▇▇▇█▇▇▇▇▇█▇▇█▇███▇█▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▅▄▃▄▃▃▄▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▁▂▁▁▁▂▁▂▁▂▁▁▂</td></tr><tr><td>train_loss_step</td><td>▆▅▅▅▇▄▅▄▄▆▃▂▃▄▄▃▂▂▃▅▁▂▃▃▄▆▄▁▃▂▄▄▃▄▄▃▅▃▄█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▂▁▂▇▄▆▅▆▆▇▇▅▅█▇▅█▆▅▆▆█▅▇▆▅▄▄▆▅▅▆▅▆▅▆▆▆▂▃</td></tr><tr><td>val_auc</td><td>▁▅▇▇▄▇▄▅▅▇▇▅▄█▇▅▇▆▅▅▅▅▅▅▂▆▅▆▆▃▄▄▅▄▁▅▄▄▄▃</td></tr><tr><td>val_f1</td><td>▂▁▂▇▇▆▆██▇▇████▇███████▇▇▅████▇███▇█▆▆▇▇</td></tr><tr><td>val_loss_epoch</td><td>▇▆▅▃▃▃▄▃▅▁▁▅▄▂▃▄▃▂▄▃▅▁▃▄▄▃▆▂▃█▄▃▇▅▅▄▆▆▅█</td></tr><tr><td>val_loss_step</td><td>▅▆▃▂▃▂▃▃▂▃▂▂▃▃▂▂▂▃▄▂▃▂▂▃▂▂▁▄▂▄▃▅▂▃▂▆▅▄▅█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.78885</td></tr><tr><td>train_auc</td><td>0.83385</td></tr><tr><td>train_f1</td><td>0.74016</td></tr><tr><td>train_loss_epoch</td><td>0.49709</td></tr><tr><td>train_loss_step</td><td>0.69601</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.68613</td></tr><tr><td>val_auc</td><td>0.79954</td></tr><tr><td>val_f1</td><td>0.68382</td></tr><tr><td>val_loss_epoch</td><td>0.68229</td></tr><tr><td>val_loss_step</td><td>0.79944</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/6zvlpnrx' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/6zvlpnrx</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_123757-6zvlpnrx\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_125008-fttpsx5r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/fttpsx5r' target=\"_blank\">GINConv_2_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/fttpsx5r' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/fttpsx5r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_64_onehot_2\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 13.5 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.7 K    Total params\n",
      "0.063     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▆▆▅▆▆▆▆▆▇▆▇▇▇▇▆▅▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇▇█▇</td></tr><tr><td>train_auc</td><td>▁▄▅▆▆▆▆▆▆▆▆▇▇▇▇▆▇▇▇▆▇▇▇▇▇█▇▇▇█▇█▇▇▇██▇█▇</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▆▅▇▇██▇▇▇▇▇▇██▇▇▇█▇▇██</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▄▄▄▄▄▃▃▄▃▃▃▂▃▂▄▂▂▂▂▂▁▂▃▂▁▂▂▂▂▂▁▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>▇▅▅▅▆▅▆▅▆▃▅▄▆▆█▃▅▄▇▃▄▂▅▂▅▁▃▇▃▅▁▃▄█▃▂▂▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▃▄█▇▇▇▆▆▇▇▅▄▄▇███▁▅▇▇▂▃▇▇▅▅█▇▇▄▆▆▆▆▇▇███</td></tr><tr><td>val_auc</td><td>▁▇▇▅▆▆▄▆▆▅▃▆▂▆█▇█▂▃▇▅▃▂▃▃▄▄▅▃▆▁▃▅▆▅▄▄█▄▄</td></tr><tr><td>val_f1</td><td>▁▃▇█▇███▇▇██▇██▇█▇█▆█▇▇▇▇█▄▇██▇▇▅▅████▇▆</td></tr><tr><td>val_loss_epoch</td><td>▅▄▂▃▃▂▄▃▂▂▄▅▅▂▃▂▁▆▄▃▂▅█▄▄▄▅▃▄▂▄▄▃▅▃▄▂▂▄▄</td></tr><tr><td>val_loss_step</td><td>▄▃▁▂▁▂▂▂▁▁▂▃▃▂▁▂▂▅▃▃▂▃▃▂▄▆▁▂▂▂▁█▅▁▄▄▂▃▄▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.78519</td></tr><tr><td>train_auc</td><td>0.84956</td></tr><tr><td>train_f1</td><td>0.73918</td></tr><tr><td>train_loss_epoch</td><td>0.46293</td></tr><tr><td>train_loss_step</td><td>0.40257</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.74818</td></tr><tr><td>val_auc</td><td>0.80644</td></tr><tr><td>val_f1</td><td>0.58683</td></tr><tr><td>val_loss_epoch</td><td>0.63689</td></tr><tr><td>val_loss_step</td><td>0.85112</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/fttpsx5r' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/fttpsx5r</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_125008-fttpsx5r\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_130212-lo8m3l4i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/lo8m3l4i' target=\"_blank\">GINConv_2_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/lo8m3l4i' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/lo8m3l4i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_64_onehot_2\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 13.5 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.7 K    Total params\n",
      "0.063     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▄▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▆▇█▇█▇▇▇▇▇████████</td></tr><tr><td>train_auc</td><td>▁▃▄▅▅▅▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▆▇▇▇▇▇█▇▇▇▇▇▇████▇</td></tr><tr><td>train_f1</td><td>▃▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇██▇█▇█▇██████████</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▃▃▂▃▃▂▂▃▃▃▂▂▂▂▂▂▂▂▁▂▂▂</td></tr><tr><td>train_loss_step</td><td>█▇▆▆▇▇▅▅▄▄▅▄▅▅▆▅▄▄▅▂▂▇▅▅▁▁▂▆▃▅▄▁▃▅▃▂▂▄▁▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▅▇▇▇▇▆█▇▅▇▆█▇█▇█▇▇▇▆██▇▇▆▇▇▄▇▇█▆▇▇▇▆▇▆</td></tr><tr><td>val_auc</td><td>▁▅▇█▇█▇▇█▇▇▇▇██▇▇▇▇▇▇▆▇▆▆█▅▆▆▆▇▆▇▇▆▇▆▆▆█</td></tr><tr><td>val_f1</td><td>▁▃▅▇█▇▇█▇████▇▇██▇██▇█▇██▇██▇█▇▇█▆██████</td></tr><tr><td>val_loss_epoch</td><td>█▆▄▃▄▃▃▄▄▄▇▃▇▁▄▄▃▁▁▄▃▄▄▄▅▄▆▅▄▇▄▅▃▅▃▄▃▄▅▅</td></tr><tr><td>val_loss_step</td><td>█▆▄▄▃▃▂▄▃▂▅▄▄▄▁▄▅▂▂▅▅▅▂▆▇▂▅▄▁▂▅█▃▁▃▂▆▅▄▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77971</td></tr><tr><td>train_auc</td><td>0.84998</td></tr><tr><td>train_f1</td><td>0.72074</td></tr><tr><td>train_loss_epoch</td><td>0.46589</td></tr><tr><td>train_loss_step</td><td>0.45738</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.70438</td></tr><tr><td>val_auc</td><td>0.82358</td></tr><tr><td>val_f1</td><td>0.7033</td></tr><tr><td>val_loss_epoch</td><td>0.57789</td></tr><tr><td>val_loss_step</td><td>0.48817</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/lo8m3l4i' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/lo8m3l4i</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_130212-lo8m3l4i\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_131425-yj76ewj4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/yj76ewj4' target=\"_blank\">GINConv_2_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/yj76ewj4' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/yj76ewj4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_64_onehot_2\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 13.5 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.7 K    Total params\n",
      "0.063     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▂▃▁▄▄▅▅▇▅▆▅▆▅▇▆▆▆▆▇▇▆▇▆▆▇▆▇▇▇▇▇█▇▇▇█▇▆</td></tr><tr><td>train_auc</td><td>▅█▅▅▅▅▇▇█▅▂▅▆▄▆▃▅▆▅▂▄▄▇▄▁▄▆▇▆▅▃▆▄▆▅▅▆▄▆▄</td></tr><tr><td>train_f1</td><td>▂▄▄▃▁▅▃▅▅▇▆▆▅▅▅▆▆▇▇▆▇▇▇▇▇▆▇▇▇▇██▇▇▇█▇█▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▆▃▆▆▇▆▆▇▆█▇▇▇▇▇▇▆▇▇▇▇▇█▆▄▆▇▅█▆▇█▆▆▆██▆▇</td></tr><tr><td>val_auc</td><td>▇▇▇▇▆▇█▇▇▆▆▆▇▇▇▅▇█▇▂▇▇█▆▁▇▇█▇▅▆▅▆▆▅▆▆▇▆▇</td></tr><tr><td>val_f1</td><td>▁▆▃▆▅▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇█▇▇█▇▇▇▇██▇▇▇█</td></tr><tr><td>val_loss_epoch</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▃▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.69744</td></tr><tr><td>train_auc</td><td>0.56422</td></tr><tr><td>train_f1</td><td>0.64447</td></tr><tr><td>train_loss_epoch</td><td>0.56556</td></tr><tr><td>train_loss_step</td><td>0.51635</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.71168</td></tr><tr><td>val_auc</td><td>0.7803</td></tr><tr><td>val_f1</td><td>0.68016</td></tr><tr><td>val_loss_epoch</td><td>0.54677</td></tr><tr><td>val_loss_step</td><td>0.55957</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/yj76ewj4' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/yj76ewj4</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_131425-yj76ewj4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_132654-dvuevlkl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/dvuevlkl' target=\"_blank\">GINConv_2_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/dvuevlkl' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/dvuevlkl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_64_onehot_2\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 13.5 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "15.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.7 K    Total params\n",
      "0.063     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▄▆▅▆▅▆▆▆▆▇▆▆▇▅▅▆▆▆▇▆▆▇▇▇█▆▇▇▆█▇▇▇▇▇██</td></tr><tr><td>train_auc</td><td>▁▄▅▅▆▆▆▆▆▇▇▇▇▇▆▇▇▆▇▇▇▇▆▇▇▇▇█▇▇▇▇█▇██████</td></tr><tr><td>train_f1</td><td>▁▅▅▅▆▆▆▅▆▇▇▇▇▇▆▇▆▆▇▆▇▇▆▇▇▇▇█▇▇▇▆████████</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▄▄▄▄▄▃▃▃▃▄▂▃▄▃▃▃▃▄▃▂▂▂▃▃▂▂▃▂▂▁▁▂▁▂▁</td></tr><tr><td>train_loss_step</td><td>▅▇▅█▇▅▄▆▅▄▄▅▅▄▄▄▅▅▃▅▃▄▅▃▆▄▃▃▆▄▄▄▃▃▄▂▃▂▁▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▄▆▅▄▇▇▆▅▆▁▇▆▅▆▇▆█▇▇▅▅▆▆▇█▇█▄▇▇▇▆▆▆▇▆▇▆▆</td></tr><tr><td>val_auc</td><td>▁▆▆▇▅█▇▇▆▆▇▆█▆▆▇███▇▅▇▅▇▇█▇█▄█▆▆▇█▅▅▄▅▃▆</td></tr><tr><td>val_f1</td><td>▁▄▇██▇▇▇█▇▇▇█▆▇▇████▇▇▇▇█▇▇▇▄█▇▇██▇█▇▇▇█</td></tr><tr><td>val_loss_epoch</td><td>▇▆▄▆▆▂▃▄▄▃▇▄▄▆▃▄▄▃▂▄▆▄▃▃▃▁▃▂█▃▃▄▄▆▃▄▅▆▅▄</td></tr><tr><td>val_loss_step</td><td>█▅▃▆▇▂▃▃▄▃▇▄▅▃▂▁▄▃▂▃▃▄▃▃▃▁▅▆▄▄▅▃▃▂▆▆▄▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8117</td></tr><tr><td>train_auc</td><td>0.86898</td></tr><tr><td>train_f1</td><td>0.75534</td></tr><tr><td>train_loss_epoch</td><td>0.43863</td></tr><tr><td>train_loss_step</td><td>0.45191</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.72263</td></tr><tr><td>val_auc</td><td>0.82026</td></tr><tr><td>val_f1</td><td>0.696</td></tr><tr><td>val_loss_epoch</td><td>0.53333</td></tr><tr><td>val_loss_step</td><td>0.45611</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/dvuevlkl' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/dvuevlkl</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_132654-dvuevlkl\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "443774c941244c8caa613129984b23de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_133956-kh1e4as1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/kh1e4as1' target=\"_blank\">GINConv_2_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/kh1e4as1' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/kh1e4as1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_64_onehot_2\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 13.5 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "19.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "19.8 K    Total params\n",
      "0.079     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▄▅▅▅▅▆▅▆▆▆▆▆▆▇▆▆▆▆▇▆▇▇▆▇▆▇▇▇▅▆█▇▇▇▇▇▇</td></tr><tr><td>train_auc</td><td>▁▄▅▅▆▆▆▆▆▆▆▇▆▇▇▇▇▆▇▇▇▇▇▇▇▇█▇██▇▇▇█████▇▇</td></tr><tr><td>train_f1</td><td>▁▄▆▅▆▆▆▆▇▆▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇██▇▅▆█▇▇▇▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▄▄▄▃▄▄▄▃▃▃▃▂▃▃▃▃▂▃▂▂▃▂▃▂▂▂▄▃▁▁▂▂▁▂▂</td></tr><tr><td>train_loss_step</td><td>▆▅▅▅▄▄▄▅▄▆▄▅▄▄▃▄▂▅▄▃▃▂▃▃█▂▄▃▃▃▃▂▂▃▁▂▂▅▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▅▇▇█▇█▇▇▇▇▄▇▂▆██▇▇▇▅██▇███▇▃█▁▇█▇▅▃▇▇███</td></tr><tr><td>val_auc</td><td>▂▆▆▆▆▇▆▆▅▅▄▆▄▅▆▆▅▅▇▃▇▇▆▆▆▆▅▁▆▂▄█▇▃▂▃▅▅▅▇</td></tr><tr><td>val_f1</td><td>▁▅▇█▆█▇▇█▇▇█▇█████▇█▇█▇████▇▇▇███▇▇▇▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>▃▂▂▁▂▁▁▁▂▂▃▂▄▃▁▂▂▂▂▃▁▁▂▁▁▁▂▄▁█▃▂▂▂▃▁▂▁▁▂</td></tr><tr><td>val_loss_step</td><td>▅▂▂▂▂▂▂▂▃▂▄▃▅▃▂▂▃▃▂▃▂█▃▂▂▂▃▂▁▁▂▂▂▃▂▃▃▂▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.78336</td></tr><tr><td>train_auc</td><td>0.84813</td></tr><tr><td>train_f1</td><td>0.74098</td></tr><tr><td>train_loss_epoch</td><td>0.47646</td></tr><tr><td>train_loss_step</td><td>0.41436</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.75547</td></tr><tr><td>val_auc</td><td>0.83065</td></tr><tr><td>val_f1</td><td>0.64921</td></tr><tr><td>val_loss_epoch</td><td>0.57664</td></tr><tr><td>val_loss_step</td><td>0.7364</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/kh1e4as1' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/kh1e4as1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_133956-kh1e4as1\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_135249-k966iaqo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/k966iaqo' target=\"_blank\">GINConv_3_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/k966iaqo' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/k966iaqo</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_16_onehot_2\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.7 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4875735e7c62486aa4727eb76693abb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▇▇▇▇▇▇▇▇█▇███▇▇▇▇▇▇█████▇█▇█▇████████</td></tr><tr><td>train_auc</td><td>▁▄▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇████████████████████</td></tr><tr><td>train_f1</td><td>▂▁▅▆▅▅▆▆▆▇▆▇▇▇▆▇▇▇▇▆▆▇▇█▇█▇▆█▆█▆█▇▇▇████</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▃▃▃▃▃▃▂▃▂▂▂▂▂▁▂▂▂▂▂▂▂▂▂▁▂▁▂▁▂▂▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▇▅▄▃▄▅▃▇▃▄▄▄█▂▃▄▅▃▂▃▁▃▅▅▁▂▁▅▃▃▂▃▅▁▂▃▃▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▄▂▆▆▄▅▄▅▆▅▇▆▇▇▇▇▆▃▇█▆█▇▅▇▇▇▅▇█▇▆▄▅▄▇█▇▆</td></tr><tr><td>val_auc</td><td>▁▄▆▆▄▆▆▇▇▆▇▇▇▇▆▇▇▆▆▇▇▆▇▆▇▆▇▇▇▇▇█▇▆▆▇▇▇▇▇</td></tr><tr><td>val_f1</td><td>▁▄▃▇▇▄▆▄▅█▆▆▆▆▇▆▆█▇▇▇▆▇▇▅▆▇▇▅▆▇▆▆▄▇▄▆▇▇█</td></tr><tr><td>val_loss_epoch</td><td>█▆▆▃▄▄▃▅▃▇▃▆▂▁▂▂▄▅▇▁▂▃▂▄▅▄▃▄▃▂▆▃▄▂▄▂▃▂▃▅</td></tr><tr><td>val_loss_step</td><td>█▆▅▄▅▅▃▆▄▆▅▂▃▄▃▄▁▆▅▃▅█▃▃▄▅▂▃▇▂▃▄▂▅▇▄▅▄█▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77148</td></tr><tr><td>train_auc</td><td>0.83117</td></tr><tr><td>train_f1</td><td>0.70449</td></tr><tr><td>train_loss_epoch</td><td>0.50262</td></tr><tr><td>train_loss_step</td><td>0.5843</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.74088</td></tr><tr><td>val_auc</td><td>0.83778</td></tr><tr><td>val_f1</td><td>0.73801</td></tr><tr><td>val_loss_epoch</td><td>0.57876</td></tr><tr><td>val_loss_step</td><td>0.56486</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/k966iaqo' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/k966iaqo</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_135249-k966iaqo\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_140550-l9e96j85</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/l9e96j85' target=\"_blank\">GINConv_3_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/l9e96j85' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/l9e96j85</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_16_onehot_2\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.7 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e8dc1e4efcf4f13acdcd49652195b91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▄▄▅▅▆▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇▇█▇▇█▇█▇██</td></tr><tr><td>train_auc</td><td>▁▂▂▄▄▄▅▅▅▆▆▆▇▇▇▇▇▇█▇▇▇▇▇▇▇████████▇▇███▇</td></tr><tr><td>train_f1</td><td>▃▂▁▂▄▄▅▅▄▆▅▇▇▇▇▇▇▆▆▆▇▇█▇▇█▇██▇▇▇▇▆▇▇█▇██</td></tr><tr><td>train_loss_epoch</td><td>█▇▇▆▆▅▅▅▅▄▄▄▃▃▃▃▂▃▂▃▂▃▂▂▂▂▂▁▁▂▂▁▂▂▂▂▁▂▂▂</td></tr><tr><td>train_loss_step</td><td>██▆▆▆▆▄▅▅▅▄▅▄▄▆▃▂▄▄▃▃▃▃▅▄▅▁▁▂▆▂▂▃▃▆▂▁▃▂▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▆▆▆▇▅█▅▇▇▇▇▇▇▇█▆▇▇▇▇▇▆▆▇▆▇▇▇█▆▆▇▇▆▇▇█▆▇</td></tr><tr><td>val_auc</td><td>▁▄▄▆▆▇▇▆▆▇▇█▇▇██▇██▇▇█▇▇▇█▇▇▇▇▇▇▆▇▆▇▇█▇▇</td></tr><tr><td>val_f1</td><td>▅▃▇▁▇▇█▇▇▇▇▇▇▆▇█▇███▇█▇▇█▇▇▇▇▇▇▇▇▇▇▇▇███</td></tr><tr><td>val_loss_epoch</td><td>█▇▇▄▅▆▅▆▄▃▄▃▂▂▃▂▅▂▃▂▁▃▄▄▃▆▂▄▂▂▅▃▁▂▃▂▁▁▃▃</td></tr><tr><td>val_loss_step</td><td>█▇▇▅▅▇▄▅▄▄▃▂▃▃▂▂▂▃▂▄▃▄▁▂▂▇▃▂▅▁▁▃▁▃▆▂▁▅▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.73675</td></tr><tr><td>train_auc</td><td>0.7757</td></tr><tr><td>train_f1</td><td>0.6409</td></tr><tr><td>train_loss_epoch</td><td>0.56197</td></tr><tr><td>train_loss_step</td><td>0.58247</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.74818</td></tr><tr><td>val_auc</td><td>0.83325</td></tr><tr><td>val_f1</td><td>0.72065</td></tr><tr><td>val_loss_epoch</td><td>0.56338</td></tr><tr><td>val_loss_step</td><td>0.58983</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/l9e96j85' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/l9e96j85</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_140550-l9e96j85\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_141914-l1dztgue</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/l1dztgue' target=\"_blank\">GINConv_3_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/l1dztgue' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/l1dztgue</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_16_onehot_2\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.7 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6032da73aeb6441caed43e0049843268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▂▂▄▅▅▅▅▆▅▆▅▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇██▇▇</td></tr><tr><td>train_auc</td><td>▁▂▂▂▃▃▂▃▃▂▂▄▁▂▄▄▂▃▂▄▂▂▃▂▃▃▄▃▃▇▅▆▅▅▆▆▅█▆▆</td></tr><tr><td>train_f1</td><td>▁▄▅▄▂▃▃▄▃▄▄▃▄▅▅▆▆▅▅▆▆▇▆▆▇▆▆▇▇▇▇▇▇▇▇▇██▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▂▁▄▇▇▆▅▄▆▅▆▆▅▆▇██▇▇▇█▇▇▇█▆▇███▆▇██▇▇█▇▆█</td></tr><tr><td>val_auc</td><td>▂▂▁▂▄▅▄▄▄▄▅▅▄▄▅▆▆▇▇▆▅▅▄▄▅▅▆▇▇▇▆▇█▇▇▇████</td></tr><tr><td>val_f1</td><td>▁▇██▇▇▅▅▆▆▆▆▆▆▇▇▇▇▇▇█▇▇▇▇█▆▇▇▇█▆▇▇▇▆█▆▅█</td></tr><tr><td>val_loss_epoch</td><td>█▆▄▃▃▃▃▃▃▃▃▄▃▂▂▂▂▂▂▂▂▁▂▂▂▃▂▂▂▂▃▃▂▁▂▂▁▂▂▃</td></tr><tr><td>val_loss_step</td><td>██▄▃▃▄▃▄▃▃▃▂▃▂▂▂▂▃▄▁▃▃▁▃▂▃▃▃▄▂▁▂▂▃▂▁▂▁▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.72761</td></tr><tr><td>train_auc</td><td>0.61801</td></tr><tr><td>train_f1</td><td>0.66592</td></tr><tr><td>train_loss_epoch</td><td>0.57336</td></tr><tr><td>train_loss_step</td><td>0.65497</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.72993</td></tr><tr><td>val_auc</td><td>0.82822</td></tr><tr><td>val_f1</td><td>0.65094</td></tr><tr><td>val_loss_epoch</td><td>0.56402</td></tr><tr><td>val_loss_step</td><td>0.66761</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/l1dztgue' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/l1dztgue</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_141914-l1dztgue\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "506211e953564718b4d71f0e7dcfb9bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_143116-vs34sbhr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/vs34sbhr' target=\"_blank\">GINConv_3_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/vs34sbhr' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/vs34sbhr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_16_onehot_2\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.7 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▆▇▇▇▇▇▇▇▇█▇███▇███▇████████████▇▇█████</td></tr><tr><td>train_auc</td><td>▁▃▆▆▇▇▇▇▇▇▇▇█▇▇▇▇█▇█▇██▇███▇████████▇███</td></tr><tr><td>train_f1</td><td>▃▁▆▆▆▇▆▇▆▆▆▇▇▇▇▇▆▇▇█▆███▇▇██▇████▇▆▇▇▆██</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▃▃▃▃▂▃▃▂▂▂▂▂▂▂▂▂▂▃▂▁▂▂▁▂▂▁▂▂▁▁▁▂▁▂▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▇█▅▆▆▆▅▄█▄▇▆▇▇▆▄▄▅▁▄▄▆▅▆▆▃▄▄▂▃▄▂▅▅▃▄▄▂▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▅▃▄▅▆▇▇█▇██▇█▅▇▁█▇█▆▆█▇█▇▇▇▆▆▆▇█▇▇▆▆▇▆▄▇</td></tr><tr><td>val_auc</td><td>▁▅▆▇▆▇▇█▇█▇▇▇▇▇▆█▇▇▇▆▇▇█▇▇█▆▆▅▇█▇▇▆▇▇▆▇▇</td></tr><tr><td>val_f1</td><td>▅▁▃▄▆▆▅▇▇█▇▇▇▃▆▇▇▇▆█▄▇█▆▆▇▆▇▇▇▇▇▇▆▇▇█▅▃█</td></tr><tr><td>val_loss_epoch</td><td>▇▅▃▅▃▄▃▂▂▃▁▃▂█▂▆▂▂▃▃▄▁▂▂▁▃▁▃▂▃▂▁▁▄▃▂▆▂▇▃</td></tr><tr><td>val_loss_step</td><td>▆▄▄▃▃▃▃▃▃▁▁▂▃▄▁█▂▂▂▄▂▂▂▃▃▂▂▁▃▃▃▄▄▃▃▂▂▄▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.78336</td></tr><tr><td>train_auc</td><td>0.84519</td></tr><tr><td>train_f1</td><td>0.71203</td></tr><tr><td>train_loss_epoch</td><td>0.49052</td></tr><tr><td>train_loss_step</td><td>0.53242</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.73723</td></tr><tr><td>val_auc</td><td>0.83004</td></tr><tr><td>val_f1</td><td>0.71429</td></tr><tr><td>val_loss_epoch</td><td>0.53777</td></tr><tr><td>val_loss_step</td><td>0.5173</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/vs34sbhr' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/vs34sbhr</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_143116-vs34sbhr\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40b99c1c5f8541de8c32c9fd16d67334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_144320-q4tte1k9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/q4tte1k9' target=\"_blank\">GINConv_3_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/q4tte1k9' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/q4tte1k9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_16_onehot_2\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.7 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "2.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▇▇▇▇▇▇▇█▇▇▇▇█▇██▇███████▇▇▇██▇██████</td></tr><tr><td>train_auc</td><td>▁▄▆▆▇▇▇▇▇▇▇▇▇▇▇▇████▇████████████▇█████▇</td></tr><tr><td>train_f1</td><td>▁▂▄▅▅▅▆▇▆▅▇▇▇▆▇▇█▇▇▇▇▇▇▇▇▇█▇▆▇▆▇█▇▇▇▆█▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▃▄▃▃▃▃▂▂▃▂▂▂▂▂▂▂▃▂▁▂▁▁▂▁▁▂▂▂▂▃▁▁▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▆▄▅▄▃▄▄▅▄▃▄▁▄▆▂▅▃▃▂▄▂▃▆▃▁▂▄▄▄▃▁▂▃▂▃▂▁▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▄▆▅▄▆▆▅▆▅▆▇▄▅▇▆▇▇▆▆▅▇▇▆▆▂█▆▂▆▅▆▆▇▆▆▅▅▆</td></tr><tr><td>val_auc</td><td>▁▃▆▇▇▇▇▆▆▇▇▇▇██▇▆▇█▇▆▅▇▇▆▇▆█▇▆▆▆▇█▇▆▇▆▇▇</td></tr><tr><td>val_f1</td><td>▁▄▄▆▆▅▇▇▇▇█▇▇▅▆██▇█▆█▇▇▇▇▆▇█▆▃▇██▆▇█▇██▆</td></tr><tr><td>val_loss_epoch</td><td>▄▃▂▁▂▂▂▂▂▂▂▃▁▂▃▃▂▂▂▃▃▃▂▃▂▃▃▁▃█▃▃▂▂▂▃▁▃▃▃</td></tr><tr><td>val_loss_step</td><td>▆▄▄▃▄▄▃▂▃▂▄▃▄▅▂▁▃▁▂▃▃▃▃▄▃▄▂▃▃▅▃▂▂▃▃▄▄▂▃█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.76234</td></tr><tr><td>train_auc</td><td>0.81182</td></tr><tr><td>train_f1</td><td>0.69267</td></tr><tr><td>train_loss_epoch</td><td>0.52723</td></tr><tr><td>train_loss_step</td><td>0.46614</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.75547</td></tr><tr><td>val_auc</td><td>0.83701</td></tr><tr><td>val_f1</td><td>0.60355</td></tr><tr><td>val_loss_epoch</td><td>0.59689</td></tr><tr><td>val_loss_step</td><td>0.78998</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/q4tte1k9' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/q4tte1k9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_144320-q4tte1k9\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_145522-wnujo840</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/wnujo840' target=\"_blank\">GINConv_3_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/wnujo840' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/wnujo840</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_32_onehot_2\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 5.9 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "6.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.5 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▆▇▇▇▇▆▇█▇█▇▇█▇██▇▇█</td></tr><tr><td>train_auc</td><td>▁▄▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇████████</td></tr><tr><td>train_f1</td><td>▁▅▅▆▆▆▆▆▆▅▆▇▇▇▆▇▆▇▇▇▇▆▇▇▇▇▆▇████▇█▇█▇▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▂▃▃▂▃▃▃▂▂▂▃▂▂▂▂▂▂▁▁▁▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>██▆█▇▃▇▆▄▇▅▆▆▄▄▆▆▃▅▄▃▆▃▇▄▆▄▃▁▃▄▄▃▆▃▄▄▅▁▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▄▆▆▇█▆█▇▇▆▄▇▆▆▆▃▇▆▅▆▇▅▆▆▆▆▅▆▅▇▃▅▆▇▇▆▇▇</td></tr><tr><td>val_auc</td><td>▂▅█▆▇█▇▆▇▆▆▅▆▆▇▆▇▆▅▅▁▄▅▂▄▅▄▄▃▄▄▅▅▁▃▆▁▄▅▅</td></tr><tr><td>val_f1</td><td>▁▃▅▆▇▇▇▇█▇█▆▇▇▇▆█▃▇▆▇▆▆▇▇▇▇▆▇▇▇▇▃▇▆▇▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>▄▄▃▂▁▂▂▂▂▂▂▃▄▂▃▄▂█▂▂▄▂▃▄▂▂▂▃▂▂▄▂▆▃▄▃▃▃▄▃</td></tr><tr><td>val_loss_step</td><td>▄▄▂▂▁▂▁▁▁▁▂▃▄▁▁▂▃▃▁▂▂▁▅▂▂▁▂▂▂▆▂▁▅▁▃█▂▃▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.80439</td></tr><tr><td>train_auc</td><td>0.87502</td></tr><tr><td>train_f1</td><td>0.74341</td></tr><tr><td>train_loss_epoch</td><td>0.43223</td></tr><tr><td>train_loss_step</td><td>0.45865</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.74453</td></tr><tr><td>val_auc</td><td>0.80385</td></tr><tr><td>val_f1</td><td>0.62766</td></tr><tr><td>val_loss_epoch</td><td>0.63281</td></tr><tr><td>val_loss_step</td><td>0.7274</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/wnujo840' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/wnujo840</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_145522-wnujo840\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_150716-qilyqyew</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qilyqyew' target=\"_blank\">GINConv_3_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qilyqyew' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qilyqyew</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_32_onehot_2\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 5.9 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "6.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.5 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▄▅▅▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇█▇▇▇█▇▇▇█</td></tr><tr><td>train_auc</td><td>▁▃▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇█▇▇▇█████</td></tr><tr><td>train_f1</td><td>▁▁▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▆▇█▇▆▇▇▇▇▇▆▇▇█▇▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▄▄▄▃▃▃▃▂▂▃▃▃▂▂▂▂▂▂▂▂▂▃▂▂▂▂▂▂▂▂▁▂▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▇▇▆▅▄▅▆▄▅▅▄▆▃▄▅▄▄▄▃▃▅▂▅▃▄▃▃▁▂▃▄▃▄▃▃▃▃▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▄▄▅▆▆▇█▅▇▅▇█▇▆▆▄▆█▇▇▇▇██▄▇█▇▇██▇▇▆▄▇▇▇▅</td></tr><tr><td>val_auc</td><td>▁▃▆▆▆▅▆▇▇▇▇█▇▇▇▇▇▇▇▇▇█▇▇▇▆▇█▆▇▇▇▇▇▇▆▇▇▇▆</td></tr><tr><td>val_f1</td><td>▁▄▄▅▇▆███████▇████████▇█████████████████</td></tr><tr><td>val_loss_epoch</td><td>█▆▅▃▂▃▅▃▅▂▅▄▃▂▄▃▆▅▁▄▃▃▃▃▂▆▃▂▂▂▂▁▁▂▄█▃▃▅▅</td></tr><tr><td>val_loss_step</td><td>█▆▅▄▄▅▃▄▅▂▅▃▃▃▃▂▆▅▂▅▃▆▃▇▂▁▃▃▄▅▃▁▅▁▅▇▂▃▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.78519</td></tr><tr><td>train_auc</td><td>0.83417</td></tr><tr><td>train_f1</td><td>0.73326</td></tr><tr><td>train_loss_epoch</td><td>0.49178</td></tr><tr><td>train_loss_step</td><td>0.48244</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.69708</td></tr><tr><td>val_auc</td><td>0.81695</td></tr><tr><td>val_f1</td><td>0.69597</td></tr><tr><td>val_loss_epoch</td><td>0.59463</td></tr><tr><td>val_loss_step</td><td>0.58201</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qilyqyew' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qilyqyew</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_150716-qilyqyew\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_151928-wa4kx9e8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/wa4kx9e8' target=\"_blank\">GINConv_3_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/wa4kx9e8' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/wa4kx9e8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_32_onehot_2\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 5.9 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "6.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.5 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▂▁▂▃▄▅▅▅▆▆▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇██▇▇█▇▇▇▇█▇▇█</td></tr><tr><td>train_auc</td><td>█▇▆▆▅▅▄▆▆▅▅▅▄▄▅▄▄▄▃▃▄▂▁▂▂▁▁▃▂▂▃▄▃▄▅▆▆▄▅▂</td></tr><tr><td>train_f1</td><td>▁▁▂▁▄▅▅▄▅▅▆▅▆▆▆▆▅▆▆▅▆▇▇▇▇▆▆██▇▇█▇▇▇▇▇▆▇█</td></tr><tr><td>train_loss_epoch</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▅▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▄▅▅▇▆▅▇▆▆▇▇▆▇▇▇▇▇▇▆█▇▇▇▇▆▇▇▆▇▇█▇▆▆▇▇▆▆█</td></tr><tr><td>val_auc</td><td>█▆▇▇▇▇▇██▇▇▆▄▅▅▄▄▅▅▃▂▁▁▁▁▁▂▂▂▂▃▂▂▃▆█▇▄▄▂</td></tr><tr><td>val_f1</td><td>▁▅▆▆▇▇▇▇▇▇█▇▇█▇▇█▇▇▇█████▆▇█▇█▇██▇▆██▆██</td></tr><tr><td>val_loss_epoch</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.75229</td></tr><tr><td>train_auc</td><td>0.4392</td></tr><tr><td>train_f1</td><td>0.69379</td></tr><tr><td>train_loss_epoch</td><td>0.5287</td></tr><tr><td>train_loss_step</td><td>0.46861</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.75547</td></tr><tr><td>val_auc</td><td>0.25877</td></tr><tr><td>val_f1</td><td>0.65641</td></tr><tr><td>val_loss_epoch</td><td>0.53532</td></tr><tr><td>val_loss_step</td><td>0.60388</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/wa4kx9e8' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/wa4kx9e8</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_151928-wa4kx9e8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_153116-sy10oeiu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/sy10oeiu' target=\"_blank\">GINConv_3_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/sy10oeiu' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/sy10oeiu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_32_onehot_2\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 5.9 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "6.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.5 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▆▆▆▇▇▆▇▇▆▆▇▇▇▇▇▆▇▇▇▇██▇██▇██▇▇██████</td></tr><tr><td>train_auc</td><td>▁▅▅▅▆▅▆▇▆▆▇▇▆▆▇▇▇▆▇▇▇▇▇▇██▇██▇██▇███████</td></tr><tr><td>train_f1</td><td>▁▆▆▆▇▅▇▇▇▆▇▇▇▇▇█▇▇█▆▇▇▇██████▇████▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▅▄▄▃▄▃▃▃▃▃▂▃▃▃▃▃▂▂▂▂▂▂▂▁▂▂▁▂▁▁▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▇▇▇▅▃▄▄▅▅▅▄▄▆▆▂▄▄▆▅▆▅▂▃▂▃▂▂▇▄▂▅▄▄▁▃▁▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▄▆▆▇▆▃▆█▆▆▆▇█▇▇▆██▆▅▇█▆█▆▆▆█▅▆▆█▃▇▆▇▆▇▇</td></tr><tr><td>val_auc</td><td>▂▆▆▆▆█▆▅▇▇▆▆▆▇▅▅▅▇▆▆▄▃▄▅▅▅▅▅▆▁▃▃▅▁▃▂▁▂▁▇</td></tr><tr><td>val_f1</td><td>▁▄▆▇█▆▄▆█▆▇█▆█▇████▆█▇█▇▇█▆███▇▆▇█▇█▇█▇▇</td></tr><tr><td>val_loss_epoch</td><td>▆▄▂▃▂▂▇▂▂▃▃▂▁▂▄▂▃▁▄▄▆▃▃▁▃▅▁▁▃▄▄▂▃█▃▃▂▅▄▄</td></tr><tr><td>val_loss_step</td><td>▄▅▃▂▃▃▅▃▃▂▂▂▄▁▂▃▃▁▂▃▃▃▄▂▂▂▃▇▆▃▄▃▅▃▅█▂▄▇▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.80713</td></tr><tr><td>train_auc</td><td>0.86196</td></tr><tr><td>train_f1</td><td>0.75206</td></tr><tr><td>train_loss_epoch</td><td>0.44711</td></tr><tr><td>train_loss_step</td><td>0.41696</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.74453</td></tr><tr><td>val_auc</td><td>0.82922</td></tr><tr><td>val_f1</td><td>0.59302</td></tr><tr><td>val_loss_epoch</td><td>0.59138</td></tr><tr><td>val_loss_step</td><td>0.67197</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/sy10oeiu' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/sy10oeiu</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_153116-sy10oeiu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_154244-9cjrmqqz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/9cjrmqqz' target=\"_blank\">GINConv_3_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/9cjrmqqz' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/9cjrmqqz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_32_onehot_2\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 5.9 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "7.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.6 K     Total params\n",
      "0.030     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9251c50bf1cb4eff9508147423fe6602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▅▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇██▇█▇▇▇█████</td></tr><tr><td>train_auc</td><td>▁▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇██▇█▇▇▇██▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▅▄▄▄▄▄▃▃▄▃▃▃▃▃▃▂▃▃▂▃▂▃▂▂▂▂▂▂▂▂▃▂▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▆▇▆▆▄▇▆▄▆▄██▅▄▄▆▂▇▄▃▃▅▅▄▃▅▃▅▄▃▂▅▄▁▄▂▂▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▆▅▅▅▅▆▇█▄▇▅▆▆▇▄▇▆▅▇▅▅▂▇▆▇▆▅▅▆▇▂▇▄▅▇▆▇▆</td></tr><tr><td>val_auc</td><td>▄▇█▅▆▆█▆▇▇▇▆▅▇▄▇▅▆▅▇▇▃▆▁▆█▆▅█▄▄▅▆█▁▅▇▅▆▄</td></tr><tr><td>val_f1</td><td>▁▃▆▆█▆▅▇▇█▄█▇▇▇▇█▇▇█▇██▃▇▇▇▇▆▇▆██▇█▆█▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>▅▅▃▂▄▃▃▃▁▂▄▃▃▃▃▃▆▃▃▅▃▃▃█▃▂▃▄▃▅▆▃█▂▇▇▂▄▄▆</td></tr><tr><td>val_loss_step</td><td>▃▃▂▂▃▄▂▂▂▂▃▂▃▁▂▂▂▁▂▅▂▅▆▂█▂▇▄▃▃▄▃▂▂▂▁▄▄▃█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.81718</td></tr><tr><td>train_auc</td><td>0.87742</td></tr><tr><td>train_f1</td><td>0.77273</td></tr><tr><td>train_loss_epoch</td><td>0.43669</td></tr><tr><td>train_loss_step</td><td>0.49603</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.73358</td></tr><tr><td>val_auc</td><td>0.79445</td></tr><tr><td>val_f1</td><td>0.65403</td></tr><tr><td>val_loss_epoch</td><td>0.6943</td></tr><tr><td>val_loss_step</td><td>0.86378</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/9cjrmqqz' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/9cjrmqqz</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_154244-9cjrmqqz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_160140-59bufo2m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/59bufo2m' target=\"_blank\">GINConv_3_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/59bufo2m' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/59bufo2m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_64_onehot_2\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 22.1 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "24.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.2 K    Total params\n",
      "0.097     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▆▆▆▇▆▆▆▆▆▇▇▇▇▇▆▆▇▇▇▇▆▇▇██████▇▇██▇█</td></tr><tr><td>train_auc</td><td>▁▅▅▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇███▇████████</td></tr><tr><td>train_f1</td><td>▁▄▆▆▆▆▇▆▇▆▆▇▇▇▇▇▇▇▇▆▆▇▇▇▇▇▇▇██████▇▇██▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▅▄▄▄▄▄▄▃▄▃▃▃▃▃▃▃▄▃▂▂▃▃▂▂▂▂▁▂▁▁▂▂▁▂▂▁</td></tr><tr><td>train_loss_step</td><td>▇▄█▅▄▄▃▅▄▅▃▃▅▄▄▃▂▃▄▂▃▄▃▆▅▃▂▁▃▄▁▂▃▃▃▄▃▁▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▄█▆▇▆▇▆▆▅█▆▅▅▆▆▄▅▆▆▇▆▅▆▄▆▄▅▃▆▆▅▅▃▄▅▆▅▃▄</td></tr><tr><td>val_auc</td><td>▂▇▇▇▇▆▇▆▆▆█▇▆▇▆▅▃▇▇▆▇▅▃▇▁▅▃▆▁▄▃▄▄▂▂▄▄▄▂▃</td></tr><tr><td>val_f1</td><td>▁▅█▇███▇▆▆█▇▆█▇▇█▆██▇▇▇█▅▇▅▆▇█▇▆▆▄▅██▇▄▅</td></tr><tr><td>val_loss_epoch</td><td>▇▄▁▂▂▃▂▃▃▃▂▄▃▃▂▃▆▅▃▂▁▁▂▂▅▂▄▄█▅▄▃▅▇▆▆▇▆▇▄</td></tr><tr><td>val_loss_step</td><td>▅▂▁▂▂▁▂▁▂▂▂▂▂▁▂▂▂▃▁▂▂▃▁▂▃▂▃▃▂▃▅▂▂▁▅▂▂▄█▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8245</td></tr><tr><td>train_auc</td><td>0.88319</td></tr><tr><td>train_f1</td><td>0.77829</td></tr><tr><td>train_loss_epoch</td><td>0.4147</td></tr><tr><td>train_loss_step</td><td>0.39131</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.68613</td></tr><tr><td>val_auc</td><td>0.77566</td></tr><tr><td>val_f1</td><td>0.46914</td></tr><tr><td>val_loss_epoch</td><td>0.6277</td></tr><tr><td>val_loss_step</td><td>0.63106</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/59bufo2m' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/59bufo2m</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_160140-59bufo2m\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92c7e7aee8c446479a2b08adb4584015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_161351-l424boyn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/l424boyn' target=\"_blank\">GINConv_3_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/l424boyn' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/l424boyn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_64_onehot_2\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 22.1 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "24.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.2 K    Total params\n",
      "0.097     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▆▆▆▇▆▆▆▆▇▇▇▇▇▇█▇▇▇▇█▇▇▇▇▇█▇▇██▇▇█████</td></tr><tr><td>train_auc</td><td>▁▃▄▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇█▇█▇████</td></tr><tr><td>train_f1</td><td>▃▁▆▆▆▆▇▇▆▇▆▇▇▇▇▇▇█▇▇▇▇█▇▇▇▇▇██▇██▇████▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▄▃▃▄▃▃▃▃▃▂▂▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂▂▂▂▂▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▇▆▄▆▅▅▅▇▄▅▅▆▄▃▄▆▂▄▄▆▄▅▅▃▄▁▄▅▃▄▅▅▅▄▄▄▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▆▇▅▆▅▆▇▇█▆▆▇▇▆▆▅▆▅█▇▆▇▆▅▆▇▇▅▆▇▆█▅▇▆▇▇▄</td></tr><tr><td>val_auc</td><td>▁▅▇█▇▇▆▆█▇▇▆▇▇▆▆▆▆▆▆▆▆▅▅▅▅▆▇▆▅▆▅▅▇▅▇▅▅▅▆</td></tr><tr><td>val_f1</td><td>▁▂▆▇█▇███▇██▆█▇▇▇██▇████▇██████▇█▇████▇▅</td></tr><tr><td>val_loss_epoch</td><td>▆▅▃▂▄▄▅▅▃▃▃▄▃▂▁▂▃▆▅▃▁▂▃▂▄▅▄▄▃▇▄▄▃▄█▄▅▆▅▇</td></tr><tr><td>val_loss_step</td><td>▇▅▃▄▅▂▅▂▂▂▃▄▃▂▄▄▂▆▃▄▁█▁▃▃█▂▆▃▄▆▃▃▄▄▅▅▄█▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.78885</td></tr><tr><td>train_auc</td><td>0.84309</td></tr><tr><td>train_f1</td><td>0.74419</td></tr><tr><td>train_loss_epoch</td><td>0.46061</td></tr><tr><td>train_loss_step</td><td>0.43237</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.67153</td></tr><tr><td>val_auc</td><td>0.80711</td></tr><tr><td>val_f1</td><td>0.4</td></tr><tr><td>val_loss_epoch</td><td>0.68559</td></tr><tr><td>val_loss_step</td><td>0.60766</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/l424boyn' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/l424boyn</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_161351-l424boyn\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_162537-qmot48sq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qmot48sq' target=\"_blank\">GINConv_3_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qmot48sq' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qmot48sq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_64_onehot_2\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 22.1 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "24.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.2 K    Total params\n",
      "0.097     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▄▄▃▅▄▅▆▆▅▆▆▆▇▇▆▆▇▆▆▇▇▇▇▇▇▆▇▇▇██▇██████</td></tr><tr><td>train_auc</td><td>▃▃▄▅▄▃▂▅▂▁▂▂▃▄▃▂▁▅▄▃▃▄▄▆▆█▇▆▄▅▄▅▄▄▃▅▂▂▄▅</td></tr><tr><td>train_f1</td><td>▂▁▃▄▁▅▄▅▅▅▅▆▆▆▇▇▆▇▇▅▆▇▇▇▇▇▇▆▆▇▇██▇████▇█</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▆▆▅▆▆▆▆▆▇▆▆▇▆▆▇▆▆▆▇▆▇▇▇▆▆▆▆▆▆▇▇▆▆▇▆█▇▆▇</td></tr><tr><td>val_auc</td><td>▇▆▅▇▆▄▇▇▃▁▂▅▇▇▆▂▅▇▆█▅▅█████▇▇▇▆▇▇▇▇▆▃▃██</td></tr><tr><td>val_f1</td><td>▁▆▇▇▆▇▆▆▆▇▇▇▇▇▇█▇▆▇▆▇▇▇█▆▇▇▇▇▇▇▇▇▇▇█▇▇▆▇</td></tr><tr><td>val_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.734</td></tr><tr><td>train_auc</td><td>0.57064</td></tr><tr><td>train_f1</td><td>0.68266</td></tr><tr><td>train_loss_epoch</td><td>0.60731</td></tr><tr><td>train_loss_step</td><td>0.6129</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.72993</td></tr><tr><td>val_auc</td><td>0.76057</td></tr><tr><td>val_f1</td><td>0.58427</td></tr><tr><td>val_loss_epoch</td><td>0.60203</td></tr><tr><td>val_loss_step</td><td>0.69494</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qmot48sq' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qmot48sq</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_162537-qmot48sq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_163716-7da34d9r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/7da34d9r' target=\"_blank\">GINConv_3_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/7da34d9r' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/7da34d9r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_64_onehot_2\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 22.1 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "24.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.3 K    Total params\n",
      "0.097     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▆▆▅▆▆▆▇▆▆▆▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇█▇█▆██▇██</td></tr><tr><td>train_auc</td><td>▁▅▅▆▆▆▆▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇▇▇█</td></tr><tr><td>train_f1</td><td>▁▅▆▇▇▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇█▆██▇██</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▅▅▄▅▄▄▅▄▄▄▄▄▃▄▃▄▄▃▃▃▃▃▃▃▃▂▂▃▂▂▂▃▂▂▂▂▁</td></tr><tr><td>train_loss_step</td><td>▆▇▅▅▅█▆▄▅▇▄▃▃▄▅▆▄▂▂▅▃▄▄▃▄▃▃▂▂▄▄▅▃▃▅▄▄▂▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▅▆▇▅██▇▆▇▇█▅▅▆▇▆▆▅▇▆▆▇▇▆▆▆▆▆▅▇▄▆▃▆▅▅▆▄▆</td></tr><tr><td>val_auc</td><td>▄▆▇▇███▇█▇█▇▆▆▇█▇▇▆▇▆▅▇▇▅▅▆▆▅▅▆▄▆▅▅▅▆▆▁▆</td></tr><tr><td>val_f1</td><td>▁▅▆█████▅▇██▆▆███▆▅█▆▇█▇▇█▇█▆▆▇▅▇▄▇█▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>▃▂▂▂▃▁▁▁▂▂▁▂▂▁▂▂▂▃▃▂▂▁▁▁▂▂▂▂▃▂▃▃▂█▁▃▃▁▃▂</td></tr><tr><td>val_loss_step</td><td>▅▄▄▃▄▃▃▃▃▃▄▃▃▃▃▃▄▃▄▃▅█▄▄▆▆▄▅▆▄▅▆▃▃▄▄▇▆▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.81993</td></tr><tr><td>train_auc</td><td>0.90396</td></tr><tr><td>train_f1</td><td>0.76407</td></tr><tr><td>train_loss_epoch</td><td>0.38582</td></tr><tr><td>train_loss_step</td><td>0.31709</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.73358</td></tr><tr><td>val_auc</td><td>0.80318</td></tr><tr><td>val_f1</td><td>0.64734</td></tr><tr><td>val_loss_epoch</td><td>0.52546</td></tr><tr><td>val_loss_step</td><td>0.3043</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/7da34d9r' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/7da34d9r</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_163716-7da34d9r\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_164837-ora0qjyj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ora0qjyj' target=\"_blank\">GINConv_3_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ora0qjyj' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ora0qjyj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_64_onehot_2\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 22.1 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "28.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "28.4 K    Total params\n",
      "0.114     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16ca71709ad14658b33d85f87da93abe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.013 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.080231…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▅▅▅▆▆▆▅▆▆▆▆▆▆▆▇▇▇▇▇▇▆▇▇▇▇▇▆▇▆▇▇▇▇▇▇█</td></tr><tr><td>train_auc</td><td>▁▄▅▅▅▅▆▆▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇████</td></tr><tr><td>train_f1</td><td>▁▅▅▅▆▆▆▇▆▆▆▇▇▆▇▆▆▆▇▇▇▇▇▇▆▆▇▇▇█▇▇▆▇▇▇████</td></tr><tr><td>train_loss_epoch</td><td>█▇▅▆▆▅▅▄▄▄▅▄▃▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▂▃▂▃▂▂▂▂▂▁▁</td></tr><tr><td>train_loss_step</td><td>▇▇█▄▆▃▅▅▃▄▅▅▄▂▃▄▅▅▄▄▄▄▄▆▄▅▅▂▅▅▅▃▃▄▂▃▁▄▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▅▄▇▆▇▇▇▇▇█▆▆▄█▇▇▆▅▆▆▆▆▄▆█▆▅▄▆▆▆▆▂▄▅▅▅▆▆</td></tr><tr><td>val_auc</td><td>▄▆▃▇▆▇█▇▇▇█▆▄▅▆▅▆▅▂▅▆▇▃▇▅▇▆▃▃▅▅▅▅▃▆▄▅▄▅▁</td></tr><tr><td>val_f1</td><td>▁▅▅▇█▇▇▇█▇██▇█▇▇▇█▇▆▆▆▇▄██▇▇▇▇▇█▇▇▅▇▅▇▆█</td></tr><tr><td>val_loss_epoch</td><td>▆▃▃▁▂▁▂▂▂▁▁▂▂▃▂▂▂▃▂▃▂▂▁▆▁▂▂▂▂▁▂▃▃▅█▂▆▅▃▅</td></tr><tr><td>val_loss_step</td><td>▇▃▅▂▄▁▁▂▂▂▂▂▂▅▁▂▄▄▃▅▁▂▃▂▄▃▂▅▂▄▆▅▅▃█▄▂█▅▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83912</td></tr><tr><td>train_auc</td><td>0.89459</td></tr><tr><td>train_f1</td><td>0.79391</td></tr><tr><td>train_loss_epoch</td><td>0.39067</td></tr><tr><td>train_loss_step</td><td>0.39769</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.70803</td></tr><tr><td>val_auc</td><td>0.75587</td></tr><tr><td>val_f1</td><td>0.67213</td></tr><tr><td>val_loss_epoch</td><td>0.7754</td></tr><tr><td>val_loss_step</td><td>0.81086</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ora0qjyj' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ora0qjyj</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_164837-ora0qjyj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_170002-z90akyya</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/z90akyya' target=\"_blank\">GINConv_4_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/z90akyya' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/z90akyya</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_16_onehot_2\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 2.3 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▆▆▆▆▆▆▆▇▇▇▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇██▇█▇▇██▇██</td></tr><tr><td>train_auc</td><td>▁▄▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████▇██████</td></tr><tr><td>train_f1</td><td>▁▄▆▆▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇▇█▇▇▇▇█████████████</td></tr><tr><td>train_loss_epoch</td><td>█▇▅▄▄▄▃▃▄▄▃▃▃▂▂▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▂▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▅▄▅▃▄▄▆▅▂▂▃▂▂▅▄▃▃▃▅▃▃▂▃▄▃▂▃▄▅▃▅▅▃▁▂▇▃▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▃▃▅▆▄▄▇▄▇▄▇▆▇▇▇▇▇▅▇▇▅▇█▆▄▇▅▇▆▇▆███▇▆▇▅</td></tr><tr><td>val_auc</td><td>▁▃▃▆▆▆▇█▇█▇█▇██▇██▇▇▇██▇▆▇▇▇▇▇▆▇▆██▇▆▇▇▇</td></tr><tr><td>val_f1</td><td>▁▂▃▄▆▆▅▄█▅▇▅█▆█▇▇█▇▆█▇▆▇█▇▅▇▆▇▇▇▇███▇▇█▆</td></tr><tr><td>val_loss_epoch</td><td>▆▆█▅▃▄▆▅▂▃▂▅▂▆▂▃▂▂▂▄▂▃▅▁▂▃▇▂▂▂▄▂▃▃▄▄▇▂▂▆</td></tr><tr><td>val_loss_step</td><td>▆▅█▅▃▂▃▄▂▃▃▆▃▂▂▃▂▁▂▆▃▃▁▄▂▁▄▂▂▄▂▁▄▃▃▂▄▃▂▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77057</td></tr><tr><td>train_auc</td><td>0.81246</td></tr><tr><td>train_f1</td><td>0.70643</td></tr><tr><td>train_loss_epoch</td><td>0.49979</td></tr><tr><td>train_loss_step</td><td>0.53226</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.70073</td></tr><tr><td>val_auc</td><td>0.8264</td></tr><tr><td>val_f1</td><td>0.45333</td></tr><tr><td>val_loss_epoch</td><td>0.65308</td></tr><tr><td>val_loss_step</td><td>0.67426</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/z90akyya' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/z90akyya</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_170002-z90akyya\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_171133-xqicropy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/xqicropy' target=\"_blank\">GINConv_4_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/xqicropy' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/xqicropy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_16_onehot_2\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 2.3 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f01ddcb17a436ab8988cfe3528dcd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▃▂▄▆▅▆▆▇▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇███▇▇▇▇█▇▇█</td></tr><tr><td>train_auc</td><td>▁▁▃▃▄▅▅▆▅▆▆▆▆▇▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇███▇▆█▇▇▇▇█</td></tr><tr><td>train_f1</td><td>▂▁▃▂▄▆▆▇▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇██▇███▇▇▇▇████</td></tr><tr><td>train_loss_epoch</td><td>█▇▇▆▅▄▅▃▄▄▃▃▃▂▃▃▂▂▂▁▂▂▂▂▂▂▂▂▂▁▂▁▂▂▂▂▂▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▆▇▅▆▄▄▃▅▄▃▂▂▃▃▅▆▅▂▂▅▂▄▂▃▄▃▁▃▅▃▂▅▂▂▁▂▅▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▃▆▅▇▃▆▆█▁▇▆█▇▄█▇▅▅▇▇▅▇▆█▆▂▇▄▇▆▁▆▅▆▅▅▅▇</td></tr><tr><td>val_auc</td><td>▁▄▅▇▇▇▅▇▇█▇▇▆▇█▇███▇▇▇▇█▇██▇█▇██▇█▇█▇█▇█</td></tr><tr><td>val_f1</td><td>▁▁▃▆▅▇▇▇▇▇▇██▇█▇███████████▇████▇██▆▇███</td></tr><tr><td>val_loss_epoch</td><td>█▇▆▅▃▅▆▂▅▁▆▂▃▅▄▄▂▂▅▄▃▄▇▂▁▂▁▅▁▇▃▂▅▃▆▄▅▃▃▁</td></tr><tr><td>val_loss_step</td><td>▆▅▅▅▃▃▅▂▄▁▆▃▅▃▃▅▂▃▂▄▃▄▃▄▅▁▄▂▄▃▂▁▃█▃▂▃▇▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.74497</td></tr><tr><td>train_auc</td><td>0.77469</td></tr><tr><td>train_f1</td><td>0.66746</td></tr><tr><td>train_loss_epoch</td><td>0.54034</td></tr><tr><td>train_loss_step</td><td>0.51877</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.75912</td></tr><tr><td>val_auc</td><td>0.8343</td></tr><tr><td>val_f1</td><td>0.72269</td></tr><tr><td>val_loss_epoch</td><td>0.53838</td></tr><tr><td>val_loss_step</td><td>0.50604</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/xqicropy' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/xqicropy</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_171133-xqicropy\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_172252-szuqcm2s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/szuqcm2s' target=\"_blank\">GINConv_4_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/szuqcm2s' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/szuqcm2s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_16_onehot_2\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 2.3 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▁▃▂▃▃▃▄▄▅▄▄▅▅▅▅▆▆▆▆▇▆▆▇▇▆▆▇▇█▇▇▇▇▇███▇</td></tr><tr><td>train_auc</td><td>▆██▆▅▆▅▆▅▆▅▄▅▃▄▄▄▃▄▄▃▄▄▃▃▃▂▂▃▂▂▁▂▁▂▂▂▂▃▅</td></tr><tr><td>train_f1</td><td>▂▃▄▄▃▄▂▁▃▂▃▂▃▄▄▄▄▅▅▅▆▆▆▇▇▇▇▇▇▇██▇█▇▇████</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▃▄▄▄▃▄▃▄▄▄▄▅▅▅▅▅▅▅▅▅▅▆▆▇▇▇▇▆▇▇▆█▇▇▇█▇▆</td></tr><tr><td>val_auc</td><td>▇██▆▅▅▄▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_f1</td><td>▁▂▄▅▅▅▅▄▅▅▅▆▆▅▅▆▆▆▅▆▆▆▆▆▇▇▇▇▇▇▇█▆█▇▇▇█▇▆</td></tr><tr><td>val_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.73035</td></tr><tr><td>train_auc</td><td>0.47975</td></tr><tr><td>train_f1</td><td>0.65171</td></tr><tr><td>train_loss_epoch</td><td>0.56385</td></tr><tr><td>train_loss_step</td><td>0.60162</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.70803</td></tr><tr><td>val_auc</td><td>0.20378</td></tr><tr><td>val_f1</td><td>0.46667</td></tr><tr><td>val_loss_epoch</td><td>0.59029</td></tr><tr><td>val_loss_step</td><td>0.67105</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/szuqcm2s' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/szuqcm2s</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_172252-szuqcm2s\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "243078fc79474b24a1da079b16a551dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_173438-7ggl9evm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/7ggl9evm' target=\"_blank\">GINConv_4_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/7ggl9evm' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/7ggl9evm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_16_onehot_2\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 2.3 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "2.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6750c9edd7b349228e77406c897d1ff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▇▇▇▇▇▇▆▇▇▇▇▇▆█▇▇█▇▇▇▇▇█▇▇▇███████▇██</td></tr><tr><td>train_auc</td><td>▁▄▆▆▇▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇██▇█▇█▇███████</td></tr><tr><td>train_f1</td><td>▁▅▆▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇██▇▇█▇▇█▇▇▇██████████</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▃▄▄▄▃▃▃▃▂▃▂▃▂▂▂▂▂▂▂▂▃▂▂▂▂▁▁▁▂▂▂▂▂▂▁▁</td></tr><tr><td>train_loss_step</td><td>▇▆▄▅▅▃▅█▅▅▄▃▁▅▂▅▃▃▃▄▂▃▄▄▅▂▄▃▄▂▅▄▂▃▄▄▂▄▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▃▃▆▇▇▆▇▆▇█▇▇▆▇▆▇▇▇█▇▅▆▇▄▆▆▇▇▇▆▆▇▇▇▇▇█▇</td></tr><tr><td>val_auc</td><td>▁▃▅▆▆▇▅▅▇▆▇█▇▇▇█▇▆▇▇▇▆▇▇▆▅▅▅▇▇▇▆▆▆▅▅▇▇▆▆</td></tr><tr><td>val_f1</td><td>▁▃▃▄▆▆▇▇▇▆▇██▇▅▆███▇██▅▆▇█▇█▇▇▆▇█▇▆▇██▇█</td></tr><tr><td>val_loss_epoch</td><td>█▆█▆█▅▃▃▄▄▄▂▄▃▅▅▅▄▂▄▃▄▇▅▅▆▃▄▃▄▇▃▄▅▅▄▁▅▄▅</td></tr><tr><td>val_loss_step</td><td>▇▅█▅▃▂▃▂▃▄▃▂▃▄▂▄▃▁▄▂▂▃▄▃▃▇▄▃▂▄▅▅▄▂▅▃▆▂▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77879</td></tr><tr><td>train_auc</td><td>0.83652</td></tr><tr><td>train_f1</td><td>0.71462</td></tr><tr><td>train_loss_epoch</td><td>0.48674</td></tr><tr><td>train_loss_step</td><td>0.46312</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.75547</td></tr><tr><td>val_auc</td><td>0.82137</td></tr><tr><td>val_f1</td><td>0.70222</td></tr><tr><td>val_loss_epoch</td><td>0.54705</td></tr><tr><td>val_loss_step</td><td>0.60113</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/7ggl9evm' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/7ggl9evm</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_173438-7ggl9evm\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8548c32cac3748b5824b1dad0dbc1afc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_174618-v4rwosea</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/v4rwosea' target=\"_blank\">GINConv_4_16_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/v4rwosea' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/v4rwosea</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_16_onehot_2\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 2.3 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "2.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.7 K     Total params\n",
      "0.011     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▆▆▇▆▆▆▆▇▆▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▆▇███▇▇█▇▇▇</td></tr><tr><td>train_auc</td><td>▁▄▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇██▇█████████████</td></tr><tr><td>train_f1</td><td>▁▄▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇▇██████▇█▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▃▃▄▃▃▂▂▃▃▂▃▂▃▂▂▃▂▂▂▁▂▂▂▂▂▂▁▁▁▂▁▁▁▂▂</td></tr><tr><td>train_loss_step</td><td>██▆▅▆▅▄▅▃▃▃▄▃▃▄▄▅▂▃▃▄▂▂▆▁▆▃▃▅▃▆▆▄▄▅▃▂▄▂▇</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▃▄▄▅▅▆▇▆▆▆▆▇▇▇▇▆▆▇▇▆▇▇▇▇█▆▇█▇█▇▆▇█▆██▅</td></tr><tr><td>val_auc</td><td>▁▃▆▆▇▇█▇████▇▇█▇▆▇▇▇▇▇▇▇▇▇▆▆▇▇▇█▇▆▇▅▇▇▆▇</td></tr><tr><td>val_f1</td><td>▁▂▃▄▅▅▅▆▇▆▆▆▆▇▇██▆▆▇█▆█▇▇▇██▇█▇█▇▆▇█▆██▆</td></tr><tr><td>val_loss_epoch</td><td>▇▆█▆██▅▃▂▄▅▆▂▃▃▃▂▃▂▁▄▅▄▃▃▃▃▄▄▃▁▁▃▅▅▄▅▂▃▄</td></tr><tr><td>val_loss_step</td><td>▆▅█▄▄▃▃▃▁▂▂▃▁▁▂▃▃▄▂▅▁▂▄▂▁▂▂▃▄▁▃▃▄▁▃▆▂▃▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.74863</td></tr><tr><td>train_auc</td><td>0.81392</td></tr><tr><td>train_f1</td><td>0.63382</td></tr><tr><td>train_loss_epoch</td><td>0.52447</td></tr><tr><td>train_loss_step</td><td>0.62786</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.70438</td></tr><tr><td>val_auc</td><td>0.82855</td></tr><tr><td>val_f1</td><td>0.47059</td></tr><tr><td>val_loss_epoch</td><td>0.57677</td></tr><tr><td>val_loss_step</td><td>0.5471</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/v4rwosea' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/v4rwosea</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_174618-v4rwosea\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8415a1f81e24467ca094749ae0494d13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_175746-t6jbhdg6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/t6jbhdg6' target=\"_blank\">GINConv_4_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/t6jbhdg6' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/t6jbhdg6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_32_onehot_2\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 8.2 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "8.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.7 K     Total params\n",
      "0.035     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇█▇▇█▇▇███████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇██▇▇███████</td></tr><tr><td>train_f1</td><td>▁▆▆▇▇▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇██▇▇▇█▇▇█▇████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▅▄▅▄▄▃▃▄▄▃▃▃▃▃▃▂▃▂▂▃▂▂▂▂▂▂▂▁▂▂▂▂▁▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>▇▅█▆▃▄▄▅▄▄▄▃▅▄▄▃▂▃▁▄▂▃▅▂▃▃▃▅▃▂▁▅▁▁▃▂▁▂▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▄▆█▇█▅▃▆▇▇▆▆▇▆▆▇▆██▆▇▇▇█▇▄▇▇▆▇▆▅▇▅▇▆▅▆</td></tr><tr><td>val_auc</td><td>▁▇█▂█▆▆▇▂▃▅▆▄▅▅▄▆▇▅█▇▅▅▂▆▇▄▁▅▄▃▅▅▅▅▄▂▃▆▇</td></tr><tr><td>val_f1</td><td>▁▄▄█▇██▅█▇█▇█▆▇█▇▇▇███▇███▇█▇███▇▆▇▅▇██▆</td></tr><tr><td>val_loss_epoch</td><td>▅▄▄▃▂▂▂▄▆▂▂▃▂▂▁▂▂▂▃▃▃▃▁▅▃▃▂▆▄▂▄▂▃▂▃▆▁▄█▆</td></tr><tr><td>val_loss_step</td><td>▃▄▂▃▂▂▁▅▅▂▂▂▃▂▂▃▂▃▁▂▂▂▂▃▃█▃▃▃▃▃▅▄▄▄▃▁▄▄▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.80256</td></tr><tr><td>train_auc</td><td>0.86598</td></tr><tr><td>train_f1</td><td>0.73529</td></tr><tr><td>train_loss_epoch</td><td>0.44845</td></tr><tr><td>train_loss_step</td><td>0.45615</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.72628</td></tr><tr><td>val_auc</td><td>0.82839</td></tr><tr><td>val_f1</td><td>0.5283</td></tr><tr><td>val_loss_epoch</td><td>0.72604</td></tr><tr><td>val_loss_step</td><td>0.83219</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/t6jbhdg6' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/t6jbhdg6</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_175746-t6jbhdg6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_180910-scfcnsgv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/scfcnsgv' target=\"_blank\">GINConv_4_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/scfcnsgv' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/scfcnsgv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_32_onehot_2\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 8.2 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "8.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.7 K     Total params\n",
      "0.035     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▅▅▆▅▇▆▆▇▇▆▇▇▇▆▇▇▇▇▇▇▇██▇███▇▇█▇█▇████</td></tr><tr><td>train_auc</td><td>▁▃▄▅▅▆▅▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇▇█████</td></tr><tr><td>train_f1</td><td>▁▁▅▆▆▆▆▇▇▆▇▇▇▇▇▇▇█▇▇▇▇▇▇██▇███▇▇█▇█▇███▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▂▂▂▁▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▆█▆▄▄▅▃▄▅▄▄▄▄▄▃▃▄▂▄▃▄▃▃▃▃▃▃▃▂▂▃▂▂▃▂▂▁▄▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▄▆▄▃██▇▇▇▇▇▆▇▄▆▇▆▇█▇██▇▇▇▇█▇▆▇▇█▆▇▅▆█▇</td></tr><tr><td>val_auc</td><td>▁▆▅▇▇▆██▆▇▇▇█▇▇▇▇▇▇▇▇███▇██▇█▇▆▇█▇▆▇▇▇▇█</td></tr><tr><td>val_f1</td><td>▇▁▄█▇▇█▇█▇▇▇▇████▇█▇█▇████▆█▇██▇█████▆██</td></tr><tr><td>val_loss_epoch</td><td>█▆▅▅▆▇▃▂▅▄▃▂▂▃▃▆▇▃▆▄▄▁▁▅▅▄▂▃▄▄▄▁▃▂▄▄▅▃▅▃</td></tr><tr><td>val_loss_step</td><td>▇▅▄▅▄▅▃▄▄▃▂▃▃▂▂▅▃▄▃▂▄▂▂▄█▃▃▂▃▃▄▃▇▃▅▃▁▅▇▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77057</td></tr><tr><td>train_auc</td><td>0.82174</td></tr><tr><td>train_f1</td><td>0.69278</td></tr><tr><td>train_loss_epoch</td><td>0.50095</td></tr><tr><td>train_loss_step</td><td>0.5229</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.74088</td></tr><tr><td>val_auc</td><td>0.82452</td></tr><tr><td>val_f1</td><td>0.71937</td></tr><tr><td>val_loss_epoch</td><td>0.55249</td></tr><tr><td>val_loss_step</td><td>0.56932</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/scfcnsgv' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/scfcnsgv</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_180910-scfcnsgv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c81af7df7c444e199fc9842af0b210a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_182056-6kx83x1r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/6kx83x1r' target=\"_blank\">GINConv_4_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/6kx83x1r' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/6kx83x1r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_32_onehot_2\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 8.2 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "8.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.7 K     Total params\n",
      "0.035     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d940a97e9e14c909fdfd24451abcf05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▃▄▄▅▃▄▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇██▇▇▇██</td></tr><tr><td>train_auc</td><td>▆▅▇█▅▁▁▃▂▅▃▃▄▄▃▃▄▂▆▅▅▄▅▅▄▄▅▂▃▁▂▁▃▁▃▃▃▄▆▄</td></tr><tr><td>train_f1</td><td>▁▂▃▆▅▅▅▄▅▅▆▇▆▇▆▆▆▇▇▇▇█▇█▇▇▇▇▇█▇▇▇▇█▇███▇</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▅▇▇▆▇▅▇▇▇▆▇█▇███▇▇▇███▇█▇▇▇▆▇▇▇▇▇▆▇▇▆▆</td></tr><tr><td>val_auc</td><td>████▄▂▂▆▆▃▂▃▄▅▃▃▄▇▇▇▇█▆▇█▇▇▂▂▁▁▁▁▂▃▂▁▂▄▄</td></tr><tr><td>val_f1</td><td>▁▃▆▇▇▇█▆█▇█▇███████▇▇██████▇▇▇▇▇▇█▇▇▇▇▇▆</td></tr><tr><td>val_loss_epoch</td><td>█▅▂▁▂▁▂▂▁▁▂▂▁▁▁▁▁▁▁▂▁▁▁▂▁▁▁▂▂▁▂▁▁▁▁▂▁▁▂▂</td></tr><tr><td>val_loss_step</td><td>█▄▁▂▄▂▁▃▁▁▁▂▁▁▁▁▂▂▁▁▁▁▁▁▁▁▂▂▂▂▂▂▁▂▂▁▁▁▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.75868</td></tr><tr><td>train_auc</td><td>0.50354</td></tr><tr><td>train_f1</td><td>0.68269</td></tr><tr><td>train_loss_epoch</td><td>0.54825</td></tr><tr><td>train_loss_step</td><td>0.58518</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.71168</td></tr><tr><td>val_auc</td><td>0.41734</td></tr><tr><td>val_f1</td><td>0.52121</td></tr><tr><td>val_loss_epoch</td><td>0.61944</td></tr><tr><td>val_loss_step</td><td>0.77678</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/6kx83x1r' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/6kx83x1r</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_182056-6kx83x1r\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_183247-dr9hcn4h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/dr9hcn4h' target=\"_blank\">GINConv_4_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/dr9hcn4h' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/dr9hcn4h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_32_onehot_2\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 8.2 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "8.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.8 K     Total params\n",
      "0.035     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "450e0f6376aa44118e8f40d7c6d97bbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▆▆▇▆▆▇▇▆▇▆▇▇▆▇▇▇▇▇▇▇▇▇██▇█▇█▇█▇▇▇███</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▇▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇█▇▇▇▇████</td></tr><tr><td>train_f1</td><td>▁▆▅▆▆▆▇▆▆▆▆▆▇▆▇▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇███</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▄▅▄▄▄▄▄▃▄▃▃▃▃▄▃▃▃▂▃▃▂▂▃▂▂▃▂▂▂▂▂▂▂▂▂▁▂</td></tr><tr><td>train_loss_step</td><td>█▆▅▆▆▆▅▄▆▇▄▄▃▄▃▃▄▄▃▆▄▂▃▃▄▂▅▄▆▄▁▄▂▁▃▂▄▅▆▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▅▅▃▇▇▇▇█▇▇█▅▇█▇▆█▇▆▅▅▇▇▇▅▆▆▇▄▇▃▆▅█▅▇▇▅▄</td></tr><tr><td>val_auc</td><td>▁██▆▇▅▄▅▇▇▇▇▇█▇▆▆▆▅▆▆▃▆▆▄▁▅▅▃▃▂▅▆▄▆▃▂▅▅▄</td></tr><tr><td>val_f1</td><td>▁▅▆▄▇▇███▇██▆▇▇▇▆█▇▆▆▅███▇▇▇▇▅▇█▆▅█▇▇▇▆▄</td></tr><tr><td>val_loss_epoch</td><td>▄▄▃▅▂▃▁▂▂▂▃▃▄▃▁▂▄▂▂▄▅▇▂▃▂▂▃▂▄▅▅▇▃▅▄▂▃▂██</td></tr><tr><td>val_loss_step</td><td>▅▂▄▄▃▃▃▃▃▄▂▂▅▃▃▃▄▂▃▂▁▂▅▁▃▂▃▅▃▄▃▆▄▄▄█▃▄▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.81993</td></tr><tr><td>train_auc</td><td>0.86569</td></tr><tr><td>train_f1</td><td>0.7847</td></tr><tr><td>train_loss_epoch</td><td>0.45649</td></tr><tr><td>train_loss_step</td><td>0.41539</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.67153</td></tr><tr><td>val_auc</td><td>0.80081</td></tr><tr><td>val_f1</td><td>0.33824</td></tr><tr><td>val_loss_epoch</td><td>0.78878</td></tr><tr><td>val_loss_step</td><td>0.67259</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/dr9hcn4h' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/dr9hcn4h</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_183247-dr9hcn4h\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_184438-yzblnyy8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/yzblnyy8' target=\"_blank\">GINConv_4_32_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/yzblnyy8' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/yzblnyy8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_32_onehot_2\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 8.2 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "9.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "9.8 K     Total params\n",
      "0.039     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79dee0bfa1d24b08acc7a92e38ffd755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▆▆▇▇▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇█▇█▇██▇█▇▇███▇█</td></tr><tr><td>train_auc</td><td>▁▅▅▆▆▆▆▇▇▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇████▇██▇█████</td></tr><tr><td>train_f1</td><td>▁▅▆▅▆▆▆▇▇▆▇█▆▇▆▇▇▇▇▇▆▇▇▇▇▇▇█▇██▇█▇▇███▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▅▄▄▃▃▃▄▄▃▃▄▃▃▃▃▃▂▃▃▂▃▃▂▂▂▂▁▁▂▂▂▂▁▁▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▅▆▅▅▅▅▅▆▇▄▃▆▅▆▇▅▆▇▅▅▄▄▄▅▄▅▃▄▅▁▄▆▆▆▄▅▅▄▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▅▅▇▆▅▇▅▇█▆▅▇▇▇▇▇▇█▆▆▇▆▇▆▇▇▇▆▇▆▅▇▇▇▇▇▆▃▆</td></tr><tr><td>val_auc</td><td>▂▃▅▅▇███▇▇▆▇▇▇▇▇▇▇▆▅▆▆▅▆▅▇▅█▅▅▅▁▅▇▆▆▆▆▅▆</td></tr><tr><td>val_f1</td><td>▁▆▆▇▆▅▇▆██▇▆▇▇▇▇▇▇█▆▆█▇▇▇▇▇▇▇▇▆▅▇▇▇█▇▆█▆</td></tr><tr><td>val_loss_epoch</td><td>▅▃▄▃▃▃▂▅▂▂▃▂▁▁▂▂▂▃▂▂▄▂▅▂▃▃▄▅▃▂▄▃▂▅▂▆▅▇█▄</td></tr><tr><td>val_loss_step</td><td>▃▁▂▁▁▂▁▂▂▁▁▂▂▁▁▁▁▁▂▂▂▂▂▁▁▂▂▁▃▂▂▁▁▂▃▁█▁▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.7925</td></tr><tr><td>train_auc</td><td>0.85303</td></tr><tr><td>train_f1</td><td>0.72147</td></tr><tr><td>train_loss_epoch</td><td>0.44792</td></tr><tr><td>train_loss_step</td><td>0.42733</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.71533</td></tr><tr><td>val_auc</td><td>0.81297</td></tr><tr><td>val_f1</td><td>0.49351</td></tr><tr><td>val_loss_epoch</td><td>0.61235</td></tr><tr><td>val_loss_step</td><td>0.56679</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/yzblnyy8' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/yzblnyy8</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_184438-yzblnyy8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_185615-4n5nv9lg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/4n5nv9lg' target=\"_blank\">GINConv_4_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/4n5nv9lg' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/4n5nv9lg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_64_onehot_2\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 30.7 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "32.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "32.8 K    Total params\n",
      "0.131     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81bb2a76b95c4c4880f20c8f210625e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▅▆▅▆▆▆▆▆▇▆▆▇▆▆▇▇▇▇▇█▇▇▇▇▇▇▇▇█▇██████</td></tr><tr><td>train_auc</td><td>▁▄▅▅▅▅▅▅▅▅▄▃▄▃▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▅▆▆▆▇▇▆▇▇▅▇▇▆▇▇▇▇▇▇██▇█▇▇▇▇▇█▇██████</td></tr><tr><td>train_loss_epoch</td><td>█▇▆▅▅▅▅▄▄▄▄▄▄▄▄▃▄▃▃▃▃▃▃▂▃▃▂▃▂▂▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>▆▆█▄▄▅▅▅▂▆▃▅▄▅▄▃▅▃▂▃▃▄▂▂▂▂▄▄▄▃▃▂▃▂▃▂▁▂▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▄▆▆▇█▇█▇█▁▆▆▆▅▆█▅▇▇▆▅▄█▆▆▆▆▇▆▄▇▇▆█▅▇▆▅▆▇</td></tr><tr><td>val_auc</td><td>▄▆▁▇█████▃▆▆▅▇▅▇▄▆▅▅▄▇▇▄▅▅▄▆▅▃▅▆▅▇▃▅▃▁▇▄</td></tr><tr><td>val_f1</td><td>▁▅▇▆▇█▆██▇█▅█▃▄██▆▇▇▃██▆▅█▇▇▅▇▆▇▆▇▇▇▇▅█▇</td></tr><tr><td>val_loss_epoch</td><td>▅▂▂▁▁▂▁▁▂▆▁▃▃▄▂▄▃▁▁▂▅▅▂▂▁▂▄▁▂█▅▁▂▃▅▂▃▂▅▃</td></tr><tr><td>val_loss_step</td><td>▄▂▃▂▂▂▂▃▁█▄▅▃▇▄▃▅▃▂▃▅▅█▂▅▃▅▃▂▃▃▆▆▄▅▇▃▅▇▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.81536</td></tr><tr><td>train_auc</td><td>0.87389</td></tr><tr><td>train_f1</td><td>0.75721</td></tr><tr><td>train_loss_epoch</td><td>0.41377</td></tr><tr><td>train_loss_step</td><td>0.37605</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.71898</td></tr><tr><td>val_auc</td><td>0.77793</td></tr><tr><td>val_f1</td><td>0.65778</td></tr><tr><td>val_loss_epoch</td><td>0.65955</td></tr><tr><td>val_loss_step</td><td>0.678</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/4n5nv9lg' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/4n5nv9lg</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_185615-4n5nv9lg\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d2cf663b90b46b093cb46145cd7722e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_190826-5xrposp8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/5xrposp8' target=\"_blank\">GINConv_4_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/5xrposp8' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/5xrposp8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_64_onehot_2\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 30.7 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "32.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "32.8 K    Total params\n",
      "0.131     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▅▅▅▆▆▇▆▆▇▇▇▆▅▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███</td></tr><tr><td>train_auc</td><td>▁▃▅▅▅▆▅▆▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███</td></tr><tr><td>train_f1</td><td>▁▄▅▅▅▅▆▇▆▇▆▇▆▇▇▆▅▇▇▇▇▇▇█▇█▇▇▇▇▇▇▇▇▇▇▇██▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▄▅▄▄▃▄▃▃▃▂▃▄▂▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▃▂▂▂▁▂▂</td></tr><tr><td>train_loss_step</td><td>█▇▆▆▆▅▆▅▃▅▅▅▆▅▄▂▄▃▄▄▂▃▃▃▅▄▅▄▄▃▄▃▃▅▅▃▁▃▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▄▂▆▇█▇▆▇▇▆▇▁▇▇▅▅▅▇▇▅█▇▄▆▇▃▄▇▇▆▇▆▄▇█▆█▂▇▇</td></tr><tr><td>val_auc</td><td>▁▆▅▇█▅▇▇█▇▇▃▆▆▄▅▆▇▇▆▇▇▅▆▇▇▅▇▆▆▅▆▃▆▇▄▆▄▆▇</td></tr><tr><td>val_f1</td><td>▄▁▇▇▇█▆▇▇▆█▇█▇▇▇█▇██▇▇▇▇█▇▇▇▇█▇█▇▇▇██▇▇█</td></tr><tr><td>val_loss_epoch</td><td>▅▄▂▃▂▂▂▁▂▁▂▇▁▂▄▃▂▁▂▄▁▂▅▁▂▅▆▁▁▁▅▃▇▃▂▂▁█▂▂</td></tr><tr><td>val_loss_step</td><td>▆▅▄▂▂▂▂▂▁▂▃▇▄▃▄▅▄▂▁▄▄▃▅▅▇▅▅▃▄▂▃▂▄▄▄█▂▂▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77971</td></tr><tr><td>train_auc</td><td>0.8253</td></tr><tr><td>train_f1</td><td>0.71138</td></tr><tr><td>train_loss_epoch</td><td>0.48174</td></tr><tr><td>train_loss_step</td><td>0.39459</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.74818</td></tr><tr><td>val_auc</td><td>0.81247</td></tr><tr><td>val_f1</td><td>0.70638</td></tr><tr><td>val_loss_epoch</td><td>0.56257</td></tr><tr><td>val_loss_step</td><td>0.59347</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/5xrposp8' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/5xrposp8</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_190826-5xrposp8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_192026-lp74q2cu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/lp74q2cu' target=\"_blank\">GINConv_4_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/lp74q2cu' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/lp74q2cu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_64_onehot_2\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 30.7 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "32.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "32.8 K    Total params\n",
      "0.131     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▃▄▄▄▄▅▅▅▆▆▆▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇█</td></tr><tr><td>train_auc</td><td>▇▆█▇█▆▄▃▄▄▅▅▄▅▅▅▄▅▅▅▃▃▁▂▂▂▄▅▅▄▅▄▅▂▂▃▂▂▂▂</td></tr><tr><td>train_f1</td><td>▁▂▂▄▂▃▅▅▆▅▅▆▆▆▇▆▆▆▇▆▇▇▇▇▇▇▇▇▇█▇▇▆▇▇▇██▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▁▄▆▆▆▅▅▆▆▆▆▆▇▇▇▇██▇▅▇▇▆▇▇▆█▇▆▅█▇▆▇▇▆▆▆▆</td></tr><tr><td>val_auc</td><td>█▇█▇▇▃▂▂▂▂▂▂▂▂▂▁▂▂▂▂▁▁▁▂▂▁▂▂▁▁▁▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val_f1</td><td>▁▂▅▆▆▆▇▆▇▆▇▇▇▇█▇▇███▆██▆▇▇▇█▇▆██▇█▇▇▇▇▇▆</td></tr><tr><td>val_loss_epoch</td><td>█▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.76782</td></tr><tr><td>train_auc</td><td>0.34065</td></tr><tr><td>train_f1</td><td>0.69617</td></tr><tr><td>train_loss_epoch</td><td>0.5357</td></tr><tr><td>train_loss_step</td><td>0.49912</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.71898</td></tr><tr><td>val_auc</td><td>0.18178</td></tr><tr><td>val_f1</td><td>0.54438</td></tr><tr><td>val_loss_epoch</td><td>0.53482</td></tr><tr><td>val_loss_step</td><td>0.51888</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/lp74q2cu' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/lp74q2cu</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_192026-lp74q2cu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_193233-a6zcw372</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/a6zcw372' target=\"_blank\">GINConv_4_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/a6zcw372' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/a6zcw372</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_64_onehot_2\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 30.7 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "32.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "32.9 K    Total params\n",
      "0.131     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▄▆▅▆▆▆▆▇▇▆▇▇▇▇▆▆▇▇▇▇▇██▇▇▇▇█▇█▇▇██▇██</td></tr><tr><td>train_auc</td><td>▁▅▆▅▆▅▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇██▇██</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▇▆▆▆▇▇▆▇▇▇▆▆▇▇▇▇▇▇██▇█▇▇█▇█▇▇██▇██</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▆▅▅▄▄▄▄▃▄▄▃▃▃▃▃▄▃▃▃▃▃▂▂▂▂▂▂▂▃▂▂▃▁▁▂▁▂</td></tr><tr><td>train_loss_step</td><td>█▆▇▆▄▄▅▅▄▃▅▄▃▄▅▄▇▆▇▄▃▃▁▄▄▂▂▇▂▄▁▄▂▃▅▃▂▄▂▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▇▇▇█▇▆▇▆▆▆▅▆▇▆▇▆▅▆▆▆▄▅▇▇▇▆▃▇▇▅▄▅▄▇▅▅▆▅</td></tr><tr><td>val_auc</td><td>▅▆▇▇▆▇█▅▇▆▆▆▅▆▆▆▆▆▇▆▅▆▅▆▆▅▆▅▄▄▇▄▃▅▄▅▁▄▄▅</td></tr><tr><td>val_f1</td><td>▁▃█▇███▇▇▆█▇███▆▇█▅▇▆█▄█▇▇▇▇██▇▇▅▅▄▇▆▆▆▇</td></tr><tr><td>val_loss_epoch</td><td>▆▅▃▂▂▁▃▂▂▂▃▂▂▂▂▁▃▂▄▃▅▂▆▃▁▄▂▃▆▂▂▂█▆▄▂▃▄▃▂</td></tr><tr><td>val_loss_step</td><td>▇▆▃▃▄▄▂▃▃▄▄▃▅▄▄▃▄▄▄▃▃▅▅▄▃▆▄▄▄▄▃▃▃▅▅▄█▃▇▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.82267</td></tr><tr><td>train_auc</td><td>0.87961</td></tr><tr><td>train_f1</td><td>0.77803</td></tr><tr><td>train_loss_epoch</td><td>0.42477</td></tr><tr><td>train_loss_step</td><td>0.46476</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.70438</td></tr><tr><td>val_auc</td><td>0.78605</td></tr><tr><td>val_f1</td><td>0.65236</td></tr><tr><td>val_loss_epoch</td><td>0.56233</td></tr><tr><td>val_loss_step</td><td>0.36603</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/a6zcw372' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/a6zcw372</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_193233-a6zcw372\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_194439-9uolnrno</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/9uolnrno' target=\"_blank\">GINConv_4_64_onehot_2</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/9uolnrno' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/9uolnrno</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_64_onehot_2\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 30.7 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "37.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "37.0 K    Total params\n",
      "0.148     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▆▆▆▇▆▆▇▆▆▇▆▇▇▆▇▇▆▇▇▇▇▇█▇▇▇▇▇▇██▇▇███</td></tr><tr><td>train_auc</td><td>▁▄▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇▇█▇█▇███</td></tr><tr><td>train_f1</td><td>▁▅▅▆▆▆▆▇▆▆▇▇▆▇▇▇▇▆▇▇▆▇▆▇▇▇█▇▇▇▇▇▇███▇██▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▅▄▄▄▄▄▄▄▄▃▄▄▃▄▃▃▃▃▃▃▃▃▂▂▃▂▂▂▂▂▂▂▃▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▇▅██▆▅▅▅▇▆▇▄▄▅▅▄▅▄▅▇▆▄▄▄▅▃▅▅▆▅▄▄▆▄▄▅▅▅▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▄▇▆█▆▇▇▆▆▄▅▅▆▆▆▆▅▆▆▄▅▅▅▆▅▆▆▄▆▅▆▆▅▆▆▄▄▆▄</td></tr><tr><td>val_auc</td><td>▁▅█▇█▇█▅▆▇▇▅▅▇▅▆▆▅▅▅▂▄▄▄▅▄▄▃▂▃▁▄▆▃▄▄▄▃▂▁</td></tr><tr><td>val_f1</td><td>▁▅▇██▇▇█▆▇▅█▆▆▆▆▇▆██▅▆▇█▆▇▇▇▅▇▅▇▇▇▇▇▄▇▇▅</td></tr><tr><td>val_loss_epoch</td><td>▄▃▁▂▂▂▁▂▂▁▂▃▃▂▃▃▁▂▃▂▂▃▂▄▂▂▂▂▂▃▅▅▂▃▂▂▇▃▂█</td></tr><tr><td>val_loss_step</td><td>▄▃▂▁▂▂▂▂▂▂▂▃▂▂▁▃▁▂▂▂▂▂▂▂▄▄▃▆▂▂▇▁▃▄▄▃▂▃▃█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.80804</td></tr><tr><td>train_auc</td><td>0.88886</td></tr><tr><td>train_f1</td><td>0.75294</td></tr><tr><td>train_loss_epoch</td><td>0.39141</td></tr><tr><td>train_loss_step</td><td>0.27043</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.67518</td></tr><tr><td>val_auc</td><td>0.76693</td></tr><tr><td>val_f1</td><td>0.37762</td></tr><tr><td>val_loss_epoch</td><td>1.02137</td></tr><tr><td>val_loss_step</td><td>0.94838</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_2</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/9uolnrno' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/9uolnrno</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_194439-9uolnrno\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_195634-g8mxdtmp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/g8mxdtmp' target=\"_blank\">GINConv_2_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/g8mxdtmp' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/g8mxdtmp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_16_onehot_3\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▆▆▇▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▆█▇▇▇███</td></tr><tr><td>train_auc</td><td>▁▃▅▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇██▇██▇████</td></tr><tr><td>train_f1</td><td>▁▃▆▆▆▆▇▆▇▅▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▇▇█▇███</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▄▃▃▃▃▂▂▃▃▂▂▃▃▂▂▂▃▂▂▂▂▂▃▂▂▂▂▂▂▁▃▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▅▅▄▅▄▄▅▄▅▂█▃▂▂▂▂▅▅▁▄▄▄▃▁▃▃▄▄▂▂▄▄▃▁▃▂▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▃▅▇▆▇▇▇█▇▇▇▇▆▇▇▇▇▇█▇▇▇▇▂▇█▇▇▇█▇█▇█▇▇▇█</td></tr><tr><td>val_auc</td><td>▁▃▄▅▆▆▆▆▇▆▆▇▇▇▇▇▇▆▇▇▇▇▇▇▇▆▇█████▇▇▇▇▇▇▇▇</td></tr><tr><td>val_f1</td><td>▁▄▃▅█▆████▇▇██▆▇▇█▇██▇█▇█▇▇▇▇▇▇█▇█████▇█</td></tr><tr><td>val_loss_epoch</td><td>█▅▆▇▄▄▄▆▃▂▃▄▃▆▃▃▄▅▃▁▅▄▄▂▆▇▃▅▂▂▁▃▆▂▂▃▂▄▂▂</td></tr><tr><td>val_loss_step</td><td>▇▄█▄▄▂▃▃▂▄▂▃▃▂▃▃▃▄▃▂▃▂▂▂▃▃▃▄▂▂▃▇▂▃▄▄▃▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77078</td></tr><tr><td>train_auc</td><td>0.81418</td></tr><tr><td>train_f1</td><td>0.70296</td></tr><tr><td>train_loss_epoch</td><td>0.50887</td></tr><tr><td>train_loss_step</td><td>0.44988</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.77656</td></tr><tr><td>val_auc</td><td>0.84854</td></tr><tr><td>val_f1</td><td>0.7109</td></tr><tr><td>val_loss_epoch</td><td>0.46977</td></tr><tr><td>val_loss_step</td><td>0.43674</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/g8mxdtmp' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/g8mxdtmp</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_195634-g8mxdtmp\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f9162916de24aa0ada99d49dc98862a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_200809-i9n6d4ur</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/i9n6d4ur' target=\"_blank\">GINConv_2_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/i9n6d4ur' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/i9n6d4ur</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_16_onehot_3\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83a95ee043c144b99daab44e503b0e2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▃▄▅▄▅▅▅▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇█▇█▇▇▇██▇</td></tr><tr><td>train_auc</td><td>▂▁▂▂▄▅▅▆▆▆▆▇▆▇▇▇▇▇█▇▇▇▇▇▇█▇██▇▇█▇██████▇</td></tr><tr><td>train_f1</td><td>▅▁▁▄▅▅▄▆▆▅▆▇▆▆▇▇█▇▇▇▇▇▇█▇█▇▇█▇▇█▇█▇█▇██▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▅▅▅▄▄▄▄▃▃▄▃▃▃▂▃▂▂▂▃▂▂▂▁▂▂▁▂▂▁▂▂▂▂▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▇▆▆▆▇▄▆▇▅▅▄█▃▄▅▂▃▅▇▂▄▅▄▃▁▄▄▂▄▂▃▅▄▅▁▃▂▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▁▂▄▅▅▆▆▇▇▇▆▆▆▇▇▇▇▇▇▇▆▇▇████▇█▇▇█▇▇▇▇▆▇█</td></tr><tr><td>val_auc</td><td>▁▂▃▅▅▅▆▆▅▇▆▆▆▇██▇▇███▇▇▇███▇▇▇█▇▇█▇██▇▇█</td></tr><tr><td>val_f1</td><td>▁▁▂▅▅▅▆▆▇▇▇▆▇▇▆▇▇▇██▇▆▇█▇█▇█▇██▇█▇██▇▆▇█</td></tr><tr><td>val_loss_epoch</td><td>██▆▇▅▆▆▅▄▄▃▄▅▅▂▃▅▃▅▃▃▄▅▂▃▁▃▄▁▃▂▄▄▂▂▂▁▄▂▃</td></tr><tr><td>val_loss_step</td><td>█▆▇▆▅▅▅▃▄▅▃▅▅▅▃▃▂▂▅▃▂▃▂▂▁▃▃▃▃▁▂▂▂▂▂▂▃▂▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.72603</td></tr><tr><td>train_auc</td><td>0.76546</td></tr><tr><td>train_f1</td><td>0.62871</td></tr><tr><td>train_loss_epoch</td><td>0.55904</td></tr><tr><td>train_loss_step</td><td>0.50887</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.7326</td></tr><tr><td>val_auc</td><td>0.80699</td></tr><tr><td>val_f1</td><td>0.70683</td></tr><tr><td>val_loss_epoch</td><td>0.55545</td></tr><tr><td>val_loss_step</td><td>0.57646</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/i9n6d4ur' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/i9n6d4ur</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_200809-i9n6d4ur\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_201924-b2koy0fi</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/b2koy0fi' target=\"_blank\">GINConv_2_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/b2koy0fi' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/b2koy0fi</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_16_onehot_3\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▂▁▂▃▄▃▄▅▄▅▆▅▅▆▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇███</td></tr><tr><td>train_auc</td><td>▂▁▂▁▃▄▄▆▅▆▇▆▄▆▆▅▆▆▆▇▇▇▇▇▇▇▇▇██▇▇▇▇▆▇▇▇▆█</td></tr><tr><td>train_f1</td><td>▄▅▃▄▃▁▂▄▄▄▅▅▆▅▆▆▆▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇███</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▄▂▅▅▄▄▅▅▆▆▆▆▆▇▆▇▆▇▇▇▇▇▇██▆███▆███▇██▇▇▇</td></tr><tr><td>val_auc</td><td>▂▁▂▃▅▆▆▆▆▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇███▇▇</td></tr><tr><td>val_f1</td><td>▁▄▄▅▆▄▅▆▆▆▇▆▇▇▇▇▇▇▇█▇▇▇██████████████▇██</td></tr><tr><td>val_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.73425</td></tr><tr><td>train_auc</td><td>0.681</td></tr><tr><td>train_f1</td><td>0.64982</td></tr><tr><td>train_loss_epoch</td><td>0.58042</td></tr><tr><td>train_loss_step</td><td>0.59501</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.75458</td></tr><tr><td>val_auc</td><td>0.81024</td></tr><tr><td>val_f1</td><td>0.71489</td></tr><tr><td>val_loss_epoch</td><td>0.5308</td></tr><tr><td>val_loss_step</td><td>0.51553</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/b2koy0fi' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/b2koy0fi</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_201924-b2koy0fi\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91c1fd1d14ea4c26b57cf333b5f033f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_203034-ghtlj7r3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ghtlj7r3' target=\"_blank\">GINConv_2_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ghtlj7r3' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ghtlj7r3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_16_onehot_3\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.1 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▅▆▆▇▆▇▇▇▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇▇▇▇▇██▇█▇</td></tr><tr><td>train_auc</td><td>▁▄▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇███▇█▇▇█▇██▇▇███████</td></tr><tr><td>train_f1</td><td>▁▃▆▅▅▅▆▇▆▆▇▆▆▆▆▇▇▆▇▇▇▆▆▆█▇▇▇▇█▇▇▆▇▇▇█▇█▆</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▅▄▄▃▄▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▃▃▂▂▂▂▂▃▂▂▁▁▂▁▂</td></tr><tr><td>train_loss_step</td><td>█▇▇▅▇▅▆▂▄▂▂▆▆▂▅▅▄▃▆▄▄▃▂▄▅▃▅▅▄▆▄▄▃▂▄▆▁▄▄▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▅▅▄▇▇▇▇▇█▇▅▇▆▇▅▅██▇▇▇█▇█▇▆▇█▇▇▆▇▅▆▆▇▆▇</td></tr><tr><td>val_auc</td><td>▁▄▅▅▆▆▇▇▇▇▇██▇███▇██████▇███▇██▇▇▇██▇▇▇█</td></tr><tr><td>val_f1</td><td>▁▃▅▅▅█▇▇▇▇█▇▇▇▆█▇███▇█▇███▇█▇█▇███▇▆█▇█▇</td></tr><tr><td>val_loss_epoch</td><td>█▆▇▄▆▅▄▂▂▃▃▃▄▂▂▄▆▄▄▃▂▃▃▂▁▆▄▅▃▄▂▂▃▃▅▅▅▃▅▁</td></tr><tr><td>val_loss_step</td><td>█▇▆▆▇▆▅▅▅▅▃▅▅▅▅▅▅▆▅▄▅▆▅▇▅▅▄▄▄▄▇▅▆▄▇▄▅▄▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.75251</td></tr><tr><td>train_auc</td><td>0.81048</td></tr><tr><td>train_f1</td><td>0.64011</td></tr><tr><td>train_loss_epoch</td><td>0.51625</td></tr><tr><td>train_loss_step</td><td>0.45833</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.78388</td></tr><tr><td>val_auc</td><td>0.85278</td></tr><tr><td>val_f1</td><td>0.7122</td></tr><tr><td>val_loss_epoch</td><td>0.4212</td></tr><tr><td>val_loss_step</td><td>0.29458</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ghtlj7r3' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ghtlj7r3</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_203034-ghtlj7r3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_204153-dsx7p6sx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/dsx7p6sx' target=\"_blank\">GINConv_2_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/dsx7p6sx' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/dsx7p6sx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_16_onehot_3\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.1 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "1.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.5 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▆▆▇▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇▇█▇▇▇▇█</td></tr><tr><td>train_auc</td><td>▁▃▅▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇██▇█▇▇████▇█</td></tr><tr><td>train_f1</td><td>▁▃▆▆▆▇▆▇▆▇▇▆█▇▇▇▇▇▇▇▇█▇▇▆█▇█▇▇▇█████▇▇▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▅▄▃▄▃▃▃▂▃▃▂▃▂▄▃▂▂▂▂▃▂▃▃▂▂▃▂▂▂▂▂▂▁▂▁</td></tr><tr><td>train_loss_step</td><td>▇█▆▅▅▃▇▅▄▃▂▄▅▅▄▄▄▆▅▄▃▄▄▂▂▃▂▅▄▁▃▄▄▅▂▃▄▃▅▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▃▆▇▅███▇█▇██▇▇▇▇█▇█▆▇▆▅████▇▆▇▇██▇▇█▆▇</td></tr><tr><td>val_auc</td><td>▁▃▄▅▆▆▆▆▇▆▇▇▇▇▇▇▇██▇█▇██▇███▇█▇▇██████▇█</td></tr><tr><td>val_f1</td><td>▁▃▄▆█▅███▇█▇███▇▇▇█▇███▆▅████▇▆▇███▇▇█▆█</td></tr><tr><td>val_loss_epoch</td><td>█▆▅▆▆▆▄▃▂▃▅▄▃▅▃▃▃▄▅▄▂▄▄▆▅▂▂▃▅▅█▃▃▃▂▄▁▂▅▃</td></tr><tr><td>val_loss_step</td><td>▆▅█▃▃▃▄▄▂▃▃▂▃▂▃▃▃▃▃▂▃▃▃▃▁▃▃▄▄▂▁▄▃▂▃▃▃▂▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.76621</td></tr><tr><td>train_auc</td><td>0.83594</td></tr><tr><td>train_f1</td><td>0.68317</td></tr><tr><td>train_loss_epoch</td><td>0.49274</td></tr><tr><td>train_loss_step</td><td>0.47625</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.76923</td></tr><tr><td>val_auc</td><td>0.84695</td></tr><tr><td>val_f1</td><td>0.73418</td></tr><tr><td>val_loss_epoch</td><td>0.48107</td></tr><tr><td>val_loss_step</td><td>0.46293</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/dsx7p6sx' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/dsx7p6sx</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_204153-dsx7p6sx\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c69dbeaeed7e4649913556b1c2c534db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_205308-xbrt2nzx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/xbrt2nzx' target=\"_blank\">GINConv_2_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/xbrt2nzx' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/xbrt2nzx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_32_onehot_3\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 3.7 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "4.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.2 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e15722822934a4da680e158cb2bdf96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇██▇█▇██▇▇███████████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇██▇▇███████████</td></tr><tr><td>train_f1</td><td>▁▅▆▇▆▇▇▇▇▇▇▇▇▇▇▇▆▇▇▇█▇▇▇▇██▇▇█▇▇███▇▇█▇█</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▃▃▃▄▃▂▂▃▂▂▃▂▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▂▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▃▅▃▆▄▆▄▄▄▂▄▄▃▂▄▄▄▅▁▂▃▁▅▃▅▁▃▁▃▂▃▃▂▃▄▂▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▂▃▁▆▇▇▆▇▇▇▇▇▇▇▇▆▅▇▇█▆█▇▇▇▅▇▇▇▇▇██▄▇█▇▄▇▄</td></tr><tr><td>val_auc</td><td>▁▄▄▆▆▆▆▆▇▇▇▇▇▇▇▇▇█▇█▇▇▇▇▇▇▆█▇▇▇█▆▇▇▇▇▇▇▇</td></tr><tr><td>val_f1</td><td>▂▃▁▆███▇▇▇███▇▇██▆████▇▇▇██▇██▇██▇██▇▇█▅</td></tr><tr><td>val_loss_epoch</td><td>▆▄█▂▃▄▂▄▂▄▂▂▄▂▂▅▄▃▃▄▃▃▄▁▁▄▂▂▁▂▄▁▁▂▃▄▂▄▃▅</td></tr><tr><td>val_loss_step</td><td>▆▆█▃▂▃▃▂▄▂▄▂▂▃▂▂▄▃▂▁▄▃▂▄▃▄▅▂▂▅▂▄▃▂▃▄▄▂▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77443</td></tr><tr><td>train_auc</td><td>0.83826</td></tr><tr><td>train_f1</td><td>0.70419</td></tr><tr><td>train_loss_epoch</td><td>0.48713</td></tr><tr><td>train_loss_step</td><td>0.48241</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.69963</td></tr><tr><td>val_auc</td><td>0.83886</td></tr><tr><td>val_f1</td><td>0.5</td></tr><tr><td>val_loss_epoch</td><td>0.60169</td></tr><tr><td>val_loss_step</td><td>0.57349</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/xbrt2nzx' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/xbrt2nzx</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_205308-xbrt2nzx\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_210502-ep0zj188</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ep0zj188' target=\"_blank\">GINConv_2_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ep0zj188' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ep0zj188</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_32_onehot_3\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 3.7 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "4.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.2 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▃▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇▇▇████▇▇███</td></tr><tr><td>train_auc</td><td>▁▃▃▅▆▆▆▆▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇▇▇██▇█▇████</td></tr><tr><td>train_f1</td><td>▂▁▃▅▇▇▆▇▇▇▇▇▇▇█▇▇▇▇██▇▇████▇▇█▇█████████</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▄▄▄▄▄▃▃▂▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▃▂▂▂▂▁▂▂▁▁▂▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▅▆▄▇▄▅▄▆▅▃▅▅▃▄▄▃▅▄▃▃▄▁▆▃▅▂▃▂▂▂▃▂▃▃▄▃▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▆▇▇▇▆▅▇▆▇▇▇▆█▇█▇▇█▇█▇██▇▇▇█▇█▇████▇█▇█▇</td></tr><tr><td>val_auc</td><td>▁▃▄▄▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▆▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇█▇█▇</td></tr><tr><td>val_f1</td><td>▅▁▅▅▅▃▇▇▆▆▇▆▇▇▇▇▇▆█▇▇█▇▇▇▇▅██▇▇█▇▇▇█▇█▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▆▅▅▅▅▅▅▅▅▃▄▆▃▄▄▄▂▄▂▂▄▃▄▅▃▃▁▃▂▅▁▂▁▂▇▂▆▂▄</td></tr><tr><td>val_loss_step</td><td>█▆▅▄▅▄▆▃▆▄▅▃▄▃▅▃▄▃▂▂▁▃▂▅▁▄▃▂▃▄▄▃▄▅▁▄▃▄▂▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.7589</td></tr><tr><td>train_auc</td><td>0.82037</td></tr><tr><td>train_f1</td><td>0.67164</td></tr><tr><td>train_loss_epoch</td><td>0.50906</td></tr><tr><td>train_loss_step</td><td>0.45895</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.74359</td></tr><tr><td>val_auc</td><td>0.8383</td></tr><tr><td>val_f1</td><td>0.72868</td></tr><tr><td>val_loss_epoch</td><td>0.57684</td></tr><tr><td>val_loss_step</td><td>0.63269</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ep0zj188' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ep0zj188</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_210502-ep0zj188\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_211709-tkgkcag7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/tkgkcag7' target=\"_blank\">GINConv_2_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/tkgkcag7' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/tkgkcag7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_32_onehot_3\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 3.7 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "4.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.2 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▂▃▂▅▅▅▆▆▅▆▆▆▆▅▆▆▇▆▇▆▆▆▇▆▇▇▅▆▆▇▇▇██▇█▇█</td></tr><tr><td>train_auc</td><td>▇▇▃▂▄▅▆▆▇▅▆▆▇█▆▆▆▄▅▄▄▄▅▄▂▂▂▁▂▃▅▆▄▄▄▅▄▅▃▃</td></tr><tr><td>train_f1</td><td>▁▃▁▃▄▅▄▄▆▅▅▅▅▆▆▅▆▆▇▆▇▅▆▆▇▆▇▆▅▇▅▇█▇▇█▇█▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▅▃▅▆▆▆▆▆▇▇▆▆▇▅█▇▇▇▇█▇▆▇█▇█▇▇▇▇▇▇█▆▇▇▇▇</td></tr><tr><td>val_auc</td><td>█▇▃▂▅▆▇▇▆▇▇▇▇▇▇▇▆▆▆▆▆▆▆▄▄▄▄▃▃▄▇▇▆▆▆▅▇▇▄▁</td></tr><tr><td>val_f1</td><td>▁▄▇▅▇▇▇▇▇▇▇▇▇▇▇▇█▇████▇███▇███▇█████████</td></tr><tr><td>val_loss_epoch</td><td>█▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.72511</td></tr><tr><td>train_auc</td><td>0.50181</td></tr><tr><td>train_f1</td><td>0.63866</td></tr><tr><td>train_loss_epoch</td><td>0.57861</td></tr><tr><td>train_loss_step</td><td>0.60116</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.75092</td></tr><tr><td>val_auc</td><td>0.35663</td></tr><tr><td>val_f1</td><td>0.69912</td></tr><tr><td>val_loss_epoch</td><td>0.54053</td></tr><tr><td>val_loss_step</td><td>0.57855</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/tkgkcag7' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/tkgkcag7</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_211709-tkgkcag7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ca4f58b0c242f8ae60b2979f55b70f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016916666666899498, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_212852-04egl4d0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/04egl4d0' target=\"_blank\">GINConv_2_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/04egl4d0' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/04egl4d0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_32_onehot_3\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 3.7 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "4.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.3 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15b24abcc1454dacb94ce68cf82f0fa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇█▇███▇█████</td></tr><tr><td>train_auc</td><td>▁▅▅▆▅▆▆▅▅▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇██▇██</td></tr><tr><td>train_f1</td><td>▁▅▆▇▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇██▇▇██▇██</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▄▄▃▄▃▃▃▃▃▂▃▃▂▃▂▃▂▂▂▃▃▂▂▂▂▂▂▁▁▂▂▂▂▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▅▇▅▄▄▆▆▃▄▅▃▃▃▄▆▄▅▄▃▃▂▃▄▅▄▄▃▁▃▄▁▃▃▁▂▂▁▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▄▆▃▇▅▂▆▆▆▇▅█▇██▇▇▇▆▃▄▆▇▆▇▇▇▇▇▅▇▇▇▆▆▇▇█</td></tr><tr><td>val_auc</td><td>▁▄▅▅▆▆▇▇▆▇▇▇▇▇▇███▇▇▇▇▇▇██▇███▇▇█▇▇█▇▇▇█</td></tr><tr><td>val_f1</td><td>▁▃▄▇▇█▅▇▇███▇███████▆▇▇█▇▆█▇███████▇▆▇█▇</td></tr><tr><td>val_loss_epoch</td><td>▇▇▄▃▆▃▅█▅▂▃▄▄▂▂▄▁▅▂▃▆▅▅▄▁▃▃▂▂▃▂▄▃▃▃▃▃▂▂▄</td></tr><tr><td>val_loss_step</td><td>▇█▆▃▅▂▄▄▄▄▅▁▅▂▂▂▁▃▂▁▂▅▆▂█▂▂▂▃▄▃▃▃▆▃▄▄▁▃▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.78904</td></tr><tr><td>train_auc</td><td>0.84999</td></tr><tr><td>train_f1</td><td>0.73295</td></tr><tr><td>train_loss_epoch</td><td>0.47106</td></tr><tr><td>train_loss_step</td><td>0.49931</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.79121</td></tr><tr><td>val_auc</td><td>0.8519</td></tr><tr><td>val_f1</td><td>0.71066</td></tr><tr><td>val_loss_epoch</td><td>0.53839</td></tr><tr><td>val_loss_step</td><td>0.65641</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/04egl4d0' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/04egl4d0</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_212852-04egl4d0\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "145180c78ff94889a8cb801874ebd342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_214047-3vbtsczl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/3vbtsczl' target=\"_blank\">GINConv_2_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/3vbtsczl' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/3vbtsczl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_32_onehot_3\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 3.7 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "5.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.3 K     Total params\n",
      "0.021     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c354a95d162d46cf8681f5506b604cd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇███▇█▇██▇▇▇</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇████▇█████▇▇</td></tr><tr><td>train_f1</td><td>▁▅▆▅▆▆▆▆▇▆▇▆▆▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇▇██▇▇▇▇▇▇▇▆▆</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▅▄▄▄▃▃▃▃▃▃▃▃▃▂▂▃▃▃▂▃▂▂▂▂▂▂▂▁▃▂▂▁▁▂▂▂</td></tr><tr><td>train_loss_step</td><td>█▇▅▅▅▅▅▄▅▂▄▇▃▄▅▃▄▅▆▃▃▃▂▃▂▂▁▃▄▅▅▃▃▂▄▅▆▂▂▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▃▆▇▇▇▆▅▇▇▇▇▆█▆▅▇▄▄▆▆▇▇▇█▄▁▇▆▄█▆▄▂▇▇▇▆▅</td></tr><tr><td>val_auc</td><td>▁▅▅▆▆▆▆▇▇▇▆▇▇▆▇▇▇▇▇▇▇█▇▇▇▇▇▇█▇▇██▇▇█▇▇▇▇</td></tr><tr><td>val_f1</td><td>▁▃▄▇██▇▇███████▇██▇▇████▇█▇▇██▄█▇▇▇▇███▆</td></tr><tr><td>val_loss_epoch</td><td>▅▇▅▄▃▃▃▃▃▃▃▃▃▃▂▅▃▃▅▅▃▃▃▃▃▂▅▇▂▂█▂▃▄▅▁▂▃▃▃</td></tr><tr><td>val_loss_step</td><td>██▆▅▅▄▅▄▅▄▄▃▂▆▄▂▅▃▆▄▄▄▁▂▄▅▆▄▆▆▃▇▂▂▄▃▄▃▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.7589</td></tr><tr><td>train_auc</td><td>0.82163</td></tr><tr><td>train_f1</td><td>0.66667</td></tr><tr><td>train_loss_epoch</td><td>0.51014</td></tr><tr><td>train_loss_step</td><td>0.5207</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.71429</td></tr><tr><td>val_auc</td><td>0.84623</td></tr><tr><td>val_f1</td><td>0.54118</td></tr><tr><td>val_loss_epoch</td><td>0.50566</td></tr><tr><td>val_loss_step</td><td>0.42861</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/3vbtsczl' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/3vbtsczl</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_214047-3vbtsczl\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_215307-7w6seryn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/7w6seryn' target=\"_blank\">GINConv_2_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/7w6seryn' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/7w6seryn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_64_onehot_3\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 13.5 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.7 K    Total params\n",
      "0.063     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01b9a6bf625045f4a0e5b616712fafaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▅▆▆▆▆▇▇▆▇▆▇▇▇▇▇▇▇▇▇▇█▇▆▇█▇▇▇████████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇▇▇███████████</td></tr><tr><td>train_f1</td><td>▁▆▅▇▆▇▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇█▇▇▇█▇█▇████████</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▄▄▃▄▃▃▃▃▃▃▂▃▂▂▂▂▃▂▃▂▁▂▃▃▂▂▂▂▁▁▂▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>▆█▅▇▅▇▄▆▇▅▂▃▄▅▃▅▅▆▄▃▄▂▅▄▃▃▄▂▅▄▃▂▂▁▄▃▂▃▁▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▃▄▇▇█▇█▇▇▅▆█▅▅▇▇█▁▆▇▇▄█▄▅▇▆█▇█▄█▆▇████▇█</td></tr><tr><td>val_auc</td><td>▁▃▄▅▅▅▆▆▆▆▆▆▆▇▆▇▇▄▄▅▆▅▆▅▆▆▆▇▇▇▄█▅▄▇▇▇▅▆▆</td></tr><tr><td>val_f1</td><td>▁▂▆██▇███▇██▇▇█▇█▇▇██▇█▇▇█▅▇██▇███▇█▇█▆█</td></tr><tr><td>val_loss_epoch</td><td>▅▅▂▂▁▂▁▂▂▄▂▁▃▂▃▂▂█▂▂▂▄▂▃▃▂▃▂▂▃▅▁▃▂▂▂▁▂▃▁</td></tr><tr><td>val_loss_step</td><td>▄▄▃▂▂▂▂▃▃▄▃▂▃▄▂▂▃█▃▂▂▃▃▃▄▃▂▂▂▂▂▃▂▂▃▂▃▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.78813</td></tr><tr><td>train_auc</td><td>0.85062</td></tr><tr><td>train_f1</td><td>0.72048</td></tr><tr><td>train_loss_epoch</td><td>0.47891</td></tr><tr><td>train_loss_step</td><td>0.52307</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.78388</td></tr><tr><td>val_auc</td><td>0.84271</td></tr><tr><td>val_f1</td><td>0.71498</td></tr><tr><td>val_loss_epoch</td><td>0.46534</td></tr><tr><td>val_loss_step</td><td>0.37855</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/7w6seryn' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/7w6seryn</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_215307-7w6seryn\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_220602-xzuts8z3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/xzuts8z3' target=\"_blank\">GINConv_2_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/xzuts8z3' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/xzuts8z3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_64_onehot_3\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 13.5 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.7 K    Total params\n",
      "0.063     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1f467e3fbda47eb86f890d5fd6bc48a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▅▅▆▆▅▆▆▆▇▆▆▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇█▇▇▇▇██▇█▇▇</td></tr><tr><td>train_auc</td><td>▁▄▅▅▆▆▆▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇██▇▇██▇████████</td></tr><tr><td>train_f1</td><td>▂▁▅▆▆▆▆▆▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇█▇██▇███▇▇███▇███</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▃▃▃▅▃▃▃▃▃▃▂▂▂▂▂▂▃▂▂▂▂▂▂▂▂▂▁▂▂▂▁▁▂▁▂▂</td></tr><tr><td>train_loss_step</td><td>▇█▆▆▅▆▄▅▄▅▃▄▃▄▃▄▃▅▃▄▅▂▃▃▄▂▃▂▄▄▂▃▂▁▂▁▁▃▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▅▄▇▇▆▆▇▇▇▇▆▇▅▇▇▆▆▇▅▆▇▇▇▇▆▆█▇▆▇▅▇█▆▇▆▇▇</td></tr><tr><td>val_auc</td><td>▁▄▅▅▇▇▅▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇█▇▇█▇▇▇▇▇</td></tr><tr><td>val_f1</td><td>▁▃▅▄██▇█▇▇█▇▇▇█▇██▆█▆▇▇█▇█▆██▇▇▇█▇█▇▇▇▇█</td></tr><tr><td>val_loss_epoch</td><td>▆▅▄▄▄▄▃▄▂▃▂▃▃▂█▃▃▄▂▄▅▁▃▂▂▁▂▆▂▄▁▁▆▃▃▃▃▂▃▂</td></tr><tr><td>val_loss_step</td><td>▇▆▅▆▅▅▃▅▃▅▅▂▃▃▇▃▇▅▁▆▁▆▄▃▃▅▄▃▃▅▅▅▃█▃▅▅▄▇▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77808</td></tr><tr><td>train_auc</td><td>0.83677</td></tr><tr><td>train_f1</td><td>0.71106</td></tr><tr><td>train_loss_epoch</td><td>0.48418</td></tr><tr><td>train_loss_step</td><td>0.47565</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.74359</td></tr><tr><td>val_auc</td><td>0.81271</td></tr><tr><td>val_f1</td><td>0.69298</td></tr><tr><td>val_loss_epoch</td><td>0.52393</td></tr><tr><td>val_loss_step</td><td>0.46921</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/xzuts8z3' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/xzuts8z3</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_220602-xzuts8z3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2c1802f2d88407da1cbd454500e3781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_221755-2j832oq4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/2j832oq4' target=\"_blank\">GINConv_2_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/2j832oq4' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/2j832oq4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_64_onehot_3\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 13.5 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.7 K    Total params\n",
      "0.063     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▂▃▁▃▄▄▅▄▅▆▅▅▆▆▆▆▅▆▆▆▆▆▇▇▇▇▆▇▆▇█▇▇▇██▇█▆▇</td></tr><tr><td>train_auc</td><td>▁▃▁▂▂▂▃▃▁▃▅▅▆▄▆▇▆▆▇▇▆▇▆▇▇▇▆▇▆▇▇█▆▇▇▆▇▇▅▆</td></tr><tr><td>train_f1</td><td>▃▃▁▄▄▄▄▃▅▇▄▅▆▆▆▇▅▇▇▇▇▆▇▇▇▇▇▇▆▇██▇▇▇███▇█</td></tr><tr><td>train_loss_epoch</td><td>█▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>▇█▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▅▅▅▆▇▄▆▆█▇▆▆▇▇▇▇█▇▇▇█▇▇▇█▇█▇▇▇█▆▇▇▇▇▆█▆</td></tr><tr><td>val_auc</td><td>▅▄▃▁▃▁▂▅▄▅▆▆▅▆▇▆▇█▇█▇▆▇██▆████▇▇▇▇▄▇█▃▃▂</td></tr><tr><td>val_f1</td><td>▁▅▆▅▇█▇▇▆█▇▆████▇█▇█▇█▇██████████████▇██</td></tr><tr><td>val_loss_epoch</td><td>█▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>▆█▂▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.72694</td></tr><tr><td>train_auc</td><td>0.67381</td></tr><tr><td>train_f1</td><td>0.66138</td></tr><tr><td>train_loss_epoch</td><td>0.57031</td></tr><tr><td>train_loss_step</td><td>0.52017</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.73626</td></tr><tr><td>val_auc</td><td>0.75036</td></tr><tr><td>val_f1</td><td>0.7</td></tr><tr><td>val_loss_epoch</td><td>0.53485</td></tr><tr><td>val_loss_step</td><td>0.54106</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/2j832oq4' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/2j832oq4</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_221755-2j832oq4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_222948-fxqp4kfz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/fxqp4kfz' target=\"_blank\">GINConv_2_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/fxqp4kfz' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/fxqp4kfz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_64_onehot_3\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 13.5 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "15.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.7 K    Total params\n",
      "0.063     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a524550d37d45dcb16ab93025a17d72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▅▆▆▆▆▅▆▆▇▅▇▆▆▆▆▆▇▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█</td></tr><tr><td>train_auc</td><td>▁▄▅▅▆▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇█▇▇█</td></tr><tr><td>train_f1</td><td>▁▅▅▅▆▆▆▆▅▇▆▇▆▇▇▆▇▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▅▄▄▄▄▄▃▄▄▄▃▃▃▃▂▃▂▂▂▂▃▂▂▂▂▂▂▂▂▁▁▂▁▂▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▅▄▅▃▄█▆▂▅▄▅▄▅▅▃▄▄▆▆▆▄▆▂▃▁▅▃▂▅▂▁▂▆▃▄▃▄█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▇▅▆▆▇▄▆▅▇▇▇▇█▇▅▇▇▇▇█▂▆▇█▅█▅▅█▆▇▇▇▅▆█▆▇</td></tr><tr><td>val_auc</td><td>▁▃▅▅▅▆▆▆▅▆▇▇▇▇▇▇▇▇▇▆█▇▆█▇█▇▇▇▇▇▇▇▆▇███▇▇</td></tr><tr><td>val_f1</td><td>▁▄▇▇▇██▇▇▆▇▇█████▇██▇█▇▆██▆█▇▆█▇█▇▇▆▆██▇</td></tr><tr><td>val_loss_epoch</td><td>█▅▃▆▃▃▄▅▃▄▂▂▂▁▁▂▂▂▃▂▂▁▆▄▂▁▅▂▃▃▃▂▃▃▃▆▄▁▃▂</td></tr><tr><td>val_loss_step</td><td>▅▄▂▃▂▂▂▃▂▄▂▂▂▂▁▂▃▁▂▂▃▃▃▂▂█▁▁▂▂▃▅▃▂▂▃▂▂▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.80548</td></tr><tr><td>train_auc</td><td>0.86884</td></tr><tr><td>train_f1</td><td>0.75433</td></tr><tr><td>train_loss_epoch</td><td>0.4528</td></tr><tr><td>train_loss_step</td><td>0.63281</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.76557</td></tr><tr><td>val_auc</td><td>0.84794</td></tr><tr><td>val_f1</td><td>0.71681</td></tr><tr><td>val_loss_epoch</td><td>0.47651</td></tr><tr><td>val_loss_step</td><td>0.46725</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/fxqp4kfz' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/fxqp4kfz</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_222948-fxqp4kfz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_224144-ukt23xko</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ukt23xko' target=\"_blank\">GINConv_2_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ukt23xko' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ukt23xko</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_64_onehot_3\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 13.5 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "19.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "19.8 K    Total params\n",
      "0.079     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c97b0357126b41cf85ed92a40c3ee554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▅▅▆▆▆▆▆▅▆▆▅▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇█▇▇▇▇▇███▇</td></tr><tr><td>train_auc</td><td>▁▄▅▅▆▆▆▆▆▆▆▆▇▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇███▇</td></tr><tr><td>train_f1</td><td>▁▅▅▆▅▇▆▆▆▆▆▇▇▆▆▇▇▇▇▇▇▇▇▇█▇▇▇▇▇█▇▇▇▇▇███▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▅▅▄▄▅▅▄▅▄▃▄▄▃▄▃▃▃▃▃▃▃▃▂▃▃▂▂▂▂▂▃▂▂▂▁▁▃</td></tr><tr><td>train_loss_step</td><td>▅▅▆▆▇█▄▆▅▄▅▅▇▄▄▄▅▄▃▃▅▄▂▄▄▄▃▄▄▂▃▂▃▂▅▄▄▁▄▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▇▇▆▇▄▇▅▇▆▆▆█▇▄█▆▇█▆▆▃▇▇▃█▆█▄▆▅▇▇▇█▆▇▇▇</td></tr><tr><td>val_auc</td><td>▁▄▄▅▆▆▆▆▇▇▆▇▇█▇▇█▇▇▇▆▇▆██▆▇▇▇▆▆▆▆▇▇▇▆▆▆█</td></tr><tr><td>val_f1</td><td>▁▃█▇██▇▇▅▇████▇▇████▆█▇▇▇▇███▇▆▆████████</td></tr><tr><td>val_loss_epoch</td><td>█▇▄▂▃▃▅▂▅▂▄▂▂▃▅▆▁▃▃▂▄▄█▃▄█▂▅▃█▂▄▂▃▄▃▆▂▇▃</td></tr><tr><td>val_loss_step</td><td>▆▅▂▂▃▃▃▃▃▃▄▄▃▂▁▄▂▅▃▂▃▂▂▂▂▂▃▃▂▅▃▂▅▄▅▁▂█▆▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77717</td></tr><tr><td>train_auc</td><td>0.8418</td></tr><tr><td>train_f1</td><td>0.695</td></tr><tr><td>train_loss_epoch</td><td>0.48435</td></tr><tr><td>train_loss_step</td><td>0.45048</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.77289</td></tr><tr><td>val_auc</td><td>0.85454</td></tr><tr><td>val_f1</td><td>0.72566</td></tr><tr><td>val_loss_epoch</td><td>0.51528</td></tr><tr><td>val_loss_step</td><td>0.62604</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ukt23xko' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ukt23xko</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_224144-ukt23xko\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_225403-ky7l1h20</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ky7l1h20' target=\"_blank\">GINConv_3_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ky7l1h20' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ky7l1h20</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_16_onehot_3\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.7 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▇▇▇▇▇▇▇▇█▇██▇███▇▇█▇▇██████▇▇█▇█████</td></tr><tr><td>train_auc</td><td>▁▄▆▆▆▇▇▇▇▇▇▇▇▇█▇▇██▇▇▇▇▇███▇████████████</td></tr><tr><td>train_f1</td><td>▂▁▄▅▅▅▆▇▆▆▆▇▇▇▇▇▇▇█▇▆▆▇▆▆▇▇▇▇▇▇▅▆▇▆▇█▇▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▃▃▃▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▂▁▂▁▁▂▁▂</td></tr><tr><td>train_loss_step</td><td>█▆▅▆▃▅▅▃▃▄▄▃▂▄▂▃▁▂▂▄▃▃▄▁▃▃▄▂▄▃▃▂▁▂▃▂▂▄▂▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▄▅█▇▇▇▆▇▇▇▆▆▇█▇▇▇▇▇▆▇▇▆▇▇▅▇▆▇▇▆▇▇▇▇█▇▇</td></tr><tr><td>val_auc</td><td>▁▄▅▆▆▆▆▇▇▇▇▇█▇▇█▇███▇▇█████▇▇▇█▇██▇▇████</td></tr><tr><td>val_f1</td><td>▁▃▄▆█▇█▇▆███▆▇▇██▇▇▇█▇██▆██▆▇▇▇█▆██████▇</td></tr><tr><td>val_loss_epoch</td><td>▇▅█▄▄▃▃▂▄▂▂▃▃▃▂▂▄▃▄▂▃▄▂▁▃▂▂▃▃▂▂▃▂▃▃▄▂▃▃▃</td></tr><tr><td>val_loss_step</td><td>█▅▇▆▃▃▄▃▄▄▂▂▃▃▄▂▂▂▄▂▁▂▃█▅▄▃▃▁▁▃▂▂▄▃▆▂▂▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.76986</td></tr><tr><td>train_auc</td><td>0.83307</td></tr><tr><td>train_f1</td><td>0.69712</td></tr><tr><td>train_loss_epoch</td><td>0.51131</td></tr><tr><td>train_loss_step</td><td>0.6065</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.78388</td></tr><tr><td>val_auc</td><td>0.85338</td></tr><tr><td>val_f1</td><td>0.70051</td></tr><tr><td>val_loss_epoch</td><td>0.49647</td></tr><tr><td>val_loss_step</td><td>0.47616</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ky7l1h20' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ky7l1h20</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_225403-ky7l1h20\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f00e99cf9e4a78877fc3a62d55c2e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_230615-nm8v2ldg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/nm8v2ldg' target=\"_blank\">GINConv_3_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/nm8v2ldg' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/nm8v2ldg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_16_onehot_3\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.7 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd34cf5737c54c5b90818038439fcb62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█▇▇█▇███▇▇</td></tr><tr><td>train_auc</td><td>▁▂▃▄▅▅▆▆▆▆▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇██▇█▇▇█▇██▇██</td></tr><tr><td>train_f1</td><td>▃▁▁▅▅▅▆▆▇▇▆▆▅▅▅▇▇▇▇▇▆▆▅▆▆▇▆▇█▇█▆▇▇▆▇▇▇▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▅▄▄▃▄▃▃▃▃▃▄▃▃▃▃▃▂▂▂▃▂▂▃▂▂▁▂▂▂▂▁▂▂▂▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▆▆▇▄▅▅▄▄▅▂▆▂▂▄▄▁▂▃▅▄▄▄▁▄▄▅▃▃▂▄▁▁▁▁▃▂▄▃▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▄▅▇▆▆▆▆▆▆▃▇▆▅▆▆▅▇▇▆▇▆▆█▇▇▇▇▇▇▇▇▆▆▄▇▅█▇█</td></tr><tr><td>val_auc</td><td>▁▃▃▅▅▅▆▆▅▅▅▆▆▅▆▆▆▇▇▆▇▇▇████▇████▆▇▇█▇███</td></tr><tr><td>val_f1</td><td>▆▁▃▇▄▆▆▅▇▆▇▇▇▇▆▆▇▇▆▅▇███▆▇▆▇▇█▇▇▇█▇█▇█▇█</td></tr><tr><td>val_loss_epoch</td><td>▇▅▆▅▅▄▄▃▅▃▇▄▄▄▃▄█▃▄▃▃▃▅▁▂▂▂▂▂▂▁▃▁▄▇▄▄▂▂▂</td></tr><tr><td>val_loss_step</td><td>▅▄▃▄▃▃▃▃▃▃█▂▂▃▂▃▃▂▃▂▁▃▃▂▂▂▂▂▁▃▁▁▂▃▁▂▂▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.72511</td></tr><tr><td>train_auc</td><td>0.77036</td></tr><tr><td>train_f1</td><td>0.62516</td></tr><tr><td>train_loss_epoch</td><td>0.54822</td></tr><tr><td>train_loss_step</td><td>0.62173</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.76923</td></tr><tr><td>val_auc</td><td>0.82752</td></tr><tr><td>val_f1</td><td>0.70968</td></tr><tr><td>val_loss_epoch</td><td>0.547</td></tr><tr><td>val_loss_step</td><td>0.58447</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/nm8v2ldg' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/nm8v2ldg</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_230615-nm8v2ldg\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_231844-5ms9bu5c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/5ms9bu5c' target=\"_blank\">GINConv_3_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/5ms9bu5c' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/5ms9bu5c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_16_onehot_3\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.7 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▃▃▄▅▄▅▅▅▆▆▆▆▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇██▇▇▇</td></tr><tr><td>train_auc</td><td>▁▁▃▂▃▃▃▃▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█▇██▇▇███▇█</td></tr><tr><td>train_f1</td><td>▁▃▅▅▅▃▁▄▄▄▅▅▅▅▆▇▆▆▆▇▇▆▆▇▇█▇▇▇██▇██▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▄▆▄▅▃▃▄▄▄▄▅▅▆▅██▅▇▇█▇▇▇▇▇▇▇▇▇██▇▇▇▇▇█▇▇</td></tr><tr><td>val_auc</td><td>▁▃▄▄▅▅▅▅▆▆▆▇▇▇▇▇▇███▇▇▇██▇█▇█▇▇██▇██▇██▇</td></tr><tr><td>val_f1</td><td>▁▆▇▅▆▄▄▅▅▅▅▆▆▆▆██▆▇▇█▇▇▇▇██▇▇███▇██▇████</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▃▂▂▂▂▂▂▂▂▁▁▂▁▁▂▂▁▁▂▁▁▂▁▁▁▁▁▁▁▁▂▁▂▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▁▁▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▂▁▁▁▁▁▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.72968</td></tr><tr><td>train_auc</td><td>0.78837</td></tr><tr><td>train_f1</td><td>0.67038</td></tr><tr><td>train_loss_epoch</td><td>0.57426</td></tr><tr><td>train_loss_step</td><td>0.61193</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.73993</td></tr><tr><td>val_auc</td><td>0.81505</td></tr><tr><td>val_f1</td><td>0.69264</td></tr><tr><td>val_loss_epoch</td><td>0.54672</td></tr><tr><td>val_loss_step</td><td>0.59017</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/5ms9bu5c' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/5ms9bu5c</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_231844-5ms9bu5c\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_233122-mic2hcs1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/mic2hcs1' target=\"_blank\">GINConv_3_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/mic2hcs1' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/mic2hcs1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_16_onehot_3\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.7 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇▇▇███████▇████</td></tr><tr><td>train_auc</td><td>▁▄▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇██████████████</td></tr><tr><td>train_f1</td><td>▂▁▄▅▅▆▆▆▅▅▆▅▆▃▅▆▆▇▅▅▅▇▇▇▇▆▇▆▇▇▇▇█▇█▇█▇▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▃▃▃▃▃▂▂▂▃▂▂▂▂▃▂▂▂▂▂▂▂▂▂▂▁▁▂▁▂▁▂▂▂▂▂</td></tr><tr><td>train_loss_step</td><td>█▆▆▇▅▃▅▅▆▃▆▅▃▄▃▄▂▄▃▄▂▇▄▄▂▄▃▄▄▄▁▄▃▃▁▆▂▆▄▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▂▁▃▆▆▆█▇▆▇▆▆▆▆▇█▇▇▆▇▇▇█▇▇▅▇▇▆▇▇▅▇▅▆▇▇█▆▆</td></tr><tr><td>val_auc</td><td>▁▄▆▆▆▆▇▇▇▇▇▇█████████▇██▇██████▇██████▇▇</td></tr><tr><td>val_f1</td><td>▄▁▄▇▇▆▇▇▇▇▇▆▇▆▇█▇▇▆▇▇████▆▇▇▇▇█▇█▆▆█▇█▆▇</td></tr><tr><td>val_loss_epoch</td><td>█▆▆▄▃▄▃▄▅▅▃▂▄▅▃▄▄▃▄▄▃▄▁▂▃▂▃▃▃▆▃▅▃▂▅▂▄▂▂▂</td></tr><tr><td>val_loss_step</td><td>█▆▆▄▄▃▅▄▄▃▃▂▃▂▃▄▂▂▃▂▁▄▅▄▅▅▁▂▃▆▄▃▃▃▂▄▃▃▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.76895</td></tr><tr><td>train_auc</td><td>0.83254</td></tr><tr><td>train_f1</td><td>0.69184</td></tr><tr><td>train_loss_epoch</td><td>0.51504</td></tr><tr><td>train_loss_step</td><td>0.55899</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.76557</td></tr><tr><td>val_auc</td><td>0.84051</td></tr><tr><td>val_f1</td><td>0.7265</td></tr><tr><td>val_loss_epoch</td><td>0.47097</td></tr><tr><td>val_loss_step</td><td>0.42572</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/mic2hcs1' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/mic2hcs1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_233122-mic2hcs1\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_234407-yd201kr8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/yd201kr8' target=\"_blank\">GINConv_3_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/yd201kr8' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/yd201kr8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_16_onehot_3\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.7 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "2.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▇▇▇▇▇▇▇█▇▇▇▇██▇█▇█▇█▇███████████████</td></tr><tr><td>train_auc</td><td>▁▄▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇███▇███████████████</td></tr><tr><td>train_f1</td><td>▂▁▂▃▆▅▅▆▆▆▇▇▆▆▆▆▇▇▆▆▇▇▇▇▇▇▇▆▇▇▇▇▇█▆▇█▇▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▄▃▃▃▃▃▃▂▃▃▃▂▂▂▂▂▂▂▂▃▂▂▂▂▂▂▂▁▂▂▂▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▇▆▅▇▅▂▄▃▄▂▃▅▃▂▇▃▃▅▂▃▃▃▃▄▂▃▁▅▂▃▄▄▂▃▂▂▅▄▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▄▂▆▇▇█▆█▇▄▇▇▆▅▇███▆▆▇▇▇▇▇▇▆▇▅▆▆▇▇▇▆▅▆▇▇</td></tr><tr><td>val_auc</td><td>▁▄▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇███▇███▇█▇▇█▆▇▇</td></tr><tr><td>val_f1</td><td>▁▅▃▆▇▇█▇██▇▇▇█▅████▆▆▇▇▇█▇▇▇▇▅▆▆█▇▇▇▅▇██</td></tr><tr><td>val_loss_epoch</td><td>█▅█▄▄▃▄▅▄▄▅▄▃▃▆▂▂▄▃▅▃▁▃▁▄▃▂▄▂▆▂▄▂▃▅▂▄▃▃▆</td></tr><tr><td>val_loss_step</td><td>▆▄▆▄▃▃▂▃▂▃▄▂▂▄▂▂▃▃▂▃▂▆▃▃▂▂▂▁▄▂▄▅▂▃▃▃▂▄▄█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77626</td></tr><tr><td>train_auc</td><td>0.82544</td></tr><tr><td>train_f1</td><td>0.69716</td></tr><tr><td>train_loss_epoch</td><td>0.5163</td></tr><tr><td>train_loss_step</td><td>0.56413</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.75458</td></tr><tr><td>val_auc</td><td>0.83269</td></tr><tr><td>val_f1</td><td>0.72874</td></tr><tr><td>val_loss_epoch</td><td>0.59643</td></tr><tr><td>val_loss_step</td><td>0.77162</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/yd201kr8' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/yd201kr8</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_234407-yd201kr8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231216_235704-iujki24j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/iujki24j' target=\"_blank\">GINConv_3_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/iujki24j' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/iujki24j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_32_onehot_3\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 5.9 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "6.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.5 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c62612e0d7504e16bb4ee3713f083073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▆▆▆▆▆▆▇▇▆▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇</td></tr><tr><td>train_auc</td><td>▁▅▅▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████▇▇███▇</td></tr><tr><td>train_f1</td><td>▁▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇█▇██▇███▇█████▇████</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▄▄▄▃▄▄▃▄▃▂▃▃▃▃▃▃▃▂▃▃▂▃▂▂▂▂▂▂▂▂▂▂▁▁▂</td></tr><tr><td>train_loss_step</td><td>███▇▅▇▆▅▆▅▅▅▅▆▆▃▆█▃▅▆▄▆▆▄▅█▅▅▄▅▄▆▃▃▄▃▅▁▆</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▆▇▇▇▅▇█▇▆▃▅▇▆▇▆▆▆▂▇▆▆▇▇▆█▄▆▆▆▅▆▇▆▆▄▄▆▄</td></tr><tr><td>val_auc</td><td>▁▅▅▄▆▅▆▇▇█▇▆▇▆▆▇▆▆▅█▇▆▇▅▇█▇█▅▄▅▆▄▆▅▇▇▇▆█</td></tr><tr><td>val_f1</td><td>▁▄▇██████▇▇▄████▇▇█▃█▇▇██▆█▅▇██▆▇██▆▅▅▇█</td></tr><tr><td>val_loss_epoch</td><td>▄█▂▃▂▃▄▂▂▃▄▇▃▃▂▃▃▂▃█▃▂▂▄▂▁▃▅▄▂▃▆▃▃▅▁▆▃▂▅</td></tr><tr><td>val_loss_step</td><td>▄▃▃▃▃▂▂▂▂▂▂▄▃▃▂▃▂▄▃█▂▂▅▅▂▃▄▃▂▂█▂▁▃▅▅▂▃▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.78356</td></tr><tr><td>train_auc</td><td>0.84405</td></tr><tr><td>train_f1</td><td>0.72914</td></tr><tr><td>train_loss_epoch</td><td>0.48236</td></tr><tr><td>train_loss_step</td><td>0.52956</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.68498</td></tr><tr><td>val_auc</td><td>0.84722</td></tr><tr><td>val_f1</td><td>0.71141</td></tr><tr><td>val_loss_epoch</td><td>0.64859</td></tr><tr><td>val_loss_step</td><td>0.70136</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/iujki24j' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/iujki24j</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231216_235704-iujki24j\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_000950-5doqtc6n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/5doqtc6n' target=\"_blank\">GINConv_3_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/5doqtc6n' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/5doqtc6n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_32_onehot_3\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 5.9 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "6.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.5 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▆▆▆▇▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇███▇</td></tr><tr><td>train_auc</td><td>▁▃▄▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇█▇█▇▇████</td></tr><tr><td>train_f1</td><td>▁▄▅▆▆▆▆▆▇▆▇▇▇▇▆▇▇█▇▇▇▇▇▇▇▆██▇▇▇▇▇▇▇▇██▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▁▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>▇█▇▇▆▇▆▅▅▅▅▆▆▆▅▄▄▇▂▄▆▅▅▅▇▄▇▅▄▄▆▄▆▅▄▄▃▆▁▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▄▅▄▆█▇▆▆▄██▇▇▁▆▇█▇▇▆▇█▇▇▆▆▇▅▆▆▆█▇▆▇▅█▇</td></tr><tr><td>val_auc</td><td>▁▃▂▃▄▅▇▇▇▇▇█████▇██▇▇▇█▇█▇▇▇▇▆▆▇▇█▇▆▇▇▆▇</td></tr><tr><td>val_f1</td><td>▁▄▆▆▅▇█▇▆█▇██▇█▇█▇█▇█▇██▇█▇▆█▇▇████▇███▇</td></tr><tr><td>val_loss_epoch</td><td>█▇▅▄▃▄▃▂▃▄█▃▂▂▄█▆▂▁▃▃▃▃▃▃▁▄▄▆▄▂▄▂▅▄▃▄▆▁▁</td></tr><tr><td>val_loss_step</td><td>▇▅▆▆▆▅▄▄▄▆▅▃▃▅▄█▅▅▄▄▃▅▅▅▄▄▄▅▂▄▅▃▄▅▃▄▅▄▅▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.75616</td></tr><tr><td>train_auc</td><td>0.81511</td></tr><tr><td>train_f1</td><td>0.69416</td></tr><tr><td>train_loss_epoch</td><td>0.51336</td></tr><tr><td>train_loss_step</td><td>0.4898</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.76923</td></tr><tr><td>val_auc</td><td>0.8295</td></tr><tr><td>val_f1</td><td>0.69565</td></tr><tr><td>val_loss_epoch</td><td>0.49334</td></tr><tr><td>val_loss_step</td><td>0.40644</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/5doqtc6n' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/5doqtc6n</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_000950-5doqtc6n\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0f43ef68a7a445bade6b2cf849a1704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_002239-p6nmorce</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/p6nmorce' target=\"_blank\">GINConv_3_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/p6nmorce' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/p6nmorce</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_32_onehot_3\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 5.9 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "6.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.5 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d48db3d8c0943ecb3908de5789a3501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▃▃▄▆▆▆▅▆▆▇▆▆▆▆▆▆▆▆▆▆▆▇▇▆▆▇▆▆▇▇▇▇▇▇▇▇█▇</td></tr><tr><td>train_auc</td><td>▁▂▂▁▂▃▃▄▄▅▅▆▅▅▆▇▆▆▇▇▇▆▇▆▇▆▆▆▆▇█▇▇█▇▇███▇</td></tr><tr><td>train_f1</td><td>▁▃▄▃▄▆▆▆▅▆▆▇▆▆▇▆▇▇▇▇▆▆▇▇▇▆▇▇▇▇█▇██▇▇███▇</td></tr><tr><td>train_loss_epoch</td><td>█▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▅█▇▇█▇█▇▇▇█▇▇█████▇██▇█▇█▆▇█▇█▇█▇█▇▇▇█</td></tr><tr><td>val_auc</td><td>▁▃▄▂▂▄▄▅▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▆▆▇▇████▇▇▇▇</td></tr><tr><td>val_f1</td><td>▁▂▆▇▇▇▇███▇▇█▇▇█▇▇█▇▇██▇▇▇█▇██▇▇▇▇▇█▇███</td></tr><tr><td>val_loss_epoch</td><td>█▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.73699</td></tr><tr><td>train_auc</td><td>0.74822</td></tr><tr><td>train_f1</td><td>0.66744</td></tr><tr><td>train_loss_epoch</td><td>0.54095</td></tr><tr><td>train_loss_step</td><td>0.52991</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.77656</td></tr><tr><td>val_auc</td><td>0.83462</td></tr><tr><td>val_f1</td><td>0.71889</td></tr><tr><td>val_loss_epoch</td><td>0.49568</td></tr><tr><td>val_loss_step</td><td>0.49317</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/p6nmorce' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/p6nmorce</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_002239-p6nmorce\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_003631-ihoe3j8d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ihoe3j8d' target=\"_blank\">GINConv_3_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ihoe3j8d' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ihoe3j8d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_32_onehot_3\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 5.9 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "6.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.5 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▆▆▆▆▆▇▆▆▇▇▇▆▇▇▇▇▇▇▇▇█▇▇▇▇▇▇█▇██▇██▇█</td></tr><tr><td>train_auc</td><td>▁▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇▇██▇███████</td></tr><tr><td>train_f1</td><td>▁▆▆▇▇▆▇▇▇▇▇▇▇▇▇▆▆▇▇▇▇▇▇▇█▇▇▇▇▇▇█▇██▇████</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▄▄▄▃▃▃▃▃▃▃▄▃▃▃▃▂▃▂▂▂▂▂▂▃▃▂▁▂▁▁▂▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▆█▇▅▇▄▆▄▄▄▃▂▅▂▄▅▃▄▆▂▄▃▂▆▃▂▆█▆▅▁▅▁▂▃▁▁▅▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▆▇▆▇▇▆▆▇▇▇▇▆█▆▇▇█▆▇▇████▄▇▅▇█▆▇▇▅▆▇▅▇▅</td></tr><tr><td>val_auc</td><td>▁▄▅▅▅▆▆▇▇▆▆▆▇▆▆▇▇▅▇▆▆▇▇▇▇█▆▇▅▇▇▆▇▇▅▆▆▆▄▅</td></tr><tr><td>val_f1</td><td>▁▃▆▇▆▇▇█▆█▇█▇▇█▆█▇██▇▇████▇█▅▇█▆█▇▇▆█▅▇▆</td></tr><tr><td>val_loss_epoch</td><td>██▇▄▄▅▄▄▇▄▄▆▂▅▆▇▃▃▂▆▆▄▃▃▄▅▆▅▅▃▂▅▃▁▄▇▅▆▄█</td></tr><tr><td>val_loss_step</td><td>▅▆▃▂▃▃▂▃▃▂▁▂▂▃▂▃▂▂▂▂▂▂▄▂▁▂▂▃▂▄▃▃▂▄▁▄▂▁▅█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.78995</td></tr><tr><td>train_auc</td><td>0.86114</td></tr><tr><td>train_f1</td><td>0.72422</td></tr><tr><td>train_loss_epoch</td><td>0.45807</td></tr><tr><td>train_loss_step</td><td>0.4929</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.71429</td></tr><tr><td>val_auc</td><td>0.81811</td></tr><tr><td>val_f1</td><td>0.5618</td></tr><tr><td>val_loss_epoch</td><td>0.6317</td></tr><tr><td>val_loss_step</td><td>0.82856</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ihoe3j8d' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ihoe3j8d</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_003631-ihoe3j8d\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_005014-554m364g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/554m364g' target=\"_blank\">GINConv_3_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/554m364g' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/554m364g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_32_onehot_3\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 5.9 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "7.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.6 K     Total params\n",
      "0.030     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11cb835808ec41099052850728e76c82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▅▆▆▆▆▆▇▇▇▇▇▇▆▇▇▇▇▇▇█▇▇▇▇█▇▇█▇█▇▇▇████</td></tr><tr><td>train_auc</td><td>▁▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇███▇██████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇████▇███▇████▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▄▄▄▃▃▃▄▃▃▃▃▃▃▃▃▂▂▂▂▃▂▃▂▃▂▂▂▁▂▂▂▁▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▅▆▅▅▄▄▃▆▄▅▅▅▅▄▄▃▂▃▃▅▄▄▃▅▄▁▇▂▄▂▂▃▃▃▃▁▁▂▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▄▅▅▅█▆▇▇██▆▇▇▇▄▆▇▇▇▆█▂▄▇▇▇▅█▇█▇▅▆▅▆▆▃▇█</td></tr><tr><td>val_auc</td><td>▁▅▆▅▆▆▆▇▆▇▆▇▇▇▇▇▇▇▇█▇▇▆▇▆▆▇▇▇▆▇▇█▇▇▆▇▆▇▆</td></tr><tr><td>val_f1</td><td>▁▄▆▆▅█▇█▇██▆▇█▇▅▇██▇▇█▇▅█▇▇▅███▇▅█▆▆▇▄██</td></tr><tr><td>val_loss_epoch</td><td>▅▄▄▃▄▂▄▂▄▄▂▄▃▃▂▆▄▁▁▃▃▂▇█▃▃▁▆▂▃▅▁▇▃▂▆▃█▁▁</td></tr><tr><td>val_loss_step</td><td>█▇▆▅▆▅▅▆▃▅▅▆▇▅▅▅▇▅▅▅▅▅█▅▇▆▅▇▆▅▅▄▆█▅▄▇▅▆▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.78447</td></tr><tr><td>train_auc</td><td>0.8584</td></tr><tr><td>train_f1</td><td>0.7072</td></tr><tr><td>train_loss_epoch</td><td>0.45962</td></tr><tr><td>train_loss_step</td><td>0.49075</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.79487</td></tr><tr><td>val_auc</td><td>0.83071</td></tr><tr><td>val_f1</td><td>0.73832</td></tr><tr><td>val_loss_epoch</td><td>0.45059</td></tr><tr><td>val_loss_step</td><td>0.28669</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/554m364g' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/554m364g</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_005014-554m364g\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8873716145514ce8bd42673588020bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_010246-gfea3cqa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/gfea3cqa' target=\"_blank\">GINConv_3_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/gfea3cqa' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/gfea3cqa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_64_onehot_3\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 22.1 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "24.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.2 K    Total params\n",
      "0.097     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▅▆▅▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▆▇▇▇▇▇▇██▇█▇▇██</td></tr><tr><td>train_auc</td><td>▁▄▅▆▆▆▆▆▆▆▇▇▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇████▇██▇██</td></tr><tr><td>train_f1</td><td>▁▅▅▆▇▆▇▆▆▇▆▇▇▆▇▇▇▇▇▆▇▇▇▇█▇▇▇▇▇▇▇██▇█▇▇█▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▅▅▅▄▄▄▄▄▄▄▄▄▃▄▄▃▃▃▂▃▂▃▃▃▂▂▂▂▁▂▃▁▂▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▆▅▇▄▅▅▆▄▅▅▆▄▅▃▄▅▄▅▄▂▄▃▆▃▄▃▄▄▅▃▃▄▃▃▂▄▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▃▄▇▅██▇▆▇▄█▆▂▇▆▆█▇▇█▇█▇█▁▇▇▇▇▇▆██▅▇▇█▇▂▇</td></tr><tr><td>val_auc</td><td>▃▆▆▇▆▆▇▇▇▇▇▇▅██▅█▇█▇████▁██▇▇▆▇▇▇▆▇▆▆▆▅▆</td></tr><tr><td>val_f1</td><td>▁▃▇▅███▆▇▇█▆▇██▇█▇▆█▇█▇█▇▆▇▇██▆██▅▇▇██▇█</td></tr><tr><td>val_loss_epoch</td><td>▄▃▂▃▂▂▂▂▃▄▂▂▅▂▃▂▂▂▃▁▁▂▁▁▇▂▁▂▁▂▃▂▂▄▁▁▂▂█▃</td></tr><tr><td>val_loss_step</td><td>▄▄▂▃▂▂▂▃▂▄▃▂▆▂▃▂▂▁▃▁▁▂▂▂▃▂▃▃▃▅▄▂█▃▁▄▂▃▃▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.81096</td></tr><tr><td>train_auc</td><td>0.88239</td></tr><tr><td>train_f1</td><td>0.74909</td></tr><tr><td>train_loss_epoch</td><td>0.41538</td></tr><tr><td>train_loss_step</td><td>0.31366</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.72894</td></tr><tr><td>val_auc</td><td>0.82554</td></tr><tr><td>val_f1</td><td>0.7197</td></tr><tr><td>val_loss_epoch</td><td>0.69157</td></tr><tr><td>val_loss_step</td><td>0.77596</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/gfea3cqa' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/gfea3cqa</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_010246-gfea3cqa\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_011545-udrhxsal</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/udrhxsal' target=\"_blank\">GINConv_3_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/udrhxsal' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/udrhxsal</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_64_onehot_3\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 22.1 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "24.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.2 K    Total params\n",
      "0.097     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2985033678e4f3ebf16f7a249d79262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▅▅▆▆▆▆▆▇▆▇▆▇▆▆▇▇▇▇▆▇▇▇▆▇▇▇▇▇▇██▇▇▇█▇▇</td></tr><tr><td>train_auc</td><td>▁▃▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇██████▇███</td></tr><tr><td>train_f1</td><td>▁▁▄▅▅▇▅▆▇▆▇▇▇▆█▇▆█▇▇▇▆▇▇▇▇▇█▇▇█▇██▇▇██▇█</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▂▂▂▃▂▂▂▂▂▂▂▂▁▂▁▁▂▂▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▅▅▅▄▆▅▅▅▅▄▅▄▃▃▃▅▃▄▄▁▃▂▅▃▄▄▄▅▄▃▂▃▂▃▂▃▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▅▄▇▄▆▆▆▇▇▆▄█▆▇▆▆▇▇▇▇▇▄▄▇▇▇▆▇▇▇▇▇▆▅▇█▇▇</td></tr><tr><td>val_auc</td><td>▁▃▅▅▇▅▇▇▇█▇▆█▇▇██▇▇██▇▇▇▇▇▆▇▆▇▇▇▇▇▇▇▆▇▆▇</td></tr><tr><td>val_f1</td><td>▁▄▆▅█▄▆█▇▇█▇██▆▇█▇█▇▇▇▇█▇██▇▆▇▇▇▇█▇▇▇█▇▇</td></tr><tr><td>val_loss_epoch</td><td>▆▅▅▄▄▅▃▅▃▃▂▃▇▄▂▂▃▂▂▂▁▄▁█▇▄▂▂▄▃▄▂▂▂▂▂▁▃▂▂</td></tr><tr><td>val_loss_step</td><td>▆▆▅▅▄▆▄▅▃▄▅▃█▃▄▃▅▃▃▁▃▃▅▅▃▄▃▄▂▅▅▆▆▅▄▄▃▆▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77443</td></tr><tr><td>train_auc</td><td>0.84725</td></tr><tr><td>train_f1</td><td>0.70975</td></tr><tr><td>train_loss_epoch</td><td>0.46899</td></tr><tr><td>train_loss_step</td><td>0.37875</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.7619</td></tr><tr><td>val_auc</td><td>0.82212</td></tr><tr><td>val_f1</td><td>0.69767</td></tr><tr><td>val_loss_epoch</td><td>0.51813</td></tr><tr><td>val_loss_step</td><td>0.4971</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/udrhxsal' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/udrhxsal</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_011545-udrhxsal\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d73c4a10db3c43529f48a6ae04656911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_012901-15nww3tb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/15nww3tb' target=\"_blank\">GINConv_3_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/15nww3tb' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/15nww3tb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_64_onehot_3\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 22.1 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "24.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.2 K    Total params\n",
      "0.097     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▄▃▅▅▅▆▅▆▆▇▆▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇▇██▇▇▇████</td></tr><tr><td>train_auc</td><td>▄▂▅▃▁▂▄▃▃▂▃▃▅▃▃▄▄▅▂▄▅▄▆▆▆▆▆▇▇█▇█▆▅▆▆▅▆▇▇</td></tr><tr><td>train_f1</td><td>▂▃▂▂▁▅▅▆▆▆▆▆▆▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇███▇</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▂▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▂▄▁▄▃▇▅▇▇▇▇▇▇▆█▇▆██▇▇█▇█▇▇▇▆▇▇▇█▇█████▇▆</td></tr><tr><td>val_auc</td><td>▄▂▄▃▁▁▂▂▃▃▄▅▇▅▃▃▇█▆▇█▇███████████▇██████</td></tr><tr><td>val_f1</td><td>▁▄▁▅▄█▆▇▇▇▇█▇▇█▇▇██▇██▇█▇▇█▆▇▇▇█▇██████▆</td></tr><tr><td>val_loss_epoch</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.75342</td></tr><tr><td>train_auc</td><td>0.58582</td></tr><tr><td>train_f1</td><td>0.67233</td></tr><tr><td>train_loss_epoch</td><td>0.49223</td></tr><tr><td>train_loss_step</td><td>0.44535</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.73993</td></tr><tr><td>val_auc</td><td>0.81453</td></tr><tr><td>val_f1</td><td>0.5896</td></tr><tr><td>val_loss_epoch</td><td>0.63427</td></tr><tr><td>val_loss_step</td><td>0.70565</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/15nww3tb' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/15nww3tb</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_012901-15nww3tb\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_014223-yhsv97u8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/yhsv97u8' target=\"_blank\">GINConv_3_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/yhsv97u8' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/yhsv97u8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_64_onehot_3\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 22.1 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "24.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.3 K    Total params\n",
      "0.097     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cca6e1aab88947afaa8982481f6604fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▅▅▆▆▆▆▆▆▆▆▇▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇███</td></tr><tr><td>train_auc</td><td>▁▅▅▆▆▆▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇███</td></tr><tr><td>train_f1</td><td>▁▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█▇▇█▇▇▇▇██▇██▇███</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▅▄▄▄▄▄▃▄▃▃▄▃▃▃▃▃▂▃▃▂▃▂▂▂▃▂▂▂▂▂▂▂▂▁▁▂</td></tr><tr><td>train_loss_step</td><td>▇▇▅█▆▇▅▅▇▅▆▆▅▄▆▆▅▄▅▅▄▆▄▄▄▅▅▅▄▃▃▅▃▄▄▁▃▄▅▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▄▇▇▆▇▇▇▇█▇▆▇▂▆█▇▆▆█▅▆▇▇▇▅▇▄▇▅▇▆█▆▇▆▅▇▇▇</td></tr><tr><td>val_auc</td><td>▁▆▆▅▅▆▇▇▇▇▇██▇█▇▇▇▇█▇▇▇▇█▆█▇█▇███▇█▇▅▆▇▆</td></tr><tr><td>val_f1</td><td>▁▄▇█▇██▇▇█▇▆█▇▆█▇▇██▅▇█▇▇▅▇▅▇█▇▆█▇▇▆▇███</td></tr><tr><td>val_loss_epoch</td><td>▅▃▂▄▂▂▂▁▂▁▃▃▂█▄▂▂▂▅▃▃▂▁▂▂▄▂▄▄▃▃▂▂▃▂▃▃▃▁▁</td></tr><tr><td>val_loss_step</td><td>▇▇▄▃▃▃▃▄▄▄▃▅▃█▄▃▅▄▄▃▄▅▄▃▃▃▅▇▃▅▄▆▅▄▄▃▃▅▆▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.80274</td></tr><tr><td>train_auc</td><td>0.87073</td></tr><tr><td>train_f1</td><td>0.75</td></tr><tr><td>train_loss_epoch</td><td>0.44816</td></tr><tr><td>train_loss_step</td><td>0.48966</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.76557</td></tr><tr><td>val_auc</td><td>0.83572</td></tr><tr><td>val_f1</td><td>0.73109</td></tr><tr><td>val_loss_epoch</td><td>0.46256</td></tr><tr><td>val_loss_step</td><td>0.35824</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/yhsv97u8' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/yhsv97u8</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_014223-yhsv97u8\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_015605-ghlshaw0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ghlshaw0' target=\"_blank\">GINConv_3_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ghlshaw0' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ghlshaw0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_64_onehot_3\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 22.1 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "28.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "28.4 K    Total params\n",
      "0.114     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▅▆▆▇▇▆▆▇▆▆▇▆▆▇▇▆▇▇▇▇▇██▇▇▇█▇███▇██▇█</td></tr><tr><td>train_auc</td><td>▁▅▅▆▆▇▇▇▇▇▇▆▇▇▇▇▆▇▇▇▇▇▇▇▇█▇▇▇██████▇████</td></tr><tr><td>train_f1</td><td>▁▄▆▆▆▇▆▇▇▆▆▇▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇▇█▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▅▄▄▄▄▃▄▄▄▄▃▃▃▄▃▃▃▂▂▃▃▃▂▃▃▃▂▂▂▂▂▂▂▁▂▂▁</td></tr><tr><td>train_loss_step</td><td>▇▇▅▅▆▅▅▆▇▆▆▄▅▅▄▃▄▅▄▆█▃▃▆▂▄▄▃▅▂▆▅▅▅▃▁▂▃▄▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▇▇▆▆▇▇▅▆▇█▇▆▆▇▇██▆█▇▇▆▆▇▃▅█▅▆▆▇▅▆▇▆▇▆▇</td></tr><tr><td>val_auc</td><td>▁▄▆▆▆▆▆▆▆▅▆▇▇▇▇█▇▇█▇█▆▇▇▆▇▃▇▆█▇▆█▆▆▇▅▇▆▆</td></tr><tr><td>val_f1</td><td>▁▃▇▇▇▇██▇▇███▆██▇██▇███▆▆█▇▆█▅▇▇▇█▇█▇▇▇█</td></tr><tr><td>val_loss_epoch</td><td>█▄▂▁▃▂▁▂▃▂▂▂▂▄▂▁▂▂▂▂▂▃▂▂▂▃▅▄▂▃▃▂▁▃▁▁▃▂▂▂</td></tr><tr><td>val_loss_step</td><td>█▅▂▃▂▃▃▃▂▂▂▃▂▃▃▂▂▂▁▂▃▂▅▂▃▄▃▃▂▄▂▆▃▂▆▄▄▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.79452</td></tr><tr><td>train_auc</td><td>0.86955</td></tr><tr><td>train_f1</td><td>0.73988</td></tr><tr><td>train_loss_epoch</td><td>0.42773</td></tr><tr><td>train_loss_step</td><td>0.3495</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.76557</td></tr><tr><td>val_auc</td><td>0.83649</td></tr><tr><td>val_f1</td><td>0.73984</td></tr><tr><td>val_loss_epoch</td><td>0.4938</td></tr><tr><td>val_loss_step</td><td>0.39767</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ghlshaw0' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ghlshaw0</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_015605-ghlshaw0\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_021019-4uduyunv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/4uduyunv' target=\"_blank\">GINConv_4_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/4uduyunv' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/4uduyunv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_16_onehot_3\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 2.3 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▆▆▇▇▇▇▇▇█▇▇▇▇▇▇▇█▇██▇██▇█▇██████▇█▇█</td></tr><tr><td>train_auc</td><td>▁▄▆▆▇▆▇▇▇▇▇▇█▇▇▇▇▇▇█▇███▇██▇███▇████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▇▇▇▇▇▇▇▇█▇▇██▇▇██▇██▇██▇█▇████▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▃▃▃▃▃▃▃▁▃▄▃▂▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁</td></tr><tr><td>train_loss_step</td><td>██▅▆▄▇▄▆▃▂▄█▂▄▇▅▃▃▆▂▃▆▄▃▅▅▆▂█▅▄▃▇█▂▅▂▃▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▁▆▅▆▅▆▇▆█▇▇▆▇▆▇▇▇▅▇▇▇▇▇▅▇▆█▇▆▇▅▇▅▆▆▅▆▆</td></tr><tr><td>val_auc</td><td>▁▄▆▆▇▇▇▇▇▇▇▇▇▆▇▇▇████▇▇▇██▇██▇▇█▇▇▇▇▇▇▇▇</td></tr><tr><td>val_f1</td><td>▁▂▂▇▅▆▅▇█▇█▇█▆▇▆▇██▅▇▇▇██▆█▇█▇▇█▅▇▅▇▇▆▇▇</td></tr><tr><td>val_loss_epoch</td><td>▅▄█▂▄▃▂▃▃▃▄▂▁▃▃▃▂▂▁▄▂▃▁▁▁▄▂▃▂▂▁▃▄▃▅▁▃▃▁▂</td></tr><tr><td>val_loss_step</td><td>▅▅█▃▂▃▃▂▂▂▂▂▂▃▂▂▂▁▂▂▁▃▁▂▁▂▂▁▃▂▂▁▂▄▃▂▂▃▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.76347</td></tr><tr><td>train_auc</td><td>0.80337</td></tr><tr><td>train_f1</td><td>0.70264</td></tr><tr><td>train_loss_epoch</td><td>0.50242</td></tr><tr><td>train_loss_step</td><td>0.42571</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.75458</td></tr><tr><td>val_auc</td><td>0.84062</td></tr><tr><td>val_f1</td><td>0.6599</td></tr><tr><td>val_loss_epoch</td><td>0.50049</td></tr><tr><td>val_loss_step</td><td>0.50788</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/4uduyunv' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/4uduyunv</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_021019-4uduyunv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_022409-k3y6pg54</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/k3y6pg54' target=\"_blank\">GINConv_4_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/k3y6pg54' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/k3y6pg54</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_16_onehot_3\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 2.3 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc239a3f7f2841a9b2aa04c27f829295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.013 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.080614…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▂▁▂▄▅▅▅▆▅▆▆▇▆▇▆▇▇▇▇▇▇▆▇▇▇█▇▆██▇█▇█▇█▇██▇</td></tr><tr><td>train_auc</td><td>▁▁▄▅▅▅▅▆▅▆▆▆▇▇▆▇▇▇▇▇▇▇▇█▇▇▇▇██▇███▇▇█▇██</td></tr><tr><td>train_f1</td><td>▄▁▃▅▆▆▆▆▆▆▆▇▇█▇▇▇▇▇▇▇▇▇▇▇█▇▇██▇█████▇███</td></tr><tr><td>train_loss_epoch</td><td>██▇▅▆▅▅▄▄▄▄▃▃▃▃▃▂▃▃▃▃▂▂▂▃▁▂▂▁▂▂▁▂▂▂▁▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>▇▇▆▆▅▇▇▆▄▄▄█▄▃▄▄▃▄▆▄▃▇▄▄▅▄▆▂▅▄▃▃▆▆▄▄▃▃▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▁▃▅▆▆▆▅▅▃▆▆▃▆▄▇▃▆▆▆▇▆▆▅▇▂▅▆▇▇▇▇▇▇▇█▅▂▇▇</td></tr><tr><td>val_auc</td><td>▁▂▄▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇█▇▇▇██▇█▇████▇███▇██▇</td></tr><tr><td>val_f1</td><td>▁▁▄▆▇▇▇▇▇▄▇▇▇▆▇▇▇▇▇▇█▇█▆█▇▆█████▇▇▇█▇▇▇█</td></tr><tr><td>val_loss_epoch</td><td>█▇▇▆▅▆▄▆▅▄▇▅▅▄▅▄▄▃▅▄▄▄▄▃▃▇▃▆▄▄▁▆▃▄▄▂▂█▂▅</td></tr><tr><td>val_loss_step</td><td>▆▅▅▄▄▄▄▄▃▄▂▄▅▄▄▃▄▂▃▂▂▃▄▁▂▂▂▄▃▂▁▁▁▃▂▂█▁▃▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.72785</td></tr><tr><td>train_auc</td><td>0.76008</td></tr><tr><td>train_f1</td><td>0.64941</td></tr><tr><td>train_loss_epoch</td><td>0.5424</td></tr><tr><td>train_loss_step</td><td>0.45389</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.75458</td></tr><tr><td>val_auc</td><td>0.81332</td></tr><tr><td>val_f1</td><td>0.74906</td></tr><tr><td>val_loss_epoch</td><td>0.61399</td></tr><tr><td>val_loss_step</td><td>0.71358</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/k3y6pg54' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/k3y6pg54</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_022409-k3y6pg54\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_023654-5w5p7zsr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/5w5p7zsr' target=\"_blank\">GINConv_4_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/5w5p7zsr' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/5w5p7zsr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_16_onehot_3\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 2.3 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▂▂▁▂▃▃▃▄▄▃▄▅▅▅▅▅▆▆▆▇▇▇▆▇▇▇█▇▇███▇█▇▇█▇██</td></tr><tr><td>train_auc</td><td>▅█▇▃▅▆▆▅▆▅▄▆▅▅▆▆▄▅▄▄▄▄▃▄▃▃▃▃▄▂▂▂▄▁▃▂▃▅▇▅</td></tr><tr><td>train_f1</td><td>▂▃▂▂▃▂▂▂▃▁▂▃▃▃▄▄▅▅▅▆▆▆▅▇▇▇▇▆▇▇▇█▇█▇▇████</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▂▃▃▂▄▃▃▂▃▃▄▄▄▅▄▅▆▅▆▆▆██▇▇▆▇▇▇█▇▇█▇████</td></tr><tr><td>val_auc</td><td>▇▇█▅▇▇█▇█▇▇▆▆▄█▇▆▃▃▃▃▄▂▂▂▂▁▁▁▁▁▂▂▁▂▁▁▃▆▄</td></tr><tr><td>val_f1</td><td>▁▂▃▅▅▂▅▄▄▃▄▄▅▅▅▅▆▆▇▆▇▇▇██▇▇▇█▇▇██▇██████</td></tr><tr><td>val_loss_epoch</td><td>█▁▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.72877</td></tr><tr><td>train_auc</td><td>0.49867</td></tr><tr><td>train_f1</td><td>0.67398</td></tr><tr><td>train_loss_epoch</td><td>0.56152</td></tr><tr><td>train_loss_step</td><td>0.45388</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.77656</td></tr><tr><td>val_auc</td><td>0.38591</td></tr><tr><td>val_f1</td><td>0.73362</td></tr><tr><td>val_loss_epoch</td><td>0.50583</td></tr><tr><td>val_loss_step</td><td>0.49407</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/5w5p7zsr' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/5w5p7zsr</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_023654-5w5p7zsr\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_024925-xmd4rk4g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/xmd4rk4g' target=\"_blank\">GINConv_4_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/xmd4rk4g' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/xmd4rk4g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_16_onehot_3\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 2.3 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "2.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇██▇█▇██▇▇</td></tr><tr><td>train_auc</td><td>▁▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█▇████▇█████▇███</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▇▆▆▇▇▇▇▇▇▆▇▇▇▇▇▇██▇▇▇▇█▇▇▇████▇███▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▃▃▃▃▃▃▃▃▃▃▃▂▃▃▃▂▂▂▃▁▂▂▂▂▂▂▁▂▂▂▁▂▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▇█▆▄▅▅▄▃▄▅▃▂▃▄▃▄▃▅█▄▃▃▅▂▃▃▂▃▄▁▄▂▁▃▁▄▃▃▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▁▄▆▅▇▆▆▇█▅▇▅█▇▇▇▇▇██▆▅▆▇▇▇███▇▇▆▅█▅▇▇▅▇</td></tr><tr><td>val_auc</td><td>▁▄▆▇▆▆▇▇▇▇▆▇▇▇█▇██▇█▇█████▇██▇▇▇▇▇▇▇▆▇▇▇</td></tr><tr><td>val_f1</td><td>▁▂▄▆▅█▆▆▇█▆▇▅██▇▇▇███▆▅▆▇▇▇▇▇▇█▇▇▅█▆█▇▅█</td></tr><tr><td>val_loss_epoch</td><td>█▇▃▅▅▃▃▄▂▄▆▃▇▃▄▃▃▅▂▂▃▃▅▃▅▃▄▃▃▃▃▄▃▄▂▆▄▂█▁</td></tr><tr><td>val_loss_step</td><td>█▇█▄▆▅▅▄▅▅▆▆▆▅▃▄▄▄▃▄▅▅▅▅▄▄▄▇▄▄▅▅▃▄▅▆▃▅▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.75251</td></tr><tr><td>train_auc</td><td>0.81683</td></tr><tr><td>train_f1</td><td>0.66502</td></tr><tr><td>train_loss_epoch</td><td>0.51568</td></tr><tr><td>train_loss_step</td><td>0.52203</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.76923</td></tr><tr><td>val_auc</td><td>0.84084</td></tr><tr><td>val_f1</td><td>0.72</td></tr><tr><td>val_loss_epoch</td><td>0.4313</td></tr><tr><td>val_loss_step</td><td>0.29844</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/xmd4rk4g' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/xmd4rk4g</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_024925-xmd4rk4g\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_030104-4fsxyitp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/4fsxyitp' target=\"_blank\">GINConv_4_16_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/4fsxyitp' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/4fsxyitp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_16_onehot_3\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 2.3 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "2.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.7 K     Total params\n",
      "0.011     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▇▆▆▇▇▆▆▆▇▇▇▇█▇▇█▇▇▇▇▇▇▇█▇██▇▇██▇█▇██</td></tr><tr><td>train_auc</td><td>▁▅▅▆▇▇▆▇▇▆▇▇▇█▇▇▇▇▇▇▇▇██▇███▇███████████</td></tr><tr><td>train_f1</td><td>▁▄▆▆▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇█▇▇▇▇▇███▇█████▇▇█▇██</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▃▃▃▃▂▄▃▃▃▂▂▂▂▂▂▂▂▃▂▂▂▂▁▁▃▁▁▂▁▁▂▁▂▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▇▅▅▄▅▆▃▄▅▃▅▇▂▃▅▄▃▅▅▄▅▄▂▁▃▄▂▃▃▄▄▃▄▂▂▃▅▃▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▄▇▆▇▅▇▆▆▆█▇█▇▅██▆▇▇▅▇▆▆███▇▆▆██▇▇██▆▆█</td></tr><tr><td>val_auc</td><td>▁▃▅▅▆▆▇▇▆▆▇▆▇▆▇▇▇▆▇▇▇▇█▇█▇▆▇▇█▇▇▇█▇█▇▇█▆</td></tr><tr><td>val_f1</td><td>▁▂▅▇▆▇▆▇▆▆▇█▇██▅██▆▇▇▅█▆▆██▇▇▆▆██▇▇██▆▇█</td></tr><tr><td>val_loss_epoch</td><td>▇█▅▄▃▃▄▄▃▃▂▃▃▄▂▆▃▂▇▃▂▃▂▃▄▃▂▁▄▅▆▃▄▂▄▂▂▃▄▃</td></tr><tr><td>val_loss_step</td><td>▇█▆▃▄▂▂▂▅▃▅▃▂▄▁▄▃▃▄▂▄▂▁▂▂▂▃▃▃▅▂▃▂▂▄▄▃▄▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.76438</td></tr><tr><td>train_auc</td><td>0.79982</td></tr><tr><td>train_f1</td><td>0.68382</td></tr><tr><td>train_loss_epoch</td><td>0.51228</td></tr><tr><td>train_loss_step</td><td>0.54503</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.77289</td></tr><tr><td>val_auc</td><td>0.82256</td></tr><tr><td>val_f1</td><td>0.72807</td></tr><tr><td>val_loss_epoch</td><td>0.52325</td></tr><tr><td>val_loss_step</td><td>0.53868</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/4fsxyitp' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/4fsxyitp</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_030104-4fsxyitp\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_031245-m6wzwyun</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/m6wzwyun' target=\"_blank\">GINConv_4_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/m6wzwyun' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/m6wzwyun</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_32_onehot_3\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 8.2 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "8.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.7 K     Total params\n",
      "0.035     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d896bc1c1e864414bdfe624e3607dd97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▆▆▆▆▇▆▆▆▆▇▅▇▇▇▇▇▆▇▇▇▇▇▇▇██▇▇▇▇▇▇█▇█</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▆▆▇▆▆▇▆▆▇▆▇▇▇▇▇▇▇█▇▇██▇▇▇▇██▇█▇███</td></tr><tr><td>train_f1</td><td>▁▆▆▆▆▆▆▆▆▇▆▆▅▆▆▅▇▇▇▇▇▆▆▇▆▇▇▇▇▇█▇▇▇▇▇▇█▇█</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▄▄▄▃▃▄▃▃▃▃▃▃▂▂▂▂▃▃▂▃▂▁▂▂▂▁▂▁▂▂▂▂▁▂▁</td></tr><tr><td>train_loss_step</td><td>▇█▇▅▅▅▇▇▇▆▅▆▄▆▅▄▅▄▄▂▆▅▄▂▇▂▂▂▄▃▁▂▇▁▂▃▂▁▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▅▅▇▇▇▇▇▇▄▄█▇▇▇▆▇▁▇▇▅▇▇▇▆▆▅▄█▇██▇█▇▅▇▆▇</td></tr><tr><td>val_auc</td><td>▁▄▅▅▅▆▆▇▇██▇▇▇▆▇▆█▄▆▇▆▇▇▇▇██▇▇▆▇█▇▇▆▇▇▇▇</td></tr><tr><td>val_f1</td><td>▁▄▅▅██▇▇▇█▅▅██▇▇█▇▇█▇████▆▇▆▅█▇██▇██▅▇▆▇</td></tr><tr><td>val_loss_epoch</td><td>▅▃▃▄▁▃▂▂▃▁▃▃▂▂▁▃▃▃█▁▂▂▂▂▂▂▂▂▂▂▃▂▂▂▂▃▅▃▄▁</td></tr><tr><td>val_loss_step</td><td>▆▇▅▅▄▄▃▄▃▃▅▇▃▄▄▃▄▄█▄▇▃▃▄▄▄▄▅▃█▄▄▃▃▅▅▄▅▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.79087</td></tr><tr><td>train_auc</td><td>0.84912</td></tr><tr><td>train_f1</td><td>0.72835</td></tr><tr><td>train_loss_epoch</td><td>0.47101</td></tr><tr><td>train_loss_step</td><td>0.43567</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.75824</td></tr><tr><td>val_auc</td><td>0.83974</td></tr><tr><td>val_f1</td><td>0.65979</td></tr><tr><td>val_loss_epoch</td><td>0.44682</td></tr><tr><td>val_loss_step</td><td>0.28645</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/m6wzwyun' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/m6wzwyun</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_031245-m6wzwyun\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfbd6cd77a9046398f445f9e49196b1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_032450-3rbw93fe</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/3rbw93fe' target=\"_blank\">GINConv_4_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/3rbw93fe' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/3rbw93fe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_32_onehot_3\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 8.2 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "8.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.7 K     Total params\n",
      "0.035     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▅▅▆▆▆▆▆▇▇▇▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇▇▇██▇</td></tr><tr><td>train_auc</td><td>▁▃▄▄▅▅▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇█▇▇▇▇█▇▇█▇█▇▇███▇</td></tr><tr><td>train_f1</td><td>▁▃▆▆▆▆▆▅▅▇▆▇▇▇▅▇▇▇▇▇▇█▇▇▇▇▇▇█▆▇█▇█▇▇▇█▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▄▃▃▃▃▃▃▂▃▃▃▂▂▂▂▂▂▃▂▁▂▂▂▁▁▂▂▂▁▁▂▂▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>▇█▇▆▆▄▆▅▅▅▅▅▄▇▆▄▆▄▄▂▄▅▅▄▅▃▃▁▄▄▃▃▇▃▃▆▃▃▅▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▅▅▆▆▅▆▅▇▇▇▆▇▆▇▇▇▇▇▇▆▅▇▇▇▇▇▆▇▆█▆▇▇▇▇▇▃▆</td></tr><tr><td>val_auc</td><td>▁▃▄▄▅▆▆▇▇███▇▇▇▇▇██▇▇▆▇▇█▇▇█▇▇▇█████▇▇▇▇</td></tr><tr><td>val_f1</td><td>▆▁▅▄▆▇▅▇▇▇▇▇▇▇▇▇▇█▇▇▇▆▇▇▇▇▇▇▇▇▇█▆▇▇▇▇▇▆▇</td></tr><tr><td>val_loss_epoch</td><td>▇▃▄▄▃▆▃▃▆▃▂▅▄▃▂▃▃▂▄▁▃▄▅▂▁▅▂▂▃▂▃▂▂▂▄▁▄▃█▂</td></tr><tr><td>val_loss_step</td><td>█▇▅▅▅▅▄▅▆▅▃▄▄▄▄▃▄▅▃▄▃▄▃▄▃▄▃▅▁▄▃▃▂▄▄▅▄▄▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.75616</td></tr><tr><td>train_auc</td><td>0.79821</td></tr><tr><td>train_f1</td><td>0.67479</td></tr><tr><td>train_loss_epoch</td><td>0.51964</td></tr><tr><td>train_loss_step</td><td>0.49565</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.74725</td></tr><tr><td>val_auc</td><td>0.81926</td></tr><tr><td>val_f1</td><td>0.7251</td></tr><tr><td>val_loss_epoch</td><td>0.51723</td></tr><tr><td>val_loss_step</td><td>0.43842</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/3rbw93fe' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/3rbw93fe</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_032450-3rbw93fe\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_033724-38nsewl0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/38nsewl0' target=\"_blank\">GINConv_4_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/38nsewl0' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/38nsewl0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_32_onehot_3\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 8.2 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "8.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.7 K     Total params\n",
      "0.035     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df36b9d041e9466794495e25aba471ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▂▁▂▃▃▃▅▄▅▅▆▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇</td></tr><tr><td>train_auc</td><td>█▅▅██▆▇▆▄▄▅▅▃▃▄▄▃▂▃▂▃▃▂▁▂▃▃▂▂▃▄▄▄▄▃▃▃▃▃▃</td></tr><tr><td>train_f1</td><td>▂▂▁▄▄▄▅▄▄▆▆▆▆▇▇▇▇▆▇▇▇▇▆█▇▆▆▇▇▆▇▇▇▇▇▇█▇█▇</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▂▅▁▂▅▂▅▄▃▅▅▆▆▅▅▆▅▆▆▆▆▆▆█▆▇▅▆▆▆▆█▆▆▆▆█▇██</td></tr><tr><td>val_auc</td><td>█▃▆█▇▇▇▅▄▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▁▁▁▁▁▁</td></tr><tr><td>val_f1</td><td>▃▆▁▂▅▂▅▅▄▅▆▇▇▆▆▇▆▆▇▆▆▆▇█▇▇▆▇▇▇▇▇▇▆▆▆█▇██</td></tr><tr><td>val_loss_epoch</td><td>▄▂▂█▁▄▂▂▂▂▂▁▂▁▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▂▂▂▁▂▂▁▁▁▂▁</td></tr><tr><td>val_loss_step</td><td>▇▆▄█▂▄▂▅▃▃▃▃▂▃▃▂▂▂▂▂▄▂▂▂▂▁▂▄▂▂▂▂▁▁▄▃▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.73242</td></tr><tr><td>train_auc</td><td>0.40855</td></tr><tr><td>train_f1</td><td>0.67696</td></tr><tr><td>train_loss_epoch</td><td>0.54775</td></tr><tr><td>train_loss_step</td><td>0.44896</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.78022</td></tr><tr><td>val_auc</td><td>0.17292</td></tr><tr><td>val_f1</td><td>0.73451</td></tr><tr><td>val_loss_epoch</td><td>0.48722</td></tr><tr><td>val_loss_step</td><td>0.4245</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/38nsewl0' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/38nsewl0</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_033724-38nsewl0\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1372f443df6444ecaa745a56174296a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333338766, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_035007-5oxswpiy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/5oxswpiy' target=\"_blank\">GINConv_4_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/5oxswpiy' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/5oxswpiy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_32_onehot_3\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 8.2 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "8.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.8 K     Total params\n",
      "0.035     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▆▆▆▆▆▇▆▆▇▇▆▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇███</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇█▇██████████</td></tr><tr><td>train_f1</td><td>▁▅▆▅▅▆▆▅▆▇▆▇▇▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇███</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▃▂▂▁▂▂▁▂▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▆▇▆▆▅▇▅▆▆▅▆█▄▃▂▃▆▇▄▃▄▃▄▄▂▃▅▆▄▂▃▄▂▄▁▁▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▆▅█▇▆██▄▇▄██▆▅█▇▇█▇▇█▇▇▄██▇█▇▅██▇▃▅█▇▆</td></tr><tr><td>val_auc</td><td>▁▄▅▆█▇█▇▇▅▇▇▇▇▇▇▇▇█▆▆▆▇▇█▃▇█▇▇▇▆▇█▇▇▇▇▅▅</td></tr><tr><td>val_f1</td><td>▁▃▆▅█▇▆▇█▅█▄██▇▅██▇█▇██▇█▇█████▅███▄▆█▇▆</td></tr><tr><td>val_loss_epoch</td><td>▆█▂▄▃▄▄▄▂▄▂▅▃▂▂▃▂▃▃▃▃▃▄▂▂▅▂▄▃▂▃▄▁▁▃▆▃▃▄▃</td></tr><tr><td>val_loss_step</td><td>▆▇▄▄▃▄▆▁▂▆▃▆▃▂▃▇▄▁▃▄▅▃▂▄▃▁▂▃▂▃▂█▃▁▂▇▅▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.79909</td></tr><tr><td>train_auc</td><td>0.86057</td></tr><tr><td>train_f1</td><td>0.74299</td></tr><tr><td>train_loss_epoch</td><td>0.45666</td></tr><tr><td>train_loss_step</td><td>0.41355</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.72894</td></tr><tr><td>val_auc</td><td>0.82812</td></tr><tr><td>val_f1</td><td>0.58889</td></tr><tr><td>val_loss_epoch</td><td>0.53644</td></tr><tr><td>val_loss_step</td><td>0.44328</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/5oxswpiy' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/5oxswpiy</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_035007-5oxswpiy\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_040355-yve0cod7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/yve0cod7' target=\"_blank\">GINConv_4_32_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/yve0cod7' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/yve0cod7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_32_onehot_3\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 8.2 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "9.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "9.8 K     Total params\n",
      "0.039     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▅▆▆▇▇▆▇▆▇▆▆▆▇▆▇▇▇▇▇▇▆▆▇█▇▇██▇█▇█▇▇█▇█</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▆▇█▇▇██████▇████</td></tr><tr><td>train_f1</td><td>▁▄▄▅▆▆▆▆▅▆▇▇▆▆▆▆▆▆▇▇▇▇▆▅▆▆▇▇▇▇▇▇█▇▇▇▇█▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▃▃▂▂▃▃▄▂▁▂▂▁▂▂▁▂▁▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>▇█▆▆▅▅▆▆▆▃▄▅▃▄▃▅▃▃▄▆▅▂▄▄▅▄▃▅▂▃▁▁▆▅▂▂▁▄▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▅▇▆▇█▆▅▇█▇▄▅▇▇▇█▃▇▃█▆▆▅▇▇▇▇▅▇█▅▄█▇▇▆▆▇</td></tr><tr><td>val_auc</td><td>▁▃▅▆▆▅▆▆▇▆▇▆▆▇▆▆▆▆▆▆▆█▇▆▇█▇▆▇▇▅▇▆▇▇▇▅▅▆▄</td></tr><tr><td>val_f1</td><td>▁▃▆▇▇██▇▅▇█▇▅▆▇███▃█▄█▆▆▅▇██▇▆▇█▆▅███▆▇█</td></tr><tr><td>val_loss_epoch</td><td>▆▄▄▂▃▃▃▂▃▅▃▃▅▅▄▄▃▃█▃█▁▄▄▃▂▃▃▃▄▅▄▅▅▂▄▃▃▃▃</td></tr><tr><td>val_loss_step</td><td>▆▇▄▃▄▄▃▃▄▂▁▁▅▆▂▃▂▂█▃▂▅▁▃▅▂▂▃▃▄▄▆▃▃▄▄▃▄▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.79909</td></tr><tr><td>train_auc</td><td>0.84518</td></tr><tr><td>train_f1</td><td>0.725</td></tr><tr><td>train_loss_epoch</td><td>0.46222</td></tr><tr><td>train_loss_step</td><td>0.42709</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.75824</td></tr><tr><td>val_auc</td><td>0.81051</td></tr><tr><td>val_f1</td><td>0.71552</td></tr><tr><td>val_loss_epoch</td><td>0.52848</td></tr><tr><td>val_loss_step</td><td>0.52781</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/yve0cod7' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/yve0cod7</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_040355-yve0cod7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_041753-x7rrgi61</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/x7rrgi61' target=\"_blank\">GINConv_4_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/x7rrgi61' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/x7rrgi61</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_64_onehot_3\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 30.7 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "32.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "32.8 K    Total params\n",
      "0.131     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b56772e7237b44f7b3b6d9071a644cfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▅▆▆▆▆▆▆▆▆▇▆▆▆▇▆▇▇▇▇█▆▇▇▇▇▇█▇█▇▇█▇█▇█</td></tr><tr><td>train_auc</td><td>▁▄▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇███</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▆▆▆▆▆▆▆▇▆▇▆▇▇▇▇▇▇█▆▇▇▇▇▇▇▇█▇▇█▇███</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▅▄▅▄▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▃▃▃▃▃▂▂▂▂▂▂▂▂▁▂▁</td></tr><tr><td>train_loss_step</td><td>▇█▅▆▆▃▄▄▆▅▄▇▇▅▃▄▅▅▇▄▃▃▃▄▅▃▄▃▆▂▄▁▂▄▃▃▂▅▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▅▆▇▇▇▇█▇▇▅▇▂▆▇▇▇▇▇▆▅▆▇▇▇▇▇▄▂▁▅▃▆█▇▅▇▇▆▆</td></tr><tr><td>val_auc</td><td>▃▄▅▇▆▇▆▇▇▅▆▇▄██▇██▅▆█▆▇▇▇▆▇█▆▁▇▄▄▇▄▄▆▇▆▆</td></tr><tr><td>val_f1</td><td>▁▅█▇▇█▇█████▇▆▇▇▇▇▇▇▅▇██▇▇▇▅▇▇▅▇▇██▇▇█▆▇</td></tr><tr><td>val_loss_epoch</td><td>▆▂▂▁▂▂▂▂▂▂▃▂▅▃▂▁▁▁▂▂▂▃▂▁▁▁▁▄▆█▄▅▃▂▁▅▂▁▃▃</td></tr><tr><td>val_loss_step</td><td>█▄▃▂▃▂▂▂▂▃▄▃▅▃▃▃▄▂▂▁▅▅▃▃▃▄▃▅▃▄▁▄▄▄▂▄▂▃▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.82009</td></tr><tr><td>train_auc</td><td>0.89287</td></tr><tr><td>train_f1</td><td>0.7769</td></tr><tr><td>train_loss_epoch</td><td>0.39793</td></tr><tr><td>train_loss_step</td><td>0.38148</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.74725</td></tr><tr><td>val_auc</td><td>0.82378</td></tr><tr><td>val_f1</td><td>0.65672</td></tr><tr><td>val_loss_epoch</td><td>0.56103</td></tr><tr><td>val_loss_step</td><td>0.57147</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/x7rrgi61' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/x7rrgi61</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_041753-x7rrgi61\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_042957-wsj3ss9g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/wsj3ss9g' target=\"_blank\">GINConv_4_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/wsj3ss9g' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/wsj3ss9g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_64_onehot_3\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 30.7 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "32.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "32.8 K    Total params\n",
      "0.131     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▆▆▆▆▇▆▆▇▇▇▆▇▇▆▇▇▇▇▇▇▇▇█▇██▇▇▇█▇▇█▇▇█</td></tr><tr><td>train_auc</td><td>▁▄▅▅▆▆▆▆▆▆▆▆▆▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇▇███▇█</td></tr><tr><td>train_f1</td><td>▁▃▅▅▅▆▅▆▆▆▆▆▇▇▅▇▆▆▇▇▇▇▇▇▇▇█▇█▇▇▇▇█▇▇██▇█</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▃▃▄▃▂▃▃▃▂▃▃▃▂▃▂▂▂▂▂▂▂▂▂▁▁▂▁▂▂▁▂▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>▇█▅▆▄▃▃▅▅▄▃▇▅▅▄▃▃▆▆▄▃▄▅▃▅▃▆▂▅▂▅▂▂▅▅▃▁▇▁▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▄▄▃▆▆▆▇▆▅▃▆▅▆▆▇▇▇▆▆▆▅█▆▆▆▆▅▆▆▄▆▇▄█▆▇▇▅</td></tr><tr><td>val_auc</td><td>▁▂▅▅▆▆▇▇▇▇▇▇█▇█▆▇█▇▇█▇▇▇▇▇▇▆▆▇▇▇▇▇▇▇▇▇▇▆</td></tr><tr><td>val_f1</td><td>▁▂▅▆▇▇▇▇▇▇▆▇▆▆█▇█▇█▇█▇▆█▇█▇▇▇▇▇▇▇▇▅███▇▇</td></tr><tr><td>val_loss_epoch</td><td>▇▆▅▃▆▄▄▄▄▂▄▆▂▅▃▃▂▃▃▂▄▄▃▂▄▄▄▂▆▅▁▆▃▁▂▆█▃▄▅</td></tr><tr><td>val_loss_step</td><td>▆█▄▃▆▃▄▂▂▃▃▆▂▂▄▄▃▁▃▁▁▄▂▂▃▃▃▅▁▂▂▂▃▄▂▃▃▂▁▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.78174</td></tr><tr><td>train_auc</td><td>0.846</td></tr><tr><td>train_f1</td><td>0.73474</td></tr><tr><td>train_loss_epoch</td><td>0.47915</td></tr><tr><td>train_loss_step</td><td>0.52425</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.71429</td></tr><tr><td>val_auc</td><td>0.79664</td></tr><tr><td>val_f1</td><td>0.71533</td></tr><tr><td>val_loss_epoch</td><td>0.60546</td></tr><tr><td>val_loss_step</td><td>0.57656</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/wsj3ss9g' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/wsj3ss9g</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_042957-wsj3ss9g\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_044203-hluossze</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/hluossze' target=\"_blank\">GINConv_4_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/hluossze' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/hluossze</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_64_onehot_3\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 30.7 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "32.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "32.8 K    Total params\n",
      "0.131     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c501d68139044e8bb2dd8ba8cf624aa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▁▁▂▃▄▄▄▆▆▆▆▆▆▆▇▆▆▆▇▆▇▇▆▇▆▇▇█▇▇▇▇█▇▇███</td></tr><tr><td>train_auc</td><td>▄▄▄▁▁▃▄▅▆▅▆▆▇▆▆▅▅▆▆▅▅▇▆▆▆▆▅▆▇▇███▇███▇██</td></tr><tr><td>train_f1</td><td>▃▁▂▁▂▂▅▄▄▅▆▆▆▇▆▇▇▆▆▇▇▆▇▇▆▇▆▇▇██▇████▇███</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▂▃▃▃▄▁▅▆▇▇▇▆▇▇▇▇▇█▇▅▇▇█▇▆▇▇▇▇▇▇▇▆█▇▇█▇▇▆</td></tr><tr><td>val_auc</td><td>▇▄▂▁▂▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█████▇▇█████▇██████</td></tr><tr><td>val_f1</td><td>▃▄▃▄▄▁▆▇▇▇▇▆▇█▇▇██▇▆███▇▇▇▇▇▇█▇▇▇█▇▇█▇█▆</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂</td></tr><tr><td>val_loss_step</td><td>█▃▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.779</td></tr><tr><td>train_auc</td><td>0.66984</td></tr><tr><td>train_f1</td><td>0.72991</td></tr><tr><td>train_loss_epoch</td><td>0.48806</td></tr><tr><td>train_loss_step</td><td>0.42228</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.73993</td></tr><tr><td>val_auc</td><td>0.83187</td></tr><tr><td>val_f1</td><td>0.59429</td></tr><tr><td>val_loss_epoch</td><td>0.68041</td></tr><tr><td>val_loss_step</td><td>0.82908</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/hluossze' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/hluossze</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_044203-hluossze\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_045336-5ghfeu87</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/5ghfeu87' target=\"_blank\">GINConv_4_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/5ghfeu87' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/5ghfeu87</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_64_onehot_3\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 30.7 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "32.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "32.9 K    Total params\n",
      "0.131     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▅▆▆▅▆▇▆▆▆▅▆▆▇▆▆▆▇▇▇▇▇▇▇██▇▆▇▇█▇█████</td></tr><tr><td>train_auc</td><td>▁▄▅▅▅▆▆▅▅▆▆▆▆▆▇▆▇▆▇▆▇▇▇▇▇▇▇█▇▇▆▇▇▇██████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▅▇▆▅▆▇▆▆▇▅▇▆▇▆▇▆▇▇▇▇▇▇▇██▇▆█████████</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▅▄▄▅▄▄▄▄▄▄▃▄▃▄▃▄▃▃▃▃▃▃▃▂▃▂▃▂▃▂▂▂▂▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▆█▄▅▆▄▅▅█▆▄▅▄▄▄▄▇▄▅▇▆▁▃▄▆▅▅▃▂▃▆▃▄▂▁▂▃▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▇▇▆▇▆▇▇▆██▃▆▇▆▄█▃█▃▇▄▂▅▇▇▆█▇▄▁▇▇▅▆▆▇█▆</td></tr><tr><td>val_auc</td><td>▂▅▅▅▆▇▇▇▆▆▇▇█▇▇▆██▃▇▆▇▁▄▅▇█▇██▇▃▆▅▆▅▆▆▆▆</td></tr><tr><td>val_f1</td><td>▁▂▇▇▇█▆▇████▃█▇█▄█▇█▇█▇▇▇▇▇▆█▇▅▇▇▇▇█▇██▆</td></tr><tr><td>val_loss_epoch</td><td>▇▆▃▂▂▁▂▁▂▂▂▂▄▂▂▅▄▁▆▁▆▂▅▅▅▁▃▄▂▁▄█▂▃▅▃▃▂▂▂</td></tr><tr><td>val_loss_step</td><td>▆▅▃▃▃▂▃▃▂▃▂▃█▃▂▃▄▃▅▃▄▃▇▃▅▄▂▇▃▄▄▂▃▃▃▃▅▄▆▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8137</td></tr><tr><td>train_auc</td><td>0.88546</td></tr><tr><td>train_f1</td><td>0.76168</td></tr><tr><td>train_loss_epoch</td><td>0.40914</td></tr><tr><td>train_loss_step</td><td>0.42174</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.71429</td></tr><tr><td>val_auc</td><td>0.82256</td></tr><tr><td>val_f1</td><td>0.57143</td></tr><tr><td>val_loss_epoch</td><td>0.49977</td></tr><tr><td>val_loss_step</td><td>0.35185</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/5ghfeu87' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/5ghfeu87</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_045336-5ghfeu87\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_050526-wdy9agh4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/wdy9agh4' target=\"_blank\">GINConv_4_64_onehot_3</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/wdy9agh4' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/wdy9agh4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_64_onehot_3\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 30.7 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "37.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "37.0 K    Total params\n",
      "0.148     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65daee37a3f8499a9d8064b7652a985c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▅▅▆▆▆▆▆▆▆▆▆▇▆▆▆▇▆▇▇▇▇▆▇▇█▇▇▇▇▇▇█▇▇█▇█</td></tr><tr><td>train_auc</td><td>▁▄▅▅▅▆▆▆▆▆▆▆▆▇▇▆▆▆▇▆▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇███</td></tr><tr><td>train_f1</td><td>▁▅▅▆▆▇▆▆▆▆▆▆▇▇▇▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇█████▇█▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▅▅▅▄▄▄▄▄▄▄▃▃▄▄▄▃▃▃▃▃▃▃▃▃▂▃▂▃▂▃▂▂▂▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>▇▇▆▆█▆▄▇▄▄▃▄▄▃▃▅▄▅▄▄▁▄▅▄▅▂▃▃▄▅▃▃▃▂▃▃▂▃▄▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▇█▆▆▇▇█▇▇▇█▇▅▅▅█▇▄▇▇▇▇▆▅▆▆▅▆▇▅▅▆▆▅▆▆▄▅</td></tr><tr><td>val_auc</td><td>▁▅▅▇▆▆▆▆▇▇▅▇█▆▇██▆▇▆▇▇▇█▇▄▇▇▄▄▆▅▄▇▆▃▃▄▄▅</td></tr><tr><td>val_f1</td><td>▁▄███▇█▇███▇█▇▅▆▅█▇▅▇▇▇█▆▇█▇▇▇██▇▇▆▇▇█▅▆</td></tr><tr><td>val_loss_epoch</td><td>█▅▃▂▄▃▂▁▂▂▂▂▁▂▅▃▃▃▁▅▃▄▂▂▃▄▁▂▂▂▂▄▂▄▃▂▃▂▄▅</td></tr><tr><td>val_loss_step</td><td>▅▃▂▂▂▂▁▂▁▂▁▁▁▂▂▂▃▁▁▃▂▂▃▂▂▁▁▂▁▂▄▂█▃▂▃▃▂▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.81461</td></tr><tr><td>train_auc</td><td>0.88939</td></tr><tr><td>train_f1</td><td>0.75572</td></tr><tr><td>train_loss_epoch</td><td>0.40638</td></tr><tr><td>train_loss_step</td><td>0.34854</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.70696</td></tr><tr><td>val_auc</td><td>0.81376</td></tr><tr><td>val_f1</td><td>0.52381</td></tr><tr><td>val_loss_epoch</td><td>0.68149</td></tr><tr><td>val_loss_step</td><td>0.77506</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_3</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/wdy9agh4' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/wdy9agh4</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_050526-wdy9agh4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_051757-1x82ulxg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/1x82ulxg' target=\"_blank\">GINConv_2_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/1x82ulxg' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/1x82ulxg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_16_onehot_4\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35f3cf4c19984492ba3b2ce2938de288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇█▇▇▇███▇▇█▇███▇▇██▇▇█▇</td></tr><tr><td>train_auc</td><td>▁▃▅▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇███▇█████████</td></tr><tr><td>train_f1</td><td>▁▃▅▆▆▆▇▇▇▅▇▇▇▇▇▇▇██▇█▇███▇▇█▇█▇█▇▇██▇▇█▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▃▄▃▃▃▄▃▃▃▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▁▂▁▂▂▂▁▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>██▅▅▅▄▄▅▅▆▂▇▅▃▃▄▄▄▄▆▂▂▄▄▃▃▃▄▂▃▄▅▅▅▄▁▅▄█▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▄▃▄▇▆▆▇▅▇▇▂▇█▇▇▆▇█▇▇█▇███▇▇█▇█▇▆████▇██</td></tr><tr><td>val_auc</td><td>▁▂▃▄▅▅▅▆▆▆▇▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇██▇▇▆▇█▇▇█▇▇</td></tr><tr><td>val_f1</td><td>▁▅▄▅█▆▇███▇▇█▇▇███▇▇▇█▇█▇█▇████▇█▇▇▇█▆▇█</td></tr><tr><td>val_loss_epoch</td><td>█▆▅█▅▄▂▃▄▅▅▇▃▁▄▁▅▁▂▃▂▃▅▁▃▄▄▃▄▅▂▄▄▄▂▄▁▆▄▅</td></tr><tr><td>val_loss_step</td><td>▆▃▇▅▂▄▅▄▅▁▂▇▃▃▁▄▂▁▁▂▃▂▂▂▆▂▄▂▂▁▃▂▂▂▄▂▂▃▄█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.76712</td></tr><tr><td>train_auc</td><td>0.82416</td></tr><tr><td>train_f1</td><td>0.6848</td></tr><tr><td>train_loss_epoch</td><td>0.49815</td></tr><tr><td>train_loss_step</td><td>0.53369</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.73993</td></tr><tr><td>val_auc</td><td>0.80136</td></tr><tr><td>val_f1</td><td>0.70539</td></tr><tr><td>val_loss_epoch</td><td>0.61205</td></tr><tr><td>val_loss_step</td><td>0.77667</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/1x82ulxg' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/1x82ulxg</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_051757-1x82ulxg\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_052949-y445mgbw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/y445mgbw' target=\"_blank\">GINConv_2_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/y445mgbw' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/y445mgbw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_16_onehot_4\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "648a8b0f069647939fcb0eb569ea9e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▃▄▄▅▆▅▅▅▆▇▆▇▇▆▇▇▇▇█▇██▇▇▇▇█▇▇█▇▇██▇▇▇█</td></tr><tr><td>train_auc</td><td>▂▁▂▃▄▄▅▅▆▅▇▇▆▇▆▆▇▇▇▇█▇▇█▇▇▇▇██▇█▇▇██▇▇██</td></tr><tr><td>train_f1</td><td>▅▂▁▃▄▅▆▆▆▃▆▇▇▇▇▆▇█▇▇█▇███▇▇▇█▇▇█▆▇██▇▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▅▅▄▄▄▄▅▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▃▂▂▁▂▂▁▁</td></tr><tr><td>train_loss_step</td><td>██▆▇▆▅▅▅▇▆▃▅▅▅▄▃▄▃▅▆▃▃▄▃▄▄▃▄▃▃▅▆▅▄▄▁▅▄▆▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▁▁▄▅▅▆▇█▆▇▆▆▇▇▆█▇▇▆▇█▆▇▇▇▇▇▆▇▇█▆▇▅█▆▆█▆</td></tr><tr><td>val_auc</td><td>▁▃▄▅▅▅▇▆▇██▇▇▇▇▆▇█▇▇██▇█▇▇▆▇███▇█▇▇█▆▇▇▇</td></tr><tr><td>val_f1</td><td>▁▁▁▄▅▆▇▇█▆▇█▆▇▇▇█▇▇███▇▇█▇▇██████▇██████</td></tr><tr><td>val_loss_epoch</td><td>██▆▇▅▆▅▅▄▅▅▃▃▂▄▂▃▁▁▅▂▃▃▁▂▅▅▁▅▃▃▅▅▃▄▄▅▄▆▇</td></tr><tr><td>val_loss_step</td><td>▅▄▄▄▄▄▃▃▃▂▂▃▃▃▂▃▂▂▁▂▃▃▂▂▂▂▃▂▂▁▂▁▂▂▃▂▃▃▂█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.74703</td></tr><tr><td>train_auc</td><td>0.79235</td></tr><tr><td>train_f1</td><td>0.6559</td></tr><tr><td>train_loss_epoch</td><td>0.53278</td></tr><tr><td>train_loss_step</td><td>0.54951</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.69231</td></tr><tr><td>val_auc</td><td>0.76672</td></tr><tr><td>val_f1</td><td>0.69343</td></tr><tr><td>val_loss_epoch</td><td>0.66093</td></tr><tr><td>val_loss_step</td><td>0.81339</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/y445mgbw' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/y445mgbw</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_052949-y445mgbw\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_054120-n0vzcoaq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/n0vzcoaq' target=\"_blank\">GINConv_2_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/n0vzcoaq' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/n0vzcoaq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_16_onehot_4\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.1 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d050fbd42e4346fabff90a3fae3e8271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▃▂▃▃▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇██▇▆▇█▇▇▇▇▇▇██▇███</td></tr><tr><td>train_auc</td><td>██▇▇▆▅▅▆▄▄▃▂▃▃▂▃▂▃▃▂▂▂▂▂▁▂▂▂▁▂▁▂▂▁▂▁▂▁▁▂</td></tr><tr><td>train_f1</td><td>▄▃▄▃▂▂▁▂▂▃▃▃▆▆▆▅▆▆▆▇▇▇▇█▇▆▇▇▇▆█▇▇▇▇█▇███</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▅▄▆▅▅▅▅▆▆▆▇▇▇▇▇█▇▇▆▆▇▇▆▇▇▇▇▇▇▇▇▇█████▇█</td></tr><tr><td>val_auc</td><td>█▅▅▄▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_f1</td><td>▁▆▅▇▆▆▆▆▇▇▇▇█▇▇▇███▇█▇███▇█▇█▇███████▇██</td></tr><tr><td>val_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.73151</td></tr><tr><td>train_auc</td><td>0.26694</td></tr><tr><td>train_f1</td><td>0.65083</td></tr><tr><td>train_loss_epoch</td><td>0.56377</td></tr><tr><td>train_loss_step</td><td>0.55817</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.72161</td></tr><tr><td>val_auc</td><td>0.22936</td></tr><tr><td>val_f1</td><td>0.66667</td></tr><tr><td>val_loss_epoch</td><td>0.58742</td></tr><tr><td>val_loss_step</td><td>0.61203</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/n0vzcoaq' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/n0vzcoaq</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_054120-n0vzcoaq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_055251-j3c57a1b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/j3c57a1b' target=\"_blank\">GINConv_2_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/j3c57a1b' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/j3c57a1b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_16_onehot_4\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.1 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▆▇█▇▇█▇▇▇▇▇▇▇▇█▇▇████</td></tr><tr><td>train_auc</td><td>▁▃▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇█▇██▇█▇██████▇</td></tr><tr><td>train_f1</td><td>▁▂▅▆▅▆▇▆▆▆▇▆▇▇▇▇▇▇▇▆▇█▇▇▇▆▇▇▇▇▆▇▇█▇▇███▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▄▃▃▄▃▃▃▃▃▂▃▂▂▂▃▂▁▂▂▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂</td></tr><tr><td>train_loss_step</td><td>█▆▅▄▃▃▂▃▃▄▂▃▅▄▃▃▄▃▃▄▂▂▄▂▅▅▃▃▂▂▁▃▂▅▃▂▁▂▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▂▃▃▅▇▆▆▇▆▇▇▆▇▇▇▆▇▇▅▇▇▇▇▇▁▆▇▇▇▇▆▇▇▇▇▇▆▇██</td></tr><tr><td>val_auc</td><td>▁▃▃▅▅▆▆▆▇▇▇▇▇▇▇▇█▆▇▇▇▇▇█▆▇██▇█▇█████▇███</td></tr><tr><td>val_f1</td><td>▁▃▃▅▇▇▇▇▇█▇▇▇█▇▇█▇▅▇█▇▇▇▇▆▇██▇▇▇█▇▇▇▇███</td></tr><tr><td>val_loss_epoch</td><td>▅▄▆▄▃▃▂▂▃▂▃▃▃▃▂▃▃▂▇▃▄▃▃▂█▇▂▂▂▂▃▁▃▂▁▃▁▂▂▃</td></tr><tr><td>val_loss_step</td><td>▆▅▄▅▄▄▄▄▃▃▂▄▂▁▃▂▂▃▅▁▂█▄▄▂▃▃▂▁▄▂▃▃▂▂▂▄▃▁▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77717</td></tr><tr><td>train_auc</td><td>0.82433</td></tr><tr><td>train_f1</td><td>0.68878</td></tr><tr><td>train_loss_epoch</td><td>0.50449</td></tr><tr><td>train_loss_step</td><td>0.49884</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.76557</td></tr><tr><td>val_auc</td><td>0.81084</td></tr><tr><td>val_f1</td><td>0.73554</td></tr><tr><td>val_loss_epoch</td><td>0.57261</td></tr><tr><td>val_loss_step</td><td>0.6697</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/j3c57a1b' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/j3c57a1b</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_055251-j3c57a1b\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_060356-ie4k577f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ie4k577f' target=\"_blank\">GINConv_2_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ie4k577f' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ie4k577f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_16_onehot_4\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.1 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "1.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.5 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▇▇▇▇▇▇▆▇▇▇▇▇▇▇█████▇████████▇▇████▇</td></tr><tr><td>train_auc</td><td>▁▄▅▆▆▇▆▇▇▆▇▆▇▇▇▇▇▇▇▇▇██▇▇▇█▇▇███████████</td></tr><tr><td>train_f1</td><td>▁▄▆▆▆▇▆▇▇▇▇▆█▇▇▇▇▇▇▇███▇▇████████▇████▇█</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▃▃▃▃▃▂▃▃▃▄▃▂▂▂▁▂▂▁▂▂▂▂▃▂▁▁▂▂▂▂▂▂▁▂▂</td></tr><tr><td>train_loss_step</td><td>██▆▄▅▇▅▄▅▆▅▄▅▆▄▄▄▃▃▃▅▂▅▅▄▅▂▆▂▂▅▅▃▁▂▁▁▄▂▇</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▄▃▆▆▆▆▇▆▆▆▆▆▇▆▆▇▇▆▇▇▇▆▇▇▇▇▇▆▇▇▇▇▇█▇▄█▄▇</td></tr><tr><td>val_auc</td><td>▁▃▄▅▅▆▆▅▆▆▆▅▇▇▆▇▇▇▇▆▆▇▆▇▆▇▇▇▆▇█▇▇▇█▇▇█▆▇</td></tr><tr><td>val_f1</td><td>▁▅▄▆▇▇▇█▆▇█▇▇█▇▇██▇▇██▇▇▇▇███▇▇▇▇██▇██▅▇</td></tr><tr><td>val_loss_epoch</td><td>█▅█▆▄▃▂▂▄▂▄▄▄▃▂▂▃▃▁▂▁▃▃▃▂▅▁▂▂▄▅▃▃▁▁▃▇▃█▃</td></tr><tr><td>val_loss_step</td><td>▅▃█▄▃▂▃▄▅▂▃▂▂▃▃▃▃▁▃▃▂▃▃▁▃▄▃▄▃▃▅▃▄▅▂▂▁▄▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.76073</td></tr><tr><td>train_auc</td><td>0.81548</td></tr><tr><td>train_f1</td><td>0.68357</td></tr><tr><td>train_loss_epoch</td><td>0.52361</td></tr><tr><td>train_loss_step</td><td>0.61463</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.71795</td></tr><tr><td>val_auc</td><td>0.7994</td></tr><tr><td>val_f1</td><td>0.64516</td></tr><tr><td>val_loss_epoch</td><td>0.54688</td></tr><tr><td>val_loss_step</td><td>0.57121</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ie4k577f' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ie4k577f</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_060356-ie4k577f\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "547523d65faf413caeb1b4233e70c4f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01691666666592937, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_061516-bxbts4dg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/bxbts4dg' target=\"_blank\">GINConv_2_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/bxbts4dg' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/bxbts4dg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_32_onehot_4\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 3.7 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "4.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.2 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇████▇▇█▇███▇██</td></tr><tr><td>train_auc</td><td>▁▅▅▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇▇▇▇█████▇█████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▆▇▇▇▇▇▇▇█▇▇██▇████▇▇█▇██▇▇██</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▅▄▄▃▄▄▃▃▃▃▃▃▃▂▃▃▂▂▃▂▂▂▂▂▂▁▂▃▂▂▂▂▁▁▂▂▂</td></tr><tr><td>train_loss_step</td><td>█▆██▄▄▆▅▃▄▃▂▆▄▅▃▄▁▄▄▄▅▂▄▄▅▃▂▁▃▂▁▃▂▂▁▅▁▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▂▄▅▆▇█▇▆█▇▇▇▇▇▇█▇▇█▅▁▇▇▅▇▇▄▃▃█▁▃▇▅▅▇▁▂▇█</td></tr><tr><td>val_auc</td><td>▁▃▄▅▅▆▆▆▆▇▇▆▆▆▇▆▇▇▇▇▆▆█▇▇▇▆▆▇█▆▆▇▆▇█▆▄▇█</td></tr><tr><td>val_f1</td><td>▁▄▄▇█████▇██▇▇▇██▇██▇▇▇██▇████▇█▇█████▇█</td></tr><tr><td>val_loss_epoch</td><td>▄▄▃▃▃▃▁▂▂▃▂▂▂▁▂▃▁▂▂▃▆▃▂▄▁▃▃▆▄▂▆▅▂▃▃▂▇█▂▂</td></tr><tr><td>val_loss_step</td><td>▅█▅▃▃▂▄▃▃▃▂▄▃▂▁▂▃▃▂▄▂▂▃▂▃▃▃▄▄▄▃▂▂▅▂█▂▃▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.79817</td></tr><tr><td>train_auc</td><td>0.84769</td></tr><tr><td>train_f1</td><td>0.74031</td></tr><tr><td>train_loss_epoch</td><td>0.47261</td></tr><tr><td>train_loss_step</td><td>0.41832</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.72894</td></tr><tr><td>val_auc</td><td>0.79962</td></tr><tr><td>val_f1</td><td>0.69421</td></tr><tr><td>val_loss_epoch</td><td>0.53536</td></tr><tr><td>val_loss_step</td><td>0.50525</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/bxbts4dg' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/bxbts4dg</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_061516-bxbts4dg\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_062633-696nh24u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/696nh24u' target=\"_blank\">GINConv_2_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/696nh24u' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/696nh24u</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_32_onehot_4\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 3.7 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "4.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.2 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇█▇█▇█</td></tr><tr><td>train_auc</td><td>▁▃▃▄▄▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇████▇█</td></tr><tr><td>train_f1</td><td>▁▁▄▅▆▆▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇█▇█▇███</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▃▂▂▂▂▂▂▂▂▃▂▂▁▂▂▂▂▁▁▂▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▇█▇▅▆▅▅▃▆▄▃▆▃▅▄▅▃▆▅▄▅▂▄▅▄▃▃▃▃▄▃▅▄▃▂▅▄▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▆▅█▇▆▆▆▆▇▆▅▅▇▇▇▆▇▅▇█▅▇▇▅▇▇▇▇▇▆▇▆▇▇▇█▇▇▇</td></tr><tr><td>val_auc</td><td>▁▅▆▆▇▇█▇▇▇█▇▇▇▇█▇█▇▇▇▇▇▇▇▇█▇▇██▇▇▇▇██▇▇▇</td></tr><tr><td>val_f1</td><td>▇▃▁█▇▄███▇█▇▇▇▇██▇▇▇▇█▇▇▇▆▆█▇▇█▇▆▆▇▇█▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▆▅▆▄▅▅▄▃▄▃▇▄▃▃▅▃▂▅▄▂█▅▄▄▄▁▄▃▄▆▄▂▄▅▃▆▆▁▃</td></tr><tr><td>val_loss_step</td><td>▇▆▄▅▄▃▄▂▅▁▄▅▅▁▁▁▅▃▅▃▃▁▂▄▃▇▂▃▇▇█▁▃▂▂▆▃▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77717</td></tr><tr><td>train_auc</td><td>0.83448</td></tr><tr><td>train_f1</td><td>0.70673</td></tr><tr><td>train_loss_epoch</td><td>0.48259</td></tr><tr><td>train_loss_step</td><td>0.41251</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.69231</td></tr><tr><td>val_auc</td><td>0.77544</td></tr><tr><td>val_f1</td><td>0.65289</td></tr><tr><td>val_loss_epoch</td><td>0.56203</td></tr><tr><td>val_loss_step</td><td>0.55381</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/696nh24u' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/696nh24u</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_062633-696nh24u\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_063747-uv0a23qc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/uv0a23qc' target=\"_blank\">GINConv_2_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/uv0a23qc' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/uv0a23qc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_32_onehot_4\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 3.7 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "4.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.2 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▃▅▅▅▆▆▆▆▇▆▇▇▇▇▆▇▇▇█▇▇▇▇█▇▇▇▇▇█▇▇████▇█</td></tr><tr><td>train_auc</td><td>▃▃▁▂▃▄▄▄▅▆▅▅▆▆▆▆▆▅▆▆▆▆▇▇▇▇▇▇▇▇▇█▇█████▇█</td></tr><tr><td>train_f1</td><td>▁▂▄▆▅▆▇▆▆▆▇▆▆█▇▇▆▇▇▇█▇▇▇▇▇█▇██▇█████▇███</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▇▇▇▇▇▇▇▆▇▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇</td></tr><tr><td>val_auc</td><td>▇▅▁▃▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇████▇██████▇████</td></tr><tr><td>val_f1</td><td>▁▄▇▇▇▇▇██▇▇▇▇█▇▇█▇▇▇█▇██▇▇▇███▇█▇▇▇██▇██</td></tr><tr><td>val_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.73973</td></tr><tr><td>train_auc</td><td>0.7641</td></tr><tr><td>train_f1</td><td>0.67052</td></tr><tr><td>train_loss_epoch</td><td>0.54367</td></tr><tr><td>train_loss_step</td><td>0.48208</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.72527</td></tr><tr><td>val_auc</td><td>0.78559</td></tr><tr><td>val_f1</td><td>0.66667</td></tr><tr><td>val_loss_epoch</td><td>0.559</td></tr><tr><td>val_loss_step</td><td>0.54805</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/uv0a23qc' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/uv0a23qc</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_063747-uv0a23qc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_065028-dmexj22s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/dmexj22s' target=\"_blank\">GINConv_2_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/dmexj22s' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/dmexj22s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_32_onehot_4\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 3.7 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "4.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.3 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▇▇▆▇▇▇█▇▇▇▇▇▇▇█▇█▇▇▇▇███████████▇██</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▇▆▆▆▇▇▇▇▇▇▇▇▇█▇██▇█▇▇███████████▇██</td></tr><tr><td>train_f1</td><td>▁▅▆▆▅▇▇▆▇▇▇█▇▆▇▇▇▇▇█▇▇▇▇▇▇███████▇▇██▇██</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▃▄▃▄▃▃▃▃▃▃▃▂▃▂▂▃▂▂▂▂▃▂▂▂▂▂▂▂▂▂▂▁▂▁▂</td></tr><tr><td>train_loss_step</td><td>█▆▄▆▄▄▅▅▄▄▅▃▄▃▄▄▅▅▂▃▄▄▃▃▅▃▃▁▄▄▃▄▃▃▃▃▆▃▁▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▁▄▇▇▇█▆▇▇▇▇▇▇▇▆▇▇▇▇▇▆▇▇▆▆▇▇▇▆▇█▃▃▆█▇█▇▇</td></tr><tr><td>val_auc</td><td>▁▃▄▄▅▆▆▇▇▇▇▆▆▇▇▇▇▇▇▇▇▆██▇▇▆▇▇▇█▇▇▇▇███▇█</td></tr><tr><td>val_f1</td><td>▁▁▅▇▇▇▇█▆█▇▇▇████▆▆▇▇▇▇██▆█▇▇▆▇▇██▇████▇</td></tr><tr><td>val_loss_epoch</td><td>▄█▃▃▂▃▃▄▂▂▂▃▃▂▂▂▄▄▄▂▃▂▂▅▂▃▃▁▃▃▁▂▄▅▂▂▄▂▂▂</td></tr><tr><td>val_loss_step</td><td>▄█▄▃▃▂▂▃▃▂▁▃▃▂▄▂▃▃▃▃▅▂▂▂▂▃▄▂▃▂▆▃▁▂▅▃▂▃▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.79087</td></tr><tr><td>train_auc</td><td>0.84128</td></tr><tr><td>train_f1</td><td>0.72175</td></tr><tr><td>train_loss_epoch</td><td>0.46681</td></tr><tr><td>train_loss_step</td><td>0.44526</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.7326</td></tr><tr><td>val_auc</td><td>0.80381</td></tr><tr><td>val_f1</td><td>0.66047</td></tr><tr><td>val_loss_epoch</td><td>0.52554</td></tr><tr><td>val_loss_step</td><td>0.50751</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/dmexj22s' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/dmexj22s</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_065028-dmexj22s\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_070347-tz2105vy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/tz2105vy' target=\"_blank\">GINConv_2_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/tz2105vy' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/tz2105vy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_32_onehot_4\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 3.7 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "5.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.3 K     Total params\n",
      "0.021     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇▇▇█▇▇██▇▇</td></tr><tr><td>train_auc</td><td>▁▅▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇█▇█▇█▇▇███▇▇▇█▇▇█▇█████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇██▇▇▇▇██▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▄▄▄▃▃▃▃▃▃▃▂▃▃▂▂▃▂▂▂▃▂▂▂▂▃▂▂▂▂▂▂▃▂▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▇▄▆▃▆▂▅▆▄▆▅▅▂▃▁▃▅▃▅▃▂▃▂▃▃▄▃▂▅▂▆▄▆▅▅▄▂▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▃▃▄▇▇▇▆▇██▇▇▇▇▁▇▆▇▆▇█▇▇▇▃▇█▇▇▇█▆▇▇▇▇█▃▇█</td></tr><tr><td>val_auc</td><td>▁▃▄▅▅▆▆▆▅▇▆▇▇▇▇▇▇▇▇▇▇▆▇▆▇▅▇█▇▇▆█▇█▇▇▇▅▆▇</td></tr><tr><td>val_f1</td><td>▁▁▃▇█▆█████▆██▇▆▅▇█▇▇▇▆██▇█▆█▇▇▅▇▇▆▆███▇</td></tr><tr><td>val_loss_epoch</td><td>▃█▃▂▂▂▃▂▂▁▂▂▁▂▅▅▅▂▃▁▂▂▃▂▄▂▂▂▁▁▂▅▃▁▄▇▁▃▂▄</td></tr><tr><td>val_loss_step</td><td>▄█▄▂▂▂▃▂▂▂▂▂▂▂▄▃▅▂▃▂▃▂▂▂▅▄▃▂▂▁▇▂▂▃▂▆▄▅▁▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.78174</td></tr><tr><td>train_auc</td><td>0.8554</td></tr><tr><td>train_f1</td><td>0.71309</td></tr><tr><td>train_loss_epoch</td><td>0.46047</td></tr><tr><td>train_loss_step</td><td>0.4166</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.72894</td></tr><tr><td>val_auc</td><td>0.79417</td></tr><tr><td>val_f1</td><td>0.61856</td></tr><tr><td>val_loss_epoch</td><td>0.65328</td></tr><tr><td>val_loss_step</td><td>0.78348</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/tz2105vy' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/tz2105vy</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_070347-tz2105vy\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac7bd5b8b0e9462897562a7094d4ac41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_071725-jpikh7ai</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/jpikh7ai' target=\"_blank\">GINConv_2_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/jpikh7ai' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/jpikh7ai</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_64_onehot_4\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 13.5 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.7 K    Total params\n",
      "0.063     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▆▆▅▆▆▆▅▆▆▆▇▆▆▇█▇▇▆▇█▇█▆▇▇████▇▇▇██▇</td></tr><tr><td>train_auc</td><td>▁▅▅▆▆▆▆▇▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇█████▇███</td></tr><tr><td>train_f1</td><td>▁▅▅▇▇▆▇▆▇▇▇▆▇▇▇▇▇▇▇█▇▇▇▇█▇█▇▇▇▇█▇█▇▇▇███</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▄▄▄▃▄▄▄▃▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▁▂▃▂▁▂▂▁▂▂▁▁</td></tr><tr><td>train_loss_step</td><td>█▆▆████▇▅▅▄▅▄▄▆▃▃▃▃▄▆▁▆▄▃▂▄▄▃▆▃▃▃▅▃▃▆▃▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▄▄▇███▆▅▅▆██▅▃▃▆██▆█▇█▇█▂▁▇▇▆▃▇▇▂▄▇▃▇▇▃▁</td></tr><tr><td>val_auc</td><td>▃▅▆▇▇▇██▇▇█▇▆▆▅▇█▇▇█▇▇██▆▃▆▇▇▅█▇▅▇▇▅▇▆▄▁</td></tr><tr><td>val_f1</td><td>▁▁▇██████████▇▇████▇██▇█▇▇█▆▅▇██▇█▆▇██▇▇</td></tr><tr><td>val_loss_epoch</td><td>▃▄▂▁▁▂▂▂▂▂▁▂▂▃▅▂▂▁▂▁▂▁▁▂▄█▂▂▅▄▁▂▇▄▂▄▂▂▅▇</td></tr><tr><td>val_loss_step</td><td>▄▅▂▂▂▂▃▃▃▃▂▂▃▄▇▂▂▁▃▂▂▄▂▂▃▄▃▇▂▅▅▂▂▂▂▃▄▃▂█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.79361</td></tr><tr><td>train_auc</td><td>0.87332</td></tr><tr><td>train_f1</td><td>0.73903</td></tr><tr><td>train_loss_epoch</td><td>0.43436</td></tr><tr><td>train_loss_step</td><td>0.45455</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.45421</td></tr><tr><td>val_auc</td><td>0.70354</td></tr><tr><td>val_f1</td><td>0.61697</td></tr><tr><td>val_loss_epoch</td><td>1.21587</td></tr><tr><td>val_loss_step</td><td>1.07028</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/jpikh7ai' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/jpikh7ai</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_071725-jpikh7ai\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_073057-bxhb5199</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/bxhb5199' target=\"_blank\">GINConv_2_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/bxhb5199' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/bxhb5199</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_64_onehot_4\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 13.5 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.7 K    Total params\n",
      "0.063     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▄▅▅▆▅▅▆▆▆▆▆▆▆▇▇▇▆▆▇▇▇▇▇▇▇▇█▇▇▇█▇▇████▇</td></tr><tr><td>train_auc</td><td>▁▃▄▅▅▆▆▅▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇██▇█████</td></tr><tr><td>train_f1</td><td>▃▁▄▆▆▆▆▆▇▇▇▆▇▇▇▇█▇▇▇▇▇▇▇▇▇███▇▇▇██▇████▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▄▄▅▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▇▆▇▅▆▅▆▆▄▄▆▃▃▅▃▃▂▃▅▆▁▅▄▂▂▄▃▃▅▂▂▃▄▂▄▃▁▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▂▃▇▅▁▇▇▇▇▆▆▇▇▇▇▆█▇▇▇▇█▇▇█▇▇▆▆▆▇▇▆▆▆▆▆▇▆▆</td></tr><tr><td>val_auc</td><td>▁▃▅▆▆▇█▇▇█▆▇▇█▇▇██▇█▇▇▇███▇▇▇▆▇▇▇▇▇▆▆▇▇▇</td></tr><tr><td>val_f1</td><td>▁▃▇▆▇▇▇▇▇█▇▇▇██▆██▇█▇█▇███▇▇▆▇▇▇██▇▇▆▇▆▇</td></tr><tr><td>val_loss_epoch</td><td>▆▆▄▄█▃▄▃▃▃▂▃▃▂▄▃▂▂▂▂▂▂▃▃▃▂▃▃▄▄▁▄▄▃▂▃▄▃▅▃</td></tr><tr><td>val_loss_step</td><td>▇▆▄▄▆▃▃▄▃▅▄▄▃▃▆▃▄▁▃▆▄▄▄▃▃▄▃▅▃▃▄▄█▅▅▃▃▄▇▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.7863</td></tr><tr><td>train_auc</td><td>0.85475</td></tr><tr><td>train_f1</td><td>0.71182</td></tr><tr><td>train_loss_epoch</td><td>0.46007</td></tr><tr><td>train_loss_step</td><td>0.42713</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.68498</td></tr><tr><td>val_auc</td><td>0.77097</td></tr><tr><td>val_f1</td><td>0.65041</td></tr><tr><td>val_loss_epoch</td><td>0.58837</td></tr><tr><td>val_loss_step</td><td>0.63348</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/bxhb5199' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/bxhb5199</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_073057-bxhb5199\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10ea4dc3fd63443c92af190d606f4e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_074435-v63n63qc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/v63n63qc' target=\"_blank\">GINConv_2_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/v63n63qc' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/v63n63qc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_64_onehot_4\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 13.5 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "15.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.7 K    Total params\n",
      "0.063     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▃▁▄▃▅▅▄▅▆▅▆▅▅▆▆▆▇▆▇▆▆▇▇▅▇▇█▇▇▆▇▇█▇█▇█▇</td></tr><tr><td>train_auc</td><td>▁▂▂▂▅▃▆▄▄▃▄▅▆▇▆▅▆▆▆▇▆█▆██▇▇██▇▅▆▅▅▆▄▂▄▆▆</td></tr><tr><td>train_f1</td><td>▁▂▂▂▃▃▅▅▄▄▅▄▆▄▅▅▆▆▇▆▆▆▇▆▇▅█▆▇▆▇▆▆▇▇▇█▇█▇</td></tr><tr><td>train_loss_epoch</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▂▂▁▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▅▁▃▄▄▅▆▆▄▅▆▅▆▇▅▆▆▇▇▄▆▆▅▇▇▆▆▆▆▇█▆▇█▇▇█▇▇</td></tr><tr><td>val_auc</td><td>▆▆▁▅▅▅▆▆▅▆▆▆▇▇▇▇▇▇▇▇▇▇█▆▆▇█▇▇██▇▆▆█▆▆▆██</td></tr><tr><td>val_f1</td><td>▁▆▁▅▅▆▇▆▇▇▇▇▇▆█▇█▇▇█▅▇▇██▇▆██████▇████▇█</td></tr><tr><td>val_loss_epoch</td><td>█▃▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.72603</td></tr><tr><td>train_auc</td><td>0.67147</td></tr><tr><td>train_f1</td><td>0.65197</td></tr><tr><td>train_loss_epoch</td><td>0.55879</td></tr><tr><td>train_loss_step</td><td>0.5766</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.7326</td></tr><tr><td>val_auc</td><td>0.78606</td></tr><tr><td>val_f1</td><td>0.68936</td></tr><tr><td>val_loss_epoch</td><td>0.56016</td></tr><tr><td>val_loss_step</td><td>0.53305</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/v63n63qc' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/v63n63qc</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_074435-v63n63qc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_075729-freml9sm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/freml9sm' target=\"_blank\">GINConv_2_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/freml9sm' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/freml9sm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_64_onehot_4\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 13.5 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "15.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.7 K    Total params\n",
      "0.063     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca43bbb4b5a94e74a719283e13e0a451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▆▆▆▆▇▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇██▇▆█</td></tr><tr><td>train_auc</td><td>▁▄▅▅▆▆▆▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇████▇███▇▇█</td></tr><tr><td>train_f1</td><td>▁▅▆▆▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇█▇▇█▇▇██▇██▇███▇██▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▄▄▄▄▃▄▄▄▃▃▃▃▂▃▂▃▃▃▂▂▂▂▂▂▁▂▁▂▂▂▁▂▂▃▁</td></tr><tr><td>train_loss_step</td><td>█▇▆▆█▅▅▇▅▆▄▇▆▆▇▅▄▆▄▅▇▅▅▅▃█▃▅▃▂▄▄▄▄▅▃▃▅▆▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▄▅▅█▇▇█▇▇▇▇▆█▇▄▇▇▇█▆▆▆▇▆▇▇▇█▇█▄▁▆▆█▇█▄▃</td></tr><tr><td>val_auc</td><td>▁▃▅▆▇█▇▇▇▇▆█▇█▇▇█▇▇▇▇▆█▇█▇▇▆▆▇▆▆▆▇▇▆█▇▅▆</td></tr><tr><td>val_f1</td><td>▁▅▆▇██▇▇▇▇▇▇██▇██▇▇█▇█▆██▇█▇█▇██▇▇▆▇▇█▅█</td></tr><tr><td>val_loss_epoch</td><td>▄▂▃▂▂▁▂▂▃▂▂▁▁▁▁▃▂▃▅▃▁▃▃▂▂▂▂▂▂▂▃▃█▂▄▃▃▂▇▄</td></tr><tr><td>val_loss_step</td><td>▅▄▄▃▂▄▂▁▂▁▂▃▄▃▃▅▂▃▄▂▃▁▁▃▃▄▅▆▄▅▅▄▂▃▄█▃▇▄▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.81553</td></tr><tr><td>train_auc</td><td>0.87979</td></tr><tr><td>train_f1</td><td>0.76782</td></tr><tr><td>train_loss_epoch</td><td>0.42315</td></tr><tr><td>train_loss_step</td><td>0.29972</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.64103</td></tr><tr><td>val_auc</td><td>0.78856</td></tr><tr><td>val_f1</td><td>0.68987</td></tr><tr><td>val_loss_epoch</td><td>0.70157</td></tr><tr><td>val_loss_step</td><td>0.68772</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/freml9sm' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/freml9sm</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_075729-freml9sm\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63f8ec1a3ff245bb8872050894065fe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_081013-2cdwgexx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/2cdwgexx' target=\"_blank\">GINConv_2_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/2cdwgexx' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/2cdwgexx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_2_64_onehot_4\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 13.5 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "19.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "19.8 K    Total params\n",
      "0.079     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dccbbdb98234ef6a792d4244b7f6b30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▅▅▅▅▅▆▅▅▆▆▆▅▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▆▇▆▇█▇▇▇</td></tr><tr><td>train_auc</td><td>▁▄▄▅▅▅▅▆▆▆▅▆▇▆▆▆▆▇▇▇▇▇▇▇▇█▇█▇▇▇█▇▇▆▇██▇▇</td></tr><tr><td>train_f1</td><td>▁▄▅▆▆▆▆▆▇▆▆▇▇▆▆▇▆▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▆▇█▇█▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▄▅▄▄▃▄▃▃▃▃▃▃▂▃▃▃▂▂▂▂▂▂▁▂▂▂▁▃▃▃▂▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▇▇▅▅█▇▆█▅▆▆▅▅▆▄▄▄▅▃▄▃▄▃▂▄▃▅▄▄▂▁▅▃▅▄▆▃▅▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▃▆▇▇▆▇▇▇▅█▇▆▄██▇█▂▇▇▆▅█▇▅▇▇▁▇▅▇▇▇▇▇▂▇▇▇▇</td></tr><tr><td>val_auc</td><td>▁▄▄▄▃▅▆▅▅▇▆▇▆▇▆▇█▆▆▇▇▇▇▅▇▅█▅▄▅▆▇▆▅▆▄▅▅▄▅</td></tr><tr><td>val_f1</td><td>▁▆▇█▇████▇▆████▇█▇▇▇███▇█▇▆▇▇█▇▇▇██▇▇█▇█</td></tr><tr><td>val_loss_epoch</td><td>▃▂▁▂▂▁▁▁▂▁▂▁▃▂▁▂▁▄▂▁▁▂▂▁▂▁▂█▁▂▁▁▁▂▂▄▂▁▃▁</td></tr><tr><td>val_loss_step</td><td>▅▃▂▂▃▂▃▃▅▂▃▃▆▂▂▄▂▇▄▃▂▃▄▃▃█▃▃▂▆▆▃▃▄▃▅▃▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.78813</td></tr><tr><td>train_auc</td><td>0.86101</td></tr><tr><td>train_f1</td><td>0.70854</td></tr><tr><td>train_loss_epoch</td><td>0.45882</td></tr><tr><td>train_loss_step</td><td>0.42176</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.7033</td></tr><tr><td>val_auc</td><td>0.77288</td></tr><tr><td>val_f1</td><td>0.68966</td></tr><tr><td>val_loss_epoch</td><td>0.53624</td></tr><tr><td>val_loss_step</td><td>0.42943</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_2_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/2cdwgexx' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/2cdwgexx</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_081013-2cdwgexx\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_082151-scqjre7d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/scqjre7d' target=\"_blank\">GINConv_3_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/scqjre7d' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/scqjre7d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_16_onehot_4\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.7 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16d52586c702465b9f2c85971e500c9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▇▇▇▇▇▇▇▇▇█▇█▇████▇██▇▇█████▇█████████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇██▇███▇██▇██████</td></tr><tr><td>train_f1</td><td>▁▁▅▆▆▆▆▇▇▆▆▆▇▇▇▇▇▇▇▇▆▇▇▆▆█▇▇▇▇▇▇▇▇▇▇█▇██</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▃▃▂▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▂▂▁▂▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▇▅▅▆▇▄▄▃▃▄▄▃▄▃▅▃▄▄▅▃▃▅▃▃▄▃▅▄▃▅▄▃▄▅▅▅▃▁▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▁▆▆▆▆▆▆▆▇▇▇▆█▆▇█▇▇▇██▆▇▆█▇▆█▇▆█▇▆▆▇▇██</td></tr><tr><td>val_auc</td><td>▁▃▅▅▅▆▆▆▆▆█▇▇▇█▇▇█▇▇▇██████▇▇▇▇▇▇█▇▇█▇██</td></tr><tr><td>val_f1</td><td>▁▂▁▆▆▆▆▆▆▆▇▆▇▇▇▇▇█▇▇▇▇▇▆▇▆▇▇▆▇▇▆▇▇▅▆█▇█▇</td></tr><tr><td>val_loss_epoch</td><td>▆▅█▃▄▅▅▃▄▄▂▂▂▄▁▂▃▄▃▃▂▃▂▄▂▃▃▂▃▂▂▄▃▂▅▃▃▃▂▃</td></tr><tr><td>val_loss_step</td><td>▅▅▇▄▂▃▅▃▃▃▃▃▂▂▂▅▂▂▄▃▁▃▂▃▃▂▃▄▃▃▃▃▃█▂▂▁▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.78721</td></tr><tr><td>train_auc</td><td>0.85751</td></tr><tr><td>train_f1</td><td>0.71199</td></tr><tr><td>train_loss_epoch</td><td>0.46804</td></tr><tr><td>train_loss_step</td><td>0.52517</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.74359</td></tr><tr><td>val_auc</td><td>0.80975</td></tr><tr><td>val_f1</td><td>0.6729</td></tr><tr><td>val_loss_epoch</td><td>0.55574</td></tr><tr><td>val_loss_step</td><td>0.57338</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/scqjre7d' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/scqjre7d</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_082151-scqjre7d\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "790f42b79a4d42c39ec8cd83b0e5cfb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016933333332417533, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_083315-1mc62t8l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/1mc62t8l' target=\"_blank\">GINConv_3_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/1mc62t8l' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/1mc62t8l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_16_onehot_4\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.7 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0c4f8a072904d639a7a6ba9d368da40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▆▆▅▆▆▆▆▇▇▆▆▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇█▇▇█▇▇▇██▇█</td></tr><tr><td>train_auc</td><td>▁▂▂▅▅▄▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇██▇██▇█▇██▇█</td></tr><tr><td>train_f1</td><td>▂▁▂▅▄▄▅▆▅▄▆▆▅▄▆▇▇▇▆▆▆▆▆▅▅▇▇▇▇█▇▇█▇▇▇██▇█</td></tr><tr><td>train_loss_epoch</td><td>█▇▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▃▃▃▂▂▂▁▁▂▂▂▂▂▂▂▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▇▇▅▆▇▅▅▄▅▄▄▃▅▃▅▄▄▃▅▃▃▄▂▄▃▁▃▂▄▄▄▄▃▄▄▄▄▂▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▅▆▅▄▆▇▆▆▇▇▆█▇▇▆▇▇▆█▇▅▆▇▇▆▇▇▇█▇▆▅▅▆▅██▆</td></tr><tr><td>val_auc</td><td>▁▂▄▅▄▅▅▅▄▆▆▇▇▇▇▇▆▇▇▆▇▆▇▇▇█▇█▇▇▇▇▇▇█▇▇▇▇▇</td></tr><tr><td>val_f1</td><td>▆▁▇▇▅▇▆▆▇▇▇▇▇█▆▇▇▇▇▇█▇█▇█▇▇███▇▇▆█▇█▇▇█▇</td></tr><tr><td>val_loss_epoch</td><td>█▆▇▆▇▇▅▅▆▅▃▃▄▃▁▃▅▃▃▅▄▃▅▃▄▃▃▂▂▃▁▃▃▃▃▃▂▂▃▃</td></tr><tr><td>val_loss_step</td><td>▇▆▇▆▄▆▅▅▆▄▅▄▃▃▄▆▄▃▄▅▂▄▄▃▅▂▃▄▄█▂▂▄▃▃▄▁█▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.76712</td></tr><tr><td>train_auc</td><td>0.81835</td></tr><tr><td>train_f1</td><td>0.68712</td></tr><tr><td>train_loss_epoch</td><td>0.51565</td></tr><tr><td>train_loss_step</td><td>0.56406</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.7033</td></tr><tr><td>val_auc</td><td>0.80517</td></tr><tr><td>val_f1</td><td>0.69434</td></tr><tr><td>val_loss_epoch</td><td>0.57257</td></tr><tr><td>val_loss_step</td><td>0.62131</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/1mc62t8l' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/1mc62t8l</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_083315-1mc62t8l\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_084451-dkj7hyx1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/dkj7hyx1' target=\"_blank\">GINConv_3_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/dkj7hyx1' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/dkj7hyx1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_16_onehot_4\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 1.7 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "1.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.8 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▂▃▃▄▄▅▅▅▅▆▆▅▅▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇█▇▇▇█████</td></tr><tr><td>train_auc</td><td>▂▂▂▂▃▁▄▂▄▂▂▂▂▂▁▂▂▂▃▄▃▃▄▃▄▅▄▆▆▅▄▆▅▅▅▇▇▆▇█</td></tr><tr><td>train_f1</td><td>▁▂▄▅▃▃▂▃▃▃▂▄▄▃▃▄▆▆▆▆▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇████</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▄▅▅▅▄▅▄▅▄▅▅▅▅▅▆▅▅▆▆▆▇▇▆▇▇▆▇▇▆▇▆█▅▇▇▇█▆</td></tr><tr><td>val_auc</td><td>▃▃▁▁▁▂▂▂▂▃▃▄▄▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▆▇▇▆▇▇▇██</td></tr><tr><td>val_f1</td><td>▁▃▆▆▆▆▆▆▆▅▆▆▆▅▆▆▇▆▆▇▆▆▇▇▆███▇█▇█▇██▇█▇█▆</td></tr><tr><td>val_loss_epoch</td><td>█▄▂▃▄▄▃▃▄▃▃▂▃▃▂▂▃▃▂▃▂▄▂▃▃▂▃▂▂▁▁▃▃▃▂▂▂▃▂▅</td></tr><tr><td>val_loss_step</td><td>█▄▃▃▂▃▃▃▂▃▂▃▂▂▂▄▂▂▃▃▂▂▂▂▃▂▂▃▂▂▃▃▃▂▂▂▁▂▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.74429</td></tr><tr><td>train_auc</td><td>0.69304</td></tr><tr><td>train_f1</td><td>0.67593</td></tr><tr><td>train_loss_epoch</td><td>0.54839</td></tr><tr><td>train_loss_step</td><td>0.61084</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.69597</td></tr><tr><td>val_auc</td><td>0.78328</td></tr><tr><td>val_f1</td><td>0.52571</td></tr><tr><td>val_loss_epoch</td><td>0.71734</td></tr><tr><td>val_loss_step</td><td>0.63129</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/dkj7hyx1' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/dkj7hyx1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_084451-dkj7hyx1\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_085613-vo6wanwt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/vo6wanwt' target=\"_blank\">GINConv_3_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/vo6wanwt' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/vo6wanwt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_16_onehot_4\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.7 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "1.9 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 K     Total params\n",
      "0.007     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▇▇▆▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇████████▇██▇█▇▇▇▇</td></tr><tr><td>train_auc</td><td>▁▄▅▆▆▇▆▆▇▇▇▇▇▇▇▇▇█▇▇▇▇▇██▇█████▇██▇█▇███</td></tr><tr><td>train_f1</td><td>▁▁▃▅▅▆▄▅▅▆▆▆▅▅▆▅▇▇▆▆▅▆▅▇▇▇█▇▇▇█▆▇▇▆▇▇▇▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▃▄▄▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▁▂▁▁▂▁▁▂▁▁▂▁▂▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▇▇▄▄▃▆▅▅▅▅▄▃▃▃▄▄▄▄▅▄▄▄▄▂▃▃▅▂▄▁▂▂▄▃▃▆▄▅▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▃▅▆▆▄▆▆▆▅▇▇▇▆▆▇▇▇▆▇▇▇▇█▅█▇▇▇▇▇▆▆▇▇▆▅▇▇</td></tr><tr><td>val_auc</td><td>▁▄▅▆▅▆▇▆▇▇▇▇▇█▇▇▇▇▇▇█████▇██▇███▇▇██▇▇▇█</td></tr><tr><td>val_f1</td><td>▁▄▄▆▇▆▄▇▆▇▆▇▇▇▇▇█▇▇▇▇▇▇▇▇▆█▆▇▇█▇▇▆▇▇▆▆▇█</td></tr><tr><td>val_loss_epoch</td><td>▇▅▇▃▄▃▇▃▄▄▃▃▃▁▂▂▄▁▃▆▃▂▃▃▁█▂▂▃▂▂▁▇▂▄▂▃▆▂▃</td></tr><tr><td>val_loss_step</td><td>▆▆▇▃▃▄▅▃▃▄▂▃▁▂▁▅▃▂▃▃▂▁▃▂▅▃▄▄▃▂▂▂▄▄▄█▅▇▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77534</td></tr><tr><td>train_auc</td><td>0.85012</td></tr><tr><td>train_f1</td><td>0.69927</td></tr><tr><td>train_loss_epoch</td><td>0.47979</td></tr><tr><td>train_loss_step</td><td>0.48561</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.73993</td></tr><tr><td>val_auc</td><td>0.81307</td></tr><tr><td>val_f1</td><td>0.73408</td></tr><tr><td>val_loss_epoch</td><td>0.55772</td></tr><tr><td>val_loss_step</td><td>0.49694</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/vo6wanwt' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/vo6wanwt</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_085613-vo6wanwt\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_090737-lyzawl7h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/lyzawl7h' target=\"_blank\">GINConv_3_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/lyzawl7h' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/lyzawl7h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_16_onehot_4\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 1.7 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "2.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▇▇▇▇▇▇█▇▇▇▇▇███▇▇███████▇█▇██████████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇██▇▇█▇█████▇████████████</td></tr><tr><td>train_f1</td><td>▂▁▃▅▅▅▅▆▆▇▆▆▆▆▆▆█▇▆▆▇█▇██▇█▆▆▆▇▇▇▇▇▇█▇▆▇</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▃▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▁▂▁▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▇█▅▇▄▄▄▂▃▃▅▆▄▃▂▂▃▃▁▂▄▃▁▂▃▂▃▃▂▄▃▄▂▃▂▄▄▂▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▁▁▅▆▆▆▅█▇█▆▆▇▆▇▆█▇▇██▆█▇▇▅▆█▇█▇▁▇█▄█▇▆▆</td></tr><tr><td>val_auc</td><td>▁▃▄▅▅▆▇▆▆▇█▇▆▇▇▇▇██▇█▇█▇▇▇▇▇██▇▇█▇█▆▇▇▇▇</td></tr><tr><td>val_f1</td><td>▁▂▂▆▆▆▅▅█▇▇▆█▇▆▇███▇██▆▇█▇▄▆█▇▇▇▇█▇▄▇█▅▆</td></tr><tr><td>val_loss_epoch</td><td>▅▄▆▂▃▂█▄▃▂▃▁▄▁▅▃▃▃▂▁▂▃▂▃▁▂▄▅▂▂▃▂▅▂▁▅▅▂▆▅</td></tr><tr><td>val_loss_step</td><td>▅▄▅▃▄▃▅▄▃▃▄▂▅▃▃▂▁▁▂▂▂▂▃▁▃▃▄▂▂▂▃▁▂▅▄▂▃▂▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.79178</td></tr><tr><td>train_auc</td><td>0.85378</td></tr><tr><td>train_f1</td><td>0.71571</td></tr><tr><td>train_loss_epoch</td><td>0.48621</td></tr><tr><td>train_loss_step</td><td>0.56367</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.69963</td></tr><tr><td>val_auc</td><td>0.80082</td></tr><tr><td>val_f1</td><td>0.55435</td></tr><tr><td>val_loss_epoch</td><td>0.68117</td></tr><tr><td>val_loss_step</td><td>0.78039</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/lyzawl7h' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/lyzawl7h</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_090737-lyzawl7h\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_091927-o29sg95r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/o29sg95r' target=\"_blank\">GINConv_3_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/o29sg95r' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/o29sg95r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_32_onehot_4\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 5.9 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "6.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.5 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7351f3a5d6664f74a3b36863f20e187f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▆▆▆▆▆▆▆▇▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇███▇▇██▇▇██</td></tr><tr><td>train_auc</td><td>▁▅▅▅▆▆▆▆▆▆▆▆▆▇▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇██▇▇███████</td></tr><tr><td>train_f1</td><td>▁▆▆▆▆▆▆▆▇▇▆▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇███▇███</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▅▄▄▄▅▃▄▄▃▄▃▃▃▃▂▄▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>▇▆▆▅▄▅▅▆▆▅▅▄▆▆▅▄▄▆▄▅█▆▇▄▂▄▅▄▅▃▅▄▄▃▃▁▃▃▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▄▆▇▇▇▇▆▄▆▆▆▆▇▇▇▇▆▆▇▇▆█▇█▇▆▇▅▇▆▄▇▇▆▅▄▆▅▆</td></tr><tr><td>val_auc</td><td>▁▄▄▄▆▆▅▆▆▆▇▆▇▇▇▅▆▇▆█▇▇▇██▇▆▆▇▆▇▆▆▆▅▆▅▅▆▅</td></tr><tr><td>val_f1</td><td>▁▄▆▇▇▇▇▆█▇▇█▆▇▇█▇▆▆▇███▆▇▇▆▇▆██▅▇▇▆▆▅█▅█</td></tr><tr><td>val_loss_epoch</td><td>▃▅▂▁▂▂▂▁▃▃▁▂▃▂▂▁▂▃▂▂▃▂▂▃▂▃▄▂▃▃▂█▂▃▅▄█▃▅▃</td></tr><tr><td>val_loss_step</td><td>▄▃▂▂▁▃▂▃▃▂▃▂▂▂▂▃▂▂▃▂▃▂▆▃▂▃▁▆▃▃▂▃▂▃▂▃▄█▅▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.80822</td></tr><tr><td>train_auc</td><td>0.87277</td></tr><tr><td>train_f1</td><td>0.75638</td></tr><tr><td>train_loss_epoch</td><td>0.43796</td></tr><tr><td>train_loss_step</td><td>0.42308</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.68498</td></tr><tr><td>val_auc</td><td>0.7756</td></tr><tr><td>val_f1</td><td>0.69065</td></tr><tr><td>val_loss_epoch</td><td>0.67237</td></tr><tr><td>val_loss_step</td><td>0.81297</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/o29sg95r' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/o29sg95r</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_091927-o29sg95r\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_093159-l6imw1ko</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/l6imw1ko' target=\"_blank\">GINConv_3_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/l6imw1ko' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/l6imw1ko</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_32_onehot_4\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 5.9 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "6.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.5 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▄▅▅▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇███████</td></tr><tr><td>train_auc</td><td>▁▄▄▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████▇███████</td></tr><tr><td>train_f1</td><td>▁▃▄▅▆▆▅▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█▇█▇███</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▅▄▃▄▃▃▄▃▂▃▂▂▂▂▂▂▂▂▂▂▃▂▂▂▂▂▂▂▁▂▁▁▁▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>▇█▇▆▅▅▇▆▅▄▅▄▇▄▄▁▃▅▃▃█▄▅▄▃▃▃▄▄▃▆▄▅▄▁▂▄▃▁▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▄▆▇▆▇▇▇▇▇█▆▇▄▇▇█▅▇▅█▇▇█▆▆▆▇▇█▅▆▇▆▆█▄█▇</td></tr><tr><td>val_auc</td><td>▁▅▅▇▆▇██▇▇▇█▇▇▇███▇█▆▇▇██▇▆▆██▇▆▇▇▆▇█▆█▇</td></tr><tr><td>val_f1</td><td>▁▃▅▆▆▆▆██▇█▇████▇████▇▇▇▇█████▇████▇████</td></tr><tr><td>val_loss_epoch</td><td>▅▆▄▂▃▃▄▄▃▃▂▂▄▂▇▁▃▄▄▃█▂▄▅▂▃▄▃▃▅▃▄▃▃▆▃▃█▃▄</td></tr><tr><td>val_loss_step</td><td>▇▄▅▅▄▇▅▃▄▃▃▂▃▅▆▄▃▃█▃▄▄▅▅▃▅▆▁▇▇▄▄▃▃▄▅▄▂▆▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77078</td></tr><tr><td>train_auc</td><td>0.83719</td></tr><tr><td>train_f1</td><td>0.70083</td></tr><tr><td>train_loss_epoch</td><td>0.49345</td></tr><tr><td>train_loss_step</td><td>0.52843</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.69231</td></tr><tr><td>val_auc</td><td>0.76776</td></tr><tr><td>val_f1</td><td>0.67692</td></tr><tr><td>val_loss_epoch</td><td>0.60226</td></tr><tr><td>val_loss_step</td><td>0.58764</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/l6imw1ko' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/l6imw1ko</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_093159-l6imw1ko\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_094526-ffn13z6c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ffn13z6c' target=\"_blank\">GINConv_3_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ffn13z6c' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ffn13z6c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_32_onehot_4\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 5.9 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "6.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.5 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▃▁▃▄▅▅▆▆▆▆▆▆▆▅▇▆▆▇▆▇▇▆▇▇▆▇▆▇▇▇▆██▇▇█▇▇</td></tr><tr><td>train_auc</td><td>▄▂▅▁▃▂▃▂▃▃▅▄▄▆▅▅▇▄▄▅▅▆▆▅▄▄▄▆▆▄▄▆▅▄▆█▆▅▇▅</td></tr><tr><td>train_f1</td><td>▁▂▃▃▃▄▅▆▅▆▆▆▆▆▇▅▇▆▆▇▇█▇▇▆▇▆▇▆▇▇▆▆██▇▆█▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▄▆▆▇▇▇▇▇▇▆▇▆▆▇▆▇▆█▆▆▇▆▆▇▅▇▆▇█▆█▆▆▇▆▆▇▆▆</td></tr><tr><td>val_auc</td><td>▇▁▄▆▅▄▄▃▃▅▆▆▄▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇█▇▇██▇██▇▆█▇</td></tr><tr><td>val_f1</td><td>▁▄▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▆▇▇▇█▆█▇▆█▇▇█▇▆</td></tr><tr><td>val_loss_epoch</td><td>█▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.74977</td></tr><tr><td>train_auc</td><td>0.62417</td></tr><tr><td>train_f1</td><td>0.6865</td></tr><tr><td>train_loss_epoch</td><td>0.52286</td></tr><tr><td>train_loss_step</td><td>0.56139</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.7033</td></tr><tr><td>val_auc</td><td>0.77451</td></tr><tr><td>val_f1</td><td>0.56684</td></tr><tr><td>val_loss_epoch</td><td>0.6093</td></tr><tr><td>val_loss_step</td><td>0.58808</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ffn13z6c' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/ffn13z6c</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_094526-ffn13z6c\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_095938-clbivgnl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/clbivgnl' target=\"_blank\">GINConv_3_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/clbivgnl' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/clbivgnl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_32_onehot_4\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 5.9 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "6.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.5 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▆▆▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇██▆▇█▇█▇████████</td></tr><tr><td>train_auc</td><td>▁▅▅▆▆▆▆▆▇▆▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇█▇▇▇▇█▇████████</td></tr><tr><td>train_f1</td><td>▁▆▆▆▇▆▇▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇██▅▇█▇█▇▇███████</td></tr><tr><td>train_loss_epoch</td><td>█▅▅▅▅▄▄▄▃▃▃▃▃▃▃▄▃▃▃▂▂▃▃▂▂▁▃▂▂▂▂▂▁▂▁▂▁▁▂▁</td></tr><tr><td>train_loss_step</td><td>██▇▅▇▄█▄▄▆▇▄▄▄▄▄▆▄▃▂▃▅▃▅▃▁▅▄▃▅▆▄▄▃▃▃▆▃▁█</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▅▅▆▇▆▇▇█▅▇▅▆▇▇█▅▇▇▆█▇▇▇▆▇▇▆▆▄▇▇▅▆▅▇▆▅▆</td></tr><tr><td>val_auc</td><td>▁▃▃▅▆▇▇▆▆▇▇▆▇██▅▇▇▇▇▆█▇█▆▄▆█▅▇▇▇▇▆▅▇▇▆▄▆</td></tr><tr><td>val_f1</td><td>▁▃▆▅▆▇▆▇▇▇▅█▅█▇█▇█▇█▆█▇█▇▆█▇▆▆█▆█▅█▅▇▆▇▇</td></tr><tr><td>val_loss_epoch</td><td>▅▆▄▅▁▂▄▃▁▄▃▃▄▁▁▂▃▅▃▂█▂▁▂▂▄▂▂▂▄▆▇▄▇▃▄▄█▂▂</td></tr><tr><td>val_loss_step</td><td>▃▄▂▁▂▁▂▂▁▂▃▁▂▁▂▁▁▂▂▁▂▂▂▂▃▂▁▂▁▁▂▂█▂▂▃▂▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.81279</td></tr><tr><td>train_auc</td><td>0.88106</td></tr><tr><td>train_f1</td><td>0.75091</td></tr><tr><td>train_loss_epoch</td><td>0.43445</td></tr><tr><td>train_loss_step</td><td>0.59261</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.69963</td></tr><tr><td>val_auc</td><td>0.78617</td></tr><tr><td>val_f1</td><td>0.58163</td></tr><tr><td>val_loss_epoch</td><td>0.54863</td></tr><tr><td>val_loss_step</td><td>0.47973</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/clbivgnl' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/clbivgnl</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_095938-clbivgnl\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_101431-qyz7w5dp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qyz7w5dp' target=\"_blank\">GINConv_3_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qyz7w5dp' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qyz7w5dp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_32_onehot_4\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 5.9 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "7.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "7.6 K     Total params\n",
      "0.030     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c1d7dac587c4aa38284e5fe5efd10f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▆▅▆▆▇▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇██▇██▇███</td></tr><tr><td>train_auc</td><td>▁▄▆▆▆▆▆▆▇▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇█▇▇██▇█▇▇█████▇</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▆▆▇▇▇▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇██▇██▇█▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▅▄▄▃▃▄▃▄▃▄▃▃▂▂▃▃▂▂▃▂▂▂▂▁▁▂▂▂▂▂▁▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▆▅▆▅▆▄▆▃▅▃▆▄▆▆▃▅▂▃▄▃▅▂▄▄▆▃▄▁▄▂▁▃▄▅▄▃▄▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▃▆▆▇▆▇▇▇▇▇▆▇▇██▇▇▇▆▇█▇█▆▆▇▇▁▆▅▇▆▆▆▇▇▇▆▇▆</td></tr><tr><td>val_auc</td><td>▁▂▄▅▅▅▄▄▆▆▆▆▆▆▇▆▆▆▃▆▆▇▇▅█▆▅▃▆▄▆▆▅▂▃▃▅▄▄▄</td></tr><tr><td>val_f1</td><td>▁▆▆▇▅▇█▇█▇▆▇▇███▆▇█▇█▆█▇▆▇▇▇▅█▇▅█▆▇█▇▇▇▆</td></tr><tr><td>val_loss_epoch</td><td>▄▃▃▂▂▃▃▁▂▁▂▂▃▁▂▂▄▂▃▂▃▃▁▃▂▂▃▇▆▄▂█▂▄▁▃▁▂▂▂</td></tr><tr><td>val_loss_step</td><td>▄▃▄▂▃▃▃▄▃▃▄▂▄▃▂▃▅▂▃▃▄▂▂▆█▄▃▃▄▃▃▄▃▇▂▅▂▆▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8</td></tr><tr><td>train_auc</td><td>0.85734</td></tr><tr><td>train_f1</td><td>0.72031</td></tr><tr><td>train_loss_epoch</td><td>0.45605</td></tr><tr><td>train_loss_step</td><td>0.39799</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.69231</td></tr><tr><td>val_auc</td><td>0.7689</td></tr><tr><td>val_f1</td><td>0.55789</td></tr><tr><td>val_loss_epoch</td><td>0.55232</td></tr><tr><td>val_loss_step</td><td>0.43579</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qyz7w5dp' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qyz7w5dp</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_101431-qyz7w5dp\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_102852-5ipao5cj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/5ipao5cj' target=\"_blank\">GINConv_3_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/5ipao5cj' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/5ipao5cj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_64_onehot_4\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 22.1 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "24.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.2 K    Total params\n",
      "0.097     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4521a252a9714badba74e5d645c3df93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▅▅▅▆▅▆▆▆▆▅▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇█▇██▇</td></tr><tr><td>train_auc</td><td>▁▅▅▆▆▆▆▆▆▆▆▆▆▇▆▆▇▇▆▇▇▇▇▇▇▇▇▇██▇██▇▇█████</td></tr><tr><td>train_f1</td><td>▁▅▅▆▆▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇█▇▇█▇██▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▆▅▅▅▅▅▄▄▅▄▄▄▄▄▄▃▄▃▃▃▂▃▃▃▂▃▂▂▂▂▂▂▃▂▂▂▁▂</td></tr><tr><td>train_loss_step</td><td>█▆▆▆▅▅▅▆▆▆▄▇▆▇▇▄▅▄▆▄▅▂▅▅▄▃▅▇▅▃▃▄▁▇▃▂▂▅▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▆▇▇▇▃▇▃▆█▇█▇██▇▃▆▆▆▇▄█▇▇▆▅▄▅▇▇▇▆▇▆▆▅▇▇▇</td></tr><tr><td>val_auc</td><td>▁▆▆▇▇▆█▆▆█▆██▇██▄▆▇▅▇▆▆▅▇█▆▃▆▇▇▆▅▅▄▅▅▆▆▆</td></tr><tr><td>val_f1</td><td>▁▆▇█▆▃▇▇▆█▇▇▇▇▇▇▇▆█▆▇▇▇▇▇▇▇▄▇▆▇▆▇▆▆▇▇▆▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▂▁▂▂▆▂▄▃▂▂▂▂▂▁▂▃▃▂▂▂▂▂▁▁▂▄▅▃▄▁▃▂▄▄▂▂▅▃▃</td></tr><tr><td>val_loss_step</td><td>█▃▃▂▃▆▂▄▄▃▃▂▃▁▂▃▅▂▃▂▅▃▅▂▆▂▄▄▄█▂▇▂▄▆▄▃▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.82283</td></tr><tr><td>train_auc</td><td>0.89265</td></tr><tr><td>train_f1</td><td>0.76167</td></tr><tr><td>train_loss_epoch</td><td>0.39491</td></tr><tr><td>train_loss_step</td><td>0.34238</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.7033</td></tr><tr><td>val_auc</td><td>0.77745</td></tr><tr><td>val_f1</td><td>0.66667</td></tr><tr><td>val_loss_epoch</td><td>0.66977</td></tr><tr><td>val_loss_step</td><td>0.67521</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/5ipao5cj' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/5ipao5cj</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_102852-5ipao5cj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "271edcc65bca455ba27dbd5843ff0ce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_104257-bgxyegas</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/bgxyegas' target=\"_blank\">GINConv_3_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/bgxyegas' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/bgxyegas</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_64_onehot_4\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 22.1 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "24.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.2 K    Total params\n",
      "0.097     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▅▅▅▅▆▆▆▆▇▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇████▇▇▇█████</td></tr><tr><td>train_auc</td><td>▁▃▅▅▅▆▅▆▆▆▆▇▆▇▇▇▆▆▇▆▇▇▇▇▇▇▇▇▇█▇██▇▇█████</td></tr><tr><td>train_f1</td><td>▁▁▄▅▃▅▅▆▆▅▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇██▇▇▇▇█████</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▅▄▄▄▃▄▃▃▃▃▃▃▃▃▃▃▂▂▂▃▂▂▃▂▂▂▂▁▂▂▂▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▆▆▇▄▅▅▅▆▄▅▄▇▅▄▄▄▆▄▃▂▄▄▄▂▄▅▃▂▂▃▁▅▃▂▁▂▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▇▆▇▆▇▆▂█▂█▇▆▇▇▆▇▇▆▅▆▆▅▇▆▅▆▇▆▅▅▇▆▆▆▇▆▆▆</td></tr><tr><td>val_auc</td><td>▁▆▇▇▇▇▆▆▆█▇▇▇█▇▇▇▇█▇▇▇▆▆█▆▆▇▇▇▆▇▇▆▇▆▇▆▆▆</td></tr><tr><td>val_f1</td><td>▁▃▇▆▇▆▇██▇█▇███▇▇▇█▇█▇██▇▇██▇▇▇█▇▇▇█▇▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>▆▅▃▅▃▃▃▃▆▂█▃▃▂▄▃▁▃▃▂▆▁▅▃▁▃▇▅▃▃▃█▄▄▄▃▃▇▃▁</td></tr><tr><td>val_loss_step</td><td>▅▅▄▄▄▄▄▄▆▃▆▄▄▄▅▄▅▃▅▄▅▆▃▅▅▄▆▅▄▅█▆▆▆▅▄▆▄▆▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.80639</td></tr><tr><td>train_auc</td><td>0.85822</td></tr><tr><td>train_f1</td><td>0.74272</td></tr><tr><td>train_loss_epoch</td><td>0.4414</td></tr><tr><td>train_loss_step</td><td>0.45116</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.68498</td></tr><tr><td>val_auc</td><td>0.75719</td></tr><tr><td>val_f1</td><td>0.61947</td></tr><tr><td>val_loss_epoch</td><td>0.52844</td></tr><tr><td>val_loss_step</td><td>0.34663</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/bgxyegas' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/bgxyegas</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_104257-bgxyegas\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_105726-90zmzeas</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/90zmzeas' target=\"_blank\">GINConv_3_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/90zmzeas' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/90zmzeas</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_64_onehot_4\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 22.1 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "24.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.2 K    Total params\n",
      "0.097     Total estimated model params size (MB)\n",
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe2ed50d0294b14a8a6624e0582ae6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▃▄▄▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇█▇▇▇▇▇▇█▇████▇███▇▇</td></tr><tr><td>train_auc</td><td>█▇▆▅▄▅▅▅▄▄▃▃▃▃▃▄▃▃▃▃▃▃▃▂▂▂▃▂▂▂▂▂▂▁▂▁▁▂▂▂</td></tr><tr><td>train_f1</td><td>▂▁▄▃▄▄▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇█▇▇▇▇▇▇█▇████▇█▇█▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▄▅▃▅▇▇▆▆▆▆▆▆▇▇▇▇▇████▇██▅███▆▇▆▆▇▆▇▇▇▆</td></tr><tr><td>val_auc</td><td>▅█▆▅▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▂▂▂▂▂▁▂▁▂▂▂▂▁▁</td></tr><tr><td>val_f1</td><td>▁▃▆▆▄▆▇▇▆▇▇▇▇▇▇▇▇▇▇███▇▇█▇▅▇▇▇▆▇▇▆▇▆▇▇▇▆</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▆▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.7589</td></tr><tr><td>train_auc</td><td>0.24592</td></tr><tr><td>train_f1</td><td>0.69231</td></tr><tr><td>train_loss_epoch</td><td>0.51367</td></tr><tr><td>train_loss_step</td><td>0.48519</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.68864</td></tr><tr><td>val_auc</td><td>0.19355</td></tr><tr><td>val_f1</td><td>0.49704</td></tr><tr><td>val_loss_epoch</td><td>0.81403</td></tr><tr><td>val_loss_step</td><td>0.79505</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/90zmzeas' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/90zmzeas</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_105726-90zmzeas\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_111151-qyeyu04o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qyeyu04o' target=\"_blank\">GINConv_3_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qyeyu04o' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qyeyu04o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_64_onehot_4\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 22.1 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "24.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.3 K    Total params\n",
      "0.097     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▅▅▆▆▆▆▅▆▆▆▇▆▇▇▇▇▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇██▇</td></tr><tr><td>train_auc</td><td>▁▄▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▆▇▇▇▆▇▇▇▇▇▇▇█▇▇▇█████</td></tr><tr><td>train_f1</td><td>▁▅▄▆▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▄▄▄▄▄▃▃▄▃▃▃▃▃▃▄▂▂▂▃▂▂▂▂▂▂▂▂▃▃▂▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▇▇▄█▇▃▃▄▃▅▅▄▅▅▆▃▅▃▅▇▂▃▅▃▄▃▄▃▃▂▃▅▁▄▃▄▅▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▄▆▅▆▆▆▆▅▇▆▆▆▇▆█▆▂▆▇▆▆▇▆▆▄▇▆▆▆▇▇▇▇▆▇▆▇▆▅</td></tr><tr><td>val_auc</td><td>▁▅▆▇▇█▇█▇█▇████▇█▆█▇▇▇▇▇▇▅█▇█▆▆▇▆██▇▇▆▆▇</td></tr><tr><td>val_f1</td><td>▁▄▇▆▇█▇▆▆█▆▇██▆█▇█▆██▆█▇▇▅▇▆██▇▇█▇██▆█▇▆</td></tr><tr><td>val_loss_epoch</td><td>▆▄▃▅▃▃▄▃▇▃▅▃▃▃▅▃▃▅▂▂▄▅▃▃▂▆▁▅▂▂▃▁▃▃▄▂█▄▃▄</td></tr><tr><td>val_loss_step</td><td>█▅▃▄▃▃▁▄▄▂▄▃▃▂▃▂▅▅▃▃▄▅▂▅▃▂▃▅▃▃▄▄▃▂▂▃▆▃█▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.81461</td></tr><tr><td>train_auc</td><td>0.88399</td></tr><tr><td>train_f1</td><td>0.76747</td></tr><tr><td>train_loss_epoch</td><td>0.4229</td></tr><tr><td>train_loss_step</td><td>0.44021</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.68498</td></tr><tr><td>val_auc</td><td>0.79232</td></tr><tr><td>val_f1</td><td>0.51685</td></tr><tr><td>val_loss_epoch</td><td>0.65573</td></tr><tr><td>val_loss_step</td><td>0.62284</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qyeyu04o' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/qyeyu04o</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_111151-qyeyu04o\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_112605-vqs939qb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/vqs939qb' target=\"_blank\">GINConv_3_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/vqs939qb' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/vqs939qb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_3_64_onehot_4\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 22.1 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "28.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "28.4 K    Total params\n",
      "0.114     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▆▆▆▆▆▆▆▆▆▆▆▇▆▆▇▆▇▇▇▇▇▇▇▇▇█▇▇▇█▇█▇▇▇█</td></tr><tr><td>train_auc</td><td>▁▅▅▆▆▆▆▆▇▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇██▇██▇██</td></tr><tr><td>train_f1</td><td>▁▂▅▆▆▆▆▆▆▆▆▆▅▇▆▇▆▆▇▆▇▇▇▇▇▇▇▇▆███▇▇▇█▇▇▇█</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▄▅▄▄▄▄▄▄▄▃▄▃▃▃▃▃▃▃▂▃▂▂▃▂▃▂▂▂▂▁▂▁▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>▇▆▆█▄▅▄▄▄▅▅▄▅▇▅▅▆▁▄▅▅▇▂▄▂▃▂▄▂▂▁▃▁▃▂▂▂▂▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▃▄▇▁▇▇▇█▆▇▇▇█▆▇▇█▇▆█▇▇▇▆▆▇█▆▇▆▆▇▆▇▆▅▇▄▆▇</td></tr><tr><td>val_auc</td><td>▁▅▆▃▇▇██▇▆▇▇▇▅█▇▇▆▆▇▇▇▇▅▃▆▇▃▇▆▄▆▅▆▅▃▆▁▄▄</td></tr><tr><td>val_f1</td><td>▁▃█▇█▇▇██▇▇███▇▇▇▇▆█▇█▇▆▇▇█▆▇▅▇▇██▆▇▆▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>▇▄▂▆▂▂▃▁▂▃▂▂▂▂▂▂▃▂▂▃▃▃▃▃▃▂▂▃▂▅▂▂▅▄▄▅▅█▄▄</td></tr><tr><td>val_loss_step</td><td>█▃▂▆▁▂▁▂▂▁▁▂▂▂▂▂▃▂▃▃▁▂▄▄▄▃▃▃▂▃█▂▂▅▃▃▄▄▄▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83105</td></tr><tr><td>train_auc</td><td>0.89034</td></tr><tr><td>train_f1</td><td>0.78613</td></tr><tr><td>train_loss_epoch</td><td>0.40183</td></tr><tr><td>train_loss_step</td><td>0.45001</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.69597</td></tr><tr><td>val_auc</td><td>0.75882</td></tr><tr><td>val_f1</td><td>0.64069</td></tr><tr><td>val_loss_epoch</td><td>0.70661</td></tr><tr><td>val_loss_step</td><td>0.92754</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_3_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/vqs939qb' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/vqs939qb</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_112605-vqs939qb\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_114035-1u8t9tyj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/1u8t9tyj' target=\"_blank\">GINConv_4_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/1u8t9tyj' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/1u8t9tyj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_16_onehot_4\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 2.3 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b43625c29344c2caa11aa2e51ca7474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇▇▇██▇█▇██████</td></tr><tr><td>train_auc</td><td>▁▄▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇▇▇█▇█▇▇█████</td></tr><tr><td>train_f1</td><td>▁▄▇▆▆▇▇▇▇▇▇▇▇▇▇▇█▇█▇███▇▇▇▇▇███▇████████</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▄▃▃▃▂▂▃▃▃▃▃▃▂▂▃▂▃▂▃▂▃▂▃▃▂▁▂▂▂▂▂▂▂▂▁</td></tr><tr><td>train_loss_step</td><td>██▇▇▄▅▅▇▅▅▅▆▅▃▅▆▇▆▇▄▄▅▇▄▃▄▅▆▄▅▅▃▆▆▁▃▅▃▅▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▂▄▅▆▇▆▆▇▇▅▆▇▇▇▇▆▆▆█▆▇▇▇▆▆█▆▇█▇▇▇▆▇▆▇▅▇</td></tr><tr><td>val_auc</td><td>▁▃▄▆▆▇▇▇▇▇▇▇▇██▇██▇▇▇██▇▇▇█▇▇▇█▇▇▇▇▇▇▇▇▇</td></tr><tr><td>val_f1</td><td>▁▂▂▄▆▆█▇▇▇▇▆▇▇█▇▇▆▇▆█▇▇▇▇▇▇█▆▇█▇▇█▆█▇▇▆▇</td></tr><tr><td>val_loss_epoch</td><td>▃▃█▄▂▃▂▂▃▂▃▃▂▂▁▁▁▃▃▃▁▂▁▃▂▂▁▂▃▃▁▃▃▂▃▂▃▃▂▁</td></tr><tr><td>val_loss_step</td><td>▄▄█▄▃▂▂▃▃▂▂▂▃▃▂▃▃▂▂▃▂▄▂▃▅▃▂▃▂▂▃▂▂▅▃▂▃▃▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.78904</td></tr><tr><td>train_auc</td><td>0.83638</td></tr><tr><td>train_f1</td><td>0.72663</td></tr><tr><td>train_loss_epoch</td><td>0.47122</td></tr><tr><td>train_loss_step</td><td>0.42755</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.71795</td></tr><tr><td>val_auc</td><td>0.78873</td></tr><tr><td>val_f1</td><td>0.62439</td></tr><tr><td>val_loss_epoch</td><td>0.51794</td></tr><tr><td>val_loss_step</td><td>0.42214</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/1u8t9tyj' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/1u8t9tyj</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_114035-1u8t9tyj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_115450-xtp1p56d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/xtp1p56d' target=\"_blank\">GINConv_4_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/xtp1p56d' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/xtp1p56d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_16_onehot_4\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 2.3 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "526d9adf20f947378e9194645eab27aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▂▄▅▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█</td></tr><tr><td>train_auc</td><td>▁▁▁▄▄▅▅▅▆▆▅▇█▆▇▇▇▇▇▇▇▇▇████▇█▇█▇█▇▇█▇▇██</td></tr><tr><td>train_f1</td><td>▃▁▂▅▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇██▇▇▇▇████▇█▇█▇██</td></tr><tr><td>train_loss_epoch</td><td>█▇▆▅▄▄▄▃▄▃▃▃▃▃▃▃▃▃▃▃▃▂▃▂▂▂▂▃▃▂▂▂▂▃▂▂▂▃▂▁</td></tr><tr><td>train_loss_step</td><td>█▇▇▆▆▅▅▇▆▆▅▆▄▅▄▆▇▅▇▄▅▄▆▂▃▄▄▆▄▄▅▃▆▅▂▃▆▄▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▁▁▆▄▇▇▆▇▇▇▆▇▇▆▇▇▄█▇███▇▄▅█▇▇▇▆▆▆▇▅▇▇▆▅▅</td></tr><tr><td>val_auc</td><td>▁▄▃▅▄▇▇▅▅▆██▇▇▇█▇▆█████▇█▇██▇█▇▇▇▇▇▇█▇▇▇</td></tr><tr><td>val_f1</td><td>▁▁▂▆▇▇▇█▇█▇▆███▆▇▇█▇▇█████▇███▇██▇█████▇</td></tr><tr><td>val_loss_epoch</td><td>█▇▇▆▆▄▄▅▅▅▅▅▃▄▄▄▃▆▃▃▁▃▂▂█▄▁▄▄▄▃▄▅▂▃▄▃▅▅▃</td></tr><tr><td>val_loss_step</td><td>██▇▆▇▃▄▆▃▄▃▂▅▄▃▃▄▅▂▂▁▅▃▅▄▃▅▃▃▃▄▆▂▃▂▂▅▄▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.76438</td></tr><tr><td>train_auc</td><td>0.78187</td></tr><tr><td>train_f1</td><td>0.6899</td></tr><tr><td>train_loss_epoch</td><td>0.5071</td></tr><tr><td>train_loss_step</td><td>0.42262</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.66667</td></tr><tr><td>val_auc</td><td>0.76182</td></tr><tr><td>val_f1</td><td>0.59556</td></tr><tr><td>val_loss_epoch</td><td>0.57158</td></tr><tr><td>val_loss_step</td><td>0.5591</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/xtp1p56d' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/xtp1p56d</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_115450-xtp1p56d\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_120924-up0gtvfa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/up0gtvfa' target=\"_blank\">GINConv_4_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/up0gtvfa' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/up0gtvfa</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_16_onehot_4\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 2.3 K \n",
      "2 | head        | Sequential       | 154   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "2.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.4 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43b1d21edc7e4f3fa6b23d269178b138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▂▂▃▃▄▅▅▅▅▅▅▅▅▆▆▆▆▇▆▆▆▇▇▇▇▇▇▇▇█▇▇▇▇█████</td></tr><tr><td>train_auc</td><td>▆█▇▆▅▇▆▆▆▆▆▆▅▆▆▅▅▆▅▄▅▄▅▅▄▃▄▂▃▂▂▂▂▂▁▂▂▂▁▁</td></tr><tr><td>train_f1</td><td>▁▃▃▄▄▄▄▅▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇██</td></tr><tr><td>train_loss_epoch</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▅▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▄▄▅▅▅▅▆▅▅▆▆▆▆▆▆▇▆▇▇█▇▆▇█▇▇▇█▇█▇██▆▇▇▇▇</td></tr><tr><td>val_auc</td><td>███▇▅▇▆▅█▆▃▅▇▅▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_f1</td><td>▁▂▆▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇█▇█▇▆▇█▇▇▇█▇██▇▇▇▇█▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.74795</td></tr><tr><td>train_auc</td><td>0.31988</td></tr><tr><td>train_f1</td><td>0.69058</td></tr><tr><td>train_loss_epoch</td><td>0.53342</td></tr><tr><td>train_loss_step</td><td>0.50109</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.7033</td></tr><tr><td>val_auc</td><td>0.21841</td></tr><tr><td>val_f1</td><td>0.58883</td></tr><tr><td>val_loss_epoch</td><td>0.56474</td></tr><tr><td>val_loss_step</td><td>0.49766</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/up0gtvfa' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/up0gtvfa</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_120924-up0gtvfa\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_122316-olp8n7dz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/olp8n7dz' target=\"_blank\">GINConv_4_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/olp8n7dz' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/olp8n7dz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_16_onehot_4\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 2.3 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 17    \n",
      "--------------------------------------------------\n",
      "2.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.5 K     Total params\n",
      "0.010     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▆▆▆▆▆▇▆▇▆▇▇▇▆▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆█▇▇▇▇█</td></tr><tr><td>train_auc</td><td>▁▄▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇████▇▇███▇██████▇████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▇▆▇▆▇▇█▇▇▇███▇██▇█▇▇██▇▇█▇█▇▇█▇▇▇██</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▃▄▃▃▃▃▃▂▃▂▂▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▁▂▂▁▂▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>██▇▅▃▆▃▂▄▃▅▃▃▃▅▅▃▅▃▃▁▂▆▄▂▂▃▆▄▄▂▂▁▂▃▃▁▃▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▁▃▆▅▅▆▇▆▆▇▇▅▅▇▆▇█▆▅▇▆▆█▆▅▆▇▆▇██▃▇▆▇▆▆▆▇</td></tr><tr><td>val_auc</td><td>▁▄▆▆▆▆▆▇▆▇▇▇▇█▇█▇███▇███▇▇█▇▇▇█▇▇▇██████</td></tr><tr><td>val_f1</td><td>▁▁▄▆▅▅▆▇▇▆▆▇▆▅▆▆▇█▆▅█▆▆█▆▅▆█▆▇▇█▄▆▆▇▆▆▆▆</td></tr><tr><td>val_loss_epoch</td><td>▃▄▂▃▃▄▂▂▂▂▄▂▃▃▁▃▂▂▂▂▁▃▁▂▃▆▄▃▃▂▂▂█▂▃▅▄▃▁▄</td></tr><tr><td>val_loss_step</td><td>▄▅▆▂▃▄▂▂▂▂▃▁▂▃▂▄▃▂▂▃▂▃▂▃▂▄▁▂▅▂▂▄▂▃▅▂▂▃▂█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.78265</td></tr><tr><td>train_auc</td><td>0.82558</td></tr><tr><td>train_f1</td><td>0.71186</td></tr><tr><td>train_loss_epoch</td><td>0.50389</td></tr><tr><td>train_loss_step</td><td>0.49854</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.69963</td></tr><tr><td>val_auc</td><td>0.79412</td></tr><tr><td>val_f1</td><td>0.52326</td></tr><tr><td>val_loss_epoch</td><td>0.73263</td></tr><tr><td>val_loss_step</td><td>0.96477</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/olp8n7dz' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/olp8n7dz</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_122316-olp8n7dz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_123735-t5fo11wl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/t5fo11wl' target=\"_blank\">GINConv_4_16_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/t5fo11wl' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/t5fo11wl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_16_onehot_4\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 2.3 K \n",
      "2  | head        | Sequential       | 154   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 281   \n",
      "--------------------------------------------------\n",
      "2.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.7 K     Total params\n",
      "0.011     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▅▆▆▆▆▆▆▆▆▆▇▇▇▇█▆█▇▇█▆▇▇█▇▇▇▇▇█▇▇██▇▇██</td></tr><tr><td>train_auc</td><td>▁▄▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇████▇█▇█▇▇█▇████</td></tr><tr><td>train_f1</td><td>▁▄▆▆▇▇▇▇▇▇▇▆▇▇▇▇█▇██▇█▇▇▇█▇▇▇▇██▇███████</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▃▄▃▃▄▃▃▃▃▂▂▂▃▃▂▂▃▂▃▃▂▁▁▂▃▂▂▁▂▂▂▂▁▂▁▁</td></tr><tr><td>train_loss_step</td><td>██▄▅▅▃▄▅▅▃▃▄▄▅▂▆▄▅▃▄▃▃▄▃▆▇▃▂▃▃▃▁▄▄▄▂▃▆▅▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▁▃▃▃▅▃▅▄▆▆▇▆▇▇▄▆▅█▅▆▇▆▆▆▅█▇▅▇▆▇▇▆▅▅▆▇▆▇</td></tr><tr><td>val_auc</td><td>▁▂▄▅▆▆▆▆▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇▇█▇▇▇▇█▇▇██▇</td></tr><tr><td>val_f1</td><td>▁▁▃▄▄▆▄▅▄▇▆▇▆▇▇▄▆▆▇▆▆▇▆▆▇▅▇▇▅▇▆▇▇█▅█▆▇▆▆</td></tr><tr><td>val_loss_epoch</td><td>▅▇█▇▆▂▆▆▅▃▂▂▃▂▁▅▂▂▃▅▅▁▂▃▁▄▁▁▅▄▃▄▁▁▇▅▇▂▃▃</td></tr><tr><td>val_loss_step</td><td>▄▆█▄▄▃▅▅▅▁▅▂▃▃▃▄▄▅▂▄▄▃▅▂▂▂▃▃▅▅▄▆▂▄▄▅▂▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.78721</td></tr><tr><td>train_auc</td><td>0.8374</td></tr><tr><td>train_f1</td><td>0.70911</td></tr><tr><td>train_loss_epoch</td><td>0.48591</td></tr><tr><td>train_loss_step</td><td>0.4992</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.69963</td></tr><tr><td>val_auc</td><td>0.79009</td></tr><tr><td>val_f1</td><td>0.52874</td></tr><tr><td>val_loss_epoch</td><td>0.63197</td></tr><tr><td>val_loss_step</td><td>0.58552</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_16_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/t5fo11wl' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/t5fo11wl</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_123735-t5fo11wl\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_125134-x5tdjgak</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/x5tdjgak' target=\"_blank\">GINConv_4_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/x5tdjgak' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/x5tdjgak</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_32_onehot_4\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 8.2 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "8.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.7 K     Total params\n",
      "0.035     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▆▆▆▇▆▆▇▇▇▇▇▇▇█▇▇▇▇█▇▇██▇▇▇▇████▇███</td></tr><tr><td>train_auc</td><td>▁▅▅▅▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇████▇████████</td></tr><tr><td>train_f1</td><td>▁▆▆▆▆▆▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇▇▇███▇▇█▇█</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▅▄▄▃▄▂▃▃▂▂▃▃▂▃▂▂▃▂▂▂▁▂▂▂▂▁▁▁▂▁▁▁▁▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>▆█▅▄▆▅▅▅▆▄▅▅▃▆▄▃▃▄▄▄▃▂▅▃▅▃▂▂▄▄▂▃▄▃▁▂▂▄▁▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▆▅▆▆█▇▇▇█▆▇▇▅▄▅▇▇▅▇█▇▆▇▅█▇▆▇▆▇▆▆▅▄▇▇▇▇</td></tr><tr><td>val_auc</td><td>▁▃▅▆▆▅▇▇██▇▆▇▇▆▅▇▆▆▆▇▆▇▇▆▆▇▆▅▇▅▆▆▄▃▅▆▆▆▄</td></tr><tr><td>val_f1</td><td>▁▄▇▅█▇█▇▇▇█▆▇▇██▅▇█▅██▆▇▇▅█▇▇▆▆▇█▆▅▅▆▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>▅▆▂▄▄▁▂▁▂▁▁▃▂▁▃▄▆▂▂▃▃▁▅▄▃▅▃▁▂▅▅▄▄▄▇█▇▂▃▃</td></tr><tr><td>val_loss_step</td><td>▃▄▂▃▂▁▁▁▁▂▂▂▁▁▃▃▅▂▂▂▃▅▂▂▂▂▂▃▂▂▂▁▂█▃▂▂▃▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.79726</td></tr><tr><td>train_auc</td><td>0.85686</td></tr><tr><td>train_f1</td><td>0.73821</td></tr><tr><td>train_loss_epoch</td><td>0.45717</td></tr><tr><td>train_loss_step</td><td>0.4675</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.70696</td></tr><tr><td>val_auc</td><td>0.76694</td></tr><tr><td>val_f1</td><td>0.61165</td></tr><tr><td>val_loss_epoch</td><td>0.58621</td></tr><tr><td>val_loss_step</td><td>0.61048</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/x5tdjgak' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/x5tdjgak</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_125134-x5tdjgak\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_130546-nungpdae</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/nungpdae' target=\"_blank\">GINConv_4_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/nungpdae' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/nungpdae</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_32_onehot_4\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 8.2 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "8.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.7 K     Total params\n",
      "0.035     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▄▅▆▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇██▇▇</td></tr><tr><td>train_auc</td><td>▁▃▃▃▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇████████▇</td></tr><tr><td>train_f1</td><td>▁▄▅▆▅▆▅▆▇▇▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇██▇▇▇█▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▅▅▄▄▄▃▄▃▃▃▃▃▂▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▂▁▁▁▂▂</td></tr><tr><td>train_loss_step</td><td>█▇▆▇█▆▆▇▄▅▇▅▅▄▅▃▃▅▇▃▅▃▅▃▅▅▂▄▃▆▂▁▃▄▁▃▂▅▂▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▅▁▅▄▆▇▆▆▆▆▅▇▆█▇▅▇▆▆█▆▅▅▆▇▄▆▆▆▆▆▆▄▆▄▆▆▇▅▆</td></tr><tr><td>val_auc</td><td>▁▂▃▃▃▄▆▇▇▇▆████▆▇▇▆▇▆▆▇▆▇▅▆▆▇▇▆▆▆▆▅▅▄▆▃▆</td></tr><tr><td>val_f1</td><td>▆▁▅▄▆█▆▅█▆▇▇█▇██▇▇██▇▆█▇▇██▆█▇▇██▆█▇▆▇██</td></tr><tr><td>val_loss_epoch</td><td>▆▅▃▄▂▃▂▂▂▂▁▂▃▂▂▄▂▁▃▂▃▂▄▃▂▅▃▁▄▂▃▄▅▂█▃▄▃▅▄</td></tr><tr><td>val_loss_step</td><td>▇▆▅▅▄▄▃▃▄▅▅▁▆▂▃▅▁▄▄▄▅▅▃▃▄▄▃▅█▃▂▅█▃▃▂▅▆▄▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77078</td></tr><tr><td>train_auc</td><td>0.80912</td></tr><tr><td>train_f1</td><td>0.68742</td></tr><tr><td>train_loss_epoch</td><td>0.50561</td></tr><tr><td>train_loss_step</td><td>0.49825</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.68132</td></tr><tr><td>val_auc</td><td>0.76574</td></tr><tr><td>val_f1</td><td>0.68364</td></tr><tr><td>val_loss_epoch</td><td>0.61213</td></tr><tr><td>val_loss_step</td><td>0.63447</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/nungpdae' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/nungpdae</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_130546-nungpdae\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_132004-flu2x3kr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/flu2x3kr' target=\"_blank\">GINConv_4_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/flu2x3kr' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/flu2x3kr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_32_onehot_4\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 8.2 K \n",
      "2 | head        | Sequential       | 562   \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "8.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.7 K     Total params\n",
      "0.035     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▃▂▃▄▄▅▅▅▆▆▆▆▆▆▆▇▇▆▇▇▆█▇▇▇▇▇▇▇██▇▇▇███▇</td></tr><tr><td>train_auc</td><td>▁▂▁▁▂▂▂▄▆▆▆▅▆▆▆▆▆▇▇█▆▆▇▇▆▇▅▆▆▆▆▆▇▆▆▅▆▅▆▅</td></tr><tr><td>train_f1</td><td>▁▃▄▃▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▆▆▇▆█▇▇▇▇▇▇▇▇█▇█▇▇██▇</td></tr><tr><td>train_loss_epoch</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>██▅▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▅▇▅▄▄▆▅▅▆▆▆▆▇▇▅▅▇▇▇▇▅▇▇▇▅▇▆▆▇▅▇▇█▇▇▇▇▆</td></tr><tr><td>val_auc</td><td>▅▄▂▁▃▃▅▆▆▆▆▆▆▆▇▇▇▆▇▇▆▆▇▇▆▆▇▇▇▆█▇▇█████▇▇</td></tr><tr><td>val_f1</td><td>▁▄▆█▆▆▅▇▆▆▇▇▇▆▇▇▅▆█▇▇▇▆▇▇▇▆▇▇▇▇▆█▇█▇▇██▆</td></tr><tr><td>val_loss_epoch</td><td>█▆▂▂▁▂▁▁▂▁▁▂▂▁▁▁▂▂▁▂▂▁▁▂▂▁▂▁▁▁▂▂▁▂▁▁▂▂▁▂</td></tr><tr><td>val_loss_step</td><td>█▄▃▂▂▂▁▁▁▂▁▁▁▁▂▁▂▂▁▁▂▂▂▁▂▂▂▁▂▁▂▂▁▁▁▁▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.76164</td></tr><tr><td>train_auc</td><td>0.6475</td></tr><tr><td>train_f1</td><td>0.69258</td></tr><tr><td>train_loss_epoch</td><td>0.50965</td></tr><tr><td>train_loss_step</td><td>0.49796</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.67399</td></tr><tr><td>val_auc</td><td>0.79237</td></tr><tr><td>val_f1</td><td>0.4472</td></tr><tr><td>val_loss_epoch</td><td>0.82904</td></tr><tr><td>val_loss_step</td><td>0.76475</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/flu2x3kr' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/flu2x3kr</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_132004-flu2x3kr\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_133420-cjifsao7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/cjifsao7' target=\"_blank\">GINConv_4_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/cjifsao7' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/cjifsao7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_32_onehot_4\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 8.2 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 33    \n",
      "--------------------------------------------------\n",
      "8.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.8 K     Total params\n",
      "0.035     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc04f7397f847cc9d6efe41cb65b57d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▆▆▆▆▇▇▇▇▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇▇█▇█</td></tr><tr><td>train_auc</td><td>▁▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇█▇█▇█▇█▇████▇█</td></tr><tr><td>train_f1</td><td>▁▆▆▆▄▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇█▇▇▇▇▆▇▇▇▇▇▇█▇██▇█▇█</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▃▂▂▃▂▃▂▃▂▂▂▂▂▂▁▂▁▁▂▁▂▁</td></tr><tr><td>train_loss_step</td><td>█▆▇▄▆▄▇▆▅▃▄▆▄▆▅▃▃▄▄▇▃▄▂▅▅▂▃▃▆▄▃▃▄▃▅▁▅▁▆▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▅▆▇▇▇▆▇▇▇▇▇█▆▅▆▇▇▆▇▇█▇██▇█▇▃▇▇▇▇▅▇█▇█▇█</td></tr><tr><td>val_auc</td><td>▁▃▄▆▅▆▄▅▆▇▆▆▆▆▆▇▅▇▇▆▇▇▇▇▇▇█▆▅▇▆▆▅▆▇▇▇▆█▇</td></tr><tr><td>val_f1</td><td>▁▅▇▆▇▇▆▇▇▇▇▇█▆▅▆▆▆▆▇▆███▇▆█▇▇▇█▇█▆▇▇▆▇▇█</td></tr><tr><td>val_loss_epoch</td><td>▄▅▃▂▄▃▄▂▂▂▂▃▂▄▅▃▄▅▃▁▁▂▂▃▂▃▂▅█▁▁▂▃▅▃▂▄▅▄▁</td></tr><tr><td>val_loss_step</td><td>▅▅▃▄▄▅▅▄▃▄▄▃▃▄▅▄▄▅▄▃▄▄▄▃▅▆▅▃▅▃▄▃▄▆▃▄█▇▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.8137</td></tr><tr><td>train_auc</td><td>0.86801</td></tr><tr><td>train_f1</td><td>0.75829</td></tr><tr><td>train_loss_epoch</td><td>0.44996</td></tr><tr><td>train_loss_step</td><td>0.53548</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.73626</td></tr><tr><td>val_auc</td><td>0.80044</td></tr><tr><td>val_f1</td><td>0.70968</td></tr><tr><td>val_loss_epoch</td><td>0.51716</td></tr><tr><td>val_loss_step</td><td>0.36845</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/cjifsao7' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/cjifsao7</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_133420-cjifsao7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_134909-8naphac2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/8naphac2' target=\"_blank\">GINConv_4_32_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/8naphac2' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/8naphac2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_32_onehot_4\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 8.2 K \n",
      "2  | head        | Sequential       | 562   \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 1.1 K \n",
      "--------------------------------------------------\n",
      "9.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "9.8 K     Total params\n",
      "0.039     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "603f34d809204cb282061ba46e18ca71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇▇█▇▇▇▇▇██▇█</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇█</td></tr><tr><td>train_f1</td><td>▁▅▅▅▇▆▆▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▆▇█▇▇▇█▇▇▇█▇████</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▄▄▄▃▄▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▃▂▂▂▂▂▁</td></tr><tr><td>train_loss_step</td><td>█▇▇▇▅▅▆▅▅▅▄▅▄▆▅▅▅▃█▆▃▅▃▇█▃▃▃▆▃▁▂▃▂▃▇▄▁▃▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▃▅▅▇▆▇▆▇▄▆▇▆▇▆█▆▇▅▇▇▄▇▇▇▆▇▆▇▆▆▇█▆▇▇▆▆▆▇</td></tr><tr><td>val_auc</td><td>▁▆▆▆▆▆▇▆▆▆▆▇▆▇▇▇▆▇▆▆▇▇▇▆▆▇▇▇▇▇▆▇█▇▇▇▇▇▇▇</td></tr><tr><td>val_f1</td><td>▁▃▆▅▇▇█▆█▄█▇▆█▆▇▇▇█▇█▄██▇█▇█▇▇█▇█▇█▇▇███</td></tr><tr><td>val_loss_epoch</td><td>▆▄▄▃▂▃▃▃▄█▂▄▅▂▇▃▄▄▃▄▃█▁▃▅▅▅▃▂▂▃▆▄▄▃▆▃▅▄▅</td></tr><tr><td>val_loss_step</td><td>▅▆▄▅▃▃▃▄▃▄▄▂▃▂▃▂▂▂▅▃▁▂▂▃▂▃▃▂▁▃▃▃▂▄▁▅▃▂▅█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.81187</td></tr><tr><td>train_auc</td><td>0.8754</td></tr><tr><td>train_f1</td><td>0.74878</td></tr><tr><td>train_loss_epoch</td><td>0.4348</td></tr><tr><td>train_loss_step</td><td>0.4645</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.71795</td></tr><tr><td>val_auc</td><td>0.78371</td></tr><tr><td>val_f1</td><td>0.66667</td></tr><tr><td>val_loss_epoch</td><td>0.66275</td></tr><tr><td>val_loss_step</td><td>0.8834</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_32_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/8naphac2' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/8naphac2</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_134909-8naphac2\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_140258-b97ukzeb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/b97ukzeb' target=\"_blank\">GINConv_4_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/b97ukzeb' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/b97ukzeb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_64_onehot_4\\mean\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 30.7 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "32.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "32.8 K    Total params\n",
      "0.131     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ee8a3b800ee4e33a844a74e3532f7d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▆▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▇█▇███████</td></tr><tr><td>train_auc</td><td>▁▄▅▆▅▆▆▅▆▆▆▆▇▆▆▇▆▆▇▇▆▇▇▆▇▇▇▇▇▇█▇████████</td></tr><tr><td>train_f1</td><td>▁▅▆▆▆▇▇▆▆▆▆▇█▇▇▇▇▇▇█▇██▇▇▇▇▆▇▇██▇███████</td></tr><tr><td>train_loss_epoch</td><td>█▆▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▃▃▃▂▃▃▃▂▂▃▂▂▂▁▂▁▂▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>███▆▇▇▅▆▆▅▄█▇█▆▅▅▃▅▄█▄▃▅▆▂▅▃▆▅▄▆▆▁▄▄▂▃▃▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▂▆▇▇▅▇▇▇▇█▇▇▇▇▇▆▆█▆▇▇▇▇▇▇▅█▅▇▇▁▇▆▇▇█▇▆▆▆</td></tr><tr><td>val_auc</td><td>▄▅▇▇██▇▆▇▇▇▇▇▇█▆▆▆▆▅▇▇▅▇▇▅▇▅▆▆▂▆▅▇▅▆▅▅▁▅</td></tr><tr><td>val_f1</td><td>▁▆▆██▇██▆█████▆█▆██▇▇█▇▇███▅▇▇▇▇█▇▆▇▇▆▆▇</td></tr><tr><td>val_loss_epoch</td><td>█▂▂▃▃▂▂▂▂▁▁▂▂▃▃▂▃▁▂▃▂▂▂▂▂▃▂▅▂▂▄▁▂▅▄▂▂▃▃▃</td></tr><tr><td>val_loss_step</td><td>█▃▂▂▃▁▂▂▂▁▁▂▁▂▂▂▂▂▃▂▁▃▃▂▂▁▂▂▂▂▁▃▃▆▂▂▂▃▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.80548</td></tr><tr><td>train_auc</td><td>0.87543</td></tr><tr><td>train_f1</td><td>0.75768</td></tr><tr><td>train_loss_epoch</td><td>0.42209</td></tr><tr><td>train_loss_step</td><td>0.31595</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.68498</td></tr><tr><td>val_auc</td><td>0.75327</td></tr><tr><td>val_f1</td><td>0.60909</td></tr><tr><td>val_loss_epoch</td><td>0.65025</td></tr><tr><td>val_loss_step</td><td>0.77528</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/b97ukzeb' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/b97ukzeb</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_140258-b97ukzeb\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_141743-iy0ycswq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/iy0ycswq' target=\"_blank\">GINConv_4_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/iy0ycswq' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/iy0ycswq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_64_onehot_4\\max\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 30.7 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "32.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "32.8 K    Total params\n",
      "0.131     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5fccb79b57d4f8ea9bdaabaeb2f84dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▆▆▆▇▆▇▇▇▇▆▆██▇▇▇█▇█▇▇██▇█▇▇███████▇</td></tr><tr><td>train_auc</td><td>▁▃▅▅▆▆▆▆▇▆▇▇▇▇▆▇▇█▇▇▇▇▇▇▇▇▇▇█▇██████████</td></tr><tr><td>train_f1</td><td>▁▃▅▅▆▆▆▆▇▆▆▇▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇███▇██▇▇</td></tr><tr><td>train_loss_epoch</td><td>█▆▄▄▄▃▃▃▃▃▃▃▂▂▃▃▂▂▂▂▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▂▂▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▆▄▆▅▄▃▅▄▄▃▆▃▅▄▅▃▂▂▃▅▃▄▂▄▂▂▂▅▃▃▂▃▁▂▄▁▁▃▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▂▆▄▇▇▅▆▇▆▄▇▇▇▆▆▇▆▇▇█▆▆█▆▆▆█▅▇▇▆▃▆▅▆▆▄▆▆</td></tr><tr><td>val_auc</td><td>▁▅▅▄▇▇▆▆█▇▆▇▇▇█▆▇▆▇██▆▇▇▆▆█▇▇█▇▇▇▆▇█▇▆▆▇</td></tr><tr><td>val_f1</td><td>▁▁▆▇▆▇▇█████▇▇▇████▇████▇█▇██▇▇████▆██▇█</td></tr><tr><td>val_loss_epoch</td><td>▅▄▄▄▂▃▁▃▃▃▆▁▂▃▂▂▂▃▃▃▂▄▂▃▄▆▃▃▅▂▂▂▄▃▄▂▄█▂▃</td></tr><tr><td>val_loss_step</td><td>▇▇▄▅▅▂▅▅▁▄█▃▃▁▂▄▂▅▅▃▂▅▃▃▂▂▂▅▂▄▃▆▄▅▄▃▂▄▂▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.76256</td></tr><tr><td>train_auc</td><td>0.83321</td></tr><tr><td>train_f1</td><td>0.69121</td></tr><tr><td>train_loss_epoch</td><td>0.48286</td></tr><tr><td>train_loss_step</td><td>0.41488</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.68864</td></tr><tr><td>val_auc</td><td>0.77898</td></tr><tr><td>val_f1</td><td>0.69091</td></tr><tr><td>val_loss_epoch</td><td>0.61298</td></tr><tr><td>val_loss_step</td><td>0.6445</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/iy0ycswq' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/iy0ycswq</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_141743-iy0ycswq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_143127-11ecu9e7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/11ecu9e7' target=\"_blank\">GINConv_4_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/11ecu9e7' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/11ecu9e7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_64_onehot_4\\sum\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params\n",
      "-------------------------------------------------\n",
      "0 | x_embedding | Identity         | 0     \n",
      "1 | model       | GIN              | 30.7 K\n",
      "2 | head        | Sequential       | 2.1 K \n",
      "3 | loss_module | CrossEntropyLoss | 0     \n",
      "4 | train_acc   | BinaryAccuracy   | 0     \n",
      "5 | train_auroc | BinaryAUROC      | 0     \n",
      "6 | train_f1    | BinaryF1Score    | 0     \n",
      "7 | valid_acc   | BinaryAccuracy   | 0     \n",
      "8 | valid_auroc | BinaryAUROC      | 0     \n",
      "9 | valid_f1    | BinaryF1Score    | 0     \n",
      "-------------------------------------------------\n",
      "32.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "32.8 K    Total params\n",
      "0.131     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04f6f47df2be4648871a602488823103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.013 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.080664…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▃▂▃▃▄▄▅▆▅▅▆▆▆▆▆▆▅▆▇▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇███▇</td></tr><tr><td>train_auc</td><td>▄▄▅▆▆████▇▅▇▆▇▆▄▃▂▄▄▅▄▃▅▆▅▄▄▃▂▃▃▃▂▂▃▄▃▃▁</td></tr><tr><td>train_f1</td><td>▁▂▂▂▃▂▂▄▅▅▅▆▅▆▅▅▅▅▆▇▆▆▆▆▆▆▆▆▆▇▇▇▆▆▇▇▇▇█▇</td></tr><tr><td>train_loss_epoch</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▄▄▅▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇▇▇▇▇▆▇▇▇▇▇▅█▇▇▇▆▇█</td></tr><tr><td>val_auc</td><td>▅▅▄▅▆▆▆▆▇▇▇▆▆▆▆▅▂▂▃▃▄█▇███▇▇▇▃▂▄▁▆▃▅▆▆▂▂</td></tr><tr><td>val_f1</td><td>▁▄▇▆█▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇▇▇▇▇▇▇▇██▇████▇▆▇█</td></tr><tr><td>val_loss_epoch</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.77808</td></tr><tr><td>train_auc</td><td>0.48663</td></tr><tr><td>train_f1</td><td>0.72292</td></tr><tr><td>train_loss_epoch</td><td>0.50204</td></tr><tr><td>train_loss_step</td><td>0.50223</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.73626</td></tr><tr><td>val_auc</td><td>0.67522</td></tr><tr><td>val_f1</td><td>0.68421</td></tr><tr><td>val_loss_epoch</td><td>0.71025</td></tr><tr><td>val_loss_step</td><td>1.00822</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/11ecu9e7' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/11ecu9e7</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_143127-11ecu9e7\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc16ab6447a4407a98c61f9d251a474c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01693333333435779, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_144459-de3v2zpv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/de3v2zpv' target=\"_blank\">GINConv_4_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/de3v2zpv' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/de3v2zpv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_64_onehot_4\\attention\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 30.7 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | GlobalAttention  | 65    \n",
      "--------------------------------------------------\n",
      "32.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "32.9 K    Total params\n",
      "0.131     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19965700cca340b59d4d0ea9bd9e50f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▆▆▆▆▆▅▆▇▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█████</td></tr><tr><td>train_auc</td><td>▁▅▆▆▆▇▆▆▆▇▇▇▇▇▆▇▇▇▇▇▇▇▇█▇▇▇▇▇▇██▇▇██████</td></tr><tr><td>train_f1</td><td>▁▅▇▇▇▇▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇██▇█▇█▇▇██████</td></tr><tr><td>train_loss_epoch</td><td>█▅▄▄▄▄▄▅▄▃▃▃▃▃▄▃▃▃▃▃▃▂▃▃▃▃▂▂▂▂▂▁▂▂▂▁▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>█▇▇▇▄▆▄▂▅█▄▅▅▅▆▅▃▅▆▄▄▅▅▃▅▄▄▇▆▃▃▄▇▄▃▆▁▄▃▅</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▁▆▆▆▇▇▆▇▆▇▆█▆▆▇▅▆▅▅█▇▇▇▆█▆▆▇▇▇▇▆▇▆▇▅▅▆▆▇</td></tr><tr><td>val_auc</td><td>▁▂▅▆▆▇▆▆▆▆▆▇▆▇▆▆▆▅▇▇▇▇▆▆█▆▇▆▅▆▆▆▆▆▆▅▃▆▆▅</td></tr><tr><td>val_f1</td><td>▁▆▇▇█▇▇▇▆█▇█▇█▇▇▆█▆███▇██▇▇█▇██▇█▆████▇█</td></tr><tr><td>val_loss_epoch</td><td>█▂▃▃▃▃▃▂▄▂▂▂▃▂▁▃▅▄▅▃▁▂▅▄▁▂▂▄█▂▃▂▅▇▄▄▃▄▇▃</td></tr><tr><td>val_loss_step</td><td>▄▃▂▂▂▂▂▂▂▂▂▂▃▂▂▂▃▂▃▁▁▂▂▁▇▂▃▂▂▂▂█▃▃▂▂█▅▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.80822</td></tr><tr><td>train_auc</td><td>0.8631</td></tr><tr><td>train_f1</td><td>0.75524</td></tr><tr><td>train_loss_epoch</td><td>0.44546</td></tr><tr><td>train_loss_step</td><td>0.48208</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.72894</td></tr><tr><td>val_auc</td><td>0.7781</td></tr><tr><td>val_f1</td><td>0.69421</td></tr><tr><td>val_loss_epoch</td><td>0.57775</td></tr><tr><td>val_loss_step</td><td>0.59077</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/de3v2zpv' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/de3v2zpv</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_144459-de3v2zpv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>y:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\wandb\\run-20231217_145832-r7op1cgh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/r7op1cgh' target=\"_blank\">GINConv_4_64_onehot_4</a></strong> to <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/r7op1cgh' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/r7op1cgh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "c:\\Users\\thu71\\AppData\\Local\\anaconda3\\envs\\scanpy\\Lib\\site-packages\\lightning\\pytorch\\callbacks\\model_checkpoint.py:617: UserWarning: Checkpoint directory \\\\bme-retromaster.ad.gatech.edu\\labs5\\coskun-lab\\Thomas\\23_PLA_revision\\data\\9PPI\\saved_models\\9PPI_v3\\Graph_GNNs_Kfold\\GIN_4_64_onehot_4\\attention2\\GraphLevelGINConv exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name        | Type             | Params\n",
      "--------------------------------------------------\n",
      "0  | x_embedding | Identity         | 0     \n",
      "1  | model       | GIN              | 30.7 K\n",
      "2  | head        | Sequential       | 2.1 K \n",
      "3  | loss_module | CrossEntropyLoss | 0     \n",
      "4  | train_acc   | BinaryAccuracy   | 0     \n",
      "5  | train_auroc | BinaryAUROC      | 0     \n",
      "6  | train_f1    | BinaryF1Score    | 0     \n",
      "7  | valid_acc   | BinaryAccuracy   | 0     \n",
      "8  | valid_auroc | BinaryAUROC      | 0     \n",
      "9  | valid_f1    | BinaryF1Score    | 0     \n",
      "10 | pool        | Attention_module | 4.2 K \n",
      "--------------------------------------------------\n",
      "37.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "37.0 K    Total params\n",
      "0.148     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>lr-Adam</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▅▅▆▆▆▆▆▆▅▅▆▆▆▇▆▆▇▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇█▇▇███</td></tr><tr><td>train_auc</td><td>▁▄▅▅▄▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇██</td></tr><tr><td>train_f1</td><td>▁▄▅▆▆▆▆▆▆▇▆▅▇▇▇▇▇▇▇▇▇▇▆▇▇▇▇▇▇█▆█▇██▇████</td></tr><tr><td>train_loss_epoch</td><td>█▇▅▅▅▅▅▅▄▅▄▄▄▄▄▄▄▄▃▃▃▃▄▃▃▃▃▃▃▂▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train_loss_step</td><td>▇█▆▅▆▄▂▅▅▅▂▁▄▃▅▁▄█▃▃▂▂▄▃▅▂▁▃▃▂▂▃▄▄▁▁▄▁▂▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▁▂▂▂▁▃▃▂▂▃▂▂▄▄▂▂▅▅▂▂▅▃▃▆▆▃▇▇▇▃▇▇▃▃█</td></tr><tr><td>val_acc</td><td>▃▅▇▇▇▁▇▅▇▇▆▅▇█▇▅▇▇▂▆▃▇▇▇▆▇▇▇▇▇█▁▇▇▇█▇▇▆▇</td></tr><tr><td>val_auc</td><td>▄▆▇█▇▁█▆▇█▇█▇██▇▆▇▇▇▆▆▇▅▇▇▇▇▇▇▇▂▆▆▆▇▇▅▆▆</td></tr><tr><td>val_f1</td><td>▁▄▇█▆▇▇███▆█████▆▆▇█▇█▇▇█▇▇▇██▇▇▆▇▇▇▇▇█▇</td></tr><tr><td>val_loss_epoch</td><td>█▃▂▁▂▄▁▂▁▂▂▃▂▁▁▂▁▂▆▂▃▂▁▃▂▁▁▁▁▂▁▆▁▂▂▁▄▂▂▂</td></tr><tr><td>val_loss_step</td><td>█▃▂▂▂▅▂▂▁▁▃▃▂▁▂▃▂▂▆▃▃▂▂▄▂▂▄▂▄▂▃▃▁▂▃▅▃▃▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>lr-Adam</td><td>0.005</td></tr><tr><td>train_acc</td><td>0.83653</td></tr><tr><td>train_auc</td><td>0.90319</td></tr><tr><td>train_f1</td><td>0.78614</td></tr><tr><td>train_loss_epoch</td><td>0.37795</td></tr><tr><td>train_loss_step</td><td>0.39654</td></tr><tr><td>trainer/global_step</td><td>719</td></tr><tr><td>val_acc</td><td>0.7033</td></tr><tr><td>val_auc</td><td>0.76356</td></tr><tr><td>val_f1</td><td>0.57592</td></tr><tr><td>val_loss_epoch</td><td>0.66198</td></tr><tr><td>val_loss_step</td><td>0.54135</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GINConv_4_64_onehot_4</strong> at: <a href='https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/r7op1cgh' target=\"_blank\">https://wandb.ai/thoomas/PLA_10152023_9PPI_v3_Kfold/runs/r7op1cgh</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231217_145832-r7op1cgh\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k_folds = 5\n",
    "kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_ids, valid_ids) in enumerate(kfold.split(dataset_filtered)):\n",
    "    train_subset = dataset_filtered.index_select(train_ids.tolist())\n",
    "    val_subset = dataset_filtered.index_select(valid_ids.tolist())\n",
    "    for NUM_LAYERS, HIDDEN_CHANNELS, pool, in list(itertools.product(*[num_layers, hiddens, pools])):\n",
    "            # Path to the folder where the pretrained models are saved\n",
    "        CHECKPOINT_PATH = checkpoint_folder / f'GIN_{NUM_LAYERS}_{HIDDEN_CHANNELS}_onehot_{fold}' / pool\n",
    "        CHECKPOINT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Skip already trained kfold and pool\n",
    "        checkpoint = CHECKPOINT_PATH / f\"GraphLevel{model}\" / f\"GraphLevel{model}.ckpt\" \n",
    "        if checkpoint.exists():\n",
    "            print(checkpoint)\n",
    "            continue\n",
    "\n",
    "        # Run training\n",
    "        run = wandb.init(project=project_name, name=f'{model}_{NUM_LAYERS}_{HIDDEN_CHANNELS}_onehot_{fold}', \n",
    "                        group=f'{model}_{pool}', \n",
    "                        # mode=\"disabled\"\n",
    "                        )\n",
    "        PPIGraph.train_graph_classifier_kfold(model, \n",
    "                                                train_subset, \n",
    "                                                val_subset, \n",
    "                                                dataset, \n",
    "                                                CHECKPOINT_PATH, \n",
    "                                                AVAIL_GPUS, \n",
    "                                                in_channels=9,\n",
    "                                                hidden_channels=HIDDEN_CHANNELS, \n",
    "                                                out_channels = HIDDEN_CHANNELS,\n",
    "                                                num_layers=NUM_LAYERS, \n",
    "                                                epochs=epochs,\n",
    "                                                embedding=False,\n",
    "                                                batch_size=128, \n",
    "                                                graph_pooling=pool)\n",
    "        run.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
