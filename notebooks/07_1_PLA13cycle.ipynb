{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.io\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import trange, tqdm, tqdm_notebook\n",
    "from joblib import Parallel, delayed\n",
    "import re\n",
    "import h5py\n",
    "import tifffile as tiff\n",
    "from natsort import natsort_keygen\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = (Path().cwd().parents[0] / 'data').absolute()\n",
    "data_processed = data_dir / 'processed'\n",
    "data_raw = r'Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\PLA\\HCC827 cell culture 13 PPIs with nuclease P1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    " \n",
    "os.environ['JDK_HOME'] = \"C:\\Program Files\\Java\\jdk-17\"\n",
    "os.environ['JAVA_HOME'] = \"C:\\Program Files\\Java\\jdk-17\"\n",
    "\n",
    "os.environ['PATH'] += ';C:\\\\Program Files\\\\Java\\\\jdk-17\\\\jre\\\\bin\\\\server\\\\;C:\\\\Program Files\\\\Java\\\\jdk-17\\\\bin\\\\;C:\\\\Program Files\\\\Java\\\\jdk-17\\\\bin\\\\jar.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers_map = {\n",
    "    'cycle1': {\n",
    "        1: 'Hoechst', \n",
    "        3: 'Sox2/Oct4',\n",
    "        4: 'NF-Kb/p-P90rsk',\n",
    "    },\n",
    "    'cycle2': {\n",
    "        1: 'Hoechst', \n",
    "        3: 'SIRT1/P53',\n",
    "        4: 'TRAIL/DR5'\n",
    "    },\n",
    "    'cycle3': {\n",
    "        1: 'Hoechst', \n",
    "        3: 'Cyclin D1/CDK4',\n",
    "        4: 'Bim/Tom20'\n",
    "    },\n",
    "    'cycle4': {\n",
    "        1: 'Hoechst', \n",
    "        3: 'EGFR/GRB2',\n",
    "        4: 'FoxO1/AKT'\n",
    "    },\n",
    "    'cycle5': {\n",
    "        1: 'Hoechst', \n",
    "        2: 'p-ERK/c-MYC',\n",
    "    },\n",
    "    'cycle6': {\n",
    "        1: 'Hoechst', \n",
    "        4: 'Mcl-1/BAK'\n",
    "    },\n",
    "    'cycle7': {\n",
    "        1: 'Hoechst', \n",
    "        4: 'Cyclin E/CDK2'\n",
    "    },\n",
    "    'cycle8': {\n",
    "        1: 'Hoechst', \n",
    "        4: 'AKT/Mtor'\n",
    "    },\n",
    "    'cycle9': {\n",
    "        1: 'Hoechst', \n",
    "        4: 'TEAD1/YAP'\n",
    "    },\n",
    "    'cycle10': {\n",
    "        1: 'Hoechst', \n",
    "        2: 'p-EGFR',\n",
    "        3: 'Phalloidin',\n",
    "        4: 'Ki67'\n",
    "    },\n",
    "   'cycle11': {\n",
    "        1: 'Hoechst', \n",
    "        2: 'NBD-C6',\n",
    "        4: 'COX IV'\n",
    "    },\n",
    "    'cycle12': {\n",
    "        1: 'Hoechst', \n",
    "        2: 'Pan-cytokeratin',\n",
    "    },\n",
    "    'cycle13': {\n",
    "        1: 'Hoechst', \n",
    "        2: 'Concanavalin A',\n",
    "        4: 'WGA'\n",
    "    },\n",
    "}\n",
    "\n",
    "def get_info(data_raw, marker_dict):\n",
    "    conditions = []\n",
    "    fovs = []\n",
    "    cycles = []\n",
    "    channels = []\n",
    "    markers = []\n",
    "    paths = [] \n",
    "    \n",
    "    # Loop through image folder\n",
    "    for (dirpath, dirnames, filenames) in os.walk(data_raw):\n",
    "        # Don't get the nuclease after bleach channel\n",
    "        if 'after nuclease' in dirpath or 'Test' in dirpath or 'wrong' in dirpath:\n",
    "            continue\n",
    "        \n",
    "        for name in sorted(filenames):\n",
    "            if \"tif\" in name and \"sti\" in name \\\n",
    "            and 'overlay' not in name \\\n",
    "            and 'Composite' not in name:\n",
    "                # Get information from image name                \n",
    "                d_split = dirpath.split('\\\\')\n",
    "                condition = d_split[-2].split(' ')[-1]\n",
    "                fov = d_split[-1].split('_')[-1]\n",
    "                cycle =  d_split[-1].split('_')[1][3:]\n",
    "                cycle = 'cycle' + cycle\n",
    "\n",
    "                n_split = name.split('_')\n",
    "                ch = int(n_split[-1][-5])\n",
    "                try: marker = marker_dict[cycle][ch] \n",
    "                except: continue\n",
    "        \n",
    "                conditions.append(condition)\n",
    "                fovs.append(fov)\n",
    "                cycles.append(cycle)\n",
    "                channels.append(ch)\n",
    "                markers.append(marker)\n",
    "                paths.append(os.path.join(dirpath, name))\n",
    "                \n",
    "    info = {\n",
    "            \"Condition\": conditions,\n",
    "            'FOV': fovs, \n",
    "            \"Cycle\": cycles,\n",
    "            \"Channels\": channels,\n",
    "            \"Markers\": markers,\n",
    "            \"Path\": paths\n",
    "        }\n",
    "\n",
    "    df = pd.DataFrame(info)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded df\n"
     ]
    }
   ],
   "source": [
    "df_meta_path = data_dir / '13cyc' / 'metadata' / 'info.csv'\n",
    "df_meta_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_exist = df_meta_path.is_file()\n",
    "\n",
    "if not df_exist:\n",
    "    print('Created df')\n",
    "    df = get_info(data_raw, markers_map)\n",
    "    df = df.sort_values(\n",
    "        by=[\"Condition\", \"FOV\", \"Cycle\", \"Channels\"],\n",
    "        key=natsort_keygen()\n",
    "    )\n",
    "    df.to_csv(df_meta_path, index=False)\n",
    "else:\n",
    "    print('Loaded df')\n",
    "    df = pd.read_csv(df_meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Condition</th>\n",
       "      <th>FOV</th>\n",
       "      <th>Cycle</th>\n",
       "      <th>Channels</th>\n",
       "      <th>Markers</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100nM</td>\n",
       "      <td>FW1</td>\n",
       "      <td>cycle1</td>\n",
       "      <td>1</td>\n",
       "      <td>Hoechst</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100nM</td>\n",
       "      <td>FW1</td>\n",
       "      <td>cycle1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sox2/Oct4</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100nM</td>\n",
       "      <td>FW1</td>\n",
       "      <td>cycle1</td>\n",
       "      <td>4</td>\n",
       "      <td>NF-Kb/p-P90rsk</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100nM</td>\n",
       "      <td>FW1</td>\n",
       "      <td>cycle2</td>\n",
       "      <td>1</td>\n",
       "      <td>Hoechst</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100nM</td>\n",
       "      <td>FW1</td>\n",
       "      <td>cycle2</td>\n",
       "      <td>3</td>\n",
       "      <td>SIRT1/P53</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>control</td>\n",
       "      <td>FW2</td>\n",
       "      <td>cycle12</td>\n",
       "      <td>1</td>\n",
       "      <td>Hoechst</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>control</td>\n",
       "      <td>FW2</td>\n",
       "      <td>cycle12</td>\n",
       "      <td>2</td>\n",
       "      <td>Pan-cytokeratin</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>control</td>\n",
       "      <td>FW2</td>\n",
       "      <td>cycle13</td>\n",
       "      <td>1</td>\n",
       "      <td>Hoechst</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>control</td>\n",
       "      <td>FW2</td>\n",
       "      <td>cycle13</td>\n",
       "      <td>2</td>\n",
       "      <td>Concanavalin A</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>control</td>\n",
       "      <td>FW2</td>\n",
       "      <td>cycle13</td>\n",
       "      <td>4</td>\n",
       "      <td>WGA</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Condition  FOV    Cycle  Channels          Markers  \\\n",
       "0       100nM  FW1   cycle1         1          Hoechst   \n",
       "1       100nM  FW1   cycle1         3        Sox2/Oct4   \n",
       "2       100nM  FW1   cycle1         4   NF-Kb/p-P90rsk   \n",
       "3       100nM  FW1   cycle2         1          Hoechst   \n",
       "4       100nM  FW1   cycle2         3        SIRT1/P53   \n",
       "..        ...  ...      ...       ...              ...   \n",
       "131   control  FW2  cycle12         1          Hoechst   \n",
       "132   control  FW2  cycle12         2  Pan-cytokeratin   \n",
       "133   control  FW2  cycle13         1          Hoechst   \n",
       "134   control  FW2  cycle13         2   Concanavalin A   \n",
       "135   control  FW2  cycle13         4              WGA   \n",
       "\n",
       "                                                  Path  \n",
       "0    Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  \n",
       "1    Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  \n",
       "2    Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  \n",
       "3    Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  \n",
       "4    Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  \n",
       "..                                                 ...  \n",
       "131  Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  \n",
       "132  Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  \n",
       "133  Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  \n",
       "134  Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  \n",
       "135  Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\P...  \n",
       "\n",
       "[136 rows x 6 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Condition  FOV\n",
       "100nM      FW1    34\n",
       "           FW2    34\n",
       "control    FW1    34\n",
       "           FW2    34\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['Condition', 'FOV']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "def save_hdf5(\n",
    "    path: str, name: str, data: np.ndarray, attr_dict=None, mode: str = \"a\"\n",
    ") -> None:\n",
    "    # Read h5 file\n",
    "    hf = h5py.File(path, mode)\n",
    "    # Create z_stack_dataset\n",
    "    if hf.get(name) is None:\n",
    "        data_shape = data.shape\n",
    "        data_type = data.dtype\n",
    "        max_shape = (data_shape[0],) + data_shape[1:]\n",
    "        dset = hf.create_dataset(\n",
    "            name,\n",
    "            shape=data_shape,\n",
    "            maxshape=max_shape,\n",
    "            chunks=True,\n",
    "            dtype=data_type,\n",
    "            compression=\"gzip\",\n",
    "        )\n",
    "        dset[:] = data\n",
    "        if attr_dict is not None:\n",
    "            for attr_key, attr_val in attr_dict.items():\n",
    "                dset.attrs[attr_key] = attr_val\n",
    "    else:\n",
    "        print(f\"Dataset {name} exists\")\n",
    "\n",
    "    hf.close()\n",
    "\n",
    "def read_img(path):\n",
    "    return skimage.io.imread(path, as_gray=True)\n",
    "\n",
    "def joblib_loop(task, pics):\n",
    "    return Parallel(n_jobs=20)(delayed(task)(i) for i in pics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded df\n"
     ]
    }
   ],
   "source": [
    "df_imgs_path = data_dir / '13cyc' / 'metadata' / 'imgs.csv'\n",
    "df_imgs_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "temp_path = data_dir  / '13cyc' / 'hdf5' / 'raw'\n",
    "temp_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_exist = df_imgs_path.is_file()\n",
    "\n",
    "if not df_exist:\n",
    "    print('Created df')\n",
    "    \n",
    "    group = df.groupby(['Condition', 'FOV'])\n",
    "    rows = []\n",
    "\n",
    "    for name, df_group in tqdm(group, total=len(group)):\n",
    "        file_name = '_'.join(np.array(name).astype(str)) + '.hdf5'\n",
    "        file_path = temp_path / file_name\n",
    "        rows.append(list(name)+[file_path])\n",
    "        \n",
    "        group_cycle = df_group.groupby('Cycle')\n",
    "        for cycle, df_cycle in group_cycle:\n",
    "            channels = df_cycle.Channels.to_list()\n",
    "            markers = df_cycle.Markers.to_list()\n",
    "            paths = df_cycle.Path.to_numpy()\n",
    "    \n",
    "            imgs = joblib_loop(read_img, paths)\n",
    "            imgs = np.array(imgs)\n",
    "            info = {\"Channels\": channels, \"Markers\": markers}\n",
    "            \n",
    "            # hdf5 as Channel -> Z mapping\n",
    "            save_hdf5(file_path, cycle, imgs, info)\n",
    "    df_imgs = pd.DataFrame(rows, columns=['Condition', 'FOV', 'Path'])        \n",
    "    df_imgs.to_csv(df_imgs_path, index=False)\n",
    "else:\n",
    "    print('Loaded df')\n",
    "    df_imgs = pd.read_csv(df_imgs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Condition</th>\n",
       "      <th>FOV</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100nM</td>\n",
       "      <td>FW1</td>\n",
       "      <td>y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\13cy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100nM</td>\n",
       "      <td>FW2</td>\n",
       "      <td>y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\13cy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>control</td>\n",
       "      <td>FW1</td>\n",
       "      <td>y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\13cy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>control</td>\n",
       "      <td>FW2</td>\n",
       "      <td>y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\13cy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Condition  FOV                                               Path\n",
       "0     100nM  FW1  y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\13cy...\n",
       "1     100nM  FW2  y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\13cy...\n",
       "2   control  FW1  y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\13cy...\n",
       "3   control  FW2  y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\13cy..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Tiffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skimage import exposure, util\n",
    "\n",
    "# def contrast_str(img, n_min=0.1, n_max=100):\n",
    "#     p2, p98 = np.percentile(img, (n_min, n_max))\n",
    "#     img_rescale = exposure.rescale_intensity(img, in_range=(p2, p98))\n",
    "#     return img_rescale\n",
    "\n",
    "# def make_imgs_same_dim(imgs):\n",
    "#     # Get max dimensions\n",
    "#     shapes = np.array([img.shape[1:] for img in imgs])\n",
    "#     min_x, min_y = shapes.min(axis=0)\n",
    "#     imgs_cropped = [img[:, :min_x, :min_y] for img in imgs]\n",
    "#     # imgs_cropped[0] = contrast_str(imgs_cropped[0])\n",
    "#     return imgs_cropped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path = data_dir /  '13cyc' /'imgs' / 'raw'\n",
    "# save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# group = df_imgs.groupby(['Condition', 'FOV'])\n",
    "# for name, df_group in group:\n",
    "#     path = df_group.iloc[0].Path\n",
    "             \n",
    "#     # Read images\n",
    "#     cycles = []\n",
    "#     imgs_all = []\n",
    "#     channels = []\n",
    "#     with h5py.File(path, \"r\") as f:\n",
    "#         for k in tqdm(f.keys(), total=len(f.keys()), leave=False):\n",
    "#             cycle = k.split('_')[0]\n",
    "#             channel = f[k].attrs['Channels']\n",
    "\n",
    "#             imgs = f[k][:]\n",
    "#             cycles.append(cycle)\n",
    "#             channels.append(channel)\n",
    "#             imgs[0] = contrast_str(imgs[0])\n",
    "#             imgs_all.append(imgs)\n",
    "    \n",
    "#     imgs_same_shape = make_imgs_same_dim(imgs_all)\n",
    "    \n",
    "#     for i, imgs in enumerate(imgs_same_shape):\n",
    "#         temp_path = save_path / '_'.join(np.array(name).astype(str))\n",
    "#         temp_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#         file_name = f'001_{cycles[i]}.tif'\n",
    "#         file_path = temp_path / file_name\n",
    "\n",
    "#         # Write image\n",
    "#         tiff.imwrite(file_path, imgs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Registration Ashlar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ashlar import fileseries, thumbnail,reg\n",
    "# import matplotlib.pyplot as plt\n",
    "# from ashlar.scripts.ashlar import process_axis_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loop all images\n",
    "# imgs_dir = data_dir / '13cyc' /'imgs' / 'raw'\n",
    "# save_dir = data_dir / '13cyc' /'imgs' / 'registered'\n",
    "# save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# imgs_dir_list = os.listdir(imgs_dir)\n",
    "\n",
    "# for dir_path in tqdm(imgs_dir_list):\n",
    "    \n",
    "#     # Create reader for each cycle\n",
    "#     readers = []\n",
    "#     for i in range(1, 14):\n",
    "#         reader = fileseries.FileSeriesReader(\n",
    "#             str(imgs_dir / dir_path),\n",
    "#             pattern='{series}_'+f'cycle{i}.tif',\n",
    "#             overlap=0.29,\n",
    "#             width=1,\n",
    "#             height=1,\n",
    "#             layout='snake',\n",
    "#             direction='horizontal',\n",
    "#             pixel_size=0.18872, \n",
    "#         )\n",
    "#         readers.append(reader)\n",
    "#     reader_1 = readers[0]\n",
    "    \n",
    "#     # Run stitching\n",
    "#     aligner0 = reg.EdgeAligner(reader_1, channel=0, filter_sigma=2, verbose=False,)\n",
    "#     aligner0.run()\n",
    "    \n",
    "#     # Generate merge image for 1 cycle\n",
    "#     # Parramter\n",
    "#     mosaic_args = {}\n",
    "#     mosaic_args['verbose'] = False\n",
    "\n",
    "#     mosaic = reg.Mosaic(\n",
    "#             aligner0,aligner0.mosaic_shape,**mosaic_args\n",
    "#         )\n",
    "#     writer_class = reg.TiffListWriter\n",
    "#     writer = writer_class(\n",
    "#             [mosaic], str(save_dir / (dir_path + '_cycle1_ch{channel}.ome.tif'))\n",
    "#     )\n",
    "#     writer.run()\n",
    "    \n",
    "#     # Loop through rest of cycles\n",
    "#     aligners = list()\n",
    "#     aligners.append(aligner0)\n",
    "\n",
    "#     for j in range(1, len(readers)):\n",
    "#         aligners.append(\n",
    "#             reg.LayerAligner(readers[j], aligners[0], channel=0, filter_sigma=2, verbose=False)\n",
    "#         )\n",
    "#         aligners[j].run()\n",
    "#         mosaic = reg.Mosaic(\n",
    "#             aligners[j], aligners[0].mosaic_shape,**mosaic_args\n",
    "#         )\n",
    "#         writer = writer_class(\n",
    "#                 [mosaic], str(save_dir / (dir_path +'_cycle'+str(j+1)+'_ch{channel}.ome.tif'))\n",
    "#         )\n",
    "#         writer.run()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Registration Image J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure, util\n",
    "\n",
    "def contrast_str(img, n_min=0.1, n_max=100):\n",
    "    p2, p98 = np.percentile(img, (n_min, n_max))\n",
    "    img_rescale = exposure.rescale_intensity(img, in_range=(p2, p98))\n",
    "    img_rescale = util.img_as_ubyte(img_rescale)\n",
    "    return img_rescale\n",
    "\n",
    "def make_imgs_same_dim(imgs):\n",
    "    # Get max dimensions\n",
    "    shapes = np.array([img.shape[1:] for img in imgs])\n",
    "    min_x, min_y = shapes.min(axis=0)\n",
    "    imgs_cropped = [img[:, :min_x, :min_y] for img in imgs]\n",
    "    # imgs_cropped[0] = contrast_str(imgs_cropped[0])\n",
    "    return imgs_cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile as tf\n",
    "from PIL import Image\n",
    "import PIL.Image\n",
    "PIL.Image.MAX_IMAGE_PIXELS = 933120000\n",
    "import shutil\n",
    "from datetime import date, datetime\n",
    "import skimage.io \n",
    "from skimage import util\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = df_imgs.groupby(['Condition', 'FOV'])\n",
    "dim = {}\n",
    "for name, df_group in group:\n",
    "    path = df_group.iloc[0].Path\n",
    "             \n",
    "    # Read images\n",
    "    cycles = []\n",
    "    imgs_all = []\n",
    "    channels = []\n",
    "\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        for k in f.keys():\n",
    "            # Read immage in info\n",
    "            cycle = k.split('_')[0][5:]\n",
    "            channel = f[k].attrs['Channels']\n",
    "            if cycle == '2':\n",
    "                dim[name] = [f[k].shape[1], f[k].shape[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a98c0de1a565438786fec9ce783a6273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d19c81f924b94bf5bba94e35e0703ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0db152191184fb5a4e8232c21522631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76ee50051dfe40b2b9d281f71cb64231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "regSavePath = data_dir / '13cyc' /'imgs' / 'registered_imagej'\n",
    "regSavePath.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "chs = [1, 2, 3, 4]\n",
    "group = df_imgs.groupby(['Condition', 'FOV'])\n",
    "for name, df_group in group:\n",
    "    path = df_group.iloc[0].Path\n",
    "             \n",
    "    # Read images\n",
    "    cycles = []\n",
    "    imgs_all = []\n",
    "    channels = []\n",
    "\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        for k in tqdm(f.keys(), total=len(f.keys()), leave=False):\n",
    "            # Read immage in info\n",
    "            cycle = k.split('_')[0][5:]\n",
    "            channel = f[k].attrs['Channels']\n",
    "            imgs = f[k][:]\n",
    "            \n",
    "            if cycle == '1':\n",
    "                dim_x = dim[name][0]\n",
    "                dim_y = dim[name][1]\n",
    "                imgs = resize(imgs, (len(imgs), dim_x, dim_y))\n",
    "                imgs = util.img_as_ubyte(imgs)\n",
    "\n",
    "            for ch in chs:\n",
    "                # Save path per Channel\n",
    "                folderPath = os.path.join(regSavePath, '_'.join(name), 'Original', 'CH' + str(ch)) # 1 index\n",
    "                if not os.path.exists(folderPath):\n",
    "                    os.makedirs(folderPath, exist_ok = True)\n",
    "                \n",
    "                fileOut = 'CH' + str(ch) + '_Cycle' + str(cycle).zfill(2) + '.tif'\n",
    "                fileOut = os.path.join(folderPath, fileOut)\n",
    "                # if os.path.exists(fileOut):\n",
    "                #     continue\n",
    "                if ch in channel:\n",
    "                    if ch == 1:\n",
    "                        img = contrast_str(imgs[list(channel).index(ch)], n_min=0.1, n_max=99.9)\n",
    "                    else:\n",
    "                        img = imgs[list(channel).index(ch)]\n",
    "                    tf.imwrite(fileOut, img, photometric = 'minisblack', bigtiff = True)\n",
    "\n",
    "                else:\n",
    "                    emptyImage = np.zeros(imgs[0].shape, np.uint8)\n",
    "                    # print('Dont exist create empty image', cycle, ch)\n",
    "                    tf.imwrite(fileOut, emptyImage, photometric = 'minisblack', bigtiff = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runMacro(\"y:/coskun-lab/Thomas/23_PLA_revision/data/13cyc/imgs/registered_imagej/100nM_FW1/Original/CH1/18Nov2023_register_transforms.ijm\");\n",
      "runMacro(\"y:/coskun-lab/Thomas/23_PLA_revision/data/13cyc/imgs/registered_imagej/100nM_FW2/Original/CH1/18Nov2023_register_transforms.ijm\");\n",
      "runMacro(\"y:/coskun-lab/Thomas/23_PLA_revision/data/13cyc/imgs/registered_imagej/control_FW1/Original/CH1/18Nov2023_register_transforms.ijm\");\n",
      "runMacro(\"y:/coskun-lab/Thomas/23_PLA_revision/data/13cyc/imgs/registered_imagej/control_FW2/Original/CH1/18Nov2023_register_transforms.ijm\");\n"
     ]
    }
   ],
   "source": [
    "group = df_imgs.groupby(['Condition', 'FOV'])\n",
    "chs = [1, 2, 3, 4]\n",
    "\n",
    "for name, channels in group:\n",
    "    name = '_'.join(name)\n",
    "    '''\n",
    "    run(\"Register Virtual Stack Slices\", \"source=[Y:/coskun-lab/Nicky/07 Temp/register large stitch] output=[Y:/coskun-lab/Nicky/07 Temp/register output] feature=Rigid registration=[Rigid                -- translate + rotate                  ] advanced shrinkage save save_dir=[Y:/coskun-lab/Nicky/07 Temp/register output] initial_gaussian_blur=1.60 steps_per_scale_octave=3 minimum_image_size=64 maximum_image_size=1024 feature_descriptor_size=8 feature_descriptor_orientation_bins=8 closest/next_closest_ratio=0.92 maximal_alignment_error=25 inlier_ratio=0.05 feature_extraction_model=Rigid registration_model=[Rigid                -- translate + rotate                  ] interpolate\");\n",
    "    run(\"Transform Virtual Stack Slices\", \"source = [Y:/coskun-lab/Nicky/07 Temp/other channels/original] output = [Y:/coskun-lab/Nicky/07 Temp/other channels/original] transforms = [Y:/coskun-lab/Nicky/07 Temp/register output] interpolate\");\n",
    "    '''\n",
    "    # folder to save registered images separated by channel to apply transforms\n",
    "    # create all folder\n",
    "    for ii, ch in enumerate(chs): # all channels\n",
    "        os.makedirs(os.path.join(regSavePath, name, 'Original', 'CH' + str(ch)), exist_ok = True)\n",
    "        os.makedirs(os.path.join(regSavePath, name, 'Registered', 'CH' + str(ch)), exist_ok = True)\n",
    "    \n",
    "    os.chdir(os.path.join(regSavePath, name, 'Original', 'CH1'))\n",
    "    now = datetime.now() # current date and time\n",
    "    date_time = now.strftime(\"%d%b%Y\")\n",
    "    macro = open(date_time + '_register_transforms.ijm', 'w')\n",
    "    \n",
    "    # register cycles on CH1\n",
    "    macro.write('run(\"Register Virtual Stack Slices\", \"source=[')\n",
    "    # original files\n",
    "    macro.write(os.path.join(regSavePath, name, 'Original', 'CH1').replace('\\\\', '/'))\n",
    "    macro.write('] output=[')\n",
    "    # registered output files\n",
    "    macro.write(os.path.join(regSavePath, name, 'Registered', 'CH1').replace('\\\\', '/'))\n",
    "    \n",
    "    # # Rigid registration: translation + rotation\n",
    "    # macro.write('] feature=Rigid registration=[Rigid                -- translate + rotate                  ] advanced shrinkage save save_dir=[')\n",
    "    # # folder to save recorded transformations \n",
    "    # macro.write('] initial_gaussian_blur=1.60 steps_per_scale_octave=3 minimum_image_size=64 maximum_image_size=1024 feature_descriptor_size=8 feature_descriptor_orientation_bins=8 closest/next_closest_ratio=0.92 maximal_alignment_error=25 inlier_ratio=0.05 feature_extraction_model=Rigid registration_model=[Rigid                -- translate + rotate                  ] interpolate\"); \\n')\n",
    "    \n",
    "    # # bigwrap registration\n",
    "    # macro.write('] feature=Similarity registration=[Elastic              -- bUnwarpJ splines                    ] advanced shrinkage save save_dir=[')\n",
    "    # # folder to save recorded transformations \n",
    "    # macro.write('] initial_gaussian_blur=1.60 steps_per_scale_octave=3 minimum_image_size=64 maximum_image_size=1024 feature_descriptor_size=8 feature_descriptor_orientation_bins=8 closest/next_closest_ratio=0.92 maximal_alignment_error=25 inlier_ratio=0.05 feature_extraction_model=Similarity registration_model=[[Elastic              -- bUnwarpJ splines                    ] interpolate registration=Mono image_subsample_factor=0 initial_deformation=[Very Coarse] final_deformation=Fine divergence_weight=0.1 curl_weight=0.1 landmark_weight=1 image_weight=0 consistency_weight=0 stop_threshold=0.01 shear=0.95 scale=0.95 isotropy=1\"); \\n')\n",
    "    \n",
    "    # Or use similarity: translation + rotation + isotropic scale\n",
    "    macro.write('] feature=Similarity registration=[Similarity           -- translate + rotate + isotropic scale] advanced shrinkage save save_dir=[')\n",
    "    # folder to save recorded transformations \n",
    "    macro.write('] initial_gaussian_blur=1.60 steps_per_scale_octave=3 minimum_image_size=64 maximum_image_size=1024 feature_descriptor_size=25 feature_descriptor_orientation_bins=8 closest/next_closest_ratio=0.92 maximal_alignment_error=50 inlier_ratio=0.05 feature_extraction_model=Similarity registration_model=[Similarity           -- translate + rotate + isotropic scale] interpolate\"); \\n')\n",
    "    \n",
    "    macro.write('run(\"Close All\"); \\n\\n')\n",
    "    \n",
    "    # now apply transform to other channels\n",
    "    for ii, ch in enumerate([1,2,3,4]): # each other channel\n",
    "        \n",
    "        macro.write('run(\"Transform Virtual Stack Slices\", \"source=[')\n",
    "        # unregsitered folder\n",
    "        macro.write(os.path.join(regSavePath, name, 'Original', 'CH' + str(ch)).replace('\\\\', '/'))\n",
    "        macro.write('] output=[')\n",
    "        # registered folder\n",
    "        macro.write(os.path.join(regSavePath, name, 'Registered', 'CH' + str(ch)).replace('\\\\', '/'))\n",
    "        macro.write('] transforms=[')\n",
    "        macro.write(os.path.join(regSavePath, name, 'Original', 'CH1').replace('\\\\', '/')) # stored in original registration folder\n",
    "        macro.write('] interpolate\"); \\n')\n",
    "        macro.write('run(\"Close All\"); \\n\\n')\n",
    "    \n",
    "    macro.close()\n",
    "    \n",
    "    # print command to run macro\n",
    "    print('runMacro(\"' + os.path.join(regSavePath, name, 'Original', 'CH1', macro.name).replace('\\\\', '/') + '\");')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine all registered images into single folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "regSavePath = data_dir / '13cyc' /'imgs' / 'registered_imagej'\n",
    "\n",
    "regSaveFinalPath = data_dir / '13cyc' / 'imgs' / 'registered_imagej_final'\n",
    "regSaveFinalPath.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "regSaveCropPath = data_dir /'13cyc'  / 'imgs' /  'registered_crop'\n",
    "regSaveCropPath.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96702af2402047bebac511fa2a758454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b256d09fabf64a99b22e9612b9586d4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cd5f07ddce64847897d3ab9c69b2275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b8b6510fa204c89b8139605f447c766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "group = df.groupby(['Condition', 'FOV'])\n",
    "\n",
    "for name, channels in group:\n",
    "    name = '_'.join(name)\n",
    "    for ii, cycle in enumerate(tqdm(channels['Cycle'].unique())): # each cycle\n",
    "    \n",
    "        dfCycle = channels.loc[channels['Cycle'] == cycle]\n",
    "        dfCycle.reset_index(drop = True, inplace = True) # index is channel - 1\n",
    "        cycle = cycle[5:]\n",
    "        for jj, ch in enumerate(dfCycle.Channels): # each channel\n",
    "            \n",
    "            # find registered file\n",
    "            tifPath = os.path.join(regSavePath, name, 'Registered', 'CH' + str(ch), 'CH' + str(ch)+ '_Cycle' + str(cycle).zfill(2) + '.tif')\n",
    "\n",
    "            # File out\n",
    "            fileOut = 'Cycle' + str(cycle).zfill(2) + \\\n",
    "            '_' + 'CH' + str(ch) + '.tif'\n",
    "            folder = regSaveFinalPath / name\n",
    "            folder.mkdir(parents=True, exist_ok=True)\n",
    "            fileOut = os.path.join(regSaveFinalPath, name, fileOut)\n",
    "            # print(tifPath)\n",
    "            # Copy\n",
    "            if os.path.exists(tifPath):\n",
    "                shutil.copyfile(tifPath, fileOut)\n",
    "            else:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Cropped image to smallest bounding box of non black region\n",
    "\n",
    "# Get channel list\n",
    "group = df.groupby(['Condition', 'FOV'])\n",
    "\n",
    "for name, df_group in group:\n",
    "    channels = df_group.Channels.tolist()\n",
    "    break\n",
    "\n",
    "# Crop\n",
    "for dir in os.listdir(regSaveFinalPath):\n",
    "\n",
    "    # Read imgs\n",
    "    imgs = []\n",
    "    paths = []\n",
    "    for file in os.listdir(regSaveFinalPath / dir):\n",
    "        if 'tif' in file:\n",
    "            path = regSaveFinalPath / dir/ file\n",
    "            imgs.append(tiff.imread(path))\n",
    "            paths.append(file)\n",
    "\n",
    "    # Get bboxs\n",
    "    bboxs = []\n",
    "    for i, img in enumerate(imgs):\n",
    "        if channels[i] != 1:\n",
    "            continue\n",
    "        bbox = skimage.measure.regionprops((img>0).astype(np.uint8))[0]['bbox']\n",
    "        bboxs.append(np.array(bbox))\n",
    "    bboxs = np.stack(bboxs)\n",
    "\n",
    "    bbox_final = [np.max(bboxs[:,0]),\n",
    "                np.max(bboxs[:,1]),\n",
    "                np.min(bboxs[:,2]),\n",
    "                np.min(bboxs[:,3])]\n",
    "\n",
    "    min_row, min_col, max_row, max_col = bbox_final\n",
    "\n",
    "    # Save cropped images\n",
    "    save_dir = regSaveCropPath / dir\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for i, img in enumerate(imgs):\n",
    "        save_path = save_dir / paths[i]\n",
    "        tiff.imwrite(save_path, img[min_row:max_row, min_col:max_col], bigtiff = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import util\n",
    "\n",
    "def get_info(data_raw, marker_dict):\n",
    "    conditions = []\n",
    "    fovs = []\n",
    "    cycles = []\n",
    "    channels = []\n",
    "    markers = []\n",
    "    paths = [] \n",
    "\n",
    "    # Loop through image folder\n",
    "    for (dirpath, dirnames, filenames) in os.walk(data_raw):\n",
    "        for name in sorted(filenames):\n",
    "            if \"tif\" in name:\n",
    "                # Get information from image name\n",
    "                n_split = name.split('_')\n",
    "                                \n",
    "                cond=dirpath.split('\\\\')[-1].split('_')[0]\n",
    "                fov=dirpath.split('\\\\')[-1].split('_')[1]\n",
    "                cycle='cycle'+str(int(n_split[0][-2:]))\n",
    "                ch = int(n_split[1][2])\n",
    "                try:\n",
    "                    marker = marker_dict[cycle][ch]\n",
    "                except:\n",
    "                    continue \n",
    "                    \n",
    "                conditions.append(cond)\n",
    "                fovs.append(fov)\n",
    "                cycles.append(cycle)\n",
    "                channels.append(ch)\n",
    "                markers.append(marker)\n",
    "                paths.append(os.path.join(dirpath, name))\n",
    "                \n",
    "    info = {\n",
    "            \"Condition\": conditions,\n",
    "            \"FOV\": fovs,\n",
    "            \"Cycle\": cycles,\n",
    "            \"Channels\": channels,\n",
    "            \"Markers\": markers,\n",
    "            \"Path\": paths\n",
    "        }\n",
    "\n",
    "    df = pd.DataFrame(info)\n",
    "    return df\n",
    "\n",
    "def joblib_loop(task, pics):\n",
    "    return Parallel(n_jobs=20)(delayed(task)(i) for i in pics)\n",
    "\n",
    "def read_img(path):\n",
    "    return skimage.io.imread(path, as_gray=True)\n",
    "\n",
    "def get_min(imgs):\n",
    "    shapes = np.array([np.array(img.shape) for img in imgs])\n",
    "    return np.min(shapes, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder is already there\n",
      "Created df\n"
     ]
    }
   ],
   "source": [
    "data_raw = data_dir /'13cyc'  / 'imgs' /  'registered_crop'\n",
    "df_meta_path = data_dir /  '13cyc' / 'metadata' / 'info_sti.csv'\n",
    "\n",
    "try:\n",
    "    df_meta_path.parent.mkdir(parents=True, exist_ok=False)\n",
    "except FileExistsError:\n",
    "    print(\"Folder is already there\")\n",
    "\n",
    "df_exist = df_meta_path.is_file()\n",
    "\n",
    "if not df_exist:\n",
    "    print('Created df')\n",
    "    df = get_info(data_raw, markers_map)\n",
    "    df.to_csv(df_meta_path, index=False)\n",
    "else:\n",
    "    print('Loaded df')\n",
    "    df = pd.read_csv(df_meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Condition  FOV\n",
       "100nM      FW1    34\n",
       "           FW2    34\n",
       "control    FW1    34\n",
       "           FW2    34\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['Condition', 'FOV']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created df\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1533029bb8f3492f818da577a602cacc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_imgs_path = data_dir / '13cyc' /'metadata' / 'imgs_reg.csv'\n",
    "temp_path =data_dir / '13cyc' /'hdf5' / 'registered'\n",
    "try:\n",
    "    temp_path.mkdir(parents=True, exist_ok=False)\n",
    "except FileExistsError:\n",
    "    print(\"Folder is already there\")\n",
    "\n",
    "df_exist = df_imgs_path.is_file()\n",
    "\n",
    "if not df_exist:\n",
    "    print('Created df')\n",
    "    group = df.groupby(['Condition','FOV'])\n",
    "    rows = []\n",
    "\n",
    "    for name, df_group in tqdm(group, total=len(group)):\n",
    "        file_name = '_'.join(np.array(name).astype(str)) + '.hdf5'\n",
    "        file_path = temp_path / file_name\n",
    "        rows.append(list(name)+[file_path])\n",
    "        \n",
    "        # if file_path.exists():\n",
    "        #     continue\n",
    "        \n",
    "        channels = df_group.Channels.to_list()\n",
    "        cycles = df_group.Cycle.to_list()\n",
    "        markers = df_group.Markers.to_list()\n",
    "        paths = df_group.Path.to_numpy()\n",
    "            \n",
    "        imgs = joblib_loop(read_img, paths)\n",
    "        min_shape = get_min(imgs)\n",
    "        imgs_cropped = np.array([img[:min_shape[0], :min_shape[1]] for img in imgs])\n",
    "        info = {\"Cycle\": cycles, \"Channel\": channels, \"Marker\": markers}\n",
    "\n",
    "        imgs_cropped[np.where(imgs_cropped.max((1,2))>1)] = imgs_cropped[np.where(imgs_cropped.max((1,2))>1)] / 255\n",
    "        imgs_cropped = util.img_as_ubyte(imgs_cropped)\n",
    "        \n",
    "        # hdf5 as Channel -> Z mapping\n",
    "        save_hdf5(file_path, 'imgs', imgs_cropped, info)\n",
    "    df_imgs = pd.DataFrame(rows, columns=['Condition', 'FOV', 'Path'])        \n",
    "    df_imgs.to_csv(df_imgs_path, index=False)\n",
    "else:\n",
    "    print('Loaded df')\n",
    "    df_imgs = pd.read_csv(df_imgs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari \n",
    "from skimage import exposure, util\n",
    "\n",
    "def contrast_str(img, n_min=0.1, n_max=99.9):\n",
    "    p2, p98 = np.percentile(img, (n_min, n_max))\n",
    "    img_rescale = exposure.rescale_intensity(img, in_range=(p2, p98))\n",
    "    img_rescale = util.img_as_ubyte(img_rescale)\n",
    "    return img_rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imgs_path = data_dir /  '13cyc' /'metadata' / 'imgs_reg.csv'\n",
    "df_imgs = pd.read_csv(df_imgs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['Channel', 'Cycle', 'Marker']>\n",
      "<KeysViewHDF5 ['Channel', 'Cycle', 'Marker']>\n",
      "<KeysViewHDF5 ['Channel', 'Cycle', 'Marker']>\n",
      "<KeysViewHDF5 ['Channel', 'Cycle', 'Marker']>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save combined images\n",
    "for row in df_imgs.itertuples():\n",
    "    # Read image\n",
    "    path = row.Path\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        print(f['imgs'].attrs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyto_markers = ['p-EGFR', 'Phalloidin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Hoechst', 'Sox2/Oct4', 'NF-Kb/p-P90rsk', 'Hoechst', 'SIRT1/P53',\n",
       "       'TRAIL/DR5', 'Hoechst', 'Cyclin D1/CDK4', 'Bim/Tom20', 'Hoechst',\n",
       "       'EGFR/GRB2', 'FoxO1/AKT', 'Hoechst', 'p-ERK/c-MYC', 'Hoechst',\n",
       "       'Mcl-1/BAK', 'Hoechst', 'Cyclin E/CDK2', 'Hoechst', 'AKT/Mtor',\n",
       "       'Hoechst', 'TEAD1/YAP', 'Hoechst', 'p-EGFR', 'Phalloidin', 'Ki67',\n",
       "       'Hoechst', 'NBD-C6', 'COX IV', 'Hoechst', 'Pan-cytokeratin',\n",
       "       'Hoechst', 'Concanavalin A', 'WGA'], dtype=object)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_seg_path = data_dir /  '13cyc' / 'imgs' / 'segmentation'\n",
    "whole_seg_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# Save combined images\n",
    "for row in df_imgs.itertuples():\n",
    "    # Read image\n",
    "    path = row.Path\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        imgs = f['imgs'][:]\n",
    "        markers = f['imgs'].attrs['Marker']\n",
    "\n",
    "    # Get dapi and cyto imgaes\n",
    "    indices = np.isin(markers, cyto_markers)\n",
    "    img_dapi = imgs[3]\n",
    "    imgs_cyto = imgs[indices,:]\n",
    "    \n",
    "    # Contrast streching and combine to rgb image\n",
    "    img_dapi = contrast_str(img_dapi, n_max=99.9)\n",
    "    imgs_cyto_scaled = [contrast_str(imgs_cyto[0], n_max=99.9), contrast_str(imgs_cyto[1], n_max=99.9)]\n",
    "    img_cyto = np.max(np.array(imgs_cyto_scaled), axis=0)\n",
    "    img_rgb = np.stack([np.zeros(img_dapi.shape),img_cyto, img_dapi], axis=0).astype(np.uint8)\n",
    "    \n",
    "    # Crop and save\n",
    "    file_name = f'{\"_\".join(row[1:3])}.tif'\n",
    "    file_path = whole_seg_path / file_name\n",
    "    tiff.imwrite(file_path, img_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import napari \n",
    "\n",
    "# napari.view_image(img[np.where(markers=='Hoechst')], channel_axis=0, visible=False, contrast_limits=[0, 256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Viewer(axes=Axes(visible=False, labels=True, colored=True, dashed=False, arrows=True), camera=Camera(center=(0.0, 1707.0, 4274.0), zoom=0.254029711077319, angles=(0.0, 0.0, 90.0), perspective=0.0, interactive=True), cursor=Cursor(position=(1.0, 1.0), scaled=True, size=1, style=<CursorStyle.STANDARD: 'standard'>), dims=Dims(ndim=2, ndisplay=2, last_used=0, range=((0.0, 3415.0, 1.0), (0.0, 8549.0, 1.0)), current_step=(1707, 4274), order=(0, 1), axis_labels=('0', '1')), grid=GridCanvas(stride=1, shape=(-1, -1), enabled=False), layers=[<Image layer 'Hoechst' at 0x2e5201b4670>, <Image layer 'Sox2/Oct4' at 0x2e52015e7d0>, <Image layer 'NF-Kb/p-P90rsk' at 0x2e52755a110>, <Image layer 'Hoechst [1]' at 0x2e52d6642e0>, <Image layer 'SIRT1/P53' at 0x2e52d6ee470>, <Image layer 'TRAIL/DR5' at 0x2e52d798640>, <Image layer 'Hoechst [2]' at 0x2e52d8227d0>, <Image layer 'Cyclin D1/CDK4' at 0x2e52d8f0310>, <Image layer 'Bim/Tom20' at 0x2e52d956b30>, <Image layer 'Hoechst [3]' at 0x2e52da206d0>, <Image layer 'EGFR/GRB2' at 0x2e52da8ae90>, <Image layer 'FoxO1/AKT' at 0x2e52db58a00>, <Image layer 'Hoechst [4]' at 0x2e52dbbf1f0>, <Image layer 'p-ERK/c-MYC' at 0x2e52dc653c0>, <Image layer 'Hoechst [5]' at 0x2e52dcfb550>, <Image layer 'Mcl-1/BAK' at 0x2e52dda9720>, <Image layer 'Hoechst [6]' at 0x2e52de2f8b0>, <Image layer 'Cyclin E/CDK2' at 0x2e52def1a80>, <Image layer 'Hoechst [7]' at 0x2e52df6fc10>, <Image layer 'AKT/Mtor' at 0x2e52e021e10>, <Image layer 'Hoechst [8]' at 0x2e52e0abee0>, <Image layer 'TEAD1/YAP' at 0x2e52e162170>, <Image layer 'Hoechst [9]' at 0x2e52e208340>, <Image layer 'p-EGFR' at 0x2e52e29a4d0>, <Image layer 'Phalloidin' at 0x2e52e3486a0>, <Image layer 'Ki67' at 0x2e52e3d2830>, <Image layer 'Hoechst [10]' at 0x2e52e4a0490>, <Image layer 'NBD-C6' at 0x2e52e506bc0>, <Image layer 'COX IV' at 0x2e52e5d0490>, <Image layer 'Hoechst [11]' at 0x2e530f82f20>, <Image layer 'Pan-cytokeratin' at 0x2e5310351b0>, <Image layer 'Hoechst [12]' at 0x2e5310bf280>, <Image layer 'Concanavalin A' at 0x2e53116d450>, <Image layer 'WGA' at 0x2e5311f7610>], scale_bar=ScaleBar(visible=False, colored=False, color=array([1., 0., 1., 1.], dtype=float32), ticks=True, position=<Position.BOTTOM_RIGHT: 'bottom_right'>, font_size=10.0, box=False, box_color=array([0. , 0. , 0. , 0.6], dtype=float32), unit=None), text_overlay=TextOverlay(visible=False, color=array([0.5, 0.5, 0.5, 1. ], dtype=float32), font_size=10.0, position=<TextOverlayPosition.TOP_LEFT: 'top_left'>, text=''), overlays=Overlays(interaction_box=InteractionBox(points=None, show=False, show_handle=False, show_vertices=False, selection_box_drag=None, selection_box_final=None, transform_start=<napari.utils.transforms.transforms.Affine object at 0x000002E52737A290>, transform_drag=<napari.utils.transforms.transforms.Affine object at 0x000002E52737A260>, transform_final=<napari.utils.transforms.transforms.Affine object at 0x000002E527379FF0>, transform=<napari.utils.transforms.transforms.Affine object at 0x000002E52737A050>, allow_new_selection=True, selected_vertex=None)), help='', status='Ready', tooltip=Tooltip(visible=False, text=''), theme='dark', title='napari', mouse_over_canvas=False, mouse_move_callbacks=[<function InteractionBoxMouseBindings.initialize_mouse_events.<locals>.mouse_move at 0x000002E5248BD6C0>], mouse_drag_callbacks=[<function InteractionBoxMouseBindings.initialize_mouse_events.<locals>.mouse_drag at 0x000002E5245BE320>], mouse_double_click_callbacks=[], mouse_wheel_callbacks=[<function dims_scroll at 0x000002E50D7DB520>], _persisted_mouse_event={}, _mouse_drag_gen={}, _mouse_wheel_gen={}, keymap={'Shift': <function InteractionBoxMouseBindings.initialize_key_events.<locals>.hold_to_lock_aspect_ratio at 0x000002E52306B490>, 'Control-Shift-R': <function InteractionBoxMouseBindings._reset_active_layer_affine at 0x000002E52497D870>, 'Control-Shift-A': <function InteractionBoxMouseBindings._transform_active_layer at 0x000002E52497D480>})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "napari.view_image(img, channel_axis=0, name=markers,contrast_limits=[0,255], visible=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation using cellpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> GPU activated? YES\n"
     ]
    }
   ],
   "source": [
    "from skimage import exposure, util\n",
    "from cellpose import core, utils, io, models, metrics\n",
    "\n",
    "use_GPU = core.use_gpu()\n",
    "yn = ['NO', 'YES']\n",
    "print(f'>>> GPU activated? {yn[use_GPU]}')\n",
    "\n",
    "def contrast_str(img, n_min=0.1, n_max=99.95):\n",
    "    p2, p98 = np.percentile(img, (n_min, n_max))\n",
    "    img_rescale = exposure.rescale_intensity(img, in_range=(p2, p98))\n",
    "    img_rescale = util.img_as_ubyte(img_rescale)\n",
    "    return img_rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32my:\\coskun-lab\\Thomas\\23_PLA_revision\\notebooks\\07_1_PLA13cycle.ipynb Cell 49\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/y%3A/coskun-lab/Thomas/23_PLA_revision/notebooks/07_1_PLA13cycle.ipynb#X66sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m whole_seg_path \u001b[39m=\u001b[39m data_dir \u001b[39m/\u001b[39m  \u001b[39m'\u001b[39m\u001b[39m13cyc\u001b[39m\u001b[39m'\u001b[39m \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mimgs\u001b[39m\u001b[39m'\u001b[39m \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39msegmentation\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/y%3A/coskun-lab/Thomas/23_PLA_revision/notebooks/07_1_PLA13cycle.ipynb#X66sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m mask_path \u001b[39m=\u001b[39m data_dir  \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39m13cyc\u001b[39m\u001b[39m'\u001b[39m \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mimgs\u001b[39m\u001b[39m'\u001b[39m \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmasks\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/y%3A/coskun-lab/Thomas/23_PLA_revision/notebooks/07_1_PLA13cycle.ipynb#X66sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m mask_path\u001b[39m.\u001b[39mmkdir(parents\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_dir' is not defined"
     ]
    }
   ],
   "source": [
    "whole_seg_path = data_dir /  '13cyc' / 'imgs' / 'segmentation'\n",
    "\n",
    "mask_path = data_dir  / '13cyc' / 'imgs' / 'masks'\n",
    "mask_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cyto segmentaion\n",
    "masks = []\n",
    "for p in os.listdir(whole_seg_path):\n",
    "    if 'tif' not in p:\n",
    "        continue\n",
    "    img = skimage.io.imread(whole_seg_path / p).transpose((2,0,1))\n",
    "    \n",
    "    # Cyto segmentation\n",
    "    model = models.CellposeModel(gpu=True, model_type='cyto2')\n",
    "    mask_cyto, flows, styles = model.eval(img, \n",
    "                                  channels=[2,3],\n",
    "                                  diameter=150,\n",
    "                                  flow_threshold=0.3,\n",
    "                                  cellprob_threshold=0.0\n",
    "                                  )\n",
    "    \n",
    "    file_path = mask_path / p\n",
    "    tiff.imwrite(file_path, mask_cyto)\n",
    "    \n",
    "    # Nuclei segemtnation\n",
    "    model = models.CellposeModel(gpu=True, model_type='nuclei')\n",
    "    mask_nuclei, flows, styles = model.eval(img, \n",
    "                                  channels=[3,0],\n",
    "                                  diameter=100,\n",
    "                                #   flow_threshold=0.6,\n",
    "                                  )\n",
    "    \n",
    "        \n",
    "    file_path = mask_path / f'Nuclei_{p}'\n",
    "    tiff.imwrite(file_path, mask_nuclei)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PLA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
