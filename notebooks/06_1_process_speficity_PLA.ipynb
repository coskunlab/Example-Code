{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.io\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import trange, tqdm, tqdm_notebook\n",
    "from joblib import Parallel, delayed\n",
    "import re\n",
    "import h5py\n",
    "import tifffile as tiff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = (Path().cwd().parents[0] / 'data').absolute()\n",
    "data_processed = data_dir / 'processed'\n",
    "data_raw = r'Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\Specificity experiments\\PLA comparison'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    " \n",
    "os.environ['JDK_HOME'] = \"C:\\Program Files\\Java\\jdk-17\"\n",
    "os.environ['JAVA_HOME'] = \"C:\\Program Files\\Java\\jdk-17\"\n",
    "\n",
    "os.environ['PATH'] += ';C:\\\\Program Files\\\\Java\\\\jdk-17\\\\jre\\\\bin\\\\server\\\\;C:\\\\Program Files\\\\Java\\\\jdk-17\\\\bin\\\\;C:\\\\Program Files\\\\Java\\\\jdk-17\\\\bin\\\\jar.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Get info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "markers_map = {\n",
    "    'cycle1': {\n",
    "        1: 'DNA', \n",
    "        3: 'Sox2/Oct4',\n",
    "        4: 'Bim/Tom20',\n",
    "    },\n",
    "    'cycle2': {\n",
    "        1: 'DNA', \n",
    "        2: 'Concanavalin A',\n",
    "        3: 'Phalloidin',\n",
    "        4: 'WGA',\n",
    "    },\n",
    "}\n",
    "\n",
    "def get_info(data_raw, marker_dict):\n",
    "    conditions = []\n",
    "    fovs = []\n",
    "    cycles = []\n",
    "    channels = []\n",
    "    markers = []\n",
    "    paths = [] \n",
    "    \n",
    "    # Loop through image folder\n",
    "    for (dirpath, dirnames, filenames) in os.walk(data_raw):\n",
    "        if 'after nuclease' in dirpath or 'Test' in dirpath or 'wrong' in dirpath:\n",
    "            continue\n",
    "        \n",
    "            \n",
    "        for name in sorted(filenames):\n",
    "            if \"tif\" in name and \"sti\" in name \\\n",
    "            and 'overlay' not in name \\\n",
    "            and 'Composite' not in name:\n",
    "                # Get information from image name\n",
    "                c = filenames[-1][-1] \n",
    "                \n",
    "                if c  == '6':\n",
    "                    condition = 'KO'\n",
    "                elif c == '8':\n",
    "                    condition = 'Control'\n",
    "                \n",
    "                d_split = dirpath.split('\\\\')\n",
    "                well = d_split[-2].split('_')[1].split(' ')[0]\n",
    "                n_split = name.split('_')\n",
    "                ch = int(n_split[-1][-5])\n",
    "\n",
    "                cycle = well\n",
    "                try: marker = marker_dict[cycle][ch] \n",
    "                except: continue\n",
    "        \n",
    "                conditions.append(condition)\n",
    "                cycles.append(cycle)\n",
    "                channels.append(ch)\n",
    "                markers.append(marker)\n",
    "                paths.append(os.path.join(dirpath, name))\n",
    "                \n",
    "    info = {\n",
    "            \"Condition\": conditions,\n",
    "            'FOV': conditions, \n",
    "            \"Cycle\": cycles,\n",
    "            \"Channels\": channels,\n",
    "            \"Markers\": markers,\n",
    "            \"Path\": paths\n",
    "        }\n",
    "\n",
    "    df = pd.DataFrame(info)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created df\n"
     ]
    }
   ],
   "source": [
    "df_meta_path = data_dir / 'specificity_PLA' / 'metadata' / 'info.csv'\n",
    "df_meta_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "df_exist = df_meta_path.is_file()\n",
    "\n",
    "if not df_exist:\n",
    "    print('Created df')\n",
    "    df = get_info(data_raw, markers_map)\n",
    "    df.to_csv(df_meta_path, index=False)\n",
    "else:\n",
    "    print('Loaded df')\n",
    "    df = pd.read_csv(df_meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Condition</th>\n",
       "      <th>FOV</th>\n",
       "      <th>Cycle</th>\n",
       "      <th>Channels</th>\n",
       "      <th>Markers</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KO</td>\n",
       "      <td>KO</td>\n",
       "      <td>cycle1</td>\n",
       "      <td>1</td>\n",
       "      <td>DNA</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KO</td>\n",
       "      <td>KO</td>\n",
       "      <td>cycle1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sox2/Oct4</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KO</td>\n",
       "      <td>KO</td>\n",
       "      <td>cycle1</td>\n",
       "      <td>4</td>\n",
       "      <td>Bim/Tom20</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Control</td>\n",
       "      <td>Control</td>\n",
       "      <td>cycle1</td>\n",
       "      <td>1</td>\n",
       "      <td>DNA</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Control</td>\n",
       "      <td>Control</td>\n",
       "      <td>cycle1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sox2/Oct4</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Control</td>\n",
       "      <td>Control</td>\n",
       "      <td>cycle1</td>\n",
       "      <td>4</td>\n",
       "      <td>Bim/Tom20</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KO</td>\n",
       "      <td>KO</td>\n",
       "      <td>cycle2</td>\n",
       "      <td>1</td>\n",
       "      <td>DNA</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KO</td>\n",
       "      <td>KO</td>\n",
       "      <td>cycle2</td>\n",
       "      <td>2</td>\n",
       "      <td>Concanavalin A</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KO</td>\n",
       "      <td>KO</td>\n",
       "      <td>cycle2</td>\n",
       "      <td>3</td>\n",
       "      <td>Phalloidin</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KO</td>\n",
       "      <td>KO</td>\n",
       "      <td>cycle2</td>\n",
       "      <td>4</td>\n",
       "      <td>WGA</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Control</td>\n",
       "      <td>Control</td>\n",
       "      <td>cycle2</td>\n",
       "      <td>1</td>\n",
       "      <td>DNA</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Control</td>\n",
       "      <td>Control</td>\n",
       "      <td>cycle2</td>\n",
       "      <td>2</td>\n",
       "      <td>Concanavalin A</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Control</td>\n",
       "      <td>Control</td>\n",
       "      <td>cycle2</td>\n",
       "      <td>3</td>\n",
       "      <td>Phalloidin</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Control</td>\n",
       "      <td>Control</td>\n",
       "      <td>cycle2</td>\n",
       "      <td>4</td>\n",
       "      <td>WGA</td>\n",
       "      <td>Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Condition      FOV   Cycle  Channels         Markers  \\\n",
       "0         KO       KO  cycle1         1             DNA   \n",
       "1         KO       KO  cycle1         3       Sox2/Oct4   \n",
       "2         KO       KO  cycle1         4       Bim/Tom20   \n",
       "3    Control  Control  cycle1         1             DNA   \n",
       "4    Control  Control  cycle1         3       Sox2/Oct4   \n",
       "5    Control  Control  cycle1         4       Bim/Tom20   \n",
       "6         KO       KO  cycle2         1             DNA   \n",
       "7         KO       KO  cycle2         2  Concanavalin A   \n",
       "8         KO       KO  cycle2         3      Phalloidin   \n",
       "9         KO       KO  cycle2         4             WGA   \n",
       "10   Control  Control  cycle2         1             DNA   \n",
       "11   Control  Control  cycle2         2  Concanavalin A   \n",
       "12   Control  Control  cycle2         3      Phalloidin   \n",
       "13   Control  Control  cycle2         4             WGA   \n",
       "\n",
       "                                                 Path  \n",
       "0   Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\S...  \n",
       "1   Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\S...  \n",
       "2   Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\S...  \n",
       "3   Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\S...  \n",
       "4   Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\S...  \n",
       "5   Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\S...  \n",
       "6   Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\S...  \n",
       "7   Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\S...  \n",
       "8   Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\S...  \n",
       "9   Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\S...  \n",
       "10  Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\S...  \n",
       "11  Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\S...  \n",
       "12  Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\S...  \n",
       "13  Y:\\coskun-lab\\Shuangyi\\ERK, YAP project_2022\\S...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Condition\n",
       "Control    7\n",
       "KO         7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Condition').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Save HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "def save_hdf5(\n",
    "    path: str, name: str, data: np.ndarray, attr_dict=None, mode: str = \"a\"\n",
    ") -> None:\n",
    "    # Read h5 file\n",
    "    hf = h5py.File(path, mode)\n",
    "    # Create z_stack_dataset\n",
    "    if hf.get(name) is None:\n",
    "        data_shape = data.shape\n",
    "        data_type = data.dtype\n",
    "        max_shape = (data_shape[0],) + data_shape[1:]\n",
    "        dset = hf.create_dataset(\n",
    "            name,\n",
    "            shape=data_shape,\n",
    "            maxshape=max_shape,\n",
    "            chunks=True,\n",
    "            dtype=data_type,\n",
    "            compression=\"gzip\",\n",
    "        )\n",
    "        dset[:] = data\n",
    "        if attr_dict is not None:\n",
    "            for attr_key, attr_val in attr_dict.items():\n",
    "                dset.attrs[attr_key] = attr_val\n",
    "    else:\n",
    "        print(f\"Dataset {name} exists\")\n",
    "\n",
    "    hf.close()\n",
    "\n",
    "def read_img(path):\n",
    "    return skimage.io.imread(path, as_gray=True)\n",
    "\n",
    "def joblib_loop(task, pics):\n",
    "    return Parallel(n_jobs=20)(delayed(task)(i) for i in pics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created df\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e667de3e94c4c69944102293036ddb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_imgs_path = data_dir / 'specificity_PLA' / 'metadata' / 'imgs.csv'\n",
    "df_imgs_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "temp_path = data_dir  /'specificity_PLA' /  'hdf5' / 'raw'\n",
    "temp_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_exist = df_imgs_path.is_file()\n",
    "\n",
    "\n",
    "if not df_exist:\n",
    "    print('Created df')\n",
    "    \n",
    "    group = df.groupby(['Condition', 'FOV'])\n",
    "    rows = []\n",
    "\n",
    "    for name, df_group in tqdm(group, total=len(group)):\n",
    "        file_name = '_'.join(np.array(name).astype(str)) + '.hdf5'\n",
    "        file_path = temp_path / file_name\n",
    "        rows.append(list(name)+[file_path])\n",
    "        \n",
    "        group_cycle = df_group.groupby('Cycle')\n",
    "        for cycle, df_cycle in group_cycle:\n",
    "            channels = df_cycle.Channels.to_list()\n",
    "            markers = df_cycle.Markers.to_list()\n",
    "            paths = df_cycle.Path.to_numpy()\n",
    "    \n",
    "            imgs = joblib_loop(read_img, paths)\n",
    "            imgs = np.array(imgs)\n",
    "            info = {\"Channels\": channels, \"Markers\": markers}\n",
    "            \n",
    "            # hdf5 as Channel -> Z mapping\n",
    "            save_hdf5(file_path, cycle, imgs, info)\n",
    "    df_imgs = pd.DataFrame(rows, columns=['Condition', 'FOV', 'Path'])        \n",
    "    df_imgs.to_csv(df_imgs_path, index=False)\n",
    "else:\n",
    "    print('Loaded df')\n",
    "    df_imgs = pd.read_csv(df_imgs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Condition</th>\n",
       "      <th>FOV</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Control</td>\n",
       "      <td>Control</td>\n",
       "      <td>y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KO</td>\n",
       "      <td>KO</td>\n",
       "      <td>y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Condition      FOV                                               Path\n",
       "0   Control  Control  y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...\n",
       "1        KO       KO  y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec..."
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Save Tiffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure, util\n",
    "\n",
    "def contrast_str(img, n_min=0.1, n_max=100):\n",
    "    p2, p98 = np.percentile(img, (n_min, n_max))\n",
    "    img_rescale = exposure.rescale_intensity(img, in_range=(p2, p98))\n",
    "    return img_rescale\n",
    "\n",
    "def make_imgs_same_dim(imgs):\n",
    "    # Get max dimensions\n",
    "    shapes = np.array([img.shape[1:] for img in imgs])\n",
    "    min_x, min_y = shapes.min(axis=0)\n",
    "    imgs_cropped = [img[:, :min_x, :min_y] for img in imgs]\n",
    "    # imgs_cropped[0] = contrast_str(imgs_cropped[0])\n",
    "    return imgs_cropped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "012bc64686114792ba396d8278f7cca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49c6be19501f4962828ef57094c762e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_path = data_dir /  'specificity_PLA' /'imgs' / 'raw'\n",
    "save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "group = df_imgs.groupby(['Condition', 'FOV'])\n",
    "for name, df_group in group:\n",
    "    path = df_group.iloc[0].Path\n",
    "             \n",
    "    # Read images\n",
    "    cycles = []\n",
    "    imgs_all = []\n",
    "    channels = []\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        for k in tqdm(f.keys(), total=len(f.keys()), leave=False):\n",
    "            cycle = k.split('_')[0]\n",
    "            channel = f[k].attrs['Channels']\n",
    "\n",
    "            imgs = f[k][:]\n",
    "            cycles.append(cycle)\n",
    "            channels.append(channel)\n",
    "            imgs[0] = contrast_str(imgs[0])\n",
    "            imgs_all.append(imgs)\n",
    "    \n",
    "    imgs_same_shape = make_imgs_same_dim(imgs_all)\n",
    "    \n",
    "    for i, imgs in enumerate(imgs_same_shape):\n",
    "        temp_path = save_path / '_'.join(np.array(name).astype(str))\n",
    "        temp_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        file_name = f'001_{cycles[i]}.tif'\n",
    "        file_path = temp_path / file_name\n",
    "\n",
    "        # Write image\n",
    "        tiff.imwrite(file_path, imgs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Registration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ashlar import fileseries, thumbnail,reg\n",
    "import matplotlib.pyplot as plt\n",
    "from ashlar.scripts.ashlar import process_axis_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e41d2e88b10b444d8eecb83f2591e2a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    assembling thumbnail 1/1\n",
      "    assembling thumbnail 1/1\n",
      "    estimated cycle offset [y x] = [4. 3.]\n",
      "    assembling thumbnail 1/1\n",
      "    assembling thumbnail 1/1\n",
      "    estimated cycle offset [y x] = [  1. -10.]\n"
     ]
    }
   ],
   "source": [
    "# Loop all images\n",
    "imgs_dir = data_dir / 'specificity_PLA' /'imgs' / 'raw'\n",
    "save_dir = data_dir / 'specificity_PLA' /'imgs' / 'registered'\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "imgs_dir_list = os.listdir(imgs_dir)\n",
    "\n",
    "for dir_path in tqdm(imgs_dir_list):\n",
    "    \n",
    "    # Create reader for each cycle\n",
    "    readers = []\n",
    "    for i in range(1, 3):\n",
    "        reader = fileseries.FileSeriesReader(\n",
    "            str(imgs_dir / dir_path),\n",
    "            pattern='{series}_'+f'cycle{i}.tif',\n",
    "            overlap=0.29,\n",
    "            width=1,\n",
    "            height=1,\n",
    "            layout='snake',\n",
    "            direction='horizontal',\n",
    "            pixel_size=0.18872, \n",
    "        )\n",
    "        readers.append(reader)\n",
    "    reader_1 = readers[0]\n",
    "    \n",
    "    # Run stitching\n",
    "    aligner0 = reg.EdgeAligner(reader_1, channel=0, filter_sigma=2, verbose=False,)\n",
    "    aligner0.run()\n",
    "    \n",
    "    # Generate merge image for 1 cycle\n",
    "    # Parramter\n",
    "    mosaic_args = {}\n",
    "    mosaic_args['verbose'] = False\n",
    "\n",
    "    mosaic = reg.Mosaic(\n",
    "            aligner0,aligner0.mosaic_shape,**mosaic_args\n",
    "        )\n",
    "    writer_class = reg.TiffListWriter\n",
    "    writer = writer_class(\n",
    "            [mosaic], str(save_dir / (dir_path + '_cycle1_ch{channel}.ome.tif'))\n",
    "    )\n",
    "    writer.run()\n",
    "    \n",
    "    # Loop through rest of cycles\n",
    "    aligners = list()\n",
    "    aligners.append(aligner0)\n",
    "\n",
    "    for j in range(1, len(readers)):\n",
    "        aligners.append(\n",
    "            reg.LayerAligner(readers[j], aligners[0], channel=0, filter_sigma=2, verbose=False)\n",
    "        )\n",
    "        aligners[j].run()\n",
    "        mosaic = reg.Mosaic(\n",
    "            aligners[j], aligners[0].mosaic_shape,**mosaic_args\n",
    "        )\n",
    "        writer = writer_class(\n",
    "                [mosaic], str(save_dir / (dir_path +'_cycle'+str(j+1)+'_ch{channel}.ome.tif'))\n",
    "        )\n",
    "        writer.run()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(data_raw, marker_dict):\n",
    "    conditions = []\n",
    "    fovs = []\n",
    "    cycles = []\n",
    "    channels = []\n",
    "    markers = []\n",
    "    paths = [] \n",
    "\n",
    "    # Loop through image folder\n",
    "    for (dirpath, dirnames, filenames) in os.walk(data_raw):\n",
    "        for name in sorted(filenames):\n",
    "            if \"tif\" in name:\n",
    "                # Get information from image name\n",
    "                n_split = name.split('_')\n",
    "                                \n",
    "                cond=n_split[0]\n",
    "                fov=n_split[1]\n",
    "                cycle=n_split[2]\n",
    "                ch = n_split[3][:3]\n",
    "                try:\n",
    "                    marker = marker_dict[cycle][ch]\n",
    "                except:\n",
    "                    continue \n",
    "                    \n",
    "                conditions.append(cond)\n",
    "                fovs.append(fov)\n",
    "                cycles.append(cycle)\n",
    "                channels.append(ch)\n",
    "                markers.append(marker)\n",
    "                paths.append(os.path.join(dirpath, name))\n",
    "                \n",
    "    info = {\n",
    "            \"Condition\": conditions,\n",
    "            \"FOV\": fovs,\n",
    "            \"Cycle\": cycles,\n",
    "            \"Channels\": channels,\n",
    "            \"Markers\": markers,\n",
    "            \"Path\": paths\n",
    "        }\n",
    "\n",
    "    df = pd.DataFrame(info)\n",
    "    return df\n",
    "\n",
    "def joblib_loop(task, pics):\n",
    "    return Parallel(n_jobs=20)(delayed(task)(i) for i in pics)\n",
    "\n",
    "def read_img(path):\n",
    "    return skimage.io.imread(path, as_gray=True)\n",
    "\n",
    "def get_min(imgs):\n",
    "    shapes = np.array([np.array(img.shape) for img in imgs])\n",
    "    return np.min(shapes, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "markers_map_new = defaultdict(dict)\n",
    "for k,v in markers_map.items():\n",
    "    for i, (ch,marker) in enumerate(v.items()):\n",
    "        markers_map_new[k][f'ch{i}'] = marker\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder is already there\n",
      "Created df\n"
     ]
    }
   ],
   "source": [
    "data_raw = data_dir  / 'specificity_PLA' /'imgs' / 'registered'\n",
    "df_meta_path = data_dir /  'specificity_PLA' / 'metadata' / 'info_sti.csv'\n",
    "\n",
    "try:\n",
    "    df_meta_path.parent.mkdir(parents=True, exist_ok=False)\n",
    "except FileExistsError:\n",
    "    print(\"Folder is already there\")\n",
    "\n",
    "df_exist = df_meta_path.is_file()\n",
    "\n",
    "if not df_exist:\n",
    "    print('Created df')\n",
    "    df = get_info(data_raw, markers_map_new)\n",
    "    df.to_csv(df_meta_path, index=False)\n",
    "else:\n",
    "    print('Loaded df')\n",
    "    df = pd.read_csv(df_meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder is already there\n",
      "Loaded df\n"
     ]
    }
   ],
   "source": [
    "df_imgs_path = data_dir /  'specificity_PLA'  /'metadata' / 'imgs_reg.csv'\n",
    "\n",
    "temp_path =data_dir /   'specificity_PLA'  /'hdf5' / 'registered'\n",
    "try:\n",
    "    temp_path.mkdir(parents=True, exist_ok=False)\n",
    "except FileExistsError:\n",
    "    print(\"Folder is already there\")\n",
    "\n",
    "df_exist = df_imgs_path.is_file()\n",
    "\n",
    "if not df_exist:\n",
    "    print('Created df')\n",
    "    group = df.groupby(['Condition','FOV'])\n",
    "    rows = []\n",
    "\n",
    "    for name, df_group in tqdm(group, total=len(group)):\n",
    "        file_name = '_'.join(np.array(name).astype(str)) + '.hdf5'\n",
    "        file_path = temp_path / file_name\n",
    "        rows.append(list(name)+[file_path])\n",
    "        \n",
    "        # if file_path.exists():\n",
    "        #     continue\n",
    "        \n",
    "        channels = df_group.Channels.to_list()\n",
    "        cycles = df_group.Cycle.to_list()\n",
    "        markers = df_group.Markers.to_list()\n",
    "        paths = df_group.Path.to_numpy()\n",
    "            \n",
    "        imgs = joblib_loop(read_img, paths)\n",
    "        min_shape = get_min(imgs)\n",
    "        imgs_cropped = np.array([img[:min_shape[0], :min_shape[1]] for img in imgs])\n",
    "        info = {\"Cycle\": cycles, \"Channel\": channels, \"Marker\": markers}\n",
    "            \n",
    "            # hdf5 as Channel -> Z mapping\n",
    "        save_hdf5(file_path, 'imgs', imgs_cropped, info)\n",
    "    df_imgs = pd.DataFrame(rows, columns=['Condition', 'FOV', 'Path'])        \n",
    "    df_imgs.to_csv(df_imgs_path, index=False)\n",
    "else:\n",
    "    print('Loaded df')\n",
    "    df_imgs = pd.read_csv(df_imgs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Condition</th>\n",
       "      <th>FOV</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Control</td>\n",
       "      <td>Control</td>\n",
       "      <td>y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KO</td>\n",
       "      <td>KO</td>\n",
       "      <td>y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Condition      FOV                                               Path\n",
       "0   Control  Control  y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec...\n",
       "1        KO       KO  y:\\coskun-lab\\Thomas\\23_PLA_revision\\data\\spec..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.exposure import match_histograms, rescale_intensity\n",
    "import cv2\n",
    "from skimage import img_as_ubyte\n",
    "import tensorflow as tf \n",
    "from skimage import exposure, util, filters, restoration\n",
    "\n",
    "def random_crop(image, NEW_IMG_HEIGHT, NEW_IMG_WIDTH):\n",
    "    cropped_image = tf.image.random_crop(\n",
    "      image, size=[3, NEW_IMG_HEIGHT, NEW_IMG_WIDTH])\n",
    "\n",
    "    return cropped_image\n",
    "\n",
    "def make_color_overlay(input_data):\n",
    "    \"\"\"Create a color overlay from 2 channel image data\n",
    "    \n",
    "    Args:\n",
    "        input_data: stack of input images\n",
    "    \n",
    "    Returns:\n",
    "        numpy.array: color-adjusted stack of overlays in RGB mode\n",
    "    \"\"\"\n",
    "    RGB_data = np.zeros(input_data.shape[:3] + (3, ), dtype='float32')\n",
    "    \n",
    "    # rescale channels to aid plotting\n",
    "    for img in range(input_data.shape[0]):\n",
    "        for channel in range(input_data.shape[-1]):\n",
    "            # get histogram for non-zero pixels\n",
    "            percentiles = np.percentile(input_data[img, :, :, channel][input_data[img, :, :, channel] > 0],\n",
    "                                            [0, 100])\n",
    "            rescaled_intensity = rescale_intensity(input_data[img, :, :, channel],\n",
    "                                                       in_range=(percentiles[0], percentiles[1]),\n",
    "                                                       out_range='float32')\n",
    "            RGB_data[img, :, :, channel + 1] = rescaled_intensity\n",
    "        \n",
    "    # create a blank array for red channel\n",
    "    return RGB_data\n",
    "\n",
    "def contrast_str(img, n_min=10, n_max=100):\n",
    "    p2, p98 = np.percentile(img, (n_min, n_max))\n",
    "    img_rescale = rescale_intensity(img, in_range=(p2, p98))\n",
    "    img_rescale = util.img_as_ubyte(img_rescale)\n",
    "    return img_rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imgs_path = data_dir /  'specificity_PLA'  /'metadata' / 'imgs_reg.csv'\n",
    "df_imgs = pd.read_csv(df_imgs_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36666d1ab5b2419ea80b545f2ab984e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for row in tqdm(df_imgs.itertuples(), total=len(df_imgs)):\n",
    "    path = row.Path\n",
    "    \n",
    "    # Read images\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        \n",
    "        markers = f['imgs'].attrs['Marker']\n",
    "        imgs = f['imgs'][:]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Viewer(axes=Axes(visible=False, labels=True, colored=True, dashed=False, arrows=True), camera=Camera(center=(0.0, 1733.0, 2310.0), zoom=0.2762042111335448, angles=(0.0, 0.0, 90.0), perspective=0.0, interactive=True), cursor=Cursor(position=(1.0, 1.0), scaled=True, size=1, style=<CursorStyle.STANDARD: 'standard'>), dims=Dims(ndim=2, ndisplay=2, last_used=0, range=((0.0, 3467.0, 1.0), (0.0, 4621.0, 1.0)), current_step=(1733, 2310), order=(0, 1), axis_labels=('0', '1')), grid=GridCanvas(stride=1, shape=(-1, -1), enabled=False), layers=[<Image layer 'DNA' at 0x287c9bf5b10>, <Image layer 'Sox2/Oct4' at 0x287c8372770>, <Image layer 'Bim/Tom20' at 0x287ca4a17b0>, <Image layer 'DNA [1]' at 0x287ca534850>, <Image layer 'Concanavalin A' at 0x287ca5e5b10>, <Image layer 'Phalloidin' at 0x287ca6881f0>, <Image layer 'WGA' at 0x287ca715e70>], scale_bar=ScaleBar(visible=False, colored=False, color=array([1., 0., 1., 1.], dtype=float32), ticks=True, position=<Position.BOTTOM_RIGHT: 'bottom_right'>, font_size=10.0, box=False, box_color=array([0. , 0. , 0. , 0.6], dtype=float32), unit=None), text_overlay=TextOverlay(visible=False, color=array([0.5, 0.5, 0.5, 1. ], dtype=float32), font_size=10.0, position=<TextOverlayPosition.TOP_LEFT: 'top_left'>, text=''), overlays=Overlays(interaction_box=InteractionBox(points=None, show=False, show_handle=False, show_vertices=False, selection_box_drag=None, selection_box_final=None, transform_start=<napari.utils.transforms.transforms.Affine object at 0x00000287BFAF5660>, transform_drag=<napari.utils.transforms.transforms.Affine object at 0x00000287BFAF5690>, transform_final=<napari.utils.transforms.transforms.Affine object at 0x00000287BFAF55A0>, transform=<napari.utils.transforms.transforms.Affine object at 0x00000287BFAF55D0>, allow_new_selection=True, selected_vertex=None)), help='', status='Ready', tooltip=Tooltip(visible=False, text=''), theme='dark', title='napari', mouse_over_canvas=False, mouse_move_callbacks=[<function InteractionBoxMouseBindings.initialize_mouse_events.<locals>.mouse_move at 0x00000287C8BAA830>], mouse_drag_callbacks=[<function InteractionBoxMouseBindings.initialize_mouse_events.<locals>.mouse_drag at 0x00000287C8BAA710>], mouse_double_click_callbacks=[], mouse_wheel_callbacks=[<function dims_scroll at 0x00000287C0DCD6C0>], _persisted_mouse_event={}, _mouse_drag_gen={}, _mouse_wheel_gen={}, keymap={'Shift': <function InteractionBoxMouseBindings.initialize_key_events.<locals>.hold_to_lock_aspect_ratio at 0x00000287C8BAA560>, 'Control-Shift-R': <function InteractionBoxMouseBindings._reset_active_layer_affine at 0x00000287C8B62200>, 'Control-Shift-A': <function InteractionBoxMouseBindings._transform_active_layer at 0x00000287C8B62290>})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import napari \n",
    "\n",
    "napari.view_image(np.stack(imgs), name=markers, channel_axis=0, contrast_limits=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imgs['FOV'] = df_imgs['FOV'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define markers to use for cytosolic segmentation\n",
    "cyto_markers = ['Phalloidin']\n",
    "\n",
    "# Define folder and create if don't exsit\n",
    "whole_seg_path = data_dir /  'specificity_PLA'  / 'imgs' / 'segmentation'\n",
    "whole_seg_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save combined images\n",
    "for row in df_imgs.itertuples():\n",
    "    # Read image\n",
    "    path = row.Path\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        imgs = f['imgs'][:]\n",
    "        markers = f['imgs'].attrs['Marker']\n",
    "\n",
    "    # Get dapi and cyto imgaes\n",
    "    indices = np.isin(markers, cyto_markers)\n",
    "    img_dapi =  imgs[-4]\n",
    "    imgs_cyto = imgs[indices,:]\n",
    "    \n",
    "    # Contrast streching and combine to rgb image\n",
    "    img_dapi = contrast_str(img_dapi, n_max=99.9)\n",
    "        \n",
    "    imgs_cyto_scaled = []\n",
    "    for img in imgs_cyto:\n",
    "        imgs_cyto_scaled = [contrast_str(img, n_max=99.9)]\n",
    "    img_cyto = np.max(np.array(imgs_cyto_scaled), axis=0)\n",
    "    img_rgb = np.stack([np.zeros(img_dapi.shape),img_cyto, img_dapi], axis=0).astype(np.uint8)\n",
    "    \n",
    "    # Crop and save\n",
    "    file_name = f'{\"_\".join(row[1:3])}.tif'\n",
    "    file_path = whole_seg_path / file_name\n",
    "    tiff.imwrite(file_path, img_rgb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PLA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
